const local_index = {"config":{"lang":["en"],"min_search_length":3,"prebuild_index":true,"separator":"[\\s\\-]+"},"docs":[{"location":"index.html","text":"","title":"Index"},{"location":"Chap_1.html","text":"To hear is to forget. To see is to remember. To do is to learn! \u2026Chinese proverb How to use this iBook \u00b6 This textbook is being prepared in the context of modern electronic publishing. By that we mean that modern digital technology\u2014such as the Internet, an iPad 1 or Android 2 tablet, a smartphone, and a laptop or desktop computer\u2014makes it possible to present not only text, equations, and figures but dynamic illustrations, audio samples, both internal and external links to relevant material, and interactive laboratory experiments. Extensive use of these possibilities is made in this iBook. This \u201cuser\u2019s guide\u201d describes how you can make use of these possibilities. This edition is primarily intended for use with a browser such as Safari, Firefox, Chrome, or Opera on a laptop or desktop computer. You can, of course, use this edition through a browser on a tablet or smartphone. The 26 Laboratory Experiments in this edition involve the use of the screen, speakers, keyboard, and a graphical user interface (GUI). An extended version of this iBook with an additional 32 Laboratory Experiments for a total of 58 experiments makes use of the microphone and camera that can be found on tablets and smartphones. The current implementation of this extended version is free and can be found here . Highlighting \u00b6 Main results will be highlighted with a background in pink and special cases of main results will be highlighted with a background in yellow . $$ \\begin{aligned} {S_{yy}}(\\Omega ) = {\\left| {H( - \\Omega )} \\right|^2}{S_{xx}}(\\Omega )\\; \\end{aligned} $$ $$ \\begin{aligned} {S_{yy}}(\\Omega ) = {\\left| {H(\\Omega )} \\right|^2}{S_{xx}}(\\Omega )\\; \\end{aligned} $$ Special cases might result, for example, when we consider only real signals or systems. In general we will consider that all signals and systems are complex, having both a real and an imaginary part. When the special case of a real signal or real system is being considered, it will be explicitly stated. Outside this device \u00b6 Occasionally, references will be made to other sources of information through an external link . Click here to see an example. When you are finished viewing the external material, return to this iBook and it should continue at the place where you left off. Getting around \u00b6 Endnotes are also linked within the iBook. When you see an endnote indicator 3 , you can click on it and be taken to the note which is at the end of the chapter. When you want to jump to the homework problems or the laboratory exercises at the end of a chapter, tap the top of the screen. Sound of music \u00b6 Dynamic examples, specifically music and animations, have been built into this iBook. To hear the results of various operations on a stochastic signal, \u201cclick\u201d on the \u201cplayback\u201d icon ( ) and the sound will be played. This is a good way to test and adjust the sound level of your iBook. Audio 1.1: Click the play triangle ( ) to hear a brief selection of Paganini. At the movies \u00b6 Animations and movies will be used to illustrate various aspects of stochastic signal processing. In laboratory exercises, for example, you may need to whistle. This famous film clip is taken from the wonderful 1944 Warner Brothers film \u201cTo Have and Have Not\u201d which starred Humphrey Bogart and Lauren Bacall. This clip is used under the fair use copyright policy 4 . Movie 1.1: Click the play triangle ( ) to learn how to whistle. Enhanced experience \u00b6 And to prevent the reader from falling into an etymological lacuna, it is possible to \u201cpoint\u201d to a word and then be offered a definition through a dictionary. iPad is a trademark of Apple Inc., registered in the U.S. and other countries. \u21a9 Android is a trademark of Google LLC. \u21a9 If you click on the return arrow at the end of this sentence (or if not available at the number prepending this text), you will return to your previous position in the chapter. \u21a9 U.S. Copyright Act, S 107: Notwithstanding the provisions of sections 106 and 106A, the fair use of a copyrighted work, including such use by reproduction in copies or phonorecords or by any other means specified by that section, for purposes such as criticism, comment, news reporting, teaching (including multiple copies for classroom use), scholarship, or research, is not an infringement of copyright. In determining whether the use made of a work in any particular case is a fair use the factors to be considered shall include - (1) the purpose and character of the use, including whether such use is of a commercial nature or is for nonprofit educational purposes; (2) the nature of the copyrighted work; (3) the amount and substantiality of the portion used in relation to the copyrighted work as a whole; and (4) the effect of the use upon the potential market for or value of the copyrighted work. The fact that a work is unpublished shall not itself bar a finding of fair use if such finding is made upon consideration of all the above factors. \u21a9","title":"1. How to use this iBook"},{"location":"Chap_1.html#how-to-use-this-ibook","text":"This textbook is being prepared in the context of modern electronic publishing. By that we mean that modern digital technology\u2014such as the Internet, an iPad 1 or Android 2 tablet, a smartphone, and a laptop or desktop computer\u2014makes it possible to present not only text, equations, and figures but dynamic illustrations, audio samples, both internal and external links to relevant material, and interactive laboratory experiments. Extensive use of these possibilities is made in this iBook. This \u201cuser\u2019s guide\u201d describes how you can make use of these possibilities. This edition is primarily intended for use with a browser such as Safari, Firefox, Chrome, or Opera on a laptop or desktop computer. You can, of course, use this edition through a browser on a tablet or smartphone. The 26 Laboratory Experiments in this edition involve the use of the screen, speakers, keyboard, and a graphical user interface (GUI). An extended version of this iBook with an additional 32 Laboratory Experiments for a total of 58 experiments makes use of the microphone and camera that can be found on tablets and smartphones. The current implementation of this extended version is free and can be found here .","title":"How to use this iBook"},{"location":"Chap_1.html#highlighting","text":"Main results will be highlighted with a background in pink and special cases of main results will be highlighted with a background in yellow . $$ \\begin{aligned} {S_{yy}}(\\Omega ) = {\\left| {H( - \\Omega )} \\right|^2}{S_{xx}}(\\Omega )\\; \\end{aligned} $$ $$ \\begin{aligned} {S_{yy}}(\\Omega ) = {\\left| {H(\\Omega )} \\right|^2}{S_{xx}}(\\Omega )\\; \\end{aligned} $$ Special cases might result, for example, when we consider only real signals or systems. In general we will consider that all signals and systems are complex, having both a real and an imaginary part. When the special case of a real signal or real system is being considered, it will be explicitly stated.","title":"Highlighting"},{"location":"Chap_1.html#outside-this-device","text":"Occasionally, references will be made to other sources of information through an external link . Click here to see an example. When you are finished viewing the external material, return to this iBook and it should continue at the place where you left off.","title":"Outside this device"},{"location":"Chap_1.html#getting-around","text":"Endnotes are also linked within the iBook. When you see an endnote indicator 3 , you can click on it and be taken to the note which is at the end of the chapter. When you want to jump to the homework problems or the laboratory exercises at the end of a chapter, tap the top of the screen.","title":"Getting around"},{"location":"Chap_1.html#sound-of-music","text":"Dynamic examples, specifically music and animations, have been built into this iBook. To hear the results of various operations on a stochastic signal, \u201cclick\u201d on the \u201cplayback\u201d icon ( ) and the sound will be played. This is a good way to test and adjust the sound level of your iBook. Audio 1.1: Click the play triangle ( ) to hear a brief selection of Paganini.","title":"Sound of music"},{"location":"Chap_1.html#at-the-movies","text":"Animations and movies will be used to illustrate various aspects of stochastic signal processing. In laboratory exercises, for example, you may need to whistle. This famous film clip is taken from the wonderful 1944 Warner Brothers film \u201cTo Have and Have Not\u201d which starred Humphrey Bogart and Lauren Bacall. This clip is used under the fair use copyright policy 4 . Movie 1.1: Click the play triangle ( ) to learn how to whistle.","title":"At the movies"},{"location":"Chap_1.html#enhanced-experience","text":"And to prevent the reader from falling into an etymological lacuna, it is possible to \u201cpoint\u201d to a word and then be offered a definition through a dictionary. iPad is a trademark of Apple Inc., registered in the U.S. and other countries. \u21a9 Android is a trademark of Google LLC. \u21a9 If you click on the return arrow at the end of this sentence (or if not available at the number prepending this text), you will return to your previous position in the chapter. \u21a9 U.S. Copyright Act, S 107: Notwithstanding the provisions of sections 106 and 106A, the fair use of a copyrighted work, including such use by reproduction in copies or phonorecords or by any other means specified by that section, for purposes such as criticism, comment, news reporting, teaching (including multiple copies for classroom use), scholarship, or research, is not an infringement of copyright. In determining whether the use made of a work in any particular case is a fair use the factors to be considered shall include - (1) the purpose and character of the use, including whether such use is of a commercial nature or is for nonprofit educational purposes; (2) the nature of the copyrighted work; (3) the amount and substantiality of the portion used in relation to the copyrighted work as a whole; and (4) the effect of the use upon the potential market for or value of the copyrighted work. The fact that a work is unpublished shall not itself bar a finding of fair use if such finding is made upon consideration of all the above factors. \u21a9","title":"Enhanced experience"},{"location":"Chap_10.html","text":"The Wiener filter \u00b6 In the previous chapter we showed that a desired effect, a maximized SNR, could be achieved by the suitable choice of a linear filter, a matched filter. We will now address a more difficult problem: the use of linear filters to estimate a stochastic signal in the presence of noise. We let \\(x[n]\\) be a stochastic, ergodic signal from a process with known statistics. The restoration case: noise \u00b6 In the presence of noise and using a linear filter, we wish to produce an estimate of \\(x[n]\\) which we call \\({x_e}[n].\\) This is frequently termed signal restoration because we are attempting to restore a signal \\(x[n]\\) that has become damaged, corrupted, and/or noisy. We want the best estimate where the definition of \u201cbest\u201d will be explained. We assume that \\(x[n]\\) is real as is the noise process \\(N[n].\\) The total signal \\(r[n]\\) composed of \\(x[n]\\) and \\(N[n]\\) is to be processed to produce the estimate \\({x_e}[n]\\) of the original \\(x[n].\\) The model is shown in Figure 10.1 . Figure 10.1: LTI filter \\(h[n\\rbrack\\) to estimate a stochastic signal \\(x[n\\rbrack\\) in the presence of additive noise. We start with: (10.1) $${x_e}[n] = \\sum\\limits_{m = - \\infty }^{ + \\infty } {r[n - m]} h[m]$$ and we define \u201cbest\u201d in terms of a measure of the difference (error) between the \u201ctrue\u201d stochastic signal \\(x[n]\\) and the estimate \\({x_e}[n].\\) Using the least mean-square error criterion \u00b6 Specifically we look at the mean (expected) square error: (10.2) $$e = mean\\text{-}squared\\;error = E\\left\\{ {{{\\left| {{x_e}[n] - x[n]} \\right|}^2}} \\right\\}$$ and we propose to choose \\(h[n]\\) in order to minimize this error. We will need a basic result from least mean-square estimation theory and this can be found in Appendix I . To determine a minimum, we look at: (10.3) $$\\begin{array}{*{20}{l}} {\\frac{{\\partial e}}{{\\partial h}}}&{ = \\frac{\\partial }{{\\partial h}}E\\left\\{ {{{\\left| {{x_e}[n] - x[n]} \\right|}^2}} \\right\\}}\\\\ {\\,\\,\\,}&{ = \\frac{\\partial }{{\\partial h}}E\\left\\{ {{{\\left( {\\sum\\limits_{m = - \\infty }^{ + \\infty } {r[n - m]} h[m] - x[n]} \\right)}^2}} \\right\\} = 0} \\end{array}$$ That is, we vary the filter to choose the one that gives the minimum mean-square error. Note that the restriction to real signals and systems ensures that we can replace the non-differentiable absolute value operation \\({\\left| \\bullet \\right|^2}\\) with the differentiable operation \\({\\left( \\bullet \\right)^2}\\) in Equation 10.3 . The equation above, of course, yields an extremum but it can be shown that this is a minimum; see Problem 10.1 . The development of this approach follows those in the references Castleman 1 , Lee 2 , and Papoulis 3 . Expressing the mean-square error \u00b6 Based upon Appendix I , and starting from Equation 10.1 and Equation 10.2 , we have: (10.4) $$\\begin{array}{*{20}{l}} e&{ = E\\left\\{ {{{\\left( {{x_e} - x} \\right)}^2}} \\right\\} = E\\left\\{ {{{\\left( {{x_e}[n] - x[n]} \\right)}^2}} \\right\\}}\\\\ {\\,\\,\\,}&{ = E\\left\\{ {{{\\left( {r[n] \\otimes h[n] - x[n]} \\right)}^2}} \\right\\}}\\\\ {\\,\\,\\,}&{ = E\\left\\{ {{{\\left( {\\sum\\limits_{k = - \\infty }^{ + \\infty } {r[n - k]h[k]} - x[n]} \\right)}^2}} \\right\\}} \\end{array}$$ We might have expected that the left-hand side of Equation 10.4 would be \\(e[n]\\) instead of \\(e.\\) The expectation operation, \\(E\\left\\{ \\bullet \\right\\},\\) combined with the assumption of ergodicity assures that the result \\(e\\) is independent of \\(n.\\) We now apply the key result\u2014orthogonality\u2014from Equation 13.3 and rewrite this as: (10.5) $$0 = \\frac{{de}}{{d{h_i}}} = \\,2E\\left\\{ {\\left( {\\sum\\limits_{k = - \\infty }^{ + \\infty } {r[n - k]h[k]} - x[n]} \\right)r[n - i]} \\right\\}$$ Correlation returns \u00b6 Rearranging this expression gives: (10.6) $$E\\left\\{ {x[n]r[n - i]} \\right\\} = E\\left\\{ {r[n - i]\\sum\\limits_{k = - \\infty }^{ + \\infty } {r[n - k]} h[k]} \\right\\}$$ The term on the left side of the equation is the cross-correlation function between \\(x[n]\\) and \\(r[n].\\) Because both signals are real, we have from Equation 5.5 and Equation 5.6 : (10.7) $$E\\left\\{ {x[n]r[n - i]} \\right\\} = {\\varphi _{xr}}[ - i] = \\varphi _{rx}^*[i] = {\\varphi _{rx}}[i]$$ Because the signal \\(r[n - i]\\) is not a function of \\(k\\) and the order of the operations of summation and expectation can\u2014with all the usual caveats\u2014be reversed, the term on the right side of the equation can be rewritten as: (10.8) $$\\begin{array}{l} E\\left\\{ {\\sum\\limits_{k = - \\infty }^{ + \\infty } {r[n - k]r[n - i]} h[k]} \\right\\} = \\\\ \\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\sum\\limits_{k = - \\infty }^{ + \\infty } {E\\left\\{ {r[n - k]r[n - i]} \\right\\}} h[k] \\end{array}$$ Again we have made use of Equation 4.13 which says that expectation as an operator distributes over sums. The Wiener-Hopf equation \u00b6 The result is an implicit expression for the optimum filter \\(h[n]\\) : (10.9) $${\\varphi _{rx}}[k] = \\sum\\limits_{m = - \\infty }^{ + \\infty } {{\\varphi _{rr}}[k - m]} h[m] = {\\varphi _{rr}}[k] \\otimes h[k]$$ Note the way the variable names \u201c \\(m\\) \u201d and \u201c \\(k\\) \u201d are used in order to be consistent with earlier notation, for example, Equation 5.5 and Equation 5.6 . We distinguish between two cases of this famous equation, the Wiener-Hopf equation . The variable \\(k\\) represents the interval over which the process is observed. In the first case, \\(k > 0\\) and this represents the case of causal observations. That is, in principle, it is only possible to estimate \\(x[n]\\) from data that have already been gathered. The estimate \\({x_e}[n]\\) can only have a causal dependence on \\(r[n]\\) and the (causal) filter choice \\(h[n].\\) With this condition the solution of the Wiener-Hopf equation is extremely difficult, far beyond what we introduce here. We will concentrate, instead, on the case \\(- \\infty \\le k \\le + \\infty\\) which admits a direct solution through application of Fourier techniques. While this case is somewhat less realistic for temporal signals (but not for spatial signals), it will enable us to develop some insights into the character of filters developed as solutions to the Wiener-Hopf equation. Such filters, independent of the conditions on \\(k,\\) are known as Wiener filters after a mathematical giant of the 20 th century Prof. Norbert Wiener (1894-1964). As seen from the Fourier domain \u00b6 We start by taking the Fourier transform of both sides of Equation 10.9 to produce: (10.10) $${S_{rx}}(\\Omega ) = {S_{rr}}(\\Omega )H(\\Omega )$$ The desired filter is, of course, \\(H(\\Omega )\\) and this is given by: (10.11) $$H(\\Omega ) = \\frac{{{S_{rx}}(\\Omega )}}{{{S_{rr}}(\\Omega )}}$$ What is that least mean-square error? \u00b6 Through a series of manipulations (following section 10.3 in Papoulis 3 ), we show that the total minimum error \\(e\\) is: (10.12) $$e = \\frac{1}{{2\\pi }}\\int\\limits_{ - \\pi }^{ + \\pi } {\\left( {{S_{xx}}(\\Omega ) - {S_{rx}}(\\Omega )H(\\Omega )} \\right)} d\\Omega$$ We start with Equation 10.4 and using some algebra and the definition of the autocorrelation function we find: (10.13) $$\\begin{array}{*{20}{l}} e&{ = E\\left\\{ {{{\\left( {{x_e}[n] - x[n]} \\right)}^2}} \\right\\} }\\\\ {\\,\\,\\,}&{ = E\\left\\{ {{x^2}[n]} \\right\\} + E\\left\\{ {x_e^2[n]} \\right\\} - 2E\\left\\{ {{x_e}[n]x[n]} \\right\\}}\\\\ {\\,\\,\\,}&{ = {\\varphi _{xx}}[0] + E\\left\\{ {x_e^2[n]} \\right\\} - 2E\\left\\{ {{x_e}[n]x[n]} \\right\\}} \\end{array}$$ Continuing with the use of Equation 10.1 this becomes a lengthy\u2014somewhat inelegant\u2014 expression: (10.14) $$\\begin{array}{*{20}{l}} e&{ = {\\varphi _{xx}}[0] + E\\left\\{ {x_e^2[n]} \\right\\} - 2E\\left\\{ {{x_e}[n]x[n]} \\right\\}}\\\\ {}&{ = {\\varphi _{xx}}[0]\\,\\, + }\\\\ {}&{\\,\\,\\,\\,E\\left\\{ {\\left( {\\sum\\limits_{m = - \\infty }^{ + \\infty } {r[n - m]} h[m]} \\right)\\left( {\\sum\\limits_{i = - \\infty }^{ + \\infty } {r[n - i]} h[i]} \\right)} \\right\\}\\,\\, - }\\\\ {}&{\\,\\,\\,\\,\\,2E\\left\\{ {\\left( {\\sum\\limits_{m = - \\infty }^{ + \\infty } {r[n - m]} h[m]} \\right)x[n]} \\right\\}} \\end{array}$$ Exchanging orders of expectation and summation, again, yields: (10.15) $$\\begin{array}{*{20}{l}} e&{ = {\\varphi _{xx}}[0]\\,\\, + }\\\\ {\\,\\,\\,}&{\\,\\,\\,\\,\\,\\,\\sum\\limits_{m = - \\infty }^{ + \\infty } {\\left( {h[m]\\sum\\limits_{i = - \\infty }^{ + \\infty } {{\\varphi _{rr}}[m - i]h[i]} } \\right)} \\,\\, - }\\\\ {\\,\\,\\,}&{\\,\\,\\,\\,\\,\\,2\\left( {\\sum\\limits_{m = - \\infty }^{ + \\infty } {{\\varphi _{rx}}[m]h[m]} } \\right)} \\end{array}$$ In Equation 10.9 we determined an expression for the optimum filter, the filter that produces the minimum mean-square error. Substituting Equation 10.9 in Equation 10.15 yields: (10.16) $$e = {\\varphi _{xx}}[0] - \\sum\\limits_{k = - \\infty }^{ + \\infty } {h[k]{\\varphi _{rx}}[k]}$$ where, once again, we have replaced the dummy variable \u201c \\(m\\) \u201d with \u201c \\(k\\) \u201d. Using Equation 5.23 and Parseval\u2019s Theorem, it is easy to see that Equation 10.16 is equivalent to Equation 10.12 . See Problem 10.2 . Classic example, classic result \u00b6 To proceed further we use one of the most common situations as an example. Let \\(x[n]\\) and \\(N[n]\\) be statistically independent and let \\(N[n]\\) have zero mean. Then: (10.17) $$\\begin{array}{*{20}{l}} {{\\varphi _{nx}}[k]}&{ = E\\left\\{ {N[n]x[n + k]} \\right\\}}\\\\ {\\,\\,\\,}&{ = E\\left\\{ {N[n]} \\right\\}E\\left\\{ {x[n + k]} \\right\\} = 0} \\end{array}$$ From the Wiener-Hopf equation, Equation 10.9 , the desired quantities are \\({\\varphi _{rx}}[k]\\) and \\({\\varphi _{rr}}[k]\\) : (10.18) $$\\begin{array}{*{20}{l}} {{\\varphi _{rx}}[k]}&{ = E\\left\\{ {r[n]x[n + k]} \\right\\}}&{}&{}\\\\ {\\,\\,\\,}&{ = E\\left\\{ {\\left( {x[n] + N[n]} \\right)x[n + k]} \\right\\}}&{}&{}\\\\ {\\,\\,\\,}&{ = E\\left\\{ {x[n]x[n + k]} \\right\\} + E\\left\\{ {N[n]x[n + k]} \\right\\}}&{}&{}\\\\ {\\,\\,\\,}&{ = {\\varphi _{xx}}[k] + {\\varphi _{nx}}[k]}&{}&{} \\end{array}$$ From Equation 10.17 we see that the second term is zero. Thus, (10.19) $${\\varphi _{rx}}[k] = {\\varphi _{xx}}[k]$$ or taking the Fourier transform of both sides, (10.20) $${S_{rx}}(\\Omega ) = {S_{xx}}(\\Omega )$$ Further, because \\(r[n] = x[n] + N[n]\\) and the noise is zero mean, we can show\u2014see Problem 10.3 \u2014that: (10.21) $${S_{rr}}(\\Omega ) = {S_{xx}}(\\Omega ) + {S_{nn}}(\\Omega )$$ Combining Equation 10.11 , Equation 10.20 , and Equation 10.21 results in: (10.22) $$H(\\Omega ) = \\frac{{{S_{xx}}(\\Omega )}}{{{S_{xx}}(\\Omega ) + {S_{nn}}(\\Omega )}}$$ To better understand this result we look at two cases. In the first case we consider those frequency regions where the signal strength (power) dominates the noise strength, that is, where (10.23) $${S_{xx}}(\\Omega )\\; > > \\;{S_{nn}}(\\Omega )$$ From our solution Equation 10.22 we see that this implies that \\(H(\\Omega ) = 1.\\) In those frequency bands where the signal-to-noise ratio is high, the Wiener filter simply passes the input spectrum \\(R(\\Omega ) = {\\mathscr{F}}\\left\\{ {r[n]} \\right\\}\\) unchanged. In the second case, we consider those frequency regions where the noise strength dominates the signal strength. We have: (10.24) $${S_{xx}}(\\Omega )\\; < < \\;{S_{nn}}(\\Omega )\\,\\,\\,\\,\\,\\, \\Rightarrow \\,\\,\\,\\,\\,\\,H(\\Omega ) = \\frac{{{S_{xx}}(\\Omega )}}{{{S_{nn}}(\\Omega )}} \\approx 0$$ The input spectrum \\(R(\\Omega )\\) is almost completely attenuated by the Wiener filter. Figure 10.2 shows the linear filter spectrum generated by the signal and noise spectra given in an example in Chapter 8 and Figure 8.2 . ( a ) ${S_{xx}}(\\Omega )$ and ${S_{nn}}(\\Omega )$: ( b ) Wiener filter $H(\\Omega )$: Figure 10.2: ( a ) Two power-density spectra \\({S_{xx}}(\\Omega )\\) (in dark red ) and \\({S_{nn}}(\\Omega )\\) (in green ) ( b ) The Wiener filter \\(H(\\Omega ) = {S_{xx}}(\\Omega )/({S_{xx}}(\\Omega ) + {S_{nn}}(\\Omega ))\\) (in blue ). The spectra \\({S_{xx}}(\\Omega )\\) and \\({S_{nn}}(\\Omega )\\) intersect at the frequencies at which the signal and noise power density spectra are equal. The more general restoration case: noise & distortion \u00b6 A more general formulation of the Wiener filter problem assumes not only a contamination of the input signal by random noise but also distortion of the input signal by a known linear filter \\({h_o}[n].\\) An example of this might be the blurred recording of an image due to camera motion where the noise source is the camera electronics. This situation is modeled in Figure 10.3 . Figure 10.3: LTI filter \\(h[n\\rbrack\\) to estimate a stochastic signal which has first been degraded by a deterministic filter \\({h_o}[n\\rbrack\\) before the additive noise. Once again, we desire an \\(h[n]\\) that will minimize the expected square error between \\(x[n]\\) and \\({x_e}[n].\\) We continue to assume real signals and systems, statistical independence of ergodic signal and ergodic noise, zero-mean signals, and zero-mean noise leading to \\(E\\left\\{ {x[n]h[n + k]} \\right\\} = E\\left\\{ {x[n + k]h[n]} \\right\\} = 0.\\) Why we avoid the inverse filter \u00b6 Our first temptation might be to use an inverse filter, \\(H(\\Omega ) = 1/{H_o}(\\Omega )\\) where \\({H_o}(\\Omega ) = {\\mathscr{F}}\\left\\{ {{h_o}[n]} \\right\\}.\\) The problem, however, lies in the behavior that the inverse filter will exhibit at those frequencies where \\({H_o}(\\Omega ) = 0.\\) At zeroes of the transfer function \\({H_o}(\\Omega ),\\) the filter \\(H(\\Omega ) = 1/{H_o}(\\Omega )\\) will diverge. This will cause the noise to overwhelm the signal in precisely those frequency bands where the signal is weakest. The Wiener filter approach avoids this problem. An example of the problem caused by the inverse approach is shown in Figure 10.4 . Figure 10.4: ( top row ) Stochastic signal \\(x[n\\rbrack\\) and its input power density spectrum \\({S_{xx}}(\\Omega )\\) ; ( second row ) The impulse response \\({h_o}[n\\rbrack\\) and the filter spectrum \\({H_o}(\\Omega )\\) of a bandpass filter; ( third row ) The noise-free distorted signal \\(r[n\\rbrack = y[n\\rbrack = x[n\\rbrack \\otimes {h_o}[n\\rbrack\\) and its output power density spectrum \\({S_{rr}}(\\Omega )\\) ; ( bottom row ) The inverse filter which has infinities at a number of frequencies and thus cannot be used to remove the distortion. All spectral graphs are plotted over the interval \\(- \\pi /2 \\le \\Omega \\le + \\pi /2\\) and all graphs are normalized in range, in the time domain {\u20131, +1} and in the frequency domain {0, +1}. Example: Sound of (distorted) music \u00b6 In the one-dimensional case illustrated 4 in Figure 10.4 , the signal is based upon a short section of Paganini\u2019s violin concerto. The signal \\(x[n]\\) and its power spectrum \\({S_{xx}}(\\Omega )\\) are shown. It is interesting to consider if music can be treated as a stochastic signal. Certainly when Paganini wrote his Violin Concerto No. 1, every note is explicitly given as well as the manner that it should be played. Nevertheless, every performance of that music is different in unpredictable ways \u2013 the violinist, the violin, the temperature in the hall, the hall acoustics and so forth. Even with a digitally-recorded version, every listening experience differs due to room acoustics, position of the listener, electronic noise in the analog music reproduction, and environmental acoustical noise. We, therefore, use music as an example of a stochastic signal. Audio 10.1: Original music: Click the play triangle ( ) to hear the original Paganini selection. The signal is passed through a band-pass filter \\({h_o}[n]\\) with spectrum \\({H_o}(\\Omega )\\) as shown in Figure 10.4 . Audio 10.2: Distorted music: Click the play triangle ( ) to hear a distorted version of the Paganini selection. The output power spectrum of the filter is \\({S_{yy}}(\\Omega )\\) and in the time domain the signal is \\(y[n]\\) as illustrated in Figure 10.3 and Figure 10.4 . For the model shown in Figure 10.3 , we assume (for now) that the noise is identically zero meaning \\(r[n] = y[n].\\) If the restoration filter is the inverse filter, \\(H(\\Omega ) = 1/{H_o}(\\Omega )\\) the zeroes in \\({H_o}(\\Omega )\\) lead to infinities in the inverse and the output is indeterminate. To make matters worse (and more realistic), we now look at what happens when the noise is not zero. Example: Cleaning up our act \u00b6 As shown in Figure 10.3 , the filtered signal \\(y[n]\\) is now corrupted by noise which we will assume to be additive, white Gaussian noise. The effects in the time domain, the spectrum \\(R(\\Omega ),\\) and the power spectral density \\({S_{rr}}(\\Omega )\\) are shown in Figure 10.5 . Again, an inverse filter would lead to significant signal corruption as the zeroes of the \\({H_o}(\\Omega )\\) which produce infinities in the inverse filter would now be multiplied by the non-zero spectral density values of the white noise. Adding noise exacerbates the problem of inverse filtering. Figure 10.5: ( top ) On the left, a white, Gaussian noise sample \\(N[n\\rbrack,\\) is added to the distorted stochastic signal \\(y[n\\rbrack\\) in Figure 10.4 to produce the output signal, \\(r[n\\rbrack\\) on the right. ( bottom ) On the left, the power density spectrum of the noise \\({S_{nn}}(\\Omega )\\) . The power density spectrum \\({S_{rr}}(\\Omega ),\\) where r = x \u2297 h o + N is shown on the right. All spectral graphs are plotted over the interval \\(- \\pi /2 \\le \\Omega \\le + \\pi /2\\) and all graphs are normalized in range, in the time domain {\u20131, +1} and in the frequency domain {0, +1}. As \u201csimple\u201d inverse filtering is in many cases inadvisable, we, therefore, seek a filter technique that is \u201cimmune\u201d to zeroes in \\({H_o}(\\Omega ).\\) Determining the Wiener filter \u00b6 Once again we require \\({\\varphi _{rx}}[k]\\) but (10.25) $$\\begin{array}{*{20}{l}} {{\\varphi _{rx}}[k]}&{ = E\\left\\{ {r[n]x[n + k]} \\right\\}}&{}&{}\\\\ {\\,\\,\\,}&{ = E\\left\\{ {\\left( {y[n] + N[n]} \\right)x[n + k]} \\right\\}}&{}&{}\\\\ {\\,\\,\\,}&{ = E\\left\\{ {y[n]x[n + k]} \\right\\}}&{}&{}\\\\ {\\,\\,\\,}&{ = {\\varphi _{yx}}[k]}&{}&{} \\end{array}$$ This leads to (see Equation 6.22 ), (10.26) $${S_{rx}}(\\Omega ) = {S_{yx}}(\\Omega ) = H_0^*(\\Omega ){S_{xx}}(\\Omega )$$ Further, (10.27) $$\\begin{array}{*{20}{l}} {{\\varphi _{rr}}[k]}&{ = E\\left\\{ {\\left( {y[n] + N[n]} \\right)\\left( {y[n + k] + N[n + k]} \\right)} \\right\\}}&{}&{}\\\\ {\\,\\,\\,}&{ = {\\varphi _{yy}}[k] + {\\varphi _{nn}}[k]}&{}&{} \\end{array}$$ Taking the Fourier transform of both sides and using Equation 6.21 gives: (10.28) $$\\begin{array}{*{20}{l}} {{S_{rr}}(\\Omega )}&{ = {S_{yy}}(\\Omega ) + {S_{nn}}(\\Omega )}\\\\ {\\,\\,\\,}&{ = {{\\left| {{H_0}(\\Omega )} \\right|}^2}{S_{xx}}(\\Omega ) + {S_{nn}}(\\Omega )} \\end{array}$$ The Wiener filter is once again defined through Equation 10.11 and, therefore, (10.29) $$H(\\Omega ) = \\frac{{H_0^*(\\Omega ){S_{xx}}(\\Omega )}}{{{{\\left| {{H_0}(\\Omega )} \\right|}^2}{S_{xx}}(\\Omega ) + {S_{nn}}(\\Omega )}}$$ This is simply a general form of Equation 10.22 where a possible LTI distortion filter, \\({{H_0}(\\Omega )},\\) has been taken into consideration. If there is no distortion filter, if \\({H_o}(\\Omega ) = 1,\\) then Equation 10.29 reverts to Equation 10.22 . There are several useful ways to rewrite Equation 10.29 . One of these is explored in Laboratory Exercise 10.5 and the reformulation is: (10.30) $$H(\\Omega ) = \\frac{{H_0^*(\\Omega )}}{{{{\\left| {{H_0}(\\Omega )} \\right|}^2} + \\left( {\\frac{{{S_{nn}}(\\Omega )}}{{{S_{xx}}(\\Omega )}}} \\right)}}$$ For those frequencies where \\({S_{xx}}(\\Omega ) > > {S_{nn}}(\\Omega ),\\) the high- \\(SNR\\) frequency bands, the filter reduces to an inverse filter: (10.31) $$H(\\Omega ) \\approx \\frac{{H_0^*(\\Omega )}}{{{{\\left| {{H_0}(\\Omega )} \\right|}^2}}} = \\frac{1}{{{H_0}(\\Omega )}} = H_0^{ - 1}(\\Omega )$$ For those frequencies where \\({S_{xx}}(\\Omega ) < < {S_{nn}}(\\Omega ),\\) the low- \\(SNR\\) frequency bands, let (10.32) $$\\frac{{{S_{nn}}(\\Omega )}}{{{S_{xx}}(\\Omega )}} \\approx {N_0}\\; > > \\;1$$ Then the filter reduces to the matched filter solution as in Equation 9.12 : (10.33) $$H(\\Omega ) \\approx \\frac{1}{{{N_0}}}H_0^*(\\Omega )$$ Finally, for those frequencies where \\({H_o}(\\Omega ) = 0,\\) we see that \\(H(\\Omega ) = 0\\) meaning no noise amplification. In Figure 10.6 we see an example of a Wiener filter designed to restore data after the effects of the bandpass filter used in Figure 10.4 and Figure 10.5 . Figure 10.6: ( top ) A section of the original stochastic (music) signal on the left and the power density spectrum \\({S_{rr}}(\\Omega )\\) of the noisy, distorted signal \\(r[n\\rbrack\\) on the right. ( bottom ) On the right, the spectrum of the Wiener filter as developed from the definition Equation 10.29 . On the left, the restored signal, \\({x_e}[n\\rbrack,\\) after application of the Wiener filter. All spectral graphs are plotted over the interval \\(- \\pi /2 \\le \\Omega \\le + \\pi /2\\) and all graphs are normalized in range, in the time domain {\u20131, +1} and in the frequency domain {0, +1}. Audio 10.3: Distortion + Noise: Click the play triangle ( ) to hear a noisy, distorted version of the Paganini selection. It is important to notice that the spectra \\(\\left\\{ {{H_o}(\\Omega ),{S_{xx}}(\\Omega ),{S_{nn}}(\\Omega )} \\right\\},\\) that are required to implement the Wiener filter in Equation 10.29 , are deterministic functions and not (stochastic) estimates. Such prior knowledge is rarely available so we are usually forced to estimate the spectra. Such estimation is the topic of the next chapter. Audio 10.4: Wiener-filter restoration: Click the play triangle ( ) to hear a Wiener-filter-restored version of the Paganini selection. This example illustrates the power of Wiener filtering. The distortion and noise in \\(r[n]\\) are considerably\u2014but not completely\u2014reduced through the use of the Wiener filter. Problems \u00b6 Problem 10.1 \u00b6 Starting from Equation 13.3 show that the extremum is a minimum as opposed to a maximum or saddle point. Problem 10.2 \u00b6 Consider two complex signals \\(p[n]\\) and \\(q[n]\\) with Fourier transforms \\(P(\\Omega )\\) and \\(Q(\\Omega ).\\) Show that: (10.34) $$\\sum\\limits_{k = - \\infty }^{ + \\infty } {q[k]{p^*}[k] = \\frac{1}{{2\\pi }}} \\int\\limits_{ - \\pi }^{ + \\pi } {Q(\\Omega )} {P^*}(\\Omega )d\\Omega$$ Please note that this is the generalized form of Parseval\u2019s Theorem. If \\(q[n] = p[n],\\) this then becomes the usual statement of the theorem. How does the result in part ( a ) change if both \\(p[n]\\) and \\(q[n]\\) are real signals? Using the result from part ( b ) show that Equation 10.16 can be rewritten as Equation 10.12 . Problem 10.3 \u00b6 Consider an ergodic, stochastic signal \\(x[n]\\) such as speech that has been corrupted by independent, additive ergodic noise \\(N[n]\\) so that the result is \\(r[n] = x[n] + N[n].\\) Determine an expression for \\({\\varphi _{rr}}[k]\\) in terms of \\({\\varphi _{xx}}[k]\\) (the autocorrelation function of the signal), \\({\\varphi _{NN}}[k]\\) (the autocorrelation function of the noise), \\({m_x}\\) (the mean of \\(x[n]\\) ), and \\({m_N}\\) (the mean of \\(N[n]\\) ). What does \\({\\varphi _{rr}}[k]\\) reduce to if the noise has zero-mean, that is, \\({m_N} = 0?\\) Determine the power spectral density of \\(r[n]\\) in terms of the power spectral densities of \\(x[n]\\) and \\(N[n]\\) assuming \\({m_N} = 0.\\) Problem 10.4 \u00b6 The continuous-time music from Paganini used in the following sections Chapter 10 , Chapter 10 , and Chapter 10 was sampled at 44.1 kHz. In Figure 10.4 , Figure 10.5 , and Figure 10.6 the spectra are displayed from \\(- \\pi /2 \\le \\Omega \\le + \\pi /2\\) What is the analog frequency range (in kHz) that is displayed in these figures? How can we justify displaying only these frequencies as opposed to the full spectra? Note : In the following laboratory exercises involving audio signals, we will be freely switching between use of the discrete time frequency variable \\(\\Omega\\) and the continuous frequency variable \\(\\omega = 2\\pi f.\\) The sampling rate remains 44.1 kHz. Laboratory Exercises \u00b6 Laboratory Exercise 10.1 \u00b6 A simple impulse has been corrupted by noise. Can the Wiener filter restore the signal and at what noise levels? Look and listen. To start the exercise, click on the icon to the left. Laboratory Exercise 10.2 \u00b6 We explore the quality of the restoration of color images that can be achieved in the presence of significant amounts of noise. To start the exercise, click on the icon to the left. Laboratory Exercise 10.3 \u00b6 We apply Wiener filtering to a two-dimensional signal, an image, that has first been distorted and then contaminated with noise. How faithful is the restored image? The mean-square error may have been minimized but is the image \u201cpretty\u201d? To start the exercise, click on the icon to the left. Laboratory Exercise 10.4 \u00b6 Images are acquired through cameras and all cameras have apertures. Can we restore an image that is distorted by an aperture effect and is \u201cdirty\u201d (noisy) as well? To start the exercise, click on the icon to the left. Laboratory Exercise 10.5 \u00b6 Using the Wiener-filter concept means having prior knowledge. What, for example, is the noise spectrum? If we make some assumptions and are prepared to justify these assumptions , perhaps we can simplify the problem with a \u201cpoor man\u2019s Wiener filter\u201d. To start the exercise, click on the icon to the left. Castleman, K. R. (1996). Digital Image Processing. Englewood Cliffs, New Jersey, Prentice-Hall \u21a9 Lee, Y. W. (1960). Statistical Theory of Communication. New York, John Wiley & Sons \u21a9 Papoulis, A. (1977). Signal Analysis. New York, McGraw-Hill \u21a9 \u21a9 The discrete-time signals x [ n ] and r [ n ] in this discussion are displayed as \u201ccontinuous\u201d curves because they contain thousands of samples and the standard display does not reproduce well. The spectra of the stochastic signals are displayed as line spectra because they are calculated from the Discrete Fourier Transform (DFT) using the FFT algorithm. Nevertheless, we continue to discuss discrete-time signals of the form \\(f[n]\\) and spectra as \\(F(\\Omega )\\) as presented in the beginning of Chapter 3. \u21a9","title":"10. The Wiener filter"},{"location":"Chap_10.html#the-wiener-filter","text":"In the previous chapter we showed that a desired effect, a maximized SNR, could be achieved by the suitable choice of a linear filter, a matched filter. We will now address a more difficult problem: the use of linear filters to estimate a stochastic signal in the presence of noise. We let \\(x[n]\\) be a stochastic, ergodic signal from a process with known statistics.","title":"The Wiener filter"},{"location":"Chap_10.html#the-restoration-case-noise","text":"In the presence of noise and using a linear filter, we wish to produce an estimate of \\(x[n]\\) which we call \\({x_e}[n].\\) This is frequently termed signal restoration because we are attempting to restore a signal \\(x[n]\\) that has become damaged, corrupted, and/or noisy. We want the best estimate where the definition of \u201cbest\u201d will be explained. We assume that \\(x[n]\\) is real as is the noise process \\(N[n].\\) The total signal \\(r[n]\\) composed of \\(x[n]\\) and \\(N[n]\\) is to be processed to produce the estimate \\({x_e}[n]\\) of the original \\(x[n].\\) The model is shown in Figure 10.1 . Figure 10.1: LTI filter \\(h[n\\rbrack\\) to estimate a stochastic signal \\(x[n\\rbrack\\) in the presence of additive noise. We start with: (10.1) $${x_e}[n] = \\sum\\limits_{m = - \\infty }^{ + \\infty } {r[n - m]} h[m]$$ and we define \u201cbest\u201d in terms of a measure of the difference (error) between the \u201ctrue\u201d stochastic signal \\(x[n]\\) and the estimate \\({x_e}[n].\\)","title":"The restoration case: noise"},{"location":"Chap_10.html#using-the-least-mean-square-error-criterion","text":"Specifically we look at the mean (expected) square error: (10.2) $$e = mean\\text{-}squared\\;error = E\\left\\{ {{{\\left| {{x_e}[n] - x[n]} \\right|}^2}} \\right\\}$$ and we propose to choose \\(h[n]\\) in order to minimize this error. We will need a basic result from least mean-square estimation theory and this can be found in Appendix I . To determine a minimum, we look at: (10.3) $$\\begin{array}{*{20}{l}} {\\frac{{\\partial e}}{{\\partial h}}}&{ = \\frac{\\partial }{{\\partial h}}E\\left\\{ {{{\\left| {{x_e}[n] - x[n]} \\right|}^2}} \\right\\}}\\\\ {\\,\\,\\,}&{ = \\frac{\\partial }{{\\partial h}}E\\left\\{ {{{\\left( {\\sum\\limits_{m = - \\infty }^{ + \\infty } {r[n - m]} h[m] - x[n]} \\right)}^2}} \\right\\} = 0} \\end{array}$$ That is, we vary the filter to choose the one that gives the minimum mean-square error. Note that the restriction to real signals and systems ensures that we can replace the non-differentiable absolute value operation \\({\\left| \\bullet \\right|^2}\\) with the differentiable operation \\({\\left( \\bullet \\right)^2}\\) in Equation 10.3 . The equation above, of course, yields an extremum but it can be shown that this is a minimum; see Problem 10.1 . The development of this approach follows those in the references Castleman 1 , Lee 2 , and Papoulis 3 .","title":"Using the least mean-square error criterion"},{"location":"Chap_10.html#expressing-the-mean-square-error","text":"Based upon Appendix I , and starting from Equation 10.1 and Equation 10.2 , we have: (10.4) $$\\begin{array}{*{20}{l}} e&{ = E\\left\\{ {{{\\left( {{x_e} - x} \\right)}^2}} \\right\\} = E\\left\\{ {{{\\left( {{x_e}[n] - x[n]} \\right)}^2}} \\right\\}}\\\\ {\\,\\,\\,}&{ = E\\left\\{ {{{\\left( {r[n] \\otimes h[n] - x[n]} \\right)}^2}} \\right\\}}\\\\ {\\,\\,\\,}&{ = E\\left\\{ {{{\\left( {\\sum\\limits_{k = - \\infty }^{ + \\infty } {r[n - k]h[k]} - x[n]} \\right)}^2}} \\right\\}} \\end{array}$$ We might have expected that the left-hand side of Equation 10.4 would be \\(e[n]\\) instead of \\(e.\\) The expectation operation, \\(E\\left\\{ \\bullet \\right\\},\\) combined with the assumption of ergodicity assures that the result \\(e\\) is independent of \\(n.\\) We now apply the key result\u2014orthogonality\u2014from Equation 13.3 and rewrite this as: (10.5) $$0 = \\frac{{de}}{{d{h_i}}} = \\,2E\\left\\{ {\\left( {\\sum\\limits_{k = - \\infty }^{ + \\infty } {r[n - k]h[k]} - x[n]} \\right)r[n - i]} \\right\\}$$","title":"Expressing the mean-square error"},{"location":"Chap_10.html#correlation-returns","text":"Rearranging this expression gives: (10.6) $$E\\left\\{ {x[n]r[n - i]} \\right\\} = E\\left\\{ {r[n - i]\\sum\\limits_{k = - \\infty }^{ + \\infty } {r[n - k]} h[k]} \\right\\}$$ The term on the left side of the equation is the cross-correlation function between \\(x[n]\\) and \\(r[n].\\) Because both signals are real, we have from Equation 5.5 and Equation 5.6 : (10.7) $$E\\left\\{ {x[n]r[n - i]} \\right\\} = {\\varphi _{xr}}[ - i] = \\varphi _{rx}^*[i] = {\\varphi _{rx}}[i]$$ Because the signal \\(r[n - i]\\) is not a function of \\(k\\) and the order of the operations of summation and expectation can\u2014with all the usual caveats\u2014be reversed, the term on the right side of the equation can be rewritten as: (10.8) $$\\begin{array}{l} E\\left\\{ {\\sum\\limits_{k = - \\infty }^{ + \\infty } {r[n - k]r[n - i]} h[k]} \\right\\} = \\\\ \\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\sum\\limits_{k = - \\infty }^{ + \\infty } {E\\left\\{ {r[n - k]r[n - i]} \\right\\}} h[k] \\end{array}$$ Again we have made use of Equation 4.13 which says that expectation as an operator distributes over sums.","title":"Correlation returns"},{"location":"Chap_10.html#the-wiener-hopf-equation","text":"The result is an implicit expression for the optimum filter \\(h[n]\\) : (10.9) $${\\varphi _{rx}}[k] = \\sum\\limits_{m = - \\infty }^{ + \\infty } {{\\varphi _{rr}}[k - m]} h[m] = {\\varphi _{rr}}[k] \\otimes h[k]$$ Note the way the variable names \u201c \\(m\\) \u201d and \u201c \\(k\\) \u201d are used in order to be consistent with earlier notation, for example, Equation 5.5 and Equation 5.6 . We distinguish between two cases of this famous equation, the Wiener-Hopf equation . The variable \\(k\\) represents the interval over which the process is observed. In the first case, \\(k > 0\\) and this represents the case of causal observations. That is, in principle, it is only possible to estimate \\(x[n]\\) from data that have already been gathered. The estimate \\({x_e}[n]\\) can only have a causal dependence on \\(r[n]\\) and the (causal) filter choice \\(h[n].\\) With this condition the solution of the Wiener-Hopf equation is extremely difficult, far beyond what we introduce here. We will concentrate, instead, on the case \\(- \\infty \\le k \\le + \\infty\\) which admits a direct solution through application of Fourier techniques. While this case is somewhat less realistic for temporal signals (but not for spatial signals), it will enable us to develop some insights into the character of filters developed as solutions to the Wiener-Hopf equation. Such filters, independent of the conditions on \\(k,\\) are known as Wiener filters after a mathematical giant of the 20 th century Prof. Norbert Wiener (1894-1964).","title":"The Wiener-Hopf equation"},{"location":"Chap_10.html#as-seen-from-the-fourier-domain","text":"We start by taking the Fourier transform of both sides of Equation 10.9 to produce: (10.10) $${S_{rx}}(\\Omega ) = {S_{rr}}(\\Omega )H(\\Omega )$$ The desired filter is, of course, \\(H(\\Omega )\\) and this is given by: (10.11) $$H(\\Omega ) = \\frac{{{S_{rx}}(\\Omega )}}{{{S_{rr}}(\\Omega )}}$$","title":"As seen from the Fourier domain"},{"location":"Chap_10.html#what-is-that-least-mean-square-error","text":"Through a series of manipulations (following section 10.3 in Papoulis 3 ), we show that the total minimum error \\(e\\) is: (10.12) $$e = \\frac{1}{{2\\pi }}\\int\\limits_{ - \\pi }^{ + \\pi } {\\left( {{S_{xx}}(\\Omega ) - {S_{rx}}(\\Omega )H(\\Omega )} \\right)} d\\Omega$$ We start with Equation 10.4 and using some algebra and the definition of the autocorrelation function we find: (10.13) $$\\begin{array}{*{20}{l}} e&{ = E\\left\\{ {{{\\left( {{x_e}[n] - x[n]} \\right)}^2}} \\right\\} }\\\\ {\\,\\,\\,}&{ = E\\left\\{ {{x^2}[n]} \\right\\} + E\\left\\{ {x_e^2[n]} \\right\\} - 2E\\left\\{ {{x_e}[n]x[n]} \\right\\}}\\\\ {\\,\\,\\,}&{ = {\\varphi _{xx}}[0] + E\\left\\{ {x_e^2[n]} \\right\\} - 2E\\left\\{ {{x_e}[n]x[n]} \\right\\}} \\end{array}$$ Continuing with the use of Equation 10.1 this becomes a lengthy\u2014somewhat inelegant\u2014 expression: (10.14) $$\\begin{array}{*{20}{l}} e&{ = {\\varphi _{xx}}[0] + E\\left\\{ {x_e^2[n]} \\right\\} - 2E\\left\\{ {{x_e}[n]x[n]} \\right\\}}\\\\ {}&{ = {\\varphi _{xx}}[0]\\,\\, + }\\\\ {}&{\\,\\,\\,\\,E\\left\\{ {\\left( {\\sum\\limits_{m = - \\infty }^{ + \\infty } {r[n - m]} h[m]} \\right)\\left( {\\sum\\limits_{i = - \\infty }^{ + \\infty } {r[n - i]} h[i]} \\right)} \\right\\}\\,\\, - }\\\\ {}&{\\,\\,\\,\\,\\,2E\\left\\{ {\\left( {\\sum\\limits_{m = - \\infty }^{ + \\infty } {r[n - m]} h[m]} \\right)x[n]} \\right\\}} \\end{array}$$ Exchanging orders of expectation and summation, again, yields: (10.15) $$\\begin{array}{*{20}{l}} e&{ = {\\varphi _{xx}}[0]\\,\\, + }\\\\ {\\,\\,\\,}&{\\,\\,\\,\\,\\,\\,\\sum\\limits_{m = - \\infty }^{ + \\infty } {\\left( {h[m]\\sum\\limits_{i = - \\infty }^{ + \\infty } {{\\varphi _{rr}}[m - i]h[i]} } \\right)} \\,\\, - }\\\\ {\\,\\,\\,}&{\\,\\,\\,\\,\\,\\,2\\left( {\\sum\\limits_{m = - \\infty }^{ + \\infty } {{\\varphi _{rx}}[m]h[m]} } \\right)} \\end{array}$$ In Equation 10.9 we determined an expression for the optimum filter, the filter that produces the minimum mean-square error. Substituting Equation 10.9 in Equation 10.15 yields: (10.16) $$e = {\\varphi _{xx}}[0] - \\sum\\limits_{k = - \\infty }^{ + \\infty } {h[k]{\\varphi _{rx}}[k]}$$ where, once again, we have replaced the dummy variable \u201c \\(m\\) \u201d with \u201c \\(k\\) \u201d. Using Equation 5.23 and Parseval\u2019s Theorem, it is easy to see that Equation 10.16 is equivalent to Equation 10.12 . See Problem 10.2 .","title":"What is that least mean-square error?"},{"location":"Chap_10.html#classic-example-classic-result","text":"To proceed further we use one of the most common situations as an example. Let \\(x[n]\\) and \\(N[n]\\) be statistically independent and let \\(N[n]\\) have zero mean. Then: (10.17) $$\\begin{array}{*{20}{l}} {{\\varphi _{nx}}[k]}&{ = E\\left\\{ {N[n]x[n + k]} \\right\\}}\\\\ {\\,\\,\\,}&{ = E\\left\\{ {N[n]} \\right\\}E\\left\\{ {x[n + k]} \\right\\} = 0} \\end{array}$$ From the Wiener-Hopf equation, Equation 10.9 , the desired quantities are \\({\\varphi _{rx}}[k]\\) and \\({\\varphi _{rr}}[k]\\) : (10.18) $$\\begin{array}{*{20}{l}} {{\\varphi _{rx}}[k]}&{ = E\\left\\{ {r[n]x[n + k]} \\right\\}}&{}&{}\\\\ {\\,\\,\\,}&{ = E\\left\\{ {\\left( {x[n] + N[n]} \\right)x[n + k]} \\right\\}}&{}&{}\\\\ {\\,\\,\\,}&{ = E\\left\\{ {x[n]x[n + k]} \\right\\} + E\\left\\{ {N[n]x[n + k]} \\right\\}}&{}&{}\\\\ {\\,\\,\\,}&{ = {\\varphi _{xx}}[k] + {\\varphi _{nx}}[k]}&{}&{} \\end{array}$$ From Equation 10.17 we see that the second term is zero. Thus, (10.19) $${\\varphi _{rx}}[k] = {\\varphi _{xx}}[k]$$ or taking the Fourier transform of both sides, (10.20) $${S_{rx}}(\\Omega ) = {S_{xx}}(\\Omega )$$ Further, because \\(r[n] = x[n] + N[n]\\) and the noise is zero mean, we can show\u2014see Problem 10.3 \u2014that: (10.21) $${S_{rr}}(\\Omega ) = {S_{xx}}(\\Omega ) + {S_{nn}}(\\Omega )$$ Combining Equation 10.11 , Equation 10.20 , and Equation 10.21 results in: (10.22) $$H(\\Omega ) = \\frac{{{S_{xx}}(\\Omega )}}{{{S_{xx}}(\\Omega ) + {S_{nn}}(\\Omega )}}$$ To better understand this result we look at two cases. In the first case we consider those frequency regions where the signal strength (power) dominates the noise strength, that is, where (10.23) $${S_{xx}}(\\Omega )\\; > > \\;{S_{nn}}(\\Omega )$$ From our solution Equation 10.22 we see that this implies that \\(H(\\Omega ) = 1.\\) In those frequency bands where the signal-to-noise ratio is high, the Wiener filter simply passes the input spectrum \\(R(\\Omega ) = {\\mathscr{F}}\\left\\{ {r[n]} \\right\\}\\) unchanged. In the second case, we consider those frequency regions where the noise strength dominates the signal strength. We have: (10.24) $${S_{xx}}(\\Omega )\\; < < \\;{S_{nn}}(\\Omega )\\,\\,\\,\\,\\,\\, \\Rightarrow \\,\\,\\,\\,\\,\\,H(\\Omega ) = \\frac{{{S_{xx}}(\\Omega )}}{{{S_{nn}}(\\Omega )}} \\approx 0$$ The input spectrum \\(R(\\Omega )\\) is almost completely attenuated by the Wiener filter. Figure 10.2 shows the linear filter spectrum generated by the signal and noise spectra given in an example in Chapter 8 and Figure 8.2 . ( a ) ${S_{xx}}(\\Omega )$ and ${S_{nn}}(\\Omega )$: ( b ) Wiener filter $H(\\Omega )$: Figure 10.2: ( a ) Two power-density spectra \\({S_{xx}}(\\Omega )\\) (in dark red ) and \\({S_{nn}}(\\Omega )\\) (in green ) ( b ) The Wiener filter \\(H(\\Omega ) = {S_{xx}}(\\Omega )/({S_{xx}}(\\Omega ) + {S_{nn}}(\\Omega ))\\) (in blue ). The spectra \\({S_{xx}}(\\Omega )\\) and \\({S_{nn}}(\\Omega )\\) intersect at the frequencies at which the signal and noise power density spectra are equal.","title":"Classic example, classic result"},{"location":"Chap_10.html#the-more-general-restoration-case-noise-distortion","text":"A more general formulation of the Wiener filter problem assumes not only a contamination of the input signal by random noise but also distortion of the input signal by a known linear filter \\({h_o}[n].\\) An example of this might be the blurred recording of an image due to camera motion where the noise source is the camera electronics. This situation is modeled in Figure 10.3 . Figure 10.3: LTI filter \\(h[n\\rbrack\\) to estimate a stochastic signal which has first been degraded by a deterministic filter \\({h_o}[n\\rbrack\\) before the additive noise. Once again, we desire an \\(h[n]\\) that will minimize the expected square error between \\(x[n]\\) and \\({x_e}[n].\\) We continue to assume real signals and systems, statistical independence of ergodic signal and ergodic noise, zero-mean signals, and zero-mean noise leading to \\(E\\left\\{ {x[n]h[n + k]} \\right\\} = E\\left\\{ {x[n + k]h[n]} \\right\\} = 0.\\)","title":"The more general restoration case: noise &amp; distortion"},{"location":"Chap_10.html#why-we-avoid-the-inverse-filter","text":"Our first temptation might be to use an inverse filter, \\(H(\\Omega ) = 1/{H_o}(\\Omega )\\) where \\({H_o}(\\Omega ) = {\\mathscr{F}}\\left\\{ {{h_o}[n]} \\right\\}.\\) The problem, however, lies in the behavior that the inverse filter will exhibit at those frequencies where \\({H_o}(\\Omega ) = 0.\\) At zeroes of the transfer function \\({H_o}(\\Omega ),\\) the filter \\(H(\\Omega ) = 1/{H_o}(\\Omega )\\) will diverge. This will cause the noise to overwhelm the signal in precisely those frequency bands where the signal is weakest. The Wiener filter approach avoids this problem. An example of the problem caused by the inverse approach is shown in Figure 10.4 . Figure 10.4: ( top row ) Stochastic signal \\(x[n\\rbrack\\) and its input power density spectrum \\({S_{xx}}(\\Omega )\\) ; ( second row ) The impulse response \\({h_o}[n\\rbrack\\) and the filter spectrum \\({H_o}(\\Omega )\\) of a bandpass filter; ( third row ) The noise-free distorted signal \\(r[n\\rbrack = y[n\\rbrack = x[n\\rbrack \\otimes {h_o}[n\\rbrack\\) and its output power density spectrum \\({S_{rr}}(\\Omega )\\) ; ( bottom row ) The inverse filter which has infinities at a number of frequencies and thus cannot be used to remove the distortion. All spectral graphs are plotted over the interval \\(- \\pi /2 \\le \\Omega \\le + \\pi /2\\) and all graphs are normalized in range, in the time domain {\u20131, +1} and in the frequency domain {0, +1}.","title":"Why we avoid the inverse filter"},{"location":"Chap_10.html#example-sound-of-distorted-music","text":"In the one-dimensional case illustrated 4 in Figure 10.4 , the signal is based upon a short section of Paganini\u2019s violin concerto. The signal \\(x[n]\\) and its power spectrum \\({S_{xx}}(\\Omega )\\) are shown. It is interesting to consider if music can be treated as a stochastic signal. Certainly when Paganini wrote his Violin Concerto No. 1, every note is explicitly given as well as the manner that it should be played. Nevertheless, every performance of that music is different in unpredictable ways \u2013 the violinist, the violin, the temperature in the hall, the hall acoustics and so forth. Even with a digitally-recorded version, every listening experience differs due to room acoustics, position of the listener, electronic noise in the analog music reproduction, and environmental acoustical noise. We, therefore, use music as an example of a stochastic signal. Audio 10.1: Original music: Click the play triangle ( ) to hear the original Paganini selection. The signal is passed through a band-pass filter \\({h_o}[n]\\) with spectrum \\({H_o}(\\Omega )\\) as shown in Figure 10.4 . Audio 10.2: Distorted music: Click the play triangle ( ) to hear a distorted version of the Paganini selection. The output power spectrum of the filter is \\({S_{yy}}(\\Omega )\\) and in the time domain the signal is \\(y[n]\\) as illustrated in Figure 10.3 and Figure 10.4 . For the model shown in Figure 10.3 , we assume (for now) that the noise is identically zero meaning \\(r[n] = y[n].\\) If the restoration filter is the inverse filter, \\(H(\\Omega ) = 1/{H_o}(\\Omega )\\) the zeroes in \\({H_o}(\\Omega )\\) lead to infinities in the inverse and the output is indeterminate. To make matters worse (and more realistic), we now look at what happens when the noise is not zero.","title":"Example: Sound of (distorted) music"},{"location":"Chap_10.html#example-cleaning-up-our-act","text":"As shown in Figure 10.3 , the filtered signal \\(y[n]\\) is now corrupted by noise which we will assume to be additive, white Gaussian noise. The effects in the time domain, the spectrum \\(R(\\Omega ),\\) and the power spectral density \\({S_{rr}}(\\Omega )\\) are shown in Figure 10.5 . Again, an inverse filter would lead to significant signal corruption as the zeroes of the \\({H_o}(\\Omega )\\) which produce infinities in the inverse filter would now be multiplied by the non-zero spectral density values of the white noise. Adding noise exacerbates the problem of inverse filtering. Figure 10.5: ( top ) On the left, a white, Gaussian noise sample \\(N[n\\rbrack,\\) is added to the distorted stochastic signal \\(y[n\\rbrack\\) in Figure 10.4 to produce the output signal, \\(r[n\\rbrack\\) on the right. ( bottom ) On the left, the power density spectrum of the noise \\({S_{nn}}(\\Omega )\\) . The power density spectrum \\({S_{rr}}(\\Omega ),\\) where r = x \u2297 h o + N is shown on the right. All spectral graphs are plotted over the interval \\(- \\pi /2 \\le \\Omega \\le + \\pi /2\\) and all graphs are normalized in range, in the time domain {\u20131, +1} and in the frequency domain {0, +1}. As \u201csimple\u201d inverse filtering is in many cases inadvisable, we, therefore, seek a filter technique that is \u201cimmune\u201d to zeroes in \\({H_o}(\\Omega ).\\)","title":"Example: Cleaning up our act"},{"location":"Chap_10.html#determining-the-wiener-filter","text":"Once again we require \\({\\varphi _{rx}}[k]\\) but (10.25) $$\\begin{array}{*{20}{l}} {{\\varphi _{rx}}[k]}&{ = E\\left\\{ {r[n]x[n + k]} \\right\\}}&{}&{}\\\\ {\\,\\,\\,}&{ = E\\left\\{ {\\left( {y[n] + N[n]} \\right)x[n + k]} \\right\\}}&{}&{}\\\\ {\\,\\,\\,}&{ = E\\left\\{ {y[n]x[n + k]} \\right\\}}&{}&{}\\\\ {\\,\\,\\,}&{ = {\\varphi _{yx}}[k]}&{}&{} \\end{array}$$ This leads to (see Equation 6.22 ), (10.26) $${S_{rx}}(\\Omega ) = {S_{yx}}(\\Omega ) = H_0^*(\\Omega ){S_{xx}}(\\Omega )$$ Further, (10.27) $$\\begin{array}{*{20}{l}} {{\\varphi _{rr}}[k]}&{ = E\\left\\{ {\\left( {y[n] + N[n]} \\right)\\left( {y[n + k] + N[n + k]} \\right)} \\right\\}}&{}&{}\\\\ {\\,\\,\\,}&{ = {\\varphi _{yy}}[k] + {\\varphi _{nn}}[k]}&{}&{} \\end{array}$$ Taking the Fourier transform of both sides and using Equation 6.21 gives: (10.28) $$\\begin{array}{*{20}{l}} {{S_{rr}}(\\Omega )}&{ = {S_{yy}}(\\Omega ) + {S_{nn}}(\\Omega )}\\\\ {\\,\\,\\,}&{ = {{\\left| {{H_0}(\\Omega )} \\right|}^2}{S_{xx}}(\\Omega ) + {S_{nn}}(\\Omega )} \\end{array}$$ The Wiener filter is once again defined through Equation 10.11 and, therefore, (10.29) $$H(\\Omega ) = \\frac{{H_0^*(\\Omega ){S_{xx}}(\\Omega )}}{{{{\\left| {{H_0}(\\Omega )} \\right|}^2}{S_{xx}}(\\Omega ) + {S_{nn}}(\\Omega )}}$$ This is simply a general form of Equation 10.22 where a possible LTI distortion filter, \\({{H_0}(\\Omega )},\\) has been taken into consideration. If there is no distortion filter, if \\({H_o}(\\Omega ) = 1,\\) then Equation 10.29 reverts to Equation 10.22 . There are several useful ways to rewrite Equation 10.29 . One of these is explored in Laboratory Exercise 10.5 and the reformulation is: (10.30) $$H(\\Omega ) = \\frac{{H_0^*(\\Omega )}}{{{{\\left| {{H_0}(\\Omega )} \\right|}^2} + \\left( {\\frac{{{S_{nn}}(\\Omega )}}{{{S_{xx}}(\\Omega )}}} \\right)}}$$ For those frequencies where \\({S_{xx}}(\\Omega ) > > {S_{nn}}(\\Omega ),\\) the high- \\(SNR\\) frequency bands, the filter reduces to an inverse filter: (10.31) $$H(\\Omega ) \\approx \\frac{{H_0^*(\\Omega )}}{{{{\\left| {{H_0}(\\Omega )} \\right|}^2}}} = \\frac{1}{{{H_0}(\\Omega )}} = H_0^{ - 1}(\\Omega )$$ For those frequencies where \\({S_{xx}}(\\Omega ) < < {S_{nn}}(\\Omega ),\\) the low- \\(SNR\\) frequency bands, let (10.32) $$\\frac{{{S_{nn}}(\\Omega )}}{{{S_{xx}}(\\Omega )}} \\approx {N_0}\\; > > \\;1$$ Then the filter reduces to the matched filter solution as in Equation 9.12 : (10.33) $$H(\\Omega ) \\approx \\frac{1}{{{N_0}}}H_0^*(\\Omega )$$ Finally, for those frequencies where \\({H_o}(\\Omega ) = 0,\\) we see that \\(H(\\Omega ) = 0\\) meaning no noise amplification. In Figure 10.6 we see an example of a Wiener filter designed to restore data after the effects of the bandpass filter used in Figure 10.4 and Figure 10.5 . Figure 10.6: ( top ) A section of the original stochastic (music) signal on the left and the power density spectrum \\({S_{rr}}(\\Omega )\\) of the noisy, distorted signal \\(r[n\\rbrack\\) on the right. ( bottom ) On the right, the spectrum of the Wiener filter as developed from the definition Equation 10.29 . On the left, the restored signal, \\({x_e}[n\\rbrack,\\) after application of the Wiener filter. All spectral graphs are plotted over the interval \\(- \\pi /2 \\le \\Omega \\le + \\pi /2\\) and all graphs are normalized in range, in the time domain {\u20131, +1} and in the frequency domain {0, +1}. Audio 10.3: Distortion + Noise: Click the play triangle ( ) to hear a noisy, distorted version of the Paganini selection. It is important to notice that the spectra \\(\\left\\{ {{H_o}(\\Omega ),{S_{xx}}(\\Omega ),{S_{nn}}(\\Omega )} \\right\\},\\) that are required to implement the Wiener filter in Equation 10.29 , are deterministic functions and not (stochastic) estimates. Such prior knowledge is rarely available so we are usually forced to estimate the spectra. Such estimation is the topic of the next chapter. Audio 10.4: Wiener-filter restoration: Click the play triangle ( ) to hear a Wiener-filter-restored version of the Paganini selection. This example illustrates the power of Wiener filtering. The distortion and noise in \\(r[n]\\) are considerably\u2014but not completely\u2014reduced through the use of the Wiener filter.","title":"Determining the Wiener filter"},{"location":"Chap_10.html#problems","text":"","title":"Problems"},{"location":"Chap_10.html#problem-101","text":"Starting from Equation 13.3 show that the extremum is a minimum as opposed to a maximum or saddle point.","title":"Problem 10.1"},{"location":"Chap_10.html#problem-102","text":"Consider two complex signals \\(p[n]\\) and \\(q[n]\\) with Fourier transforms \\(P(\\Omega )\\) and \\(Q(\\Omega ).\\) Show that: (10.34) $$\\sum\\limits_{k = - \\infty }^{ + \\infty } {q[k]{p^*}[k] = \\frac{1}{{2\\pi }}} \\int\\limits_{ - \\pi }^{ + \\pi } {Q(\\Omega )} {P^*}(\\Omega )d\\Omega$$ Please note that this is the generalized form of Parseval\u2019s Theorem. If \\(q[n] = p[n],\\) this then becomes the usual statement of the theorem. How does the result in part ( a ) change if both \\(p[n]\\) and \\(q[n]\\) are real signals? Using the result from part ( b ) show that Equation 10.16 can be rewritten as Equation 10.12 .","title":"Problem 10.2"},{"location":"Chap_10.html#problem-103","text":"Consider an ergodic, stochastic signal \\(x[n]\\) such as speech that has been corrupted by independent, additive ergodic noise \\(N[n]\\) so that the result is \\(r[n] = x[n] + N[n].\\) Determine an expression for \\({\\varphi _{rr}}[k]\\) in terms of \\({\\varphi _{xx}}[k]\\) (the autocorrelation function of the signal), \\({\\varphi _{NN}}[k]\\) (the autocorrelation function of the noise), \\({m_x}\\) (the mean of \\(x[n]\\) ), and \\({m_N}\\) (the mean of \\(N[n]\\) ). What does \\({\\varphi _{rr}}[k]\\) reduce to if the noise has zero-mean, that is, \\({m_N} = 0?\\) Determine the power spectral density of \\(r[n]\\) in terms of the power spectral densities of \\(x[n]\\) and \\(N[n]\\) assuming \\({m_N} = 0.\\)","title":"Problem 10.3"},{"location":"Chap_10.html#problem-104","text":"The continuous-time music from Paganini used in the following sections Chapter 10 , Chapter 10 , and Chapter 10 was sampled at 44.1 kHz. In Figure 10.4 , Figure 10.5 , and Figure 10.6 the spectra are displayed from \\(- \\pi /2 \\le \\Omega \\le + \\pi /2\\) What is the analog frequency range (in kHz) that is displayed in these figures? How can we justify displaying only these frequencies as opposed to the full spectra? Note : In the following laboratory exercises involving audio signals, we will be freely switching between use of the discrete time frequency variable \\(\\Omega\\) and the continuous frequency variable \\(\\omega = 2\\pi f.\\) The sampling rate remains 44.1 kHz.","title":"Problem 10.4"},{"location":"Chap_10.html#laboratory-exercises","text":"","title":"Laboratory Exercises"},{"location":"Chap_10.html#laboratory-exercise-101","text":"A simple impulse has been corrupted by noise. Can the Wiener filter restore the signal and at what noise levels? Look and listen. To start the exercise, click on the icon to the left.","title":"Laboratory Exercise 10.1"},{"location":"Chap_10.html#laboratory-exercise-102","text":"We explore the quality of the restoration of color images that can be achieved in the presence of significant amounts of noise. To start the exercise, click on the icon to the left.","title":"Laboratory Exercise 10.2"},{"location":"Chap_10.html#laboratory-exercise-103","text":"We apply Wiener filtering to a two-dimensional signal, an image, that has first been distorted and then contaminated with noise. How faithful is the restored image? The mean-square error may have been minimized but is the image \u201cpretty\u201d? To start the exercise, click on the icon to the left.","title":"Laboratory Exercise 10.3"},{"location":"Chap_10.html#laboratory-exercise-104","text":"Images are acquired through cameras and all cameras have apertures. Can we restore an image that is distorted by an aperture effect and is \u201cdirty\u201d (noisy) as well? To start the exercise, click on the icon to the left.","title":"Laboratory Exercise 10.4"},{"location":"Chap_10.html#laboratory-exercise-105","text":"Using the Wiener-filter concept means having prior knowledge. What, for example, is the noise spectrum? If we make some assumptions and are prepared to justify these assumptions , perhaps we can simplify the problem with a \u201cpoor man\u2019s Wiener filter\u201d. To start the exercise, click on the icon to the left. Castleman, K. R. (1996). Digital Image Processing. Englewood Cliffs, New Jersey, Prentice-Hall \u21a9 Lee, Y. W. (1960). Statistical Theory of Communication. New York, John Wiley & Sons \u21a9 Papoulis, A. (1977). Signal Analysis. New York, McGraw-Hill \u21a9 \u21a9 The discrete-time signals x [ n ] and r [ n ] in this discussion are displayed as \u201ccontinuous\u201d curves because they contain thousands of samples and the standard display does not reproduce well. The spectra of the stochastic signals are displayed as line spectra because they are calculated from the Discrete Fourier Transform (DFT) using the FFT algorithm. Nevertheless, we continue to discuss discrete-time signals of the form \\(f[n]\\) and spectra as \\(F(\\Omega )\\) as presented in the beginning of Chapter 3. \u21a9","title":"Laboratory Exercise 10.5"},{"location":"Chap_11.html","text":"Aspects of Estimation \u00b6 In this and the next chapter we will look at the problem of estimating the parameters of a stochastic process from experimental data. That is, how to estimate: (11.1) $${m_x} = E\\left\\{ {x[n]} \\right\\} = \\; < x[n] >$$ (11.2) $${\\varphi _{xx}}[k] = E\\left\\{ {x[n]{x^*}[n + k]} \\right\\} = \\; < x[n]{x^*}[n + k] >$$ (11.3) $${S_{xx}}(\\Omega ) = {\\mathscr{F}}\\left\\{ {{\\varphi _{xx}}[k]} \\right\\}$$ There is a formal theory of estimation that addresses a variety of issues and the development of that theory can be quite complicated. An introduction can be found in van den Bos 1 . Instead we look at a few simple criteria. To estimate the mean of a process given \\(N\\) samples, we might, for example, use one of the following: arithmetic mean: (11.4) $${\\mu _A} = \\,\\, < x[n]{ > _A}\\; = \\frac{1}{N}\\sum\\limits_{n = 0}^{N - 1} {x[n]}$$ geometric mean: (11.5) $${\\mu _G} = \\,\\,\\, < x[n]{ > _G}\\; = {\\left( {\\prod\\limits_{n = 0}^{N - 1} {x[n]} } \\right)^{1/N}}$$ harmonic mean: (11.6) $${\\mu _H} = \\,\\,\\, < x[n]{ > _H}\\; = N{\\left( {\\sum\\limits_{n = 0}^{N - 1} {\\frac{1}{{x[n]}}} } \\right)^{ - 1}}$$ These three ways of defining a mean are collectively referred to as the Pythagorean means and, as one might expect, there are useful relationships among the three. From experience we expect that Equation 11.4 will be the preferred form and, in fact, this can be shown from \u201cmaximum likelihood\u201d estimation theory under many hypotheses. There are, however, numerous examples that can be found in finance, economics, the social sciences, and the physical sciences where one of the other two means is to be preferred. Let us look at how a choice is made. Maximum-likelihood estimation \u00b6 We assume that \\(N\\) independent measurements have been made of an ergodic random process that is described by the probability distribution \\(p({x_i}|\\theta )\\) where \\(\\theta\\) is a parameter of the distribution. In the case of coin flipping that parameter might be \\(\\theta = p = p(Heads)\\) as described in Chapter 4 . The joint distribution of these \\(N\\) measurements is given by \\(p\\left( {{x_1},{x_2},{x_3},\\,...\\,,{x_N}|\\theta } \\right).\\) But because of the independence of these \\(N\\) measurements we can rewrite this using Equation 3.8 as: (11.7) $$p({x_1},{x_2},{x_3},...,{x_N}|\\theta ) = \\prod\\limits_{i = 1}^N {p({x_i}|\\theta )}$$ Given all of these measurements, the question is: How do we estimate \\(\\theta?\\) There are a variety of estimation criteria and the one we choose is maximum-likelihood estimation , ML-estimation. In this approach we choose the value of \\(\\theta = {\\theta _{ML}}\\) such that (11.8) $$p\\left( {{x_1},{x_2},{x_3},\\,...\\,,{x_N}|{\\theta _{ML}}} \\right) \\geqslant p\\left( {{x_1},{x_2},{x_3},\\,...\\,,{x_N}|{\\theta _o}} \\right)$$ where \\({\\theta _{ML}} \\ne {\\theta _o}.\\) In words, the ML-estimate of the parameter \\(\\theta\\) is the estimate that gives the maximum probability (likelihood) of collecting the data that we have just acquired. To see how this is used in practice let us look at a specific example. Example: Estimating the Poisson rate \u00b6 In this example we refer to the Poisson random process defined in Chapter 8 . We repeat the definition of the Poisson probability distribution: (11.9) $$p(n|\\lambda T) = \\frac{{{{\\left( {\\lambda T} \\right)}^n}{e^{ - \\lambda T}}}}{{n!}}$$ where \\(\\lambda\\) is the number of events per unit \u201ctime\u201d and \\(T\\) is the duration of an observation window. We see that \\(\\theta = \\lambda T.\\) To find the ML-estimate of \\(\\theta\\) given \\(N\\) measurements of, say, photon emission \\(\\left\\{ {{n_1},{n_2},\\,...\\,,{n_N}|\\theta } \\right\\}\\) we use the result in Equation 11.7 to write the likelihood function \\(L(\\theta )\\) : (11.10) $$L(\\theta ) = \\prod\\limits_{i = 1}^N {p({n_i}|\\theta )} = \\prod\\limits_{i = 1}^N {\\frac{{{\\theta ^{{n_i}}}{e^{ - \\theta }}}}{{{n_i}!}}}$$ We seek the value of \\(\\theta\\) that maximizes \\(L(\\theta ).\\) At first glance this might seem like an intractable problem. One of the standard procedures\u2014a.k.a. \u201ctricks of the trade\u201d\u2014can, however, be applied. It is not difficult to show that if \\({\\theta _{ML}}\\) maximizes \\(\\ln \\left[ {L(\\theta )} \\right]\\) \u2014where \\(\\ln\\) is the natural logarithm function\u2014then it maximizes \\(L(\\theta )\\) as well. See Problem 11.1 . Applying this gives: (11.11) $$\\begin{array}{*{20}{l}} {\\ln \\left[ {L(\\theta )} \\right]}&{ = \\ln \\left[ {\\prod\\limits_{i = 1}^N {\\frac{{{\\theta ^{{n_i}}}{e^{ - \\theta }}}}{{{n_i}!}}} } \\right] = \\sum\\limits_{i = 1}^N {\\ln } \\left[ {\\frac{{{\\theta ^{{n_i}}}{e^{ - \\theta }}}}{{{n_i}!}}} \\right]}\\\\ {\\,\\,\\,}&{ = \\sum\\limits_{i = 1}^N {{n_i}\\ln } \\left( \\theta \\right) - \\sum\\limits_{i = 1}^N \\theta - \\sum\\limits_{i = 1}^N {n!} } \\end{array}$$ To find the maximum (extremum actually) we set the derivative with respect to \\(\\theta\\) to zero. (11.12) $$\\begin{array}{*{20}{l}} {\\frac{{\\partial \\ln \\left[ {L(\\theta )} \\right]}}{{\\partial \\theta }}}&{ = \\frac{\\partial }{{\\partial \\theta }}\\left( {\\sum\\limits_{i = 1}^N {{n_i}\\ln } \\left( \\theta \\right) - \\sum\\limits_{i = 1}^N \\theta - \\sum\\limits_{i = 1}^N {n!} } \\right)}\\\\ {\\,\\,\\,}&{ = \\frac{1}{\\theta }\\sum\\limits_{i = 1}^N {{n_i}} - N = 0} \\end{array}$$ (How would you show that this extremum is a maximum as opposed to a minimum or saddle point?) Solving for \\(\\theta\\) gives the ML-estimate: (11.13) $$\\frac{1}{\\theta }\\sum\\limits_{i = 1}^N {{n_i}} - N = 0\\,\\,\\,\\,\\,\\,\\, \\Rightarrow \\,\\,\\,\\,\\,\\,{\\theta _{ML}} = \\frac{1}{N}\\sum\\limits_{i = 1}^N {{n_i}}$$ The ML-estimate of the parameter \\(\\theta = \\lambda T\\) is simply the arithmetic average ( \\({\\mu _A}\\) ) of the measurements. Other examples can be found in Problem 11.2 . But is it a \u201cgood\u201d estimate? \u00b6 In a given formula such as Equation 11.4 we might also ask: On the average does the formula give the \u201cright\u201d answer? If we take a very large number of samples will our estimation error become smaller? With regard to the first question we introduce a concept that is central to obtaining good estimates: the concept of bias . Formally if \\(a\\) is a (deterministic) parameter of a random process and \\(\\hat a\\) is the estimate of \\(a\\) then the bias \\(B\\) is: (11.14) $$B = E\\left\\{ {\\hat a} \\right\\} - a$$ We should remember that \\(\\hat a\\) is a random variable because it is a function of random data. If \\(B > 0\\) we have an overestimate of \\(a\\) and if \\(B < 0\\) we have an underestimate. We define an unbiased estimate as one that has \\(B = 0.\\) An unbiased estimate is desirable because it means that the estimate will be neither consistently too high nor consistently too low. Continuing, we define the mean-square error between the parameter and its estimate as (11.15) $$e = E\\left\\{ {{{\\left( {\\hat a - a} \\right)}^2}} \\right\\}$$ We will show in Problem 11.5 that choosing an unbiased estimate ( \\(B = 0\\) ) can, under certain circumstances, minimize the mean-square error measure. In Problem 11.6 and Problem 11.7 we will show that this is not always the case. When it is the case, the estimators are referred to as minimum-variance unbiased estimators ( MVUE ). An unbiased estimate\u2014whether it is minimum-variance or not\u2014is frequently referred to as an accurate estimate. In reformulating the second question we see that the central issue is convergence. It should be obvious that if the value of a parameter \\(\\theta\\) is \\(2/\\pi\\) \u2014see Buffon\u2019s needle \u2014and we have \\(N = 37\\) samples from an experiment designed to estimate \\(\\theta,\\) then it will not be possible to get the exact value. By increasing \\(N,\\) however, we would hope to improve our estimate. In other words, we would like the error, as we continue to use more data in our estimate, to go to zero. Formally, we want \\(\\sigma _a^2 \\to 0\\) as the number of samples \\(N \\to \\infty.\\) That is, the variance (or its square root, the standard deviation) of the estimate should go to zero as the number of samples becomes very large. As the variance of the estimate goes to zero, we describe the estimate as becoming more precise . If in the limit as \\(N \\to \\infty\\) both the bias and the variance go to zero, we say that the estimate is consistent 2 . This type of behavior is illustrated in Figure 11.1 . Figure 11.1: The convergence of an estimate \\(\\hat a\\) to \\(a\\) as the number of samples \\(N\\) involved in the estimation procedure increases. As \\(N\\) increases the uncertainty in the estimate, as measured by the standard deviation, decreases. The green curve is for the number of samples \\({N_3},\\) the red curve for \\({N_2}\\) and the blue curve for \\({N_1}\\) where \\({N_3} > {N_2} > {N_1}.\\) A convenient way to remember the concepts of accuracy and precision and to distinguish between them is through a (hypothetical) game of darts where the goal is to throw \\(N\\) darts such that each one lands in the center of the dart board, in the \u201cbullseye\u201d. This is illustrated in Figure 11.2 . Figure 11.2: ( left ) Placement of five darts by one player showing high accuracy but low precision . ( right ) Placement of five darts by a second player showing low accuracy but high precision . The \u201cintuitive\u201d meanings of the words accurate and precise are illustrated here and intended to serve as a permanent reminder. Estimating the mean \u00b6 As an example consider \\({m_x} = E\\left\\{ {x[n]} \\right\\}.\\) We look at the arithmetic estimate for \\({m_x}\\) given by: (11.16) $$< x[n] > \\; = \\frac{1}{N}\\sum\\limits_{n = 0}^{N - 1} {x[n]}$$ We determine the bias as follows: (11.17) $$E\\left\\{ { < x[n] > } \\right\\}\\; = \\frac{1}{N}\\sum\\limits_{n = 0}^{N - 1} {E\\left\\{ {x[n]} \\right\\}} = {m_x}$$ (11.18) $$B = E\\left\\{ { < x[n] > } \\right\\} - {m_x} = {m_x} - {m_x} = 0$$ Thus the arithmetic mean generates an unbiased estimate of the true mean. The variance, \\(Var( \\bullet ),\\) of the estimate is: (11.19) $$\\sigma _N^2 = Var\\left\\{ {\\frac{1}{N}\\sum\\limits_{n = 0}^{N - 1} {x[n]} } \\right\\} = \\frac{1}{{{N^2}}}\\sum\\limits_{n = 0}^{N - 1} {Var\\left\\{ {x[n]} \\right\\}}$$ This right-most term follows from the assumption that the data samples \\(\\{ x[n]\\}\\) are statistically independent of one another. Continuing, (11.20) $$\\sigma _N^2 = \\frac{1}{{{N^2}}}\\sum\\limits_{n = 0}^{N - 1} {\\sigma _x^2} = \\frac{1}{{{N^2}}}N\\sigma _x^2 = \\frac{{\\sigma _x^2}}{N}$$ Thus, as the number of samples \\(N \\to \\infty,\\) the variance of the estimate goes to zero as \\(1/N.\\) Because the bias \\(B\\) is zero and the variance goes to zero for large \\(N,\\) we see that the estimate for the mean of a random process based upon Equation 11.16 is a consistent estimate. An illustration of how the estimate shown in Figure 11.1 converges to a final value is shown in Movie 11.1 . Movie 11.1: Convergence of the estimate of a parameter as the number of samples $N$ increases. Note that the estimate is biased\u2014an overestimate\u2014but approaches the true value as $N \\to \\infty.$ The estimate is asymptotically unbiased . Further, the variance decreases as $N$ increases. Estimating the autocorrelation function \u00b6 We now look at a more difficult problem, that of estimating the autocorrelation function of a real, random process starting from statistically independent data samples. Formally, (11.21) $${\\varphi _{xx}}[k] = E\\left\\{ {x[n]{x^*}[n + k]} \\right\\} = \\;E\\left\\{ {x[n]x[n + k]} \\right\\}$$ If \\(N\\) samples of \\(\\{ x[n]\\}\\) are available then only \\(N - |k|\\) samples are available to compute the average of the product \\(x[n]\\,x[n + k].\\) This is illustrated graphically in Figure 11.3 and represents the fact that the number of overlaps between \\(x[n]\\) and \\(x[n + k]\\) will be \\(N - \\left| k \\right|.\\) Figure 11.3: ( top ) The original signal \\(x[n\\rbrack.\\) ( bottom ) The shifted version \\(x[n - k\\rbrack.\\) The overlap has the width \\(N - |k|\\) and the region is indicated in orange . A dynamic rendering of the overlap that occurs during the calculation of the correlation is shown in Movie 11.2 . Movie 11.2: As the autocorrelation of a finite duration signal is computed, the number of samples that overlap changes but is limited to $N - \\left| k \\right|.$ To estimate the mean of a parameter, we will use our result above, Equation 11.16 , applied to: (11.22) $${c_{xx}}[k] = \\frac{1}{{N - \\left| k \\right|}}\\sum\\limits_{n = 0}^{N - \\left| k \\right| - 1} {x[n]x[n + k]}$$ The variable \\(k\\) can be positive or negative but there will still be only \\(N - \\left| k \\right|\\) overlaps. How good is our estimator? \u00b6 The estimate of \\({\\varphi _{xx}}[k]\\) is \\({c_{xx}}[k].\\) Our first question is: Is this estimate unbiased? The bias is given by: (11.23) $$B = E\\left\\{ {{c_{xx}}[k]} \\right\\} - {\\varphi _{xx}}[k]$$ Using Equation 11.23 : (11.24) $$\\begin{array}{*{20}{l}} B&{ = E\\left\\{ {\\frac{1}{{N - \\left| k \\right|}}\\sum\\limits_{n = 0}^{N - \\left| k \\right| - 1} {x[n]x[n + k]} } \\right\\} - {\\varphi _{xx}}[k]}\\\\ {\\,\\,\\,}&{ = \\frac{1}{{N - \\left| k \\right|}}\\sum\\limits_{n = 0}^{N - \\left| k \\right| - 1} {E\\left\\{ {x[n]x[n + k]} \\right\\}} - {\\varphi _{xx}}[k]}\\\\ {\\,\\,\\,}&{ = \\frac{1}{{N - \\left| k \\right|}}\\sum\\limits_{n = 0}^{N - \\left| k \\right| - 1} {{\\varphi _{xx}}[k]} - {\\varphi _{xx}}[k]} \\end{array}$$ If \\(\\left| k \\right| < N\\) we have \\(B = 0,\\) an unbiased estimate. Our next question concerns the issue of whether \\({c_{xx}}[k]\\) forms a consistent estimate of \\({\\varphi _{xx}}[k].\\) Since we know that the estimate is unbiased, it remains to be shown that the variance of the estimate goes to zero as the number of data samples \\(N\\) increases. The variance of the estimate, \\(Var\\{ {c_{xx}}[k]\\},\\) is given (for large \\(N\\) ) by: (11.25) $$\\begin{array}{*{20}{l}} {Var\\{ {c_{xx}}[k]\\} \\approx \\frac{N}{{{{\\left( {N - \\left| k \\right|} \\right)}^2}}}\\, \\times }\\\\ {\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\left( {\\sum\\limits_{m = - \\infty }^{ + \\infty } {\\left( {\\varphi _{xx}^2[m] + {\\varphi _{xx}}[m + k]{\\varphi _{xx}}[m - k]} \\right)} } \\right)} \\end{array}$$ where formal derivation of the term under the summation is too complicated (and tedious) to be worked out in detail here; see Bartlett 3 and Jenkins 4 , instead. We now define a function (11.26) $$\\Phi [k] = \\sum\\limits_{m = - \\infty }^{ + \\infty } {\\left( {\\varphi _{xx}^2[m] + {\\varphi _{xx}}[m + k]{\\varphi _{xx}}[m - k]} \\right)}$$ which leads to: (11.27) $$Var\\{ {c_{xx}}[k]\\} \\approx \\frac{N}{{{{\\left( {N - \\left| k \\right|} \\right)}^2}}}\\Phi [k]$$ Let us look at \\(\\Phi [k]\\) in more detail. It consists of two terms: (11.28) $$\\Phi [k] = \\sum\\limits_{m = - \\infty }^{ + \\infty } {\\varphi _{xx}^2[m]} + \\sum\\limits_{m = - \\infty }^{ + \\infty } {{\\varphi _{xx}}[m + k]{\\varphi _{xx}}[m - k]}$$ The first term, assuming it converges, is a positive, real number and independent of \\(k.\\) The remark that it is real follows from our assumption at the beginning of a section in Chapter 11 . The second term is even in \\(k\\) as a simple substitution of \\(- k\\) shows. This means that \\(\\Phi [k]\\) is even. Further, the second term is itself an autocorrelation. Remembering our remarks at the beginning of Chapter 5 , the second term is the autocorrelation of the deterministic correlation function with itself! Using Equation 6.32 , this means the maximum value of \\(\\Phi [k]\\) is given by: (11.29) $${\\Phi _{\\max }} = 2\\sum\\limits_{m = - \\infty }^{ + \\infty } {\\varphi _{xx}^2[m]} \\,\\, \\ge \\,\\,\\Phi [k]\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\left| k \\right| < N$$ Other aspects of \\(\\Phi [k]\\) will be considered in Problem 11.9 . To better appreciate the behavior of \\(\\Phi [k]\\) and how that influences the variance of the estimate of the autocorrelation function \\(Var\\{ {c_{xx}}[k]\\},\\) let us look at one specific example. Langevin redux \u00b6 In our case-study of the Langevin equation we saw in Equation 7.14 that the theory-based autocorrelation function for the stochastic velocity process was given by: (11.30) $${\\varphi _{vv}}[k] = {\\left( {\\frac{1}{m}} \\right)^2}\\left( {\\frac{{{F_o}}}{{1 - {\\rho ^2}}}} \\right){\\rho ^{\\left| k \\right|}} = \\frac{A}{{1 - {\\rho ^2}}}{\\rho ^{\\left| k \\right|}}$$ where \\(0 < \\rho = {e^{ - \\lambda {T_s}/m}} < 1\\) and the constant \\(A = {F_o}/{m^2}.\\) Velocity data collected from this type of study would then represent the basis for estimating \\({\\varphi _{vv}}[k].\\) What can we expect from \\({\\Phi _{vv}}[k],\\) the velocity example of \\(\\Phi [k],\\) based upon this Langevin assumption? This first term in Equation 11.28 can be computed directly and the result for \\({\\Phi _{vv}}[k]\\) becomes: (11.31) $${\\Phi _{vv}}[k] = \\frac{{{A^2}(1 + {\\rho ^2})}}{{{{(1 - {\\rho ^2})}^3}}} + \\sum\\limits_{m = - \\infty }^{ + \\infty } {{\\varphi _{vv}}[m + k]{\\varphi _{vv}}[m - k]} $$ Understanding the behavior of the second term can be gained by first plotting the various components \\({\\varphi _{vv}}[m + k],\\) \\({\\varphi _{vv}}[m - k],\\) and \\({\\varphi _{vv}}[m + k]{\\varphi _{vv}}[m - k].\\) This is illustrated in Figure 11.4 . Figure 11.4: ( red ) the function \\({\\varphi _{vv}}[m + k\\rbrack,\\) ( green ) the function \\({\\varphi _{vv}}[m - k\\rbrack,\\) and ( blue ) the function \\({\\varphi _{vv}}[m + k\\rbrack{\\varphi _{vv}}[m - k\\rbrack.\\) All are plotted for \\(A = 1,\\) \\(m = 5,\\) and \\(\\rho = 0.9.\\) It is clear from Figure 11.4 that \\({\\varphi _{vv}}[m + k]{\\varphi _{vv}}[m - k]\\) is even in \\(k\\) and even in \\(m.\\) The former has already been proven; the latter will be proven in Problem 11.9 . A consequence of the even symmetry is that to find \\({\\Phi _{vv}}[k]\\) we need only solve the problem for \\(k \\ge 0.\\) For \\(0 \\le k \\le m,\\) we have \\(m \\pm k \\ge 0\\) and it follows that: (11.32) $$\\begin{array}{*{20}{l}} {{\\varphi _{vv}}[m + k]{\\varphi _{vv}}[m - k]}&{ = {{\\left( {\\frac{A}{{1 - {\\rho ^2}}}} \\right)}^2}{\\rho ^{\\left| {m + k} \\right|}}{\\rho ^{\\left| {m - k} \\right|}}}\\\\ {\\,\\,\\,}&{ = {{\\left( {\\frac{A}{{1 - {\\rho ^2}}}} \\right)}^2}{\\rho ^{m + k}}{\\rho ^{m - k}} = {{\\left( {\\frac{A}{{1 - {\\rho ^2}}}} \\right)}^2}{\\rho ^{2m}}} \\end{array}$$ This is a constant independent of \\(k\\) and explains the \u201cflat behavior\u201d observed for \\(0 \\le k \\le m\\) in Figure 11.4 . Following replacement of \\(\\left| {m - k} \\right|\\) with \\(\\left| {k - m} \\right|\\) and for \\(0 \\le m \\le k,\\) we have \\(k \\pm m \\ge 0.\\) It follows that: (11.33) $$\\begin{array}{*{20}{l}} {{\\varphi _{vv}}[m + k]{\\varphi _{vv}}[m - k]}&{ = {{\\left( {\\frac{A}{{1 - {\\rho ^2}}}} \\right)}^2}{\\rho ^{\\left| {k + m} \\right|}}{\\rho ^{\\left| {k - m} \\right|}}}\\\\ {\\,\\,\\,}&{ = {{\\left( {\\frac{A}{{1 - {\\rho ^2}}}} \\right)}^2}{\\rho ^{k + m}}{\\rho ^{k - m}} = {{\\left( {\\frac{A}{{1 - {\\rho ^2}}}} \\right)}^2}{\\rho ^{2k}}} \\end{array}$$ This is an exponentially decreasing function for \\(k > 0\\) and explains the behavior observed for \\(0 \\le m \\le k\\) in Figure 11.4 . To continue, we deconstruct the sum in Equation 11.31 for \\(k \\ge 0\\) as follows: (11.34) $$\\begin{array}{l} \\sum\\limits_{m = 0}^{ + \\infty } {{\\varphi _{vv}}[m + k]{\\varphi _{vv}}[m - k]} = \\underbrace {{\\varphi _{vv}}[k]{\\varphi _{vv}}[k]}_{m = 0}\\,\\, + \\\\ \\,\\,\\,\\,\\,\\,\\,\\,\\,\\underbrace {\\sum\\limits_{m = 1}^k {{\\varphi _{vv}}[m + k]{\\varphi _{vv}}[m - k]} }_{0 < m \\le k}\\,\\,\\, + \\\\ \\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\underbrace {\\sum\\limits_{m = k + 1}^{ + \\infty } {{\\varphi _{vv}}[m + k]{\\varphi _{vv}}[m - k]} }_{k < m \\le \\infty } \\end{array}$$ Substituting the various terms we have already found: (11.35) $$\\begin{array}{l} \\sum\\limits_{m = 0}^{ + \\infty } {{\\varphi _{vv}}[m + k]{\\varphi _{vv}}[m - k]} = \\underbrace {{{\\left( {\\frac{A}{{1 - {\\rho ^2}}}} \\right)}^2}{\\rho ^{2k}}}_{m = 0}\\,\\, + \\\\ \\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\underbrace {\\sum\\limits_{m = 1}^k {{{\\left( {\\frac{A}{{1 - {\\rho ^2}}}} \\right)}^2}{\\rho ^{2k}}} }_{0 < m \\le k} + \\underbrace {\\sum\\limits_{m = k + 1}^{ + \\infty } {{{\\left( {\\frac{A}{{1 - {\\rho ^2}}}} \\right)}^2}{\\rho ^{2m}}} }_{k < m \\le \\infty } \\end{array}$$ The two sums in Equation 11.35 converge yielding for \\(k \\ge 0\\) : (11.36) $$\\begin{array}{l} \\sum\\limits_{m = 0}^{ + \\infty } {{\\varphi _{vv}}[m + k]{\\varphi _{vv}}[m - k]} = {\\left( {\\frac{A}{{1 - {\\rho ^2}}}} \\right)^2}{\\rho ^{2k}}\\,\\, + \\\\ \\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,{\\left( {\\frac{A}{{1 - {\\rho ^2}}}} \\right)^2}k{\\rho ^{2k}} + {\\left( {\\frac{A}{{1 - {\\rho ^2}}}} \\right)^2}\\frac{{{\\rho ^{2(k + 1)}}}}{{1 - {\\rho ^2}}} \\end{array}$$ Combining the even term for \\(k < 0\\) gives the final result: (11.37) $$\\begin{array}{l} {\\Phi _{vv}}[k] = \\frac{{{A^2}(1 + {\\rho ^2})}}{{{{(1 - {\\rho ^2})}^3}}} + {\\left( {\\frac{A}{{1 - {\\rho ^2}}}} \\right)^2}{\\rho ^{2\\left| k \\right|}}\\,\\, + \\\\ \\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,2{\\left( {\\frac{A}{{1 - {\\rho ^2}}}} \\right)^2}\\left| k \\right|{\\rho ^{2\\left| k \\right|}} + 2{\\left( {\\frac{A}{{1 - {\\rho ^2}}}} \\right)^2}\\frac{{{\\rho ^{2(\\left| k \\right| + 1)}}}}{{1 - {\\rho ^2}}} \\end{array}$$ Rewriting these terms yields: (11.38) $$\\begin{array}{l} {\\Phi _{vv}}[k] = \\frac{{{A^2}}}{{{{(1 - {\\rho ^2})}^3}}}\\,\\,\\, \\times \\\\ \\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\left( {1 + {\\rho ^2} + (1 - 2\\left| k \\right|){\\rho ^{2\\left| k \\right| + 2}} + (1 + 2\\left| k \\right|){\\rho ^{2\\left| k \\right|}}} \\right) \\end{array}$$ In Figure 11.5 we show the behavior of the function \\({\\Phi _{vv}}[k]\\) for several values of the parameter \\(\\rho.\\) Figure 11.5: Function \\({\\Phi _{vv}}[k\\rbrack\\) for the estimate of the variance of the autocorrelation function of the Langevin velocity process. ( grey ) \\({\\Phi _{vv}}[k\\rbrack\\) for \\(\\rho = 0.9,\\) ( blue ) \\({\\Phi _{vv}}[k\\rbrack\\) for \\(\\rho = 0.875,\\) ( red ) \\({\\Phi _{vv}}[k\\rbrack\\) for \\(\\rho = 0.85.\\) All are plotted for \\(A = 1.\\) This continuation of the case study of the Langevin equation that was begun in Chapter 7 shows how the estimation of an important descriptor of that random process, the autocorrelation function, can be analyzed. The differential equation\u2014and hence the resulting difference equation\u2014was first order. See Equation 7.1 and Equation 7.5 . As a consequence the results presented here are applicable for most first-order processes. Trouble in paradise \u00b6 We return to our general remarks concerning the variance of the estimate of the autocorrelation function. If \\(\\Phi [k]\\) is bounded (as in the above example with \\({\\Phi _{\\max }}\\) from Equation 11.29 ), that is, if \\(\\left| {\\Phi [k]} \\right| < \\infty\\) for all \\(\\left| k \\right| < N,\\) we might think that Equation 11.27 implies that the variance goes to zero as \\({N^{ - 1}}.\\) This, however, is not true for all values of \\(k.\\) As \\(\\left| k \\right| \\to N\\) the variance diverges (blows-up) independent of how large \\(N\\) is! Thus the estimate given in Equation 11.22 is not consistent. We might try, instead, a different estimate of the autocorrelation function. Specifically, (11.39) $$\\begin{array}{*{20}{l}} {{{\\hat c}_{xx}}[k]}&{ = \\frac{1}{N}\\sum\\limits_{n = 0}^{N - \\left| k \\right| - 1} {x[n]x[n + k]} }\\\\ {\\,\\,\\,}&{ = \\left( {\\frac{{N - \\left| k \\right|}}{N}} \\right){c_{xx}}[k]} \\end{array}$$ The simple relation between the two estimates for \\({\\varphi _{xx}}[k]\\) gives: (11.40) $$E\\left\\{ {{{\\hat c}_{xx}}[k]} \\right\\} = \\left( {\\frac{{N - \\left| k \\right|}}{N}} \\right){\\varphi _{xx}}[k]$$ Clearly \\({\\hat c_{xx}}[k]\\) is a biased estimate, an underestimate . The variance, however, is (11.41) $$Var\\{ {\\hat c_{xx}}[k]\\} = {\\left( {\\frac{{N - \\left| k \\right|}}{N}} \\right)^2}Var\\{ {c_{xx}}[k]\\} = \\frac{1}{N}\\Phi$$ which converges to zero as \\(N \\to \\infty.\\) We are faced with a choice: if we choose \\({c_{xx}}[k]\\) we have an estimate of \\({\\varphi _{xx}}[k]\\) that is unbiased but blows up (diverges) as \\(\\left| k \\right| \\to N.\\) This occurs because as \\(\\left| k \\right|\\) approaches \\(N,\\) there are very few overlapping data samples\u2014see Movie 11.2 \u2014and thus the variance associated with the estimate is large. If we choose \\({\\hat c_{xx}}[k]\\) we have an estimate that converges nicely as \\(N \\to \\infty\\) but is biased; it is an underestimate. Such a trade-off between desired properties is not uncommon in the estimation of parameters of stochastic signals. In this chapter we have looked at the estimation of the mean Equation 11.1 and the correlation function Equation 11.2 . In the next chapter we will consider the problem of estimating the power spectral density Equation 11.3 . Problems \u00b6 Problem 11.1 \u00b6 We are given a function of \\(x\\) that is non-negative, that is, \\(f(x) \\ge 0\\) for all \\(x.\\) Show that the values of \\(x\\) for which \\(\\ln \\left( {f(x)} \\right)\\) has an extremum are also values of \\(x\\) where \\(f(x)\\) has an extremum. Problem 11.2 \u00b6 The Gaussian (normal) probability density function is given by: \\[p\\left( {x\\left|\\,{\\mu ,\\sigma } \\right.} \\right) = \\frac{1}{{\\sqrt {2\\pi } \\sigma }}{e^{ - {{(x - \\mu )}^2}/2{\\sigma ^2}}}\\] Determine a maximum-likelihood estimate for \\(\\mu\\) given \\(N\\) data samples \\(\\left\\{ {{x_1},{x_2},...,{x_N}} \\right\\}.\\) Assume that \\(\\sigma\\) is known. Problem 11.3 \u00b6 We wish to determine if a coin is \u201cfair\u201d. We flip the coin \\(N\\) times at 10:00 in the morning and write down the number of \u201cHeads\u201d \\(n.\\) We then repeat this process for \\(M\\) days. What is the ML-estimate for the probability of Heads, \\(p = p(Heads)?\\) Why might the time of performing this experiment be relevant? Problem 11.4 \u00b6 The probability density function for the emission of the first photon from a fluorescent sample in the time interval \\((0,t)\\) is given by: \\[p\\left( {t\\left| {\\,\\lambda } \\right.} \\right) = \\lambda t{e^{ - \\lambda t}}\\,\\,\\,\\,\\,\\,\\,\\,t \\geqslant 0\\] We have a series of independent measurements for the emission times of first photons from identical molecules \\(\\left\\{ {{t_1},{t_2},{t_3},...,{t_N}} \\right\\}.\\) Determine the ML-estimate for \\(\\lambda.\\) What is the relation between \\({\\lambda _{ML}}\\) from part ( a ) and the harmonic mean given in Equation 11.6 ? Problem 11.5 \u00b6 Let a random process have a parameter\u2014for example the mean or variance\u2014whose true (non-random) value is \\(a\\) and whose estimate is \\(\\hat a.\\) The mean-square error associated with this estimate is given by \\(e\\) : (11.42) $$e = E\\left\\{ {{{\\left( {\\hat a - a} \\right)}^2}} \\right\\}$$ Let \\({\\tilde a}\\) be the unbiased estimate of \\(a,\\) that is \\(B = E\\left\\{ {\\tilde a} \\right\\} - a = 0.\\) Show that if the goal is to minimize the mean-square error \\(e,\\) then the best estimate for \\(a\\) is the unbiased estimate, that is \\(\\hat a = \\tilde a.\\) Hint : Consider replacing \\({\\left( {\\hat a - a} \\right)}\\) with \\(\\left( {\\hat a - \\tilde a + \\tilde a - a} \\right).\\) Problem 11.6 \u00b6 We know from Equation 4.18 that for any random variable \\(\\theta\\) where the mean and variance exist (that is, are finite) we have \\(Var\\left( \\theta \\right) = E\\left\\{ {{\\theta ^2}} \\right\\} - {\\left( {E\\left\\{ \\theta \\right\\}} \\right)^2}.\\) If \\({\\theta _o}\\) is the true value of a parameter of a distribution, such as the mean or variance, and \\(\\theta\\) is an estimate of \\({\\theta _o}\\) based upon collected data, then \\(\\theta - {\\theta _o}\\) is also a random variable and we have: (11.43) $$Var(\\theta - {\\theta _o}) = E\\left\\{ {{{(\\theta - {\\theta _o})}^2}} \\right\\} - {\\left( {E\\left\\{ {\\theta - {\\theta _o}} \\right\\}} \\right)^2}$$ Use this to show that: (11.44) $$e = Var(\\theta ) + {B^2}(\\theta )$$ where, as in Equation 11.42 , \\(e\\) is the mean square error in the estimate of \\(\\theta\\) and \\(B\\) is the bias in the estimate. Hint : This might be a good time to review Problem 4.4 . Problem 11.7 \u00b6 Consider an ergodic Gaussian random process \\(x\\) which, without loss of generality, is standardized. That is, \\({\\mu _x} = 0\\) and \\({\\sigma _x} = 1.\\) (See Problem 4.9 .) We wish to estimate the variance of this process based upon \\(N\\) samples. We propose an estimator of the form: (11.45) $$s_x^2 = \\frac{1}{K}\\sum\\limits_{n = 1}^N {{{\\left( {{x_n} - < x > } \\right)}^2}}$$ where \\(< x >\\) is the arithmetic mean Equation 11.4 of the \\(N\\) samples of \\(x.\\) In this problem we will explore the consequences of choosing different values for \\(K.\\) It can be shown that: (11.46) $$\\frac{1}{{\\sigma _x^2}}\\sum\\limits_{n = 1}^N {{{\\left( {{x_n} - < x > } \\right)}^2}}$$ is a Chi-squared ( \\({\\chi ^2}\\) ) distributed random variable with \\(N - 1\\) degrees-of-freedom ( dof ); see Cram\u00e9r 5 . The mean and variance of a \\({\\chi ^2}\\) distributed random variable are dof and 2\u2022 dof , respectively. Determine the bias \\(B\\) associated with the estimate for the variance \\(\\sigma _x^2.\\) How should Equation 11.45 be modified if the estimate is to be unbiased, that is, \\(B = 0?\\) What is the variance associated with the estimate in Equation 11.45 ? What does this become if the unbiased version of Equation 11.45 is used? Is the unbiased estimate of the variance a consistent estimator? Using Equation 11.44 , what value of \\(K\\) in Equation 11.45 yields a minimum mean-square error \\(e?\\) Is this the same value of \\(K\\) that you found for an unbiased estimate in part ( b ) of this problem? Is Equation 11.45 a minimum-variance unbiased estimator (MVUE)? Problem 11.8 \u00b6 The real, ergodic, stochastic signal \\(x[n]\\) is characterized by a mean value of \\({m_x} = < x[n] > = 0\\) and an autocorrelation \\({\\varphi _{xx}}[k] = < x[n]{x^*}[n + k] >.\\) Let \\(y[n] = A \\bullet x[n]\\) where \\(A\\) is a constant to be determined. Find the value of \\(A\\) that minimizes \\({\\varphi _{ee}}[k]\\) where \\(e[n] = y[n] - x[n - N]\\) for a fixed value of \\(N.\\) That is, we wish \\(y[n]\\) to be a least-mean-square predictor of \\(x[n]\\) and \\(e[n]\\) represents the error in the prediction at any given time. Discuss your result for the two extreme cases: \\(N = 0\\) \\(N >> 0\\) where we assume that \\(x[n]\\) and \\(x[n - N]\\) are essentially uncorrelated. Problem 11.9 \u00b6 We have from Equation 11.26 that: (11.47) $$\\begin{array}{*{20}{l}} {\\Phi [k]}&{ = \\sum\\limits_{m = - \\infty }^{ + \\infty } {\\left( {\\varphi _{xx}^2[m] + {\\varphi _{xx}}[m + k]{\\varphi _{xx}}[m - k]} \\right)} }\\\\ {\\,\\,\\,}&{ = \\sum\\limits_{m = - \\infty }^{ + \\infty } {\\varphi _{xx}^2[m]} + \\sum\\limits_{m = - \\infty }^{ + \\infty } {{\\varphi _{xx}}[m + k]{\\varphi _{xx}}[m - k]} } \\end{array}$$ Assume that the random variable \\(x\\) is real. Using Equation 5.5 prove that \\({{\\varphi _{xx}}[m + k]{\\varphi _{xx}}[m - k]}\\) is even in \\(m.\\) As indicated in the text, the second term, which has the form \\(\\sum {{\\varphi _{xx}}[m + k]{\\varphi _{xx}}[m - k]},\\) is an autocorrelation function. Let us call it \\({\\psi _{xx}}[k].\\) Determine the power spectral density \\({S_{\\psi \\psi }}(\\Omega ) = {\\mathscr{F}}\\left\\{ {{\\psi _{xx}}[k]} \\right\\}\\) in terms of \\({S_{xx}}(\\Omega )\\) and \\(X(\\Omega ).\\) Determine the maximum value of \\({\\Phi _{vv}}[k],\\) the complicated term involved in the variance of the estimate of the autocorrelation function of the Langevin velocity process. Your result should be in terms of \\(A\\) and \\(\\rho.\\) You might also want to review Chapter 7 and Chapter 7 . You are required to keep \\(N\\) and \\(k\\) constant in Equation 11.25 and you wish to decrease the variance of your estimate of the autocorrelation function of the Langevin velocity process in part ( c ). Should you raise or lower the temperature \\(\\Psi\\) at which an experiment is performed? Does your mathematical result agree with your physical intuition? Explain your reasoning. Again, you might want to review Chapter 7 . Problem 11.10 \u00b6 Show that for \\(0 < m \\le k\\) that the term \\({\\varphi _{vv}}[m + k]{\\varphi _{vv}}[m - k]\\) in Equation 11.31 becomes: (11.48) $${\\varphi _{vv}}[m + k]{\\varphi _{vv}}[m - k] = {\\left( {\\frac{A}{{1 - {\\rho ^2}}}} \\right)^2}{\\rho ^{2k}}$$ Hint : Use the evenness properties of Problem 11.9 . Laboratory Exercises \u00b6 Laboratory Exercise 11.1 \u00b6 There is more than just one \u201cmean\u201d. And depending upon the nature of an estimation problem, one may be more suitable than another. That is no mean feat. To start the exercise, click on the icon to the left. Laboratory Exercise 11.2 \u00b6 Is precision the same as accuracy? Answer the question now and then answer the question after the exercise. To start the exercise, click on the icon to the left. Laboratory Exercise 11.3 \u00b6 Can you measure a distance of 1 mm with a ruler that is only marked in centimeters? Or how about the length of a bridge that is less than a mile long with an odometer that only reports whole (integer) miles? To start the exercise, click on the icon to the left. van den Bos, A. (2007). Parameter Estimation for Scientists and Engineers. Hoboken, New Jersey, Wiley-Interscience \u21a9 The usual definition of \u201cconsistent\u201d involves the convergence in probability of the estimate. By using the Tchebyshev inequality in probability theory it can be shown that the two definitions are equivalent. \u21a9 Bartlett, M. S. (1946). \u201cOn the theoretical specification and sampling properties of autocorrelated time series.\u201d Journal of the Royal Statistical Society Suppplement, Vol. 8(1) \u21a9 Jenkins, G. M. and D. G. Watts (1998). Spectral Analysis and Its Applications, Emerson Adams Press \u21a9 Cram\u00e9r, H. (1946). Mathematical Methods of Statistics. Princeton, New Jersey, Princeton University Press, Section 18.1 \u21a9","title":"11. Aspects of Estimation"},{"location":"Chap_11.html#aspects-of-estimation","text":"In this and the next chapter we will look at the problem of estimating the parameters of a stochastic process from experimental data. That is, how to estimate: (11.1) $${m_x} = E\\left\\{ {x[n]} \\right\\} = \\; < x[n] >$$ (11.2) $${\\varphi _{xx}}[k] = E\\left\\{ {x[n]{x^*}[n + k]} \\right\\} = \\; < x[n]{x^*}[n + k] >$$ (11.3) $${S_{xx}}(\\Omega ) = {\\mathscr{F}}\\left\\{ {{\\varphi _{xx}}[k]} \\right\\}$$ There is a formal theory of estimation that addresses a variety of issues and the development of that theory can be quite complicated. An introduction can be found in van den Bos 1 . Instead we look at a few simple criteria. To estimate the mean of a process given \\(N\\) samples, we might, for example, use one of the following: arithmetic mean: (11.4) $${\\mu _A} = \\,\\, < x[n]{ > _A}\\; = \\frac{1}{N}\\sum\\limits_{n = 0}^{N - 1} {x[n]}$$ geometric mean: (11.5) $${\\mu _G} = \\,\\,\\, < x[n]{ > _G}\\; = {\\left( {\\prod\\limits_{n = 0}^{N - 1} {x[n]} } \\right)^{1/N}}$$ harmonic mean: (11.6) $${\\mu _H} = \\,\\,\\, < x[n]{ > _H}\\; = N{\\left( {\\sum\\limits_{n = 0}^{N - 1} {\\frac{1}{{x[n]}}} } \\right)^{ - 1}}$$ These three ways of defining a mean are collectively referred to as the Pythagorean means and, as one might expect, there are useful relationships among the three. From experience we expect that Equation 11.4 will be the preferred form and, in fact, this can be shown from \u201cmaximum likelihood\u201d estimation theory under many hypotheses. There are, however, numerous examples that can be found in finance, economics, the social sciences, and the physical sciences where one of the other two means is to be preferred. Let us look at how a choice is made.","title":"Aspects of Estimation"},{"location":"Chap_11.html#maximum-likelihood-estimation","text":"We assume that \\(N\\) independent measurements have been made of an ergodic random process that is described by the probability distribution \\(p({x_i}|\\theta )\\) where \\(\\theta\\) is a parameter of the distribution. In the case of coin flipping that parameter might be \\(\\theta = p = p(Heads)\\) as described in Chapter 4 . The joint distribution of these \\(N\\) measurements is given by \\(p\\left( {{x_1},{x_2},{x_3},\\,...\\,,{x_N}|\\theta } \\right).\\) But because of the independence of these \\(N\\) measurements we can rewrite this using Equation 3.8 as: (11.7) $$p({x_1},{x_2},{x_3},...,{x_N}|\\theta ) = \\prod\\limits_{i = 1}^N {p({x_i}|\\theta )}$$ Given all of these measurements, the question is: How do we estimate \\(\\theta?\\) There are a variety of estimation criteria and the one we choose is maximum-likelihood estimation , ML-estimation. In this approach we choose the value of \\(\\theta = {\\theta _{ML}}\\) such that (11.8) $$p\\left( {{x_1},{x_2},{x_3},\\,...\\,,{x_N}|{\\theta _{ML}}} \\right) \\geqslant p\\left( {{x_1},{x_2},{x_3},\\,...\\,,{x_N}|{\\theta _o}} \\right)$$ where \\({\\theta _{ML}} \\ne {\\theta _o}.\\) In words, the ML-estimate of the parameter \\(\\theta\\) is the estimate that gives the maximum probability (likelihood) of collecting the data that we have just acquired. To see how this is used in practice let us look at a specific example.","title":"Maximum-likelihood estimation"},{"location":"Chap_11.html#example-estimating-the-poisson-rate","text":"In this example we refer to the Poisson random process defined in Chapter 8 . We repeat the definition of the Poisson probability distribution: (11.9) $$p(n|\\lambda T) = \\frac{{{{\\left( {\\lambda T} \\right)}^n}{e^{ - \\lambda T}}}}{{n!}}$$ where \\(\\lambda\\) is the number of events per unit \u201ctime\u201d and \\(T\\) is the duration of an observation window. We see that \\(\\theta = \\lambda T.\\) To find the ML-estimate of \\(\\theta\\) given \\(N\\) measurements of, say, photon emission \\(\\left\\{ {{n_1},{n_2},\\,...\\,,{n_N}|\\theta } \\right\\}\\) we use the result in Equation 11.7 to write the likelihood function \\(L(\\theta )\\) : (11.10) $$L(\\theta ) = \\prod\\limits_{i = 1}^N {p({n_i}|\\theta )} = \\prod\\limits_{i = 1}^N {\\frac{{{\\theta ^{{n_i}}}{e^{ - \\theta }}}}{{{n_i}!}}}$$ We seek the value of \\(\\theta\\) that maximizes \\(L(\\theta ).\\) At first glance this might seem like an intractable problem. One of the standard procedures\u2014a.k.a. \u201ctricks of the trade\u201d\u2014can, however, be applied. It is not difficult to show that if \\({\\theta _{ML}}\\) maximizes \\(\\ln \\left[ {L(\\theta )} \\right]\\) \u2014where \\(\\ln\\) is the natural logarithm function\u2014then it maximizes \\(L(\\theta )\\) as well. See Problem 11.1 . Applying this gives: (11.11) $$\\begin{array}{*{20}{l}} {\\ln \\left[ {L(\\theta )} \\right]}&{ = \\ln \\left[ {\\prod\\limits_{i = 1}^N {\\frac{{{\\theta ^{{n_i}}}{e^{ - \\theta }}}}{{{n_i}!}}} } \\right] = \\sum\\limits_{i = 1}^N {\\ln } \\left[ {\\frac{{{\\theta ^{{n_i}}}{e^{ - \\theta }}}}{{{n_i}!}}} \\right]}\\\\ {\\,\\,\\,}&{ = \\sum\\limits_{i = 1}^N {{n_i}\\ln } \\left( \\theta \\right) - \\sum\\limits_{i = 1}^N \\theta - \\sum\\limits_{i = 1}^N {n!} } \\end{array}$$ To find the maximum (extremum actually) we set the derivative with respect to \\(\\theta\\) to zero. (11.12) $$\\begin{array}{*{20}{l}} {\\frac{{\\partial \\ln \\left[ {L(\\theta )} \\right]}}{{\\partial \\theta }}}&{ = \\frac{\\partial }{{\\partial \\theta }}\\left( {\\sum\\limits_{i = 1}^N {{n_i}\\ln } \\left( \\theta \\right) - \\sum\\limits_{i = 1}^N \\theta - \\sum\\limits_{i = 1}^N {n!} } \\right)}\\\\ {\\,\\,\\,}&{ = \\frac{1}{\\theta }\\sum\\limits_{i = 1}^N {{n_i}} - N = 0} \\end{array}$$ (How would you show that this extremum is a maximum as opposed to a minimum or saddle point?) Solving for \\(\\theta\\) gives the ML-estimate: (11.13) $$\\frac{1}{\\theta }\\sum\\limits_{i = 1}^N {{n_i}} - N = 0\\,\\,\\,\\,\\,\\,\\, \\Rightarrow \\,\\,\\,\\,\\,\\,{\\theta _{ML}} = \\frac{1}{N}\\sum\\limits_{i = 1}^N {{n_i}}$$ The ML-estimate of the parameter \\(\\theta = \\lambda T\\) is simply the arithmetic average ( \\({\\mu _A}\\) ) of the measurements. Other examples can be found in Problem 11.2 .","title":"Example: Estimating the Poisson rate"},{"location":"Chap_11.html#but-is-it-a-good-estimate","text":"In a given formula such as Equation 11.4 we might also ask: On the average does the formula give the \u201cright\u201d answer? If we take a very large number of samples will our estimation error become smaller? With regard to the first question we introduce a concept that is central to obtaining good estimates: the concept of bias . Formally if \\(a\\) is a (deterministic) parameter of a random process and \\(\\hat a\\) is the estimate of \\(a\\) then the bias \\(B\\) is: (11.14) $$B = E\\left\\{ {\\hat a} \\right\\} - a$$ We should remember that \\(\\hat a\\) is a random variable because it is a function of random data. If \\(B > 0\\) we have an overestimate of \\(a\\) and if \\(B < 0\\) we have an underestimate. We define an unbiased estimate as one that has \\(B = 0.\\) An unbiased estimate is desirable because it means that the estimate will be neither consistently too high nor consistently too low. Continuing, we define the mean-square error between the parameter and its estimate as (11.15) $$e = E\\left\\{ {{{\\left( {\\hat a - a} \\right)}^2}} \\right\\}$$ We will show in Problem 11.5 that choosing an unbiased estimate ( \\(B = 0\\) ) can, under certain circumstances, minimize the mean-square error measure. In Problem 11.6 and Problem 11.7 we will show that this is not always the case. When it is the case, the estimators are referred to as minimum-variance unbiased estimators ( MVUE ). An unbiased estimate\u2014whether it is minimum-variance or not\u2014is frequently referred to as an accurate estimate. In reformulating the second question we see that the central issue is convergence. It should be obvious that if the value of a parameter \\(\\theta\\) is \\(2/\\pi\\) \u2014see Buffon\u2019s needle \u2014and we have \\(N = 37\\) samples from an experiment designed to estimate \\(\\theta,\\) then it will not be possible to get the exact value. By increasing \\(N,\\) however, we would hope to improve our estimate. In other words, we would like the error, as we continue to use more data in our estimate, to go to zero. Formally, we want \\(\\sigma _a^2 \\to 0\\) as the number of samples \\(N \\to \\infty.\\) That is, the variance (or its square root, the standard deviation) of the estimate should go to zero as the number of samples becomes very large. As the variance of the estimate goes to zero, we describe the estimate as becoming more precise . If in the limit as \\(N \\to \\infty\\) both the bias and the variance go to zero, we say that the estimate is consistent 2 . This type of behavior is illustrated in Figure 11.1 . Figure 11.1: The convergence of an estimate \\(\\hat a\\) to \\(a\\) as the number of samples \\(N\\) involved in the estimation procedure increases. As \\(N\\) increases the uncertainty in the estimate, as measured by the standard deviation, decreases. The green curve is for the number of samples \\({N_3},\\) the red curve for \\({N_2}\\) and the blue curve for \\({N_1}\\) where \\({N_3} > {N_2} > {N_1}.\\) A convenient way to remember the concepts of accuracy and precision and to distinguish between them is through a (hypothetical) game of darts where the goal is to throw \\(N\\) darts such that each one lands in the center of the dart board, in the \u201cbullseye\u201d. This is illustrated in Figure 11.2 . Figure 11.2: ( left ) Placement of five darts by one player showing high accuracy but low precision . ( right ) Placement of five darts by a second player showing low accuracy but high precision . The \u201cintuitive\u201d meanings of the words accurate and precise are illustrated here and intended to serve as a permanent reminder.","title":"But is it a \u201cgood\u201d estimate?"},{"location":"Chap_11.html#estimating-the-mean","text":"As an example consider \\({m_x} = E\\left\\{ {x[n]} \\right\\}.\\) We look at the arithmetic estimate for \\({m_x}\\) given by: (11.16) $$< x[n] > \\; = \\frac{1}{N}\\sum\\limits_{n = 0}^{N - 1} {x[n]}$$ We determine the bias as follows: (11.17) $$E\\left\\{ { < x[n] > } \\right\\}\\; = \\frac{1}{N}\\sum\\limits_{n = 0}^{N - 1} {E\\left\\{ {x[n]} \\right\\}} = {m_x}$$ (11.18) $$B = E\\left\\{ { < x[n] > } \\right\\} - {m_x} = {m_x} - {m_x} = 0$$ Thus the arithmetic mean generates an unbiased estimate of the true mean. The variance, \\(Var( \\bullet ),\\) of the estimate is: (11.19) $$\\sigma _N^2 = Var\\left\\{ {\\frac{1}{N}\\sum\\limits_{n = 0}^{N - 1} {x[n]} } \\right\\} = \\frac{1}{{{N^2}}}\\sum\\limits_{n = 0}^{N - 1} {Var\\left\\{ {x[n]} \\right\\}}$$ This right-most term follows from the assumption that the data samples \\(\\{ x[n]\\}\\) are statistically independent of one another. Continuing, (11.20) $$\\sigma _N^2 = \\frac{1}{{{N^2}}}\\sum\\limits_{n = 0}^{N - 1} {\\sigma _x^2} = \\frac{1}{{{N^2}}}N\\sigma _x^2 = \\frac{{\\sigma _x^2}}{N}$$ Thus, as the number of samples \\(N \\to \\infty,\\) the variance of the estimate goes to zero as \\(1/N.\\) Because the bias \\(B\\) is zero and the variance goes to zero for large \\(N,\\) we see that the estimate for the mean of a random process based upon Equation 11.16 is a consistent estimate. An illustration of how the estimate shown in Figure 11.1 converges to a final value is shown in Movie 11.1 . Movie 11.1: Convergence of the estimate of a parameter as the number of samples $N$ increases. Note that the estimate is biased\u2014an overestimate\u2014but approaches the true value as $N \\to \\infty.$ The estimate is asymptotically unbiased . Further, the variance decreases as $N$ increases.","title":"Estimating the mean"},{"location":"Chap_11.html#estimating-the-autocorrelation-function","text":"We now look at a more difficult problem, that of estimating the autocorrelation function of a real, random process starting from statistically independent data samples. Formally, (11.21) $${\\varphi _{xx}}[k] = E\\left\\{ {x[n]{x^*}[n + k]} \\right\\} = \\;E\\left\\{ {x[n]x[n + k]} \\right\\}$$ If \\(N\\) samples of \\(\\{ x[n]\\}\\) are available then only \\(N - |k|\\) samples are available to compute the average of the product \\(x[n]\\,x[n + k].\\) This is illustrated graphically in Figure 11.3 and represents the fact that the number of overlaps between \\(x[n]\\) and \\(x[n + k]\\) will be \\(N - \\left| k \\right|.\\) Figure 11.3: ( top ) The original signal \\(x[n\\rbrack.\\) ( bottom ) The shifted version \\(x[n - k\\rbrack.\\) The overlap has the width \\(N - |k|\\) and the region is indicated in orange . A dynamic rendering of the overlap that occurs during the calculation of the correlation is shown in Movie 11.2 . Movie 11.2: As the autocorrelation of a finite duration signal is computed, the number of samples that overlap changes but is limited to $N - \\left| k \\right|.$ To estimate the mean of a parameter, we will use our result above, Equation 11.16 , applied to: (11.22) $${c_{xx}}[k] = \\frac{1}{{N - \\left| k \\right|}}\\sum\\limits_{n = 0}^{N - \\left| k \\right| - 1} {x[n]x[n + k]}$$ The variable \\(k\\) can be positive or negative but there will still be only \\(N - \\left| k \\right|\\) overlaps.","title":"Estimating the autocorrelation function"},{"location":"Chap_11.html#how-good-is-our-estimator","text":"The estimate of \\({\\varphi _{xx}}[k]\\) is \\({c_{xx}}[k].\\) Our first question is: Is this estimate unbiased? The bias is given by: (11.23) $$B = E\\left\\{ {{c_{xx}}[k]} \\right\\} - {\\varphi _{xx}}[k]$$ Using Equation 11.23 : (11.24) $$\\begin{array}{*{20}{l}} B&{ = E\\left\\{ {\\frac{1}{{N - \\left| k \\right|}}\\sum\\limits_{n = 0}^{N - \\left| k \\right| - 1} {x[n]x[n + k]} } \\right\\} - {\\varphi _{xx}}[k]}\\\\ {\\,\\,\\,}&{ = \\frac{1}{{N - \\left| k \\right|}}\\sum\\limits_{n = 0}^{N - \\left| k \\right| - 1} {E\\left\\{ {x[n]x[n + k]} \\right\\}} - {\\varphi _{xx}}[k]}\\\\ {\\,\\,\\,}&{ = \\frac{1}{{N - \\left| k \\right|}}\\sum\\limits_{n = 0}^{N - \\left| k \\right| - 1} {{\\varphi _{xx}}[k]} - {\\varphi _{xx}}[k]} \\end{array}$$ If \\(\\left| k \\right| < N\\) we have \\(B = 0,\\) an unbiased estimate. Our next question concerns the issue of whether \\({c_{xx}}[k]\\) forms a consistent estimate of \\({\\varphi _{xx}}[k].\\) Since we know that the estimate is unbiased, it remains to be shown that the variance of the estimate goes to zero as the number of data samples \\(N\\) increases. The variance of the estimate, \\(Var\\{ {c_{xx}}[k]\\},\\) is given (for large \\(N\\) ) by: (11.25) $$\\begin{array}{*{20}{l}} {Var\\{ {c_{xx}}[k]\\} \\approx \\frac{N}{{{{\\left( {N - \\left| k \\right|} \\right)}^2}}}\\, \\times }\\\\ {\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\left( {\\sum\\limits_{m = - \\infty }^{ + \\infty } {\\left( {\\varphi _{xx}^2[m] + {\\varphi _{xx}}[m + k]{\\varphi _{xx}}[m - k]} \\right)} } \\right)} \\end{array}$$ where formal derivation of the term under the summation is too complicated (and tedious) to be worked out in detail here; see Bartlett 3 and Jenkins 4 , instead. We now define a function (11.26) $$\\Phi [k] = \\sum\\limits_{m = - \\infty }^{ + \\infty } {\\left( {\\varphi _{xx}^2[m] + {\\varphi _{xx}}[m + k]{\\varphi _{xx}}[m - k]} \\right)}$$ which leads to: (11.27) $$Var\\{ {c_{xx}}[k]\\} \\approx \\frac{N}{{{{\\left( {N - \\left| k \\right|} \\right)}^2}}}\\Phi [k]$$ Let us look at \\(\\Phi [k]\\) in more detail. It consists of two terms: (11.28) $$\\Phi [k] = \\sum\\limits_{m = - \\infty }^{ + \\infty } {\\varphi _{xx}^2[m]} + \\sum\\limits_{m = - \\infty }^{ + \\infty } {{\\varphi _{xx}}[m + k]{\\varphi _{xx}}[m - k]}$$ The first term, assuming it converges, is a positive, real number and independent of \\(k.\\) The remark that it is real follows from our assumption at the beginning of a section in Chapter 11 . The second term is even in \\(k\\) as a simple substitution of \\(- k\\) shows. This means that \\(\\Phi [k]\\) is even. Further, the second term is itself an autocorrelation. Remembering our remarks at the beginning of Chapter 5 , the second term is the autocorrelation of the deterministic correlation function with itself! Using Equation 6.32 , this means the maximum value of \\(\\Phi [k]\\) is given by: (11.29) $${\\Phi _{\\max }} = 2\\sum\\limits_{m = - \\infty }^{ + \\infty } {\\varphi _{xx}^2[m]} \\,\\, \\ge \\,\\,\\Phi [k]\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\left| k \\right| < N$$ Other aspects of \\(\\Phi [k]\\) will be considered in Problem 11.9 . To better appreciate the behavior of \\(\\Phi [k]\\) and how that influences the variance of the estimate of the autocorrelation function \\(Var\\{ {c_{xx}}[k]\\},\\) let us look at one specific example.","title":"How good is our estimator?"},{"location":"Chap_11.html#langevin-redux","text":"In our case-study of the Langevin equation we saw in Equation 7.14 that the theory-based autocorrelation function for the stochastic velocity process was given by: (11.30) $${\\varphi _{vv}}[k] = {\\left( {\\frac{1}{m}} \\right)^2}\\left( {\\frac{{{F_o}}}{{1 - {\\rho ^2}}}} \\right){\\rho ^{\\left| k \\right|}} = \\frac{A}{{1 - {\\rho ^2}}}{\\rho ^{\\left| k \\right|}}$$ where \\(0 < \\rho = {e^{ - \\lambda {T_s}/m}} < 1\\) and the constant \\(A = {F_o}/{m^2}.\\) Velocity data collected from this type of study would then represent the basis for estimating \\({\\varphi _{vv}}[k].\\) What can we expect from \\({\\Phi _{vv}}[k],\\) the velocity example of \\(\\Phi [k],\\) based upon this Langevin assumption? This first term in Equation 11.28 can be computed directly and the result for \\({\\Phi _{vv}}[k]\\) becomes: (11.31) $${\\Phi _{vv}}[k] = \\frac{{{A^2}(1 + {\\rho ^2})}}{{{{(1 - {\\rho ^2})}^3}}} + \\sum\\limits_{m = - \\infty }^{ + \\infty } {{\\varphi _{vv}}[m + k]{\\varphi _{vv}}[m - k]} $$ Understanding the behavior of the second term can be gained by first plotting the various components \\({\\varphi _{vv}}[m + k],\\) \\({\\varphi _{vv}}[m - k],\\) and \\({\\varphi _{vv}}[m + k]{\\varphi _{vv}}[m - k].\\) This is illustrated in Figure 11.4 . Figure 11.4: ( red ) the function \\({\\varphi _{vv}}[m + k\\rbrack,\\) ( green ) the function \\({\\varphi _{vv}}[m - k\\rbrack,\\) and ( blue ) the function \\({\\varphi _{vv}}[m + k\\rbrack{\\varphi _{vv}}[m - k\\rbrack.\\) All are plotted for \\(A = 1,\\) \\(m = 5,\\) and \\(\\rho = 0.9.\\) It is clear from Figure 11.4 that \\({\\varphi _{vv}}[m + k]{\\varphi _{vv}}[m - k]\\) is even in \\(k\\) and even in \\(m.\\) The former has already been proven; the latter will be proven in Problem 11.9 . A consequence of the even symmetry is that to find \\({\\Phi _{vv}}[k]\\) we need only solve the problem for \\(k \\ge 0.\\) For \\(0 \\le k \\le m,\\) we have \\(m \\pm k \\ge 0\\) and it follows that: (11.32) $$\\begin{array}{*{20}{l}} {{\\varphi _{vv}}[m + k]{\\varphi _{vv}}[m - k]}&{ = {{\\left( {\\frac{A}{{1 - {\\rho ^2}}}} \\right)}^2}{\\rho ^{\\left| {m + k} \\right|}}{\\rho ^{\\left| {m - k} \\right|}}}\\\\ {\\,\\,\\,}&{ = {{\\left( {\\frac{A}{{1 - {\\rho ^2}}}} \\right)}^2}{\\rho ^{m + k}}{\\rho ^{m - k}} = {{\\left( {\\frac{A}{{1 - {\\rho ^2}}}} \\right)}^2}{\\rho ^{2m}}} \\end{array}$$ This is a constant independent of \\(k\\) and explains the \u201cflat behavior\u201d observed for \\(0 \\le k \\le m\\) in Figure 11.4 . Following replacement of \\(\\left| {m - k} \\right|\\) with \\(\\left| {k - m} \\right|\\) and for \\(0 \\le m \\le k,\\) we have \\(k \\pm m \\ge 0.\\) It follows that: (11.33) $$\\begin{array}{*{20}{l}} {{\\varphi _{vv}}[m + k]{\\varphi _{vv}}[m - k]}&{ = {{\\left( {\\frac{A}{{1 - {\\rho ^2}}}} \\right)}^2}{\\rho ^{\\left| {k + m} \\right|}}{\\rho ^{\\left| {k - m} \\right|}}}\\\\ {\\,\\,\\,}&{ = {{\\left( {\\frac{A}{{1 - {\\rho ^2}}}} \\right)}^2}{\\rho ^{k + m}}{\\rho ^{k - m}} = {{\\left( {\\frac{A}{{1 - {\\rho ^2}}}} \\right)}^2}{\\rho ^{2k}}} \\end{array}$$ This is an exponentially decreasing function for \\(k > 0\\) and explains the behavior observed for \\(0 \\le m \\le k\\) in Figure 11.4 . To continue, we deconstruct the sum in Equation 11.31 for \\(k \\ge 0\\) as follows: (11.34) $$\\begin{array}{l} \\sum\\limits_{m = 0}^{ + \\infty } {{\\varphi _{vv}}[m + k]{\\varphi _{vv}}[m - k]} = \\underbrace {{\\varphi _{vv}}[k]{\\varphi _{vv}}[k]}_{m = 0}\\,\\, + \\\\ \\,\\,\\,\\,\\,\\,\\,\\,\\,\\underbrace {\\sum\\limits_{m = 1}^k {{\\varphi _{vv}}[m + k]{\\varphi _{vv}}[m - k]} }_{0 < m \\le k}\\,\\,\\, + \\\\ \\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\underbrace {\\sum\\limits_{m = k + 1}^{ + \\infty } {{\\varphi _{vv}}[m + k]{\\varphi _{vv}}[m - k]} }_{k < m \\le \\infty } \\end{array}$$ Substituting the various terms we have already found: (11.35) $$\\begin{array}{l} \\sum\\limits_{m = 0}^{ + \\infty } {{\\varphi _{vv}}[m + k]{\\varphi _{vv}}[m - k]} = \\underbrace {{{\\left( {\\frac{A}{{1 - {\\rho ^2}}}} \\right)}^2}{\\rho ^{2k}}}_{m = 0}\\,\\, + \\\\ \\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\underbrace {\\sum\\limits_{m = 1}^k {{{\\left( {\\frac{A}{{1 - {\\rho ^2}}}} \\right)}^2}{\\rho ^{2k}}} }_{0 < m \\le k} + \\underbrace {\\sum\\limits_{m = k + 1}^{ + \\infty } {{{\\left( {\\frac{A}{{1 - {\\rho ^2}}}} \\right)}^2}{\\rho ^{2m}}} }_{k < m \\le \\infty } \\end{array}$$ The two sums in Equation 11.35 converge yielding for \\(k \\ge 0\\) : (11.36) $$\\begin{array}{l} \\sum\\limits_{m = 0}^{ + \\infty } {{\\varphi _{vv}}[m + k]{\\varphi _{vv}}[m - k]} = {\\left( {\\frac{A}{{1 - {\\rho ^2}}}} \\right)^2}{\\rho ^{2k}}\\,\\, + \\\\ \\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,{\\left( {\\frac{A}{{1 - {\\rho ^2}}}} \\right)^2}k{\\rho ^{2k}} + {\\left( {\\frac{A}{{1 - {\\rho ^2}}}} \\right)^2}\\frac{{{\\rho ^{2(k + 1)}}}}{{1 - {\\rho ^2}}} \\end{array}$$ Combining the even term for \\(k < 0\\) gives the final result: (11.37) $$\\begin{array}{l} {\\Phi _{vv}}[k] = \\frac{{{A^2}(1 + {\\rho ^2})}}{{{{(1 - {\\rho ^2})}^3}}} + {\\left( {\\frac{A}{{1 - {\\rho ^2}}}} \\right)^2}{\\rho ^{2\\left| k \\right|}}\\,\\, + \\\\ \\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,2{\\left( {\\frac{A}{{1 - {\\rho ^2}}}} \\right)^2}\\left| k \\right|{\\rho ^{2\\left| k \\right|}} + 2{\\left( {\\frac{A}{{1 - {\\rho ^2}}}} \\right)^2}\\frac{{{\\rho ^{2(\\left| k \\right| + 1)}}}}{{1 - {\\rho ^2}}} \\end{array}$$ Rewriting these terms yields: (11.38) $$\\begin{array}{l} {\\Phi _{vv}}[k] = \\frac{{{A^2}}}{{{{(1 - {\\rho ^2})}^3}}}\\,\\,\\, \\times \\\\ \\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\left( {1 + {\\rho ^2} + (1 - 2\\left| k \\right|){\\rho ^{2\\left| k \\right| + 2}} + (1 + 2\\left| k \\right|){\\rho ^{2\\left| k \\right|}}} \\right) \\end{array}$$ In Figure 11.5 we show the behavior of the function \\({\\Phi _{vv}}[k]\\) for several values of the parameter \\(\\rho.\\) Figure 11.5: Function \\({\\Phi _{vv}}[k\\rbrack\\) for the estimate of the variance of the autocorrelation function of the Langevin velocity process. ( grey ) \\({\\Phi _{vv}}[k\\rbrack\\) for \\(\\rho = 0.9,\\) ( blue ) \\({\\Phi _{vv}}[k\\rbrack\\) for \\(\\rho = 0.875,\\) ( red ) \\({\\Phi _{vv}}[k\\rbrack\\) for \\(\\rho = 0.85.\\) All are plotted for \\(A = 1.\\) This continuation of the case study of the Langevin equation that was begun in Chapter 7 shows how the estimation of an important descriptor of that random process, the autocorrelation function, can be analyzed. The differential equation\u2014and hence the resulting difference equation\u2014was first order. See Equation 7.1 and Equation 7.5 . As a consequence the results presented here are applicable for most first-order processes.","title":"Langevin redux"},{"location":"Chap_11.html#trouble-in-paradise","text":"We return to our general remarks concerning the variance of the estimate of the autocorrelation function. If \\(\\Phi [k]\\) is bounded (as in the above example with \\({\\Phi _{\\max }}\\) from Equation 11.29 ), that is, if \\(\\left| {\\Phi [k]} \\right| < \\infty\\) for all \\(\\left| k \\right| < N,\\) we might think that Equation 11.27 implies that the variance goes to zero as \\({N^{ - 1}}.\\) This, however, is not true for all values of \\(k.\\) As \\(\\left| k \\right| \\to N\\) the variance diverges (blows-up) independent of how large \\(N\\) is! Thus the estimate given in Equation 11.22 is not consistent. We might try, instead, a different estimate of the autocorrelation function. Specifically, (11.39) $$\\begin{array}{*{20}{l}} {{{\\hat c}_{xx}}[k]}&{ = \\frac{1}{N}\\sum\\limits_{n = 0}^{N - \\left| k \\right| - 1} {x[n]x[n + k]} }\\\\ {\\,\\,\\,}&{ = \\left( {\\frac{{N - \\left| k \\right|}}{N}} \\right){c_{xx}}[k]} \\end{array}$$ The simple relation between the two estimates for \\({\\varphi _{xx}}[k]\\) gives: (11.40) $$E\\left\\{ {{{\\hat c}_{xx}}[k]} \\right\\} = \\left( {\\frac{{N - \\left| k \\right|}}{N}} \\right){\\varphi _{xx}}[k]$$ Clearly \\({\\hat c_{xx}}[k]\\) is a biased estimate, an underestimate . The variance, however, is (11.41) $$Var\\{ {\\hat c_{xx}}[k]\\} = {\\left( {\\frac{{N - \\left| k \\right|}}{N}} \\right)^2}Var\\{ {c_{xx}}[k]\\} = \\frac{1}{N}\\Phi$$ which converges to zero as \\(N \\to \\infty.\\) We are faced with a choice: if we choose \\({c_{xx}}[k]\\) we have an estimate of \\({\\varphi _{xx}}[k]\\) that is unbiased but blows up (diverges) as \\(\\left| k \\right| \\to N.\\) This occurs because as \\(\\left| k \\right|\\) approaches \\(N,\\) there are very few overlapping data samples\u2014see Movie 11.2 \u2014and thus the variance associated with the estimate is large. If we choose \\({\\hat c_{xx}}[k]\\) we have an estimate that converges nicely as \\(N \\to \\infty\\) but is biased; it is an underestimate. Such a trade-off between desired properties is not uncommon in the estimation of parameters of stochastic signals. In this chapter we have looked at the estimation of the mean Equation 11.1 and the correlation function Equation 11.2 . In the next chapter we will consider the problem of estimating the power spectral density Equation 11.3 .","title":"Trouble in paradise"},{"location":"Chap_11.html#problems","text":"","title":"Problems"},{"location":"Chap_11.html#problem-111","text":"We are given a function of \\(x\\) that is non-negative, that is, \\(f(x) \\ge 0\\) for all \\(x.\\) Show that the values of \\(x\\) for which \\(\\ln \\left( {f(x)} \\right)\\) has an extremum are also values of \\(x\\) where \\(f(x)\\) has an extremum.","title":"Problem 11.1"},{"location":"Chap_11.html#problem-112","text":"The Gaussian (normal) probability density function is given by: \\[p\\left( {x\\left|\\,{\\mu ,\\sigma } \\right.} \\right) = \\frac{1}{{\\sqrt {2\\pi } \\sigma }}{e^{ - {{(x - \\mu )}^2}/2{\\sigma ^2}}}\\] Determine a maximum-likelihood estimate for \\(\\mu\\) given \\(N\\) data samples \\(\\left\\{ {{x_1},{x_2},...,{x_N}} \\right\\}.\\) Assume that \\(\\sigma\\) is known.","title":"Problem 11.2"},{"location":"Chap_11.html#problem-113","text":"We wish to determine if a coin is \u201cfair\u201d. We flip the coin \\(N\\) times at 10:00 in the morning and write down the number of \u201cHeads\u201d \\(n.\\) We then repeat this process for \\(M\\) days. What is the ML-estimate for the probability of Heads, \\(p = p(Heads)?\\) Why might the time of performing this experiment be relevant?","title":"Problem 11.3"},{"location":"Chap_11.html#problem-114","text":"The probability density function for the emission of the first photon from a fluorescent sample in the time interval \\((0,t)\\) is given by: \\[p\\left( {t\\left| {\\,\\lambda } \\right.} \\right) = \\lambda t{e^{ - \\lambda t}}\\,\\,\\,\\,\\,\\,\\,\\,t \\geqslant 0\\] We have a series of independent measurements for the emission times of first photons from identical molecules \\(\\left\\{ {{t_1},{t_2},{t_3},...,{t_N}} \\right\\}.\\) Determine the ML-estimate for \\(\\lambda.\\) What is the relation between \\({\\lambda _{ML}}\\) from part ( a ) and the harmonic mean given in Equation 11.6 ?","title":"Problem 11.4"},{"location":"Chap_11.html#problem-115","text":"Let a random process have a parameter\u2014for example the mean or variance\u2014whose true (non-random) value is \\(a\\) and whose estimate is \\(\\hat a.\\) The mean-square error associated with this estimate is given by \\(e\\) : (11.42) $$e = E\\left\\{ {{{\\left( {\\hat a - a} \\right)}^2}} \\right\\}$$ Let \\({\\tilde a}\\) be the unbiased estimate of \\(a,\\) that is \\(B = E\\left\\{ {\\tilde a} \\right\\} - a = 0.\\) Show that if the goal is to minimize the mean-square error \\(e,\\) then the best estimate for \\(a\\) is the unbiased estimate, that is \\(\\hat a = \\tilde a.\\) Hint : Consider replacing \\({\\left( {\\hat a - a} \\right)}\\) with \\(\\left( {\\hat a - \\tilde a + \\tilde a - a} \\right).\\)","title":"Problem 11.5"},{"location":"Chap_11.html#problem-116","text":"We know from Equation 4.18 that for any random variable \\(\\theta\\) where the mean and variance exist (that is, are finite) we have \\(Var\\left( \\theta \\right) = E\\left\\{ {{\\theta ^2}} \\right\\} - {\\left( {E\\left\\{ \\theta \\right\\}} \\right)^2}.\\) If \\({\\theta _o}\\) is the true value of a parameter of a distribution, such as the mean or variance, and \\(\\theta\\) is an estimate of \\({\\theta _o}\\) based upon collected data, then \\(\\theta - {\\theta _o}\\) is also a random variable and we have: (11.43) $$Var(\\theta - {\\theta _o}) = E\\left\\{ {{{(\\theta - {\\theta _o})}^2}} \\right\\} - {\\left( {E\\left\\{ {\\theta - {\\theta _o}} \\right\\}} \\right)^2}$$ Use this to show that: (11.44) $$e = Var(\\theta ) + {B^2}(\\theta )$$ where, as in Equation 11.42 , \\(e\\) is the mean square error in the estimate of \\(\\theta\\) and \\(B\\) is the bias in the estimate. Hint : This might be a good time to review Problem 4.4 .","title":"Problem 11.6"},{"location":"Chap_11.html#problem-117","text":"Consider an ergodic Gaussian random process \\(x\\) which, without loss of generality, is standardized. That is, \\({\\mu _x} = 0\\) and \\({\\sigma _x} = 1.\\) (See Problem 4.9 .) We wish to estimate the variance of this process based upon \\(N\\) samples. We propose an estimator of the form: (11.45) $$s_x^2 = \\frac{1}{K}\\sum\\limits_{n = 1}^N {{{\\left( {{x_n} - < x > } \\right)}^2}}$$ where \\(< x >\\) is the arithmetic mean Equation 11.4 of the \\(N\\) samples of \\(x.\\) In this problem we will explore the consequences of choosing different values for \\(K.\\) It can be shown that: (11.46) $$\\frac{1}{{\\sigma _x^2}}\\sum\\limits_{n = 1}^N {{{\\left( {{x_n} - < x > } \\right)}^2}}$$ is a Chi-squared ( \\({\\chi ^2}\\) ) distributed random variable with \\(N - 1\\) degrees-of-freedom ( dof ); see Cram\u00e9r 5 . The mean and variance of a \\({\\chi ^2}\\) distributed random variable are dof and 2\u2022 dof , respectively. Determine the bias \\(B\\) associated with the estimate for the variance \\(\\sigma _x^2.\\) How should Equation 11.45 be modified if the estimate is to be unbiased, that is, \\(B = 0?\\) What is the variance associated with the estimate in Equation 11.45 ? What does this become if the unbiased version of Equation 11.45 is used? Is the unbiased estimate of the variance a consistent estimator? Using Equation 11.44 , what value of \\(K\\) in Equation 11.45 yields a minimum mean-square error \\(e?\\) Is this the same value of \\(K\\) that you found for an unbiased estimate in part ( b ) of this problem? Is Equation 11.45 a minimum-variance unbiased estimator (MVUE)?","title":"Problem 11.7"},{"location":"Chap_11.html#problem-118","text":"The real, ergodic, stochastic signal \\(x[n]\\) is characterized by a mean value of \\({m_x} = < x[n] > = 0\\) and an autocorrelation \\({\\varphi _{xx}}[k] = < x[n]{x^*}[n + k] >.\\) Let \\(y[n] = A \\bullet x[n]\\) where \\(A\\) is a constant to be determined. Find the value of \\(A\\) that minimizes \\({\\varphi _{ee}}[k]\\) where \\(e[n] = y[n] - x[n - N]\\) for a fixed value of \\(N.\\) That is, we wish \\(y[n]\\) to be a least-mean-square predictor of \\(x[n]\\) and \\(e[n]\\) represents the error in the prediction at any given time. Discuss your result for the two extreme cases: \\(N = 0\\) \\(N >> 0\\) where we assume that \\(x[n]\\) and \\(x[n - N]\\) are essentially uncorrelated.","title":"Problem 11.8"},{"location":"Chap_11.html#problem-119","text":"We have from Equation 11.26 that: (11.47) $$\\begin{array}{*{20}{l}} {\\Phi [k]}&{ = \\sum\\limits_{m = - \\infty }^{ + \\infty } {\\left( {\\varphi _{xx}^2[m] + {\\varphi _{xx}}[m + k]{\\varphi _{xx}}[m - k]} \\right)} }\\\\ {\\,\\,\\,}&{ = \\sum\\limits_{m = - \\infty }^{ + \\infty } {\\varphi _{xx}^2[m]} + \\sum\\limits_{m = - \\infty }^{ + \\infty } {{\\varphi _{xx}}[m + k]{\\varphi _{xx}}[m - k]} } \\end{array}$$ Assume that the random variable \\(x\\) is real. Using Equation 5.5 prove that \\({{\\varphi _{xx}}[m + k]{\\varphi _{xx}}[m - k]}\\) is even in \\(m.\\) As indicated in the text, the second term, which has the form \\(\\sum {{\\varphi _{xx}}[m + k]{\\varphi _{xx}}[m - k]},\\) is an autocorrelation function. Let us call it \\({\\psi _{xx}}[k].\\) Determine the power spectral density \\({S_{\\psi \\psi }}(\\Omega ) = {\\mathscr{F}}\\left\\{ {{\\psi _{xx}}[k]} \\right\\}\\) in terms of \\({S_{xx}}(\\Omega )\\) and \\(X(\\Omega ).\\) Determine the maximum value of \\({\\Phi _{vv}}[k],\\) the complicated term involved in the variance of the estimate of the autocorrelation function of the Langevin velocity process. Your result should be in terms of \\(A\\) and \\(\\rho.\\) You might also want to review Chapter 7 and Chapter 7 . You are required to keep \\(N\\) and \\(k\\) constant in Equation 11.25 and you wish to decrease the variance of your estimate of the autocorrelation function of the Langevin velocity process in part ( c ). Should you raise or lower the temperature \\(\\Psi\\) at which an experiment is performed? Does your mathematical result agree with your physical intuition? Explain your reasoning. Again, you might want to review Chapter 7 .","title":"Problem 11.9"},{"location":"Chap_11.html#problem-1110","text":"Show that for \\(0 < m \\le k\\) that the term \\({\\varphi _{vv}}[m + k]{\\varphi _{vv}}[m - k]\\) in Equation 11.31 becomes: (11.48) $${\\varphi _{vv}}[m + k]{\\varphi _{vv}}[m - k] = {\\left( {\\frac{A}{{1 - {\\rho ^2}}}} \\right)^2}{\\rho ^{2k}}$$ Hint : Use the evenness properties of Problem 11.9 .","title":"Problem 11.10"},{"location":"Chap_11.html#laboratory-exercises","text":"","title":"Laboratory Exercises"},{"location":"Chap_11.html#laboratory-exercise-111","text":"There is more than just one \u201cmean\u201d. And depending upon the nature of an estimation problem, one may be more suitable than another. That is no mean feat. To start the exercise, click on the icon to the left.","title":"Laboratory Exercise 11.1"},{"location":"Chap_11.html#laboratory-exercise-112","text":"Is precision the same as accuracy? Answer the question now and then answer the question after the exercise. To start the exercise, click on the icon to the left.","title":"Laboratory Exercise 11.2"},{"location":"Chap_11.html#laboratory-exercise-113","text":"Can you measure a distance of 1 mm with a ruler that is only marked in centimeters? Or how about the length of a bridge that is less than a mile long with an odometer that only reports whole (integer) miles? To start the exercise, click on the icon to the left. van den Bos, A. (2007). Parameter Estimation for Scientists and Engineers. Hoboken, New Jersey, Wiley-Interscience \u21a9 The usual definition of \u201cconsistent\u201d involves the convergence in probability of the estimate. By using the Tchebyshev inequality in probability theory it can be shown that the two definitions are equivalent. \u21a9 Bartlett, M. S. (1946). \u201cOn the theoretical specification and sampling properties of autocorrelated time series.\u201d Journal of the Royal Statistical Society Suppplement, Vol. 8(1) \u21a9 Jenkins, G. M. and D. G. Watts (1998). Spectral Analysis and Its Applications, Emerson Adams Press \u21a9 Cram\u00e9r, H. (1946). Mathematical Methods of Statistics. Princeton, New Jersey, Princeton University Press, Section 18.1 \u21a9","title":"Laboratory Exercise 11.3"},{"location":"Chap_12.html","text":"Spectral Estimation \u00b6 We may not have an analytical model of a signal, its autocorrelation function, or its power spectral density. An example of this problem was presented in Chapter 5 . It should be clear that the phenomenon of weather is far too complex to admit an analytical solution for the autocorrelation function of the temperature \\({\\varphi _{TT}}[k]\\) or its power spectral density \\({S_{TT}}(\\Omega ).\\) We must work with estimates of these quantities. In the previous chapter we examined the central questions of estimation: bias and convergence applied to means, variances, and correlations. In this chapter we will look at the problem of estimating the power spectral density. Our estimate of the power spectrum of a random process is \\({I_N}(\\Omega ).\\) That is \\({I_N}(\\Omega )\\) is the estimate of \\({S_{xx}}(\\Omega ) = {\\mathscr{F}}\\left\\{ {{\\varphi _{xx}}[k]} \\right\\}.\\) We begin with a stochastic signal whose power spectral density is shown in Figure 8.2 and given, for \\({S_o} = 1\\) and \\(\\alpha = 4/7,\\) by Equation 8.10 : (12.1) $${S_{xx}}(\\Omega ) = \\frac{{{S_o}}}{{1 + {\\alpha ^2} - 2\\alpha \\cos \\Omega }} = \\frac{{49}}{{65 - 56\\cos \\Omega }}$$ We use the spectral estimator: (12.2) $${I_N}(\\Omega ) = {\\mathscr{F}}\\left\\{ {{{\\hat c}_{xx}}[k]} \\right\\} = \\sum\\limits_{k = 0}^{N - 1} {{{\\hat c}_{xx}}[k]} \\,{e^{ - j\\Omega k}}$$ But \\({{{\\hat c}_{xx}}[k]}\\) is, itself, formed with the aid of Equation 11.39 from \\(x[n]\\) and using basic Fourier theory: (12.3) $${I_N}(\\Omega ) = \\frac{1}{N}{\\left| {X(\\Omega )} \\right|^2}$$ The periodogram \u2013 unbiased? \u00b6 This basic estimate is referred to in the literature as a periodogram . The issue we will now examine is whether the periodogram \\({I_N}(\\Omega )\\) is a good estimate of \\({S_{xx}}(\\Omega ).\\) By now we understand that \u201cgood\u201d relates to the issues of bias and convergence. This bias is defined as: (12.4) $$B = E\\left\\{ {{I_N}(\\Omega )} \\right\\} - {S_{xx}}(\\Omega ) = B(\\Omega )$$ The term that must be investigated is: (12.5) $$\\begin{array}{*{20}{l}} {E\\left\\{ {{I_N}(\\Omega )} \\right\\}}&{ = E\\left\\{ {\\sum\\limits_{k = 0}^{N - 1} {{{\\hat c}_{xx}}[k]} \\,{e^{ - j\\Omega k}}} \\right\\}}\\\\ {\\,\\,\\,}&{ = \\sum\\limits_{k = 0}^{N - 1} {E\\left\\{ {{{\\hat c}_{xx}}[k]} \\right\\}\\,} {e^{ - j\\Omega k}}} \\end{array}$$ As the only term inside the first set of braces that is stochastic is \\({{{\\hat c}_{xx}}[k]},\\) we can exchange the order of expectation and summation. From Equation 11.40 we can replace the expectation as follows: (12.6) $$\\begin{array}{*{20}{l}} {E\\left\\{ {{I_N}(\\Omega )} \\right\\}}&{ = \\sum\\limits_{k = 0}^{N - 1} {\\left( {\\frac{{N - \\left| k \\right|}}{N}} \\right)} {\\varphi _{xx}}[k]{e^{ - j\\Omega k}}}\\\\ {\\,\\,\\,}&{ = \\sum\\limits_{k = 0}^{N - 1} {\\left( {1 - \\frac{{\\left| k \\right|}}{N}} \\right)} {\\varphi _{xx}}[k]{e^{ - j\\Omega k}}}\\\\ {\\,\\,\\,}&{ = \\sum\\limits_{k = 0}^{N - 1} {{\\varphi _{xx}}[k]{e^{ - j\\Omega k}}} - \\sum\\limits_{k = 0}^{N - 1} {\\frac{{\\left| k \\right|}}{N}{\\varphi _{xx}}[k]{e^{ - j\\Omega k}}} } \\end{array}$$ The first sum does not have the limits that we should expect from the formal definition of \\({S_{xx}}(\\Omega )\\) ; the variable \\(k\\) does not go from \\(- \\infty\\) to \\(+ \\infty.\\) See Equation 12.9 below. The second sum in Equation 12.6 shows clearly that the estimate is biased. Specifically, the term \\(\\left| k \\right|/N\\) would seem to indicate that \\(E\\left\\{ {{I_N}(\\Omega )} \\right\\}\\) is an underestimate. Thus the periodogram based upon \\({{{\\hat c}_{xx}}[k]}\\) is a biased estimate of \\({S_{xx}}(\\Omega ).\\) We might choose instead to consider the spectral estimate given by: (12.7) $${P_N}(\\Omega ) = {\\mathscr{F}}\\left\\{ {{c_{xx}}[k]} \\right\\} = \\sum\\limits_{k = 0}^{N - 1} {{c_{xx}}[k]} {e^{ - j\\Omega k}}$$ Once again our computation of the bias requires: (12.8) $$\\begin{array}{*{20}{l}} {E\\left\\{ {{P_N}(\\Omega )} \\right\\}}&{ = E\\left\\{ {\\sum\\limits_{k = 0}^{N - 1} {{c_{xx}}[k]} {e^{ - j\\Omega k}}} \\right\\}}\\\\ {\\,\\,\\,}&{ = \\sum\\limits_{k = 0}^{N - 1} {E\\left\\{ {{c_{xx}}[k]} \\right\\}} {e^{ - j\\Omega k}} = \\sum\\limits_{k = 0}^{N - 1} {{\\varphi _{xx}}[k]{e^{ - j\\Omega k}}} } \\end{array}$$ This last line follows from \\({{c_{xx}}[k]}\\) being an unbiased estimate of \\({{\\varphi _{xx}}[k]}.\\) It might seem at this point that we have found an unbiased estimate of \\({S_{xx}}(\\Omega ).\\) Our result Equation 12.8 , however, is not the same as: (12.9) $${S_{xx}}(\\Omega ) = {\\mathscr{F}}\\left\\{ {{\\varphi _{xx}}[k]} \\right\\} = \\sum\\limits_{k = - \\infty }^{ + \\infty } {{\\varphi _{xx}}[k]} {e^{ - j\\Omega k}}$$ Once again the difference lies in the limits of the summation. In Equation 12.8 the limits on \\(k\\) are \\(0 \\le k \\le N - 1\\) while in Equation 12.9 the limits on \\(k\\) are \\(- \\infty \\le k \\le + \\infty.\\) The limits in Equation 12.8 represent the fact that we have only a finite amount of data to estimate \\({S_{xx}}(\\Omega ).\\) The conclusion is clear: Both estimates, \\({I_N}(\\Omega )\\) and \\({P_N}(\\Omega ),\\) are biased estimates of the power spectral density \\({S_{xx}}(\\Omega ).\\) Windowed observations \u00b6 Our stochastic process is being observed through a \u201cwindow\u201d of width \\(N.\\) This finite-length data record introduces a bias into our estimate of the power density spectrum. This window bias can be observed in both \\({I_N}(\\Omega )\\) ( Equation 12.6 ) and \\({P_N}(\\Omega )\\) ( Equation 12.8 ). It is possible to rewrite our expression for \\(E\\left\\{ {{I_N}(\\Omega )} \\right\\}\\) and \\(E\\left\\{ {{P_N}(\\Omega )} \\right\\}\\) using the concept of a deterministic window function , \\(w[n].\\) (12.10) $$E\\left\\{ {{I_N}(\\Omega )} \\right\\} = \\sum\\limits_{k = - \\infty }^{ + \\infty } {{w_I}[k]{\\varphi _{xx}}[k]{e^{ - j\\Omega k}}}$$ (12.11) $$E\\left\\{ {{P_N}(\\Omega )} \\right\\} = \\sum\\limits_{k = - \\infty }^{ + \\infty } {{w_P}[k]{\\varphi _{xx}}[k]{e^{ - j\\Omega k}}}$$ The two summations extend over an infinite data record and the influence of a finite data record, as well as the difference between the two estimates, has been transferred to the window function. Triangular (Bartlett) window: (12.12) $${w_I}[k] = \\left\\{ {\\begin{array}{*{20}{c}} {\\frac{{N - \\left| k \\right|}}{N}}&{\\left| k \\right| < N}\\\\ 0&{\\left| k \\right| \\ge N} \\end{array}} \\right.$$ Rectangular (Block) window: (12.13) $${w_P}[k] = \\left\\{ {\\begin{array}{*{20}{c}} 1&{\\left| k \\right| < N}\\\\ 0&{\\left| k \\right| \\ge N} \\end{array}} \\right.$$ From Fourier theory we know that the influence of the window on the spectrum \\({S_{xx}}(\\Omega )\\) will be given by: (12.14) $$E\\left\\{ {{I_N}(\\Omega )} \\right\\} = \\frac{1}{{2\\pi }}{W_I}(\\Omega ) \\otimes {S_{xx}}(\\Omega )$$ (12.15) $$E\\left\\{ {{P_N}(\\Omega )} \\right\\} = \\frac{1}{{2\\pi }}{W_P}(\\Omega ) \\otimes {S_{xx}}(\\Omega )$$ That is, multiplication in the time domain \\(n\\) yields convolution in the frequency domain \\(\\Omega\\) where: (12.16) $${W_I}(\\Omega ) = {\\mathscr{F}}\\left\\{ {{w_I}[k]} \\right\\}\\,\\,\\,\\,\\,\\,\\,\\,\\,{W_P}(\\Omega ) = {\\mathscr{F}}\\left\\{ {{w_P}[k]} \\right\\}$$ Plots of the two windows \\({w_I}[k]\\) and \\({w_P}[k]\\) as well as their spectra \\({W_I}(\\Omega )\\) and \\({W_P}(\\Omega )\\) are given in Figure 12.1 . A comparison of various properties is useful. The ideal window would have the form in the frequency domain of \\(W(\\Omega ) = 2\\pi \\,\\delta \\left( \\Omega \\right).\\) This is because the convolutions in Equation 12.14 and Equation 12.15 would then yield the desired spectrum, \\({S_{xx}}(\\Omega ).\\) Instead we have spectra \\({W_I}(\\Omega )\\) and \\({W_P}(\\Omega )\\) that have wider center lobes than the impulse \\(\\delta \\left( \\Omega \\right)\\) and that have side lobes that further contaminate the spectral estimate. Comparing the two spectra, we see that \\({W_I}(\\Omega )\\) has a wide center lobe but small side lobes while \\({W_P}(\\Omega )\\) has a narrower center lobe but larger side lobes, another example of a trade-off. Once we have accepted the idea that windowing of the data is inevitable 1 , we can consider searching for other window shapes that might have certain desirable properties for spectral estimation. Figure 12.1: ( top ) Spectrum \\({W_I}\\left( \\Omega \\right)\\) associated with a triangular (Bartlett) window \\({w_I}[n\\rbrack\\) ; ( bottom ) Spectrum \\({W_P}\\left( \\Omega \\right)\\) associated with a rectangular (Block) window \\({w_P}[n\\rbrack.\\) Note the trade-off between the width of the main lobe and the height of the side lobes. The spectrum associated with windowing is not only affected by a window\u2019s shape but by the window\u2019s length as well. In Movie 12.1 we show how the spectrum \\({W_P}(\\Omega )\\) is affected by the length (width) of the window \\({w_P}[k].\\) Movie 12.1: Tradeoff between ( top ) window width and ( bottom ) spectral bandwidth. The window extends from $- N$ to $+ N.$ Notice, in particular, the width of the main, central spectral lobe as $N$ increases. The width of this window is \\(2N + 1\\) and, as \\(N \\to \\infty,\\) the window approaches the ideal, impulse-like behavior, \\(\\delta \\left( \\Omega \\right).\\) The exact form of \\({W_P}(\\Omega )\\) is given in Equation 12.17 . (12.17) $${W_P}(\\Omega ) = \\frac{{\\sin \\left( {\\Omega \\left( {2N + 1} \\right)/2} \\right)}}{{\\sin \\left( {\\Omega /2} \\right)}}$$ The periodogram \u2013 what about convergence? \u00b6 In the previous section we looked at the issue of bias in spectral estimation. The issue of convergence, as we have seen earlier, is also pivotal. In general, however, the issue is too complicated to analyze here. The results for certain simplifying assumptions show that, as estimates, \\({I_N}(\\Omega )\\) and \\({P_N}(\\Omega )\\) are seriously deficient. In other words, neither one provides an estimate whose variance goes to zero as \\(N \\to \\infty.\\) This effect is illustrated in Figure 12.2 where the lack of convergence in the spectral estimate as \\(N\\) increases is shown. As \\(N\\) grows, the estimate of the spectrum at any given frequency \\(\\Omega\\) does not converge but, instead, continues to fluctuate and behave as an underestimate. The theory to explain this has been worked out for Gaussian white noise with zero-mean and standard deviation \\(\\sigma.\\) It can be shown (Jenkins 2 ) that: (12.18) $$Var\\left\\{ {{I_N}(\\Omega )} \\right\\} = {\\sigma ^4}\\left( {1 + {{\\left( {\\frac{{\\sin (N\\Omega )}}{{N\\sin \\Omega }}} \\right)}^2}} \\right)$$ Thus as \\(N \\to \\infty\\) we have \\(Var\\left\\{ {{I_N}\\left( \\Omega \\right)} \\right\\} = {\\sigma ^4}\\) and we conclude that the variance of the estimate does not go to zero. Neither the periodogram \\({I_N}(\\Omega )\\) nor \\({P_N}(\\Omega )\\) is a consistent estimate of \\({S_{xx}}(\\Omega ).\\) Further, as explained in Section 11.3.2 of Jenkins 2 and illustrated in Figure 12.2 , the rapidity of the fluctuations in the spectral estimate increases as \\(N\\) increases. Figure 12.2: The \u201ctrue\u201d power spectral density of a stochastic signal \\({S_{xx}}(\\Omega )\\) (in dark red ) and an \\({I_N}(\\Omega )\\) estimate based upon ( top ) \\(N = 16\\) and \\(N = 64\\) samples; ( middle ) \\({I_N}(\\Omega )\\) estimate based upon \\(N = 256\\) and \\(N = 1024\\) samples; ( bottom ) \\({I_N}(\\Omega )\\) estimate based upon \\(N = 4096\\) and \\(N = 16384\\) samples. The most well-known technique for dealing with this problem is Bartlett\u2019s procedure. We begin with \\(M\\) samples of data, that is, \\(\\left\\{ {x[0],x[1],x[2],...,x[M - 1]} \\right\\}.\\) We now split the \\(M\\) samples up into \\(K\\) non-overlapping, contiguous records, each of length \\(N.\\) That is \\(M = K \\bullet N.\\) As an example we might have \\(M = 2048\\) samples and choose \\(K = 16\\) records with \\(N = 128\\) samples/record. For each record \\(k = 1,2,...,16\\) we compute the periodogram \\(I_N^{(k)}\\left( \\Omega \\right),\\) that is, we compute \\(K\\) different periodograms, one per record. We now form the Bartlett estimate of the spectrum: (12.19) $${B_I}(\\Omega ) = \\frac{1}{K}\\sum\\limits_{k = 1}^K {I_N^{(k)}(\\Omega )}$$ The Bartlett estimate is the arithmetic mean (average) of the \\(K\\) periodograms. Of course, it is also possible to form the Bartlett estimate using \\(P_N^{(k)}\\left( \\Omega \\right)\\) giving: (12.20) $${B_P}(\\Omega ) = \\frac{1}{K}\\sum\\limits_{k = 1}^K {P_N^{(k)}(\\Omega )}$$ Because each of the \\(K\\) records is independent of the other \\(K - 1\\) records\u2014do you understand why?\u2014we have: (12.21) $$\\begin{array}{l} E\\left\\{ {{B_I}(\\Omega )} \\right\\} = \\frac{1}{K}\\sum\\limits_{k = 1}^K {E\\left\\{ {I_N^{(k)}(\\Omega )} \\right\\}} = E\\left\\{ {I_N^{(k)}(\\Omega )} \\right\\}\\\\ Var\\left\\{ {{B_I}(\\Omega )} \\right\\} = \\frac{1}{K}Var\\left\\{ {I_N^{(k)}(\\Omega )} \\right\\} \\end{array}$$ (12.22) $$\\begin{array}{l} E\\left\\{ {{B_P}(\\Omega )} \\right\\} = \\frac{1}{K}\\sum\\limits_{k = 1}^K {E\\left\\{ {P_N^{(k)}(\\Omega )} \\right\\}} = E\\left\\{ {P_N^{(k)}(\\Omega )} \\right\\}\\\\ Var\\left\\{ {{B_P}(\\Omega )} \\right\\} = \\frac{1}{K}Var\\left\\{ {P_N^{(k)}(\\Omega )} \\right\\} \\end{array}$$ Whether we choose \\({{B_I}(\\Omega )}\\) or \\({{B_P}(\\Omega )}\\) we can achieve a convergent estimate of the spectrum by choosing a large value for \\(K.\\) Thus the splitting of the \\(M\\) data samples into \\(K\\) records generates \\(1/K\\) convergence as \\(K \\to M.\\) This convergence does not, however, come for free. For fixed \\(M,\\) as we choose larger and larger values of \\(K,\\) the value of \\(N\\) (the number of samples per record) must decrease. Since the bias is only dependent on \\(N\\) (and not \\(K\\) ), Equation 12.21 and Equation 12.22 , the bias will get worse as \\(K\\) increases. Spectral estimation, like life, is filled with compromises. Summarizing we see that for fixed \\(M\\) : \\(\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,N\\) large \\(\\Rightarrow\\) \\(K\\) small \\(\\Rightarrow\\) good bias, poor convergence \\(\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,N\\) small \\(\\Rightarrow\\) \\(K\\) large \\(\\Rightarrow\\) poor bias, good convergence An example of the application of this Bartlett technique to the data shown in Figure 12.2 is shown in Figure 12.3 . Figure 12.3: Bartlett estimates of the spectrum for various values of \\(M,\\) \\(K,\\) and \\(N\\) where \\(M = K \\bullet N.\\) The \u201ctrue\u201d spectrum is shown in dark red . The evolution of this Bartlett estimation of a \u201ctrue\u201d spectrum is shown in Movie 12.2 . Movie 12.2: Bartlett estimation with $M$ samples, $K$ records, and $N$ samples/record. Once again we are confronted with a trade-off. The proper choice of \\(M,\\) \\(N,\\) and \\(K\\) then becomes dependent on the specifics of the problem and what the goals and constraints of the estimation problem are. Other windows \u00b6 In the previous section we have looked at two windows: the Block (rectangular) window and the triangular window. The latter is also known as the Bartlett window. Once we have accepted the idea that windowing is inevitable, we might search for \u201coptimum\u201d windows, windows that give a \u201cbest\u201d estimate of an underlying spectrum. In addition to the two previously mentioned windows, we will describe the Gauss, Tukey, Hamming, Hann, Parzen, and Verbeek windows. The first five of these are well-described in the literature ; the last one is described in Problem 12.2 . These weighted windows have been proposed and analyzed and their various properties are summarized in Table 12.1 and Table 12.2 . It is important, however, to decide what criteria will be used to assess effectiveness of any specific window. We would like to use as little data as possible to estimate a spectrum so this implies that the duration of the window should be as small as possible. In the frequency domain, however, the window spectrum is convolved with the true spectrum. This means that an ideal window has a spectral bandwidth that is as narrow, as impulse-like, as possible. Putting these two requirements together means using a window that has a small time-bandwidth product . A continuous-time Gaussian of infinite extent is known to fulfill this condition but we will be dealing with discrete-time windows of finite extent. A family of windows \u00b6 For purposes of comparison, we assume that all windows are real, even, and normalized such that \\(w[n = 0] = 1.\\) As the windows are of finite extent and even, this means that they are identically zero for \\(\\left| n \\right| > N\\) with an extent (duration) of \\(2N + 1.\\) The windows are defined in Table 12.1 and their properties are compared in Table 12.2 . Window Definition w[n] Graph w[n] Window Definition w[n] Graph w[n] Polynomial-based windows Block $1$ Bartlett $1 - \\left| {\\frac{n}{N}} \\right|$ Parzen $1 - {\\left( {\\frac{n}{N}} \\right)^2}$ Gaussian-based windows Gauss ${e^{ - q}}\\,\\,\\,\\,\\,\\,\\,\\,q = \\frac{1}{2}{\\left( {\\frac{n}{{\\sigma N}}} \\right)^2}$ Verbeek $\\left( {1 + q + \\frac{{{q^2}}}{2}} \\right){e^{ - q}}\\,\\,\\,\\,\\,\\,\\,\\,q = \\frac{1}{2}{\\left( {\\frac{n}{{\\sigma N}}} \\right)^2}$ Cosine-based windows Tukey $0.5 + 0.5\\cos \\left( {\\frac{{\\pi n}}{N}} \\right)$ Hamming $0.54 + 0.46\\cos \\left( {\\frac{{\\pi n}}{N}} \\right)$ Hann $\\cos \\left( {\\frac{{\\pi n}}{2N}} \\right)$ Table 12.1: Definition of window functions. All windows, $w[n],$ are defined over the interval $- N \\le n \\le + N$ and are identically zero outside this interval. For the examples shown below on the right, $N = 9$ and $\\sigma = 1/3.$ Comparison of these windows reveals some of the consequences associated with each choice. We denote the time duration as \\(\\Delta {n_{rms}}\\) and the bandwidth as \\(\\Delta {\\Omega _{rms}}.\\) They are defined by: (12.23) $$\\Delta {n_{rms}} = \\sqrt {\\left( {\\sum\\limits_{n = - N}^{ + N} {{n^2}{w^2}[n]} } \\right)/\\left( {\\sum\\limits_{n = - N}^{ + N} {{w^2}[n]} } \\right)}$$ (12.24) $$\\Delta {\\Omega _{rms}} = \\sqrt {\\left( {\\int\\limits_{ - \\pi }^{ + \\pi } {{\\Omega ^2}{{\\left| {W(\\Omega )} \\right|}^2}d\\Omega } } \\right)/\\left( {\\int\\limits_{ - \\pi }^{ + \\pi } {{{\\left| {W(\\Omega )} \\right|}^2}d\\Omega } } \\right)}$$ These two measures are intentionally chosen to resemble the \u201cstandard deviation\u201d of an associated (even) \u201cprobability\u201d function. In the case of Equation 12.23 , it is the normalized function \\({\\left| {w[n]} \\right|^2}.\\) In the case of Equation 12.24 , it is the normalized function \\({\\left| {W\\left( \\Omega \\right)} \\right|^2}\\) . We do this because it is possible to show that, for all continuous-time signals, the time-bandwidth product \\(\\Delta {t_{rms}}\\Delta {\\omega _{rms}} \\ge 1/2.\\) This is, of course, the well-known Uncertainty Principle. Further, it can be shown that for continuous-time signals, the Gaussian signal (filter) achieves the minimum. This result holds for discrete-time signals but a proof has, to our knowledge, not been published. The proof of this result, the Uncertainty Principle for discrete-time signals \\(\\Delta {n_{rms}}\\Delta {\\Omega _{rms}} \\ge 1/2,\\) is, therefore, presented in Appendix II . Table 12.2 shows the values for the time duration, frequency bandwidth, and time-bandwidth product for each of the eight windows defined in Table 12.1 and using \\(N = 9\\) and \\(\\sigma = 1/3.\\) Window W ( \u03a9) \u0394n rms \u0394 \u03a9 rms \u0394n rms \u0394 \u03a9 rms Window W (\u03a9) \u0394n rms \u0394 \u03a9 rms \u0394n rms \u0394 \u03a9 rms Verbeek 3.739 0.166 0.619 Hann 3.253 0.177 0.577 Parzen 3.401 0.179 0.611 Hamming 2.764 0.186 0.515 Bartlett 2.837 0.197 0.558 Tukey 2.550 0.200 0.510 Gauss 2.121 0.236 0.5 Block 5.477 0.382 2.093 Table 12.2: Comparison of window functions. $\\Delta {n_{rms}}$ = $rms$ width of the window in the discrete-time domain, $\\Delta {\\Omega _{rms}}$ = $rms$ width of the window spectrum in the frequency domain, and $\\Delta {n_{rms}}\\Delta {\\Omega _{rms}}$ = the time-bandwidth product. Windows are defined over the interval $- N \\le n \\le + N$ and are identically zero outside this interval. The numerical values are, again, calculated for $N = 9$ and $\\sigma = 1/3.$ Because all the windows involve the same $2N + 1$ samples, they are sorted according to increasing values of the spectral width, $\\Delta {\\Omega _{rms}}. $ At first glance we might seem to desire a filter that yields a good spectral estimate while using a minimum amount of data. This translates to a small duration and a small bandwidth. But in Table 12.1 and Table 12.2 , the filters and their spectra that are displayed, all involve the same amount of data, \\(2N + 1\\) samples. A small spectral bandwidth comes from the desire to have \\(W\\left( \\Omega \\right)\\) as much like \\(2\\pi \\,\\delta \\left( \\Omega \\right)\\) as possible. See Equation 12.14 and Equation 12.15 . On this basis we would choose the Verbeek window from among those presented here as it has the smallest bandwidth. We note, in passing, that the discrete-time version of the Gauss window does achieve the minimum time-bandwidth product predicted by the Uncertainty Principle but that its bandwidth is 42% wider than the Verbeek window. Problems \u00b6 Problem 12.1 \u00b6 In Equation 12.17 we presented the spectrum \\({W_P}\\left( \\Omega \\right)\\) associated with the Block window \\({w_P}[n].\\) Determine \\({W_I}\\left( \\Omega \\right),\\) the spectrum associated with the Bartlett window \\({w_I}[n].\\) We define the width of the main lobe of a window spectrum \\(W\\left( \\Omega \\right)\\) as the distance between the first two positions on the frequency axis around \\(\\Omega = 0\\) where \\(W\\left( \\Omega \\right) = 0.\\) This is illustrated in Figure 12.4 . Figure 12.4: Spectrum \\(W\\left( \\Omega \\right)\\) of a window \\(w[n\\rbrack\\) that can be found in Table 12.1 and Table 12.2. The width of the main lobe, as defined in the text, is the distance between the two, dashed blue lines. For a window consisting of \\(2N + 1\\) samples, determine the width of the main lobe for each of the following windows: Block (rectangular) window Bartlett (triangular) window Parzen (parabolic) window Tukey window Hann window Problem 12.2 \u00b6 Eight different windows have been examined in this chapter. How and why does one develop a new window? To address this question let us look at the characteristics a window \u201cshould\u201d have. It should i) be narrow in the time domain to use as few samples as possible, ii) be narrow in the frequency domain so that it resembles an impulse; see Equation 12.14 , iii) have a narrow main lobe so that the distortion caused by the convolution in Equation 12.14 should be minimized, and iv) have small sidelobes for the same reason. In this problem we will look at the implications of the first two requirements, (i) and (ii). Further, we will cast the discussion in the continuous-time domain \\(t\\) and the associated frequency domain \\(\\omega\\) for simplicity\u2019s sake. The limits of what can be achieved given requirements (i) and (ii) are described in the Uncertainty Principle ( Chapter 12 and Chapter 13 ). The duration-bandwidth product has a lower bound and we know that the Gaussian window achieves this bound. But as we shall see in Laboratory Exercise 12.4 , the actual performance of the Gaussian window when compared, for example, to a Block (rectangular) window can leave much to be desired. An explanation for this is that multiplying the recorded data by a Gaussian window suppresses the amplitude information of a significant number of samples, information that could be used to obtain a better estimate of the power spectral density. This suppression is illustrated in Figure 12.5 . Figure 12.5: 1.024 s of a signal sampled at 44.1 kHz. The original (synthetic) signal is in blue . The same signal multiplied by a Gaussian window is in orange . The value of \\(\\sigma\\) used in Figure 12.5 is \\(\\sigma = 1/4\\) when defined on the zero-centered interval (\u20131, +1). How many samples correspond to \\(\\sigma?\\) How many seconds? Through this choice of \\(\\sigma\\) the Gaussian tapers smoothly to zero at the edges of the window. In 2003, Verbeek 3 considered how the Gaussian window could be modified such that less data would be suppressed in amplitude while the smooth tapering would be maintained. He reasoned as follows. If the Gaussian window \\({w_G}(q) = {e^{ - {q^2}/2}}\\) is multiplied by \\({e^{ + {q^2}/2}}\\) then the result is \\(1\\) and the window is flat like the Block filter. If instead, a Taylor series expansion \\(P(q)\\) of \\({e^{ + {q^2}/2}}\\) around \\(q = 0\\) is used to multiply \\({e^{ - {q^2}/2}},\\) then the modified Gaussian window will be flat in the vicinity of \\(q = 0.\\) What is the Taylor series expansion of \\({e^{ + {q^2}/2}}\\) around \\(q = 0\\) to second order, that is, a second-order polynomial \\({P_2}(q)?\\) Is the modified window \\({w_V}(q) = {P_2}(q)\\,{e^{ - {q^2}/2}}\\) flat around \\(q = 0?\\) To assess this, look at derivatives \\({d^m}{w_V}(q)/d{q^m}\\) of the modified window around \\(q = 0\\) for various values of \\(m.\\) What is the first value of \\(m\\) such that the value of that derivative at \\(q = 0\\) is not flat? Plot \\({w_G}(q)\\) and \\({w_V}(q)\\) over the interval \\(- 5 \\leq q \\leq + 5.\\) Determine the spectra \\({W_G}(\\omega ) =\\) \\({\\mathscr{F}}\\left\\{ {{w_G}(q)} \\right\\}\\) and \\({W_V}(\\omega ) =\\) \\({\\mathscr{F}}\\left\\{ {{w_V}(q)} \\right\\}.\\) Hint : What is the mathematical relationship between \\({W_G}(\\omega )\\) and \\({W_V}(\\omega )?\\) Plot the spectra over the interval \\(- 4 \\leq \\omega \\leq + 4.\\) Use of the Verbeek window and other windows will be explored in Laboratory Exercise 12.3 and Laboratory Exercise 12.4 . Problem 12.3 \u00b6 This problem concerns the recognition of separate musical tones. Full disclosure : We wrote this problem for the 2002 Dutch Physics Olympiad. Caveat emptor! The musical notes middle \\(A\\) and middle \\({A^\\# }\\) are known to have the frequencies: \\[\\begin{array}{*{20}{l}} {A:}&{440\\,{\\rm{Hz}} = {f_0}}\\\\ {{A^\\# }:}&{440 \\bullet {2^{1/12}}\\,\\,{\\rm{Hz}} = 440 \\bullet 1.0595\\,{\\rm{Hz}} = 466.2\\,{\\rm{Hz}} = {f_1}} \\end{array}\\] The positions of these notes on a piano keyboard are shown in Figure 12.6 . A single sound, not from the piano, has been recorded which consists of either \\(A,\\) \\({A^\\# },\\) or the normalized sum of \\(A\\) and \\({A^\\# }.\\) The recorded signal is also shown in Figure 12.6 . The \\(SNR > 60\\) dB. Figure 12.6: ( left ) Piano keyboard illustrating the notes \\(A\\) and \\({A^\\# }.\\) ( right ) A portion of the recorded signal. What is the minimum length of time \\(T\\) in seconds that is required to distinguish between the three alternatives: \\(A,\\) \\({A^\\# },\\) or \\(\\left( {A + {A^\\# }} \\right)/2?\\) Explain your choice of measurement technique and what the consequences are for the accuracy of your determination. Laboratory Exercises \u00b6 Laboratory Exercise 12.1 \u00b6 We examine the practical aspects of estimating the spectrum of a \u201ctrivial\u201d signal. Click on the icon to the left to start. Laboratory Exercise 12.2 \u00b6 Modern society has taught us to be impatient. We want everything to be available now . In spectral estimation that means using as few samples as possible. What are the consequences? To start the exercise, click on the icon to the left. Laboratory Exercise 12.3 \u00b6 Using a finite amount of data to estimate a spectrum\u2014any spectrum\u2014is like observing the data source through a window. What is the effect of the window and what if we \u201cshape\u201d the window? To start the exercise, click on the icon to the left. Laboratory Exercise 12.4 \u00b6 We continue to explore the effects of window size and window shape. But now let us throw a little noise into the spectral estimation problem. To start the exercise, click on the icon to the left. All data are \u201cwindowed\u201d. There are no data available from before the Big Bang. \u21a9 Jenkins, G. M. and D. G. Watts (1998). Spectral Analysis and Its Applications, Emerson Adams Press \u21a9 \u21a9 Verbeek, P. W. (2003). A modified Gaussian window for spectral estimation. Department of Imaging Science & Technology, Delft University of Technology \u21a9","title":"12. Spectral Estimation"},{"location":"Chap_12.html#spectral-estimation","text":"We may not have an analytical model of a signal, its autocorrelation function, or its power spectral density. An example of this problem was presented in Chapter 5 . It should be clear that the phenomenon of weather is far too complex to admit an analytical solution for the autocorrelation function of the temperature \\({\\varphi _{TT}}[k]\\) or its power spectral density \\({S_{TT}}(\\Omega ).\\) We must work with estimates of these quantities. In the previous chapter we examined the central questions of estimation: bias and convergence applied to means, variances, and correlations. In this chapter we will look at the problem of estimating the power spectral density. Our estimate of the power spectrum of a random process is \\({I_N}(\\Omega ).\\) That is \\({I_N}(\\Omega )\\) is the estimate of \\({S_{xx}}(\\Omega ) = {\\mathscr{F}}\\left\\{ {{\\varphi _{xx}}[k]} \\right\\}.\\) We begin with a stochastic signal whose power spectral density is shown in Figure 8.2 and given, for \\({S_o} = 1\\) and \\(\\alpha = 4/7,\\) by Equation 8.10 : (12.1) $${S_{xx}}(\\Omega ) = \\frac{{{S_o}}}{{1 + {\\alpha ^2} - 2\\alpha \\cos \\Omega }} = \\frac{{49}}{{65 - 56\\cos \\Omega }}$$ We use the spectral estimator: (12.2) $${I_N}(\\Omega ) = {\\mathscr{F}}\\left\\{ {{{\\hat c}_{xx}}[k]} \\right\\} = \\sum\\limits_{k = 0}^{N - 1} {{{\\hat c}_{xx}}[k]} \\,{e^{ - j\\Omega k}}$$ But \\({{{\\hat c}_{xx}}[k]}\\) is, itself, formed with the aid of Equation 11.39 from \\(x[n]\\) and using basic Fourier theory: (12.3) $${I_N}(\\Omega ) = \\frac{1}{N}{\\left| {X(\\Omega )} \\right|^2}$$","title":"Spectral Estimation"},{"location":"Chap_12.html#the-periodogram-unbiased","text":"This basic estimate is referred to in the literature as a periodogram . The issue we will now examine is whether the periodogram \\({I_N}(\\Omega )\\) is a good estimate of \\({S_{xx}}(\\Omega ).\\) By now we understand that \u201cgood\u201d relates to the issues of bias and convergence. This bias is defined as: (12.4) $$B = E\\left\\{ {{I_N}(\\Omega )} \\right\\} - {S_{xx}}(\\Omega ) = B(\\Omega )$$ The term that must be investigated is: (12.5) $$\\begin{array}{*{20}{l}} {E\\left\\{ {{I_N}(\\Omega )} \\right\\}}&{ = E\\left\\{ {\\sum\\limits_{k = 0}^{N - 1} {{{\\hat c}_{xx}}[k]} \\,{e^{ - j\\Omega k}}} \\right\\}}\\\\ {\\,\\,\\,}&{ = \\sum\\limits_{k = 0}^{N - 1} {E\\left\\{ {{{\\hat c}_{xx}}[k]} \\right\\}\\,} {e^{ - j\\Omega k}}} \\end{array}$$ As the only term inside the first set of braces that is stochastic is \\({{{\\hat c}_{xx}}[k]},\\) we can exchange the order of expectation and summation. From Equation 11.40 we can replace the expectation as follows: (12.6) $$\\begin{array}{*{20}{l}} {E\\left\\{ {{I_N}(\\Omega )} \\right\\}}&{ = \\sum\\limits_{k = 0}^{N - 1} {\\left( {\\frac{{N - \\left| k \\right|}}{N}} \\right)} {\\varphi _{xx}}[k]{e^{ - j\\Omega k}}}\\\\ {\\,\\,\\,}&{ = \\sum\\limits_{k = 0}^{N - 1} {\\left( {1 - \\frac{{\\left| k \\right|}}{N}} \\right)} {\\varphi _{xx}}[k]{e^{ - j\\Omega k}}}\\\\ {\\,\\,\\,}&{ = \\sum\\limits_{k = 0}^{N - 1} {{\\varphi _{xx}}[k]{e^{ - j\\Omega k}}} - \\sum\\limits_{k = 0}^{N - 1} {\\frac{{\\left| k \\right|}}{N}{\\varphi _{xx}}[k]{e^{ - j\\Omega k}}} } \\end{array}$$ The first sum does not have the limits that we should expect from the formal definition of \\({S_{xx}}(\\Omega )\\) ; the variable \\(k\\) does not go from \\(- \\infty\\) to \\(+ \\infty.\\) See Equation 12.9 below. The second sum in Equation 12.6 shows clearly that the estimate is biased. Specifically, the term \\(\\left| k \\right|/N\\) would seem to indicate that \\(E\\left\\{ {{I_N}(\\Omega )} \\right\\}\\) is an underestimate. Thus the periodogram based upon \\({{{\\hat c}_{xx}}[k]}\\) is a biased estimate of \\({S_{xx}}(\\Omega ).\\) We might choose instead to consider the spectral estimate given by: (12.7) $${P_N}(\\Omega ) = {\\mathscr{F}}\\left\\{ {{c_{xx}}[k]} \\right\\} = \\sum\\limits_{k = 0}^{N - 1} {{c_{xx}}[k]} {e^{ - j\\Omega k}}$$ Once again our computation of the bias requires: (12.8) $$\\begin{array}{*{20}{l}} {E\\left\\{ {{P_N}(\\Omega )} \\right\\}}&{ = E\\left\\{ {\\sum\\limits_{k = 0}^{N - 1} {{c_{xx}}[k]} {e^{ - j\\Omega k}}} \\right\\}}\\\\ {\\,\\,\\,}&{ = \\sum\\limits_{k = 0}^{N - 1} {E\\left\\{ {{c_{xx}}[k]} \\right\\}} {e^{ - j\\Omega k}} = \\sum\\limits_{k = 0}^{N - 1} {{\\varphi _{xx}}[k]{e^{ - j\\Omega k}}} } \\end{array}$$ This last line follows from \\({{c_{xx}}[k]}\\) being an unbiased estimate of \\({{\\varphi _{xx}}[k]}.\\) It might seem at this point that we have found an unbiased estimate of \\({S_{xx}}(\\Omega ).\\) Our result Equation 12.8 , however, is not the same as: (12.9) $${S_{xx}}(\\Omega ) = {\\mathscr{F}}\\left\\{ {{\\varphi _{xx}}[k]} \\right\\} = \\sum\\limits_{k = - \\infty }^{ + \\infty } {{\\varphi _{xx}}[k]} {e^{ - j\\Omega k}}$$ Once again the difference lies in the limits of the summation. In Equation 12.8 the limits on \\(k\\) are \\(0 \\le k \\le N - 1\\) while in Equation 12.9 the limits on \\(k\\) are \\(- \\infty \\le k \\le + \\infty.\\) The limits in Equation 12.8 represent the fact that we have only a finite amount of data to estimate \\({S_{xx}}(\\Omega ).\\) The conclusion is clear: Both estimates, \\({I_N}(\\Omega )\\) and \\({P_N}(\\Omega ),\\) are biased estimates of the power spectral density \\({S_{xx}}(\\Omega ).\\)","title":"The periodogram \u2013 unbiased?"},{"location":"Chap_12.html#windowed-observations","text":"Our stochastic process is being observed through a \u201cwindow\u201d of width \\(N.\\) This finite-length data record introduces a bias into our estimate of the power density spectrum. This window bias can be observed in both \\({I_N}(\\Omega )\\) ( Equation 12.6 ) and \\({P_N}(\\Omega )\\) ( Equation 12.8 ). It is possible to rewrite our expression for \\(E\\left\\{ {{I_N}(\\Omega )} \\right\\}\\) and \\(E\\left\\{ {{P_N}(\\Omega )} \\right\\}\\) using the concept of a deterministic window function , \\(w[n].\\) (12.10) $$E\\left\\{ {{I_N}(\\Omega )} \\right\\} = \\sum\\limits_{k = - \\infty }^{ + \\infty } {{w_I}[k]{\\varphi _{xx}}[k]{e^{ - j\\Omega k}}}$$ (12.11) $$E\\left\\{ {{P_N}(\\Omega )} \\right\\} = \\sum\\limits_{k = - \\infty }^{ + \\infty } {{w_P}[k]{\\varphi _{xx}}[k]{e^{ - j\\Omega k}}}$$ The two summations extend over an infinite data record and the influence of a finite data record, as well as the difference between the two estimates, has been transferred to the window function. Triangular (Bartlett) window: (12.12) $${w_I}[k] = \\left\\{ {\\begin{array}{*{20}{c}} {\\frac{{N - \\left| k \\right|}}{N}}&{\\left| k \\right| < N}\\\\ 0&{\\left| k \\right| \\ge N} \\end{array}} \\right.$$ Rectangular (Block) window: (12.13) $${w_P}[k] = \\left\\{ {\\begin{array}{*{20}{c}} 1&{\\left| k \\right| < N}\\\\ 0&{\\left| k \\right| \\ge N} \\end{array}} \\right.$$ From Fourier theory we know that the influence of the window on the spectrum \\({S_{xx}}(\\Omega )\\) will be given by: (12.14) $$E\\left\\{ {{I_N}(\\Omega )} \\right\\} = \\frac{1}{{2\\pi }}{W_I}(\\Omega ) \\otimes {S_{xx}}(\\Omega )$$ (12.15) $$E\\left\\{ {{P_N}(\\Omega )} \\right\\} = \\frac{1}{{2\\pi }}{W_P}(\\Omega ) \\otimes {S_{xx}}(\\Omega )$$ That is, multiplication in the time domain \\(n\\) yields convolution in the frequency domain \\(\\Omega\\) where: (12.16) $${W_I}(\\Omega ) = {\\mathscr{F}}\\left\\{ {{w_I}[k]} \\right\\}\\,\\,\\,\\,\\,\\,\\,\\,\\,{W_P}(\\Omega ) = {\\mathscr{F}}\\left\\{ {{w_P}[k]} \\right\\}$$ Plots of the two windows \\({w_I}[k]\\) and \\({w_P}[k]\\) as well as their spectra \\({W_I}(\\Omega )\\) and \\({W_P}(\\Omega )\\) are given in Figure 12.1 . A comparison of various properties is useful. The ideal window would have the form in the frequency domain of \\(W(\\Omega ) = 2\\pi \\,\\delta \\left( \\Omega \\right).\\) This is because the convolutions in Equation 12.14 and Equation 12.15 would then yield the desired spectrum, \\({S_{xx}}(\\Omega ).\\) Instead we have spectra \\({W_I}(\\Omega )\\) and \\({W_P}(\\Omega )\\) that have wider center lobes than the impulse \\(\\delta \\left( \\Omega \\right)\\) and that have side lobes that further contaminate the spectral estimate. Comparing the two spectra, we see that \\({W_I}(\\Omega )\\) has a wide center lobe but small side lobes while \\({W_P}(\\Omega )\\) has a narrower center lobe but larger side lobes, another example of a trade-off. Once we have accepted the idea that windowing of the data is inevitable 1 , we can consider searching for other window shapes that might have certain desirable properties for spectral estimation. Figure 12.1: ( top ) Spectrum \\({W_I}\\left( \\Omega \\right)\\) associated with a triangular (Bartlett) window \\({w_I}[n\\rbrack\\) ; ( bottom ) Spectrum \\({W_P}\\left( \\Omega \\right)\\) associated with a rectangular (Block) window \\({w_P}[n\\rbrack.\\) Note the trade-off between the width of the main lobe and the height of the side lobes. The spectrum associated with windowing is not only affected by a window\u2019s shape but by the window\u2019s length as well. In Movie 12.1 we show how the spectrum \\({W_P}(\\Omega )\\) is affected by the length (width) of the window \\({w_P}[k].\\) Movie 12.1: Tradeoff between ( top ) window width and ( bottom ) spectral bandwidth. The window extends from $- N$ to $+ N.$ Notice, in particular, the width of the main, central spectral lobe as $N$ increases. The width of this window is \\(2N + 1\\) and, as \\(N \\to \\infty,\\) the window approaches the ideal, impulse-like behavior, \\(\\delta \\left( \\Omega \\right).\\) The exact form of \\({W_P}(\\Omega )\\) is given in Equation 12.17 . (12.17) $${W_P}(\\Omega ) = \\frac{{\\sin \\left( {\\Omega \\left( {2N + 1} \\right)/2} \\right)}}{{\\sin \\left( {\\Omega /2} \\right)}}$$","title":"Windowed observations"},{"location":"Chap_12.html#the-periodogram-what-about-convergence","text":"In the previous section we looked at the issue of bias in spectral estimation. The issue of convergence, as we have seen earlier, is also pivotal. In general, however, the issue is too complicated to analyze here. The results for certain simplifying assumptions show that, as estimates, \\({I_N}(\\Omega )\\) and \\({P_N}(\\Omega )\\) are seriously deficient. In other words, neither one provides an estimate whose variance goes to zero as \\(N \\to \\infty.\\) This effect is illustrated in Figure 12.2 where the lack of convergence in the spectral estimate as \\(N\\) increases is shown. As \\(N\\) grows, the estimate of the spectrum at any given frequency \\(\\Omega\\) does not converge but, instead, continues to fluctuate and behave as an underestimate. The theory to explain this has been worked out for Gaussian white noise with zero-mean and standard deviation \\(\\sigma.\\) It can be shown (Jenkins 2 ) that: (12.18) $$Var\\left\\{ {{I_N}(\\Omega )} \\right\\} = {\\sigma ^4}\\left( {1 + {{\\left( {\\frac{{\\sin (N\\Omega )}}{{N\\sin \\Omega }}} \\right)}^2}} \\right)$$ Thus as \\(N \\to \\infty\\) we have \\(Var\\left\\{ {{I_N}\\left( \\Omega \\right)} \\right\\} = {\\sigma ^4}\\) and we conclude that the variance of the estimate does not go to zero. Neither the periodogram \\({I_N}(\\Omega )\\) nor \\({P_N}(\\Omega )\\) is a consistent estimate of \\({S_{xx}}(\\Omega ).\\) Further, as explained in Section 11.3.2 of Jenkins 2 and illustrated in Figure 12.2 , the rapidity of the fluctuations in the spectral estimate increases as \\(N\\) increases. Figure 12.2: The \u201ctrue\u201d power spectral density of a stochastic signal \\({S_{xx}}(\\Omega )\\) (in dark red ) and an \\({I_N}(\\Omega )\\) estimate based upon ( top ) \\(N = 16\\) and \\(N = 64\\) samples; ( middle ) \\({I_N}(\\Omega )\\) estimate based upon \\(N = 256\\) and \\(N = 1024\\) samples; ( bottom ) \\({I_N}(\\Omega )\\) estimate based upon \\(N = 4096\\) and \\(N = 16384\\) samples. The most well-known technique for dealing with this problem is Bartlett\u2019s procedure. We begin with \\(M\\) samples of data, that is, \\(\\left\\{ {x[0],x[1],x[2],...,x[M - 1]} \\right\\}.\\) We now split the \\(M\\) samples up into \\(K\\) non-overlapping, contiguous records, each of length \\(N.\\) That is \\(M = K \\bullet N.\\) As an example we might have \\(M = 2048\\) samples and choose \\(K = 16\\) records with \\(N = 128\\) samples/record. For each record \\(k = 1,2,...,16\\) we compute the periodogram \\(I_N^{(k)}\\left( \\Omega \\right),\\) that is, we compute \\(K\\) different periodograms, one per record. We now form the Bartlett estimate of the spectrum: (12.19) $${B_I}(\\Omega ) = \\frac{1}{K}\\sum\\limits_{k = 1}^K {I_N^{(k)}(\\Omega )}$$ The Bartlett estimate is the arithmetic mean (average) of the \\(K\\) periodograms. Of course, it is also possible to form the Bartlett estimate using \\(P_N^{(k)}\\left( \\Omega \\right)\\) giving: (12.20) $${B_P}(\\Omega ) = \\frac{1}{K}\\sum\\limits_{k = 1}^K {P_N^{(k)}(\\Omega )}$$ Because each of the \\(K\\) records is independent of the other \\(K - 1\\) records\u2014do you understand why?\u2014we have: (12.21) $$\\begin{array}{l} E\\left\\{ {{B_I}(\\Omega )} \\right\\} = \\frac{1}{K}\\sum\\limits_{k = 1}^K {E\\left\\{ {I_N^{(k)}(\\Omega )} \\right\\}} = E\\left\\{ {I_N^{(k)}(\\Omega )} \\right\\}\\\\ Var\\left\\{ {{B_I}(\\Omega )} \\right\\} = \\frac{1}{K}Var\\left\\{ {I_N^{(k)}(\\Omega )} \\right\\} \\end{array}$$ (12.22) $$\\begin{array}{l} E\\left\\{ {{B_P}(\\Omega )} \\right\\} = \\frac{1}{K}\\sum\\limits_{k = 1}^K {E\\left\\{ {P_N^{(k)}(\\Omega )} \\right\\}} = E\\left\\{ {P_N^{(k)}(\\Omega )} \\right\\}\\\\ Var\\left\\{ {{B_P}(\\Omega )} \\right\\} = \\frac{1}{K}Var\\left\\{ {P_N^{(k)}(\\Omega )} \\right\\} \\end{array}$$ Whether we choose \\({{B_I}(\\Omega )}\\) or \\({{B_P}(\\Omega )}\\) we can achieve a convergent estimate of the spectrum by choosing a large value for \\(K.\\) Thus the splitting of the \\(M\\) data samples into \\(K\\) records generates \\(1/K\\) convergence as \\(K \\to M.\\) This convergence does not, however, come for free. For fixed \\(M,\\) as we choose larger and larger values of \\(K,\\) the value of \\(N\\) (the number of samples per record) must decrease. Since the bias is only dependent on \\(N\\) (and not \\(K\\) ), Equation 12.21 and Equation 12.22 , the bias will get worse as \\(K\\) increases. Spectral estimation, like life, is filled with compromises. Summarizing we see that for fixed \\(M\\) : \\(\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,N\\) large \\(\\Rightarrow\\) \\(K\\) small \\(\\Rightarrow\\) good bias, poor convergence \\(\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,N\\) small \\(\\Rightarrow\\) \\(K\\) large \\(\\Rightarrow\\) poor bias, good convergence An example of the application of this Bartlett technique to the data shown in Figure 12.2 is shown in Figure 12.3 . Figure 12.3: Bartlett estimates of the spectrum for various values of \\(M,\\) \\(K,\\) and \\(N\\) where \\(M = K \\bullet N.\\) The \u201ctrue\u201d spectrum is shown in dark red . The evolution of this Bartlett estimation of a \u201ctrue\u201d spectrum is shown in Movie 12.2 . Movie 12.2: Bartlett estimation with $M$ samples, $K$ records, and $N$ samples/record. Once again we are confronted with a trade-off. The proper choice of \\(M,\\) \\(N,\\) and \\(K\\) then becomes dependent on the specifics of the problem and what the goals and constraints of the estimation problem are.","title":"The periodogram \u2013 what about convergence?"},{"location":"Chap_12.html#other-windows","text":"In the previous section we have looked at two windows: the Block (rectangular) window and the triangular window. The latter is also known as the Bartlett window. Once we have accepted the idea that windowing is inevitable, we might search for \u201coptimum\u201d windows, windows that give a \u201cbest\u201d estimate of an underlying spectrum. In addition to the two previously mentioned windows, we will describe the Gauss, Tukey, Hamming, Hann, Parzen, and Verbeek windows. The first five of these are well-described in the literature ; the last one is described in Problem 12.2 . These weighted windows have been proposed and analyzed and their various properties are summarized in Table 12.1 and Table 12.2 . It is important, however, to decide what criteria will be used to assess effectiveness of any specific window. We would like to use as little data as possible to estimate a spectrum so this implies that the duration of the window should be as small as possible. In the frequency domain, however, the window spectrum is convolved with the true spectrum. This means that an ideal window has a spectral bandwidth that is as narrow, as impulse-like, as possible. Putting these two requirements together means using a window that has a small time-bandwidth product . A continuous-time Gaussian of infinite extent is known to fulfill this condition but we will be dealing with discrete-time windows of finite extent.","title":"Other windows"},{"location":"Chap_12.html#a-family-of-windows","text":"For purposes of comparison, we assume that all windows are real, even, and normalized such that \\(w[n = 0] = 1.\\) As the windows are of finite extent and even, this means that they are identically zero for \\(\\left| n \\right| > N\\) with an extent (duration) of \\(2N + 1.\\) The windows are defined in Table 12.1 and their properties are compared in Table 12.2 . Window Definition w[n] Graph w[n] Window Definition w[n] Graph w[n] Polynomial-based windows Block $1$ Bartlett $1 - \\left| {\\frac{n}{N}} \\right|$ Parzen $1 - {\\left( {\\frac{n}{N}} \\right)^2}$ Gaussian-based windows Gauss ${e^{ - q}}\\,\\,\\,\\,\\,\\,\\,\\,q = \\frac{1}{2}{\\left( {\\frac{n}{{\\sigma N}}} \\right)^2}$ Verbeek $\\left( {1 + q + \\frac{{{q^2}}}{2}} \\right){e^{ - q}}\\,\\,\\,\\,\\,\\,\\,\\,q = \\frac{1}{2}{\\left( {\\frac{n}{{\\sigma N}}} \\right)^2}$ Cosine-based windows Tukey $0.5 + 0.5\\cos \\left( {\\frac{{\\pi n}}{N}} \\right)$ Hamming $0.54 + 0.46\\cos \\left( {\\frac{{\\pi n}}{N}} \\right)$ Hann $\\cos \\left( {\\frac{{\\pi n}}{2N}} \\right)$ Table 12.1: Definition of window functions. All windows, $w[n],$ are defined over the interval $- N \\le n \\le + N$ and are identically zero outside this interval. For the examples shown below on the right, $N = 9$ and $\\sigma = 1/3.$ Comparison of these windows reveals some of the consequences associated with each choice. We denote the time duration as \\(\\Delta {n_{rms}}\\) and the bandwidth as \\(\\Delta {\\Omega _{rms}}.\\) They are defined by: (12.23) $$\\Delta {n_{rms}} = \\sqrt {\\left( {\\sum\\limits_{n = - N}^{ + N} {{n^2}{w^2}[n]} } \\right)/\\left( {\\sum\\limits_{n = - N}^{ + N} {{w^2}[n]} } \\right)}$$ (12.24) $$\\Delta {\\Omega _{rms}} = \\sqrt {\\left( {\\int\\limits_{ - \\pi }^{ + \\pi } {{\\Omega ^2}{{\\left| {W(\\Omega )} \\right|}^2}d\\Omega } } \\right)/\\left( {\\int\\limits_{ - \\pi }^{ + \\pi } {{{\\left| {W(\\Omega )} \\right|}^2}d\\Omega } } \\right)}$$ These two measures are intentionally chosen to resemble the \u201cstandard deviation\u201d of an associated (even) \u201cprobability\u201d function. In the case of Equation 12.23 , it is the normalized function \\({\\left| {w[n]} \\right|^2}.\\) In the case of Equation 12.24 , it is the normalized function \\({\\left| {W\\left( \\Omega \\right)} \\right|^2}\\) . We do this because it is possible to show that, for all continuous-time signals, the time-bandwidth product \\(\\Delta {t_{rms}}\\Delta {\\omega _{rms}} \\ge 1/2.\\) This is, of course, the well-known Uncertainty Principle. Further, it can be shown that for continuous-time signals, the Gaussian signal (filter) achieves the minimum. This result holds for discrete-time signals but a proof has, to our knowledge, not been published. The proof of this result, the Uncertainty Principle for discrete-time signals \\(\\Delta {n_{rms}}\\Delta {\\Omega _{rms}} \\ge 1/2,\\) is, therefore, presented in Appendix II . Table 12.2 shows the values for the time duration, frequency bandwidth, and time-bandwidth product for each of the eight windows defined in Table 12.1 and using \\(N = 9\\) and \\(\\sigma = 1/3.\\) Window W ( \u03a9) \u0394n rms \u0394 \u03a9 rms \u0394n rms \u0394 \u03a9 rms Window W (\u03a9) \u0394n rms \u0394 \u03a9 rms \u0394n rms \u0394 \u03a9 rms Verbeek 3.739 0.166 0.619 Hann 3.253 0.177 0.577 Parzen 3.401 0.179 0.611 Hamming 2.764 0.186 0.515 Bartlett 2.837 0.197 0.558 Tukey 2.550 0.200 0.510 Gauss 2.121 0.236 0.5 Block 5.477 0.382 2.093 Table 12.2: Comparison of window functions. $\\Delta {n_{rms}}$ = $rms$ width of the window in the discrete-time domain, $\\Delta {\\Omega _{rms}}$ = $rms$ width of the window spectrum in the frequency domain, and $\\Delta {n_{rms}}\\Delta {\\Omega _{rms}}$ = the time-bandwidth product. Windows are defined over the interval $- N \\le n \\le + N$ and are identically zero outside this interval. The numerical values are, again, calculated for $N = 9$ and $\\sigma = 1/3.$ Because all the windows involve the same $2N + 1$ samples, they are sorted according to increasing values of the spectral width, $\\Delta {\\Omega _{rms}}. $ At first glance we might seem to desire a filter that yields a good spectral estimate while using a minimum amount of data. This translates to a small duration and a small bandwidth. But in Table 12.1 and Table 12.2 , the filters and their spectra that are displayed, all involve the same amount of data, \\(2N + 1\\) samples. A small spectral bandwidth comes from the desire to have \\(W\\left( \\Omega \\right)\\) as much like \\(2\\pi \\,\\delta \\left( \\Omega \\right)\\) as possible. See Equation 12.14 and Equation 12.15 . On this basis we would choose the Verbeek window from among those presented here as it has the smallest bandwidth. We note, in passing, that the discrete-time version of the Gauss window does achieve the minimum time-bandwidth product predicted by the Uncertainty Principle but that its bandwidth is 42% wider than the Verbeek window.","title":"A family of windows"},{"location":"Chap_12.html#problems","text":"","title":"Problems"},{"location":"Chap_12.html#problem-121","text":"In Equation 12.17 we presented the spectrum \\({W_P}\\left( \\Omega \\right)\\) associated with the Block window \\({w_P}[n].\\) Determine \\({W_I}\\left( \\Omega \\right),\\) the spectrum associated with the Bartlett window \\({w_I}[n].\\) We define the width of the main lobe of a window spectrum \\(W\\left( \\Omega \\right)\\) as the distance between the first two positions on the frequency axis around \\(\\Omega = 0\\) where \\(W\\left( \\Omega \\right) = 0.\\) This is illustrated in Figure 12.4 . Figure 12.4: Spectrum \\(W\\left( \\Omega \\right)\\) of a window \\(w[n\\rbrack\\) that can be found in Table 12.1 and Table 12.2. The width of the main lobe, as defined in the text, is the distance between the two, dashed blue lines. For a window consisting of \\(2N + 1\\) samples, determine the width of the main lobe for each of the following windows: Block (rectangular) window Bartlett (triangular) window Parzen (parabolic) window Tukey window Hann window","title":"Problem 12.1"},{"location":"Chap_12.html#problem-122","text":"Eight different windows have been examined in this chapter. How and why does one develop a new window? To address this question let us look at the characteristics a window \u201cshould\u201d have. It should i) be narrow in the time domain to use as few samples as possible, ii) be narrow in the frequency domain so that it resembles an impulse; see Equation 12.14 , iii) have a narrow main lobe so that the distortion caused by the convolution in Equation 12.14 should be minimized, and iv) have small sidelobes for the same reason. In this problem we will look at the implications of the first two requirements, (i) and (ii). Further, we will cast the discussion in the continuous-time domain \\(t\\) and the associated frequency domain \\(\\omega\\) for simplicity\u2019s sake. The limits of what can be achieved given requirements (i) and (ii) are described in the Uncertainty Principle ( Chapter 12 and Chapter 13 ). The duration-bandwidth product has a lower bound and we know that the Gaussian window achieves this bound. But as we shall see in Laboratory Exercise 12.4 , the actual performance of the Gaussian window when compared, for example, to a Block (rectangular) window can leave much to be desired. An explanation for this is that multiplying the recorded data by a Gaussian window suppresses the amplitude information of a significant number of samples, information that could be used to obtain a better estimate of the power spectral density. This suppression is illustrated in Figure 12.5 . Figure 12.5: 1.024 s of a signal sampled at 44.1 kHz. The original (synthetic) signal is in blue . The same signal multiplied by a Gaussian window is in orange . The value of \\(\\sigma\\) used in Figure 12.5 is \\(\\sigma = 1/4\\) when defined on the zero-centered interval (\u20131, +1). How many samples correspond to \\(\\sigma?\\) How many seconds? Through this choice of \\(\\sigma\\) the Gaussian tapers smoothly to zero at the edges of the window. In 2003, Verbeek 3 considered how the Gaussian window could be modified such that less data would be suppressed in amplitude while the smooth tapering would be maintained. He reasoned as follows. If the Gaussian window \\({w_G}(q) = {e^{ - {q^2}/2}}\\) is multiplied by \\({e^{ + {q^2}/2}}\\) then the result is \\(1\\) and the window is flat like the Block filter. If instead, a Taylor series expansion \\(P(q)\\) of \\({e^{ + {q^2}/2}}\\) around \\(q = 0\\) is used to multiply \\({e^{ - {q^2}/2}},\\) then the modified Gaussian window will be flat in the vicinity of \\(q = 0.\\) What is the Taylor series expansion of \\({e^{ + {q^2}/2}}\\) around \\(q = 0\\) to second order, that is, a second-order polynomial \\({P_2}(q)?\\) Is the modified window \\({w_V}(q) = {P_2}(q)\\,{e^{ - {q^2}/2}}\\) flat around \\(q = 0?\\) To assess this, look at derivatives \\({d^m}{w_V}(q)/d{q^m}\\) of the modified window around \\(q = 0\\) for various values of \\(m.\\) What is the first value of \\(m\\) such that the value of that derivative at \\(q = 0\\) is not flat? Plot \\({w_G}(q)\\) and \\({w_V}(q)\\) over the interval \\(- 5 \\leq q \\leq + 5.\\) Determine the spectra \\({W_G}(\\omega ) =\\) \\({\\mathscr{F}}\\left\\{ {{w_G}(q)} \\right\\}\\) and \\({W_V}(\\omega ) =\\) \\({\\mathscr{F}}\\left\\{ {{w_V}(q)} \\right\\}.\\) Hint : What is the mathematical relationship between \\({W_G}(\\omega )\\) and \\({W_V}(\\omega )?\\) Plot the spectra over the interval \\(- 4 \\leq \\omega \\leq + 4.\\) Use of the Verbeek window and other windows will be explored in Laboratory Exercise 12.3 and Laboratory Exercise 12.4 .","title":"Problem 12.2"},{"location":"Chap_12.html#problem-123","text":"This problem concerns the recognition of separate musical tones. Full disclosure : We wrote this problem for the 2002 Dutch Physics Olympiad. Caveat emptor! The musical notes middle \\(A\\) and middle \\({A^\\# }\\) are known to have the frequencies: \\[\\begin{array}{*{20}{l}} {A:}&{440\\,{\\rm{Hz}} = {f_0}}\\\\ {{A^\\# }:}&{440 \\bullet {2^{1/12}}\\,\\,{\\rm{Hz}} = 440 \\bullet 1.0595\\,{\\rm{Hz}} = 466.2\\,{\\rm{Hz}} = {f_1}} \\end{array}\\] The positions of these notes on a piano keyboard are shown in Figure 12.6 . A single sound, not from the piano, has been recorded which consists of either \\(A,\\) \\({A^\\# },\\) or the normalized sum of \\(A\\) and \\({A^\\# }.\\) The recorded signal is also shown in Figure 12.6 . The \\(SNR > 60\\) dB. Figure 12.6: ( left ) Piano keyboard illustrating the notes \\(A\\) and \\({A^\\# }.\\) ( right ) A portion of the recorded signal. What is the minimum length of time \\(T\\) in seconds that is required to distinguish between the three alternatives: \\(A,\\) \\({A^\\# },\\) or \\(\\left( {A + {A^\\# }} \\right)/2?\\) Explain your choice of measurement technique and what the consequences are for the accuracy of your determination.","title":"Problem 12.3"},{"location":"Chap_12.html#laboratory-exercises","text":"","title":"Laboratory Exercises"},{"location":"Chap_12.html#laboratory-exercise-121","text":"We examine the practical aspects of estimating the spectrum of a \u201ctrivial\u201d signal. Click on the icon to the left to start.","title":"Laboratory Exercise 12.1"},{"location":"Chap_12.html#laboratory-exercise-122","text":"Modern society has taught us to be impatient. We want everything to be available now . In spectral estimation that means using as few samples as possible. What are the consequences? To start the exercise, click on the icon to the left.","title":"Laboratory Exercise 12.2"},{"location":"Chap_12.html#laboratory-exercise-123","text":"Using a finite amount of data to estimate a spectrum\u2014any spectrum\u2014is like observing the data source through a window. What is the effect of the window and what if we \u201cshape\u201d the window? To start the exercise, click on the icon to the left.","title":"Laboratory Exercise 12.3"},{"location":"Chap_12.html#laboratory-exercise-124","text":"We continue to explore the effects of window size and window shape. But now let us throw a little noise into the spectral estimation problem. To start the exercise, click on the icon to the left. All data are \u201cwindowed\u201d. There are no data available from before the Big Bang. \u21a9 Jenkins, G. M. and D. G. Watts (1998). Spectral Analysis and Its Applications, Emerson Adams Press \u21a9 \u21a9 Verbeek, P. W. (2003). A modified Gaussian window for spectral estimation. Department of Imaging Science & Technology, Delft University of Technology \u21a9","title":"Laboratory Exercise 12.4"},{"location":"Chap_13.html","text":"Appendices \u00b6 Appendix I: Mean-Square Error Minimization \u00b6 We wish to estimate a random variable \\(x\\) as a linear combination \\({x_e}\\) of other random variables \\(r.\\) The weighting coefficients in the linear combination are \\(h.\\) These coefficients are not random. The linear combination is: (13.1) $${x_e} = \\sum\\limits_k {{h_k}{r_k}}$$ The difference between the estimated value \\({x_e}\\) and the true value \\(x\\) represents the error of the estimation procedure \\(error = {x_e} - x.\\) If this term is greater than zero we have an overestimate and if it less than zero we have an underestimate. We will consider both cases as equally objectionable. To accomplish this we consider the squared error \\({\\left( {{x_e} - x} \\right)^2}.\\) The mean-square error is then given by: (13.2) $$e = E\\left\\{ {{{\\left( {{x_e} - x} \\right)}^2}} \\right\\} = E\\left\\{ {{{\\left( {\\sum\\limits_k {{h_k}{r_k}} - x} \\right)}^2}} \\right\\}$$ We seek the value of the coefficient set \\(h\\) that minimizes this mean-square error. Taking the derivative with respect to one of the coefficients \\({{h_i}}\\) gives: (13.3) $$0 = \\frac{{\\partial e}}{{\\partial {h_i}}} = \\left( {\\frac{{\\partial e}}{{\\partial q}}} \\right)\\left( {\\frac{{\\partial q}}{{\\partial {h_i}}}} \\right) = 2E\\left\\{ {\\left( {\\sum\\limits_k {{h_k}{r_k} - x} } \\right){r_i}} \\right\\}$$ where we have (temporarily) set \\(q = \\left( {\\sum\\nolimits_k {{h_k}{r_k} - x} } \\right).\\) Note the critical step of exchanging the order of differentiation \\(\\partial \\left( \\bullet \\right)/\\partial {h_i}\\) and expectation \\(E\\left\\{ \\bullet \\right\\}.\\) See Equation 4.13 and Equation 4.14 . The result in Equation 13.3 must be simultaneously applied for every coefficient \\({h_i}\\) to produce the minimum mean-square error. This leads to a set of simultaneous equations which in some textbooks (Papoulis 1 ) is formulated as a vector equation. In that vector formulation the data vector \\({\\bf{r}}\\) is orthogonal to the error vector, \\({\\bf{e}} = {{\\bf{x}}_{\\bf{e}}} - {\\bf{x}},\\) as their inner product\u2014as exemplified by Equation 13.3 \u2014is zero. We, however, shall use the formulation shown above. Appendix II: The Discrete-Time Uncertainty Principle \u00b6 We begin with a discrete-time signal \\(x[n]\\) whose Fourier transform exists and is given by \\(X(\\Omega ) = {\\mathscr{F}}\\left\\{ {x[n]} \\right\\}.\\) We note that \\(X(\\Omega - \\pi ) = X(\\Omega + \\pi )\\) ; the spectrum is periodic. We will make use of Parseval\u2019s relation in both discrete and continuous time, Equation 13.4 . (13.4) $$\\begin{array}{*{20}{l}} {\\sum\\limits_{n = - \\infty }^{ + \\infty } {{{\\left| {x[n]} \\right|}^2} = \\frac{1}{{2\\pi }}\\int\\limits_{ - \\pi }^{ + \\pi } {{{\\left| {X(\\Omega )} \\right|}^2}d\\Omega } } }\\\\ {\\int\\limits_{ - \\infty }^{ + \\infty } {{{\\left| {x(t)} \\right|}^2}dt} = \\frac{1}{{2\\pi }}\\int\\limits_{ - \\infty }^{ + \\infty } {{{\\left| {X(\\omega )} \\right|}^2}d\\omega } } \\end{array}$$ Without loss of generality we assume that: (13.5) $$\\sum\\limits_{n = - \\infty }^{ + \\infty } {{{\\left| {x[n]} \\right|}^2}} = 1$$ (13.6) $$\\sum\\limits_{n = - \\infty }^{ + \\infty } {n{{\\left| {x[n]} \\right|}^2}} = 0$$ These two assumptions mean that the terms \\(\\left\\{ {{{\\left| {x[n]} \\right|}^2}} \\right\\}\\) are real, positive, and normalized for all \\(n.\\) They can be thought of as probabilities ( Equation 13.5 ) and that the average value of these probabilities is zero ( Equation 13.6 ). The general case, where the average is not zero, can be treated with a straightforward change of variable. Our proof is based upon the one given in Folland 2 . We start with the definitions of the squared signal-duration Equation 13.7 and the squared signal-bandwidth Equation 13.8 . (13.7) $$\\begin{array}{*{20}{l}} {{{\\left( {\\Delta {n_{rms}}} \\right)}^2}}&{ = \\left( {\\sum\\limits_{n = - \\infty }^{ + \\infty } {{n^2}{{\\left| {x[n]} \\right|}^2}} } \\right)/\\sum\\limits_{n = - \\infty }^{ + \\infty } {{{\\left| {x[n]} \\right|}^2}} }\\\\ {\\,\\,\\,}&{ = \\sum\\limits_{n = - \\infty }^{ + \\infty } {{n^2}{{\\left| {x[n]} \\right|}^2}} } \\end{array}$$ (13.8) $$\\begin{array}{*{20}{l}} {{{\\left( {\\Delta {\\Omega _{rms}}} \\right)}^2}}&{ = \\left( {\\int\\limits_{ - \\pi }^{ + \\pi } {{\\Omega ^2}{{\\left| {X(\\Omega )} \\right|}^2}d\\Omega } } \\right)/\\left( {\\int\\limits_{ - \\pi }^{ + \\pi } {{{\\left| {X(\\Omega )} \\right|}^2}d\\Omega } } \\right)}\\\\ {\\,\\,\\,}&{ = \\frac{1}{{2\\pi }}\\int\\limits_{ - \\pi }^{ + \\pi } {{\\Omega ^2}{{\\left| {X(\\Omega )} \\right|}^2}d\\Omega } } \\end{array}$$ We intend to show that: (13.9) $${\\left( {\\Delta {n_{rms}}} \\right)^2}{\\left( {\\Delta {\\Omega _{rms}}} \\right)^2} \\ge \\frac{1}{4}\\,\\,\\,\\,\\, \\Rightarrow \\,\\,\\,\\,\\,\\left( {\\Delta {n_{rms}}} \\right)\\left( {\\Delta {\\Omega _{rms}}} \\right) \\ge \\frac{1}{2}$$ We begin by forming a continuous and piecewise-smooth, continuous-time signal \\(y(t)\\) from the discrete-time signal \\(x[n].\\) By construction, \\(y(t = k) = x[k]\\) with a sampling interval of \\(T = 1.\\) (13.10) $$y(t) = \\sum\\limits_{n = - \\infty }^{ + \\infty } {x[n]{\\rm{sinc}}(t - n)} = \\sum\\limits_{n = - \\infty }^{ + \\infty } {x[n]\\frac{{\\sin \\left( {\\pi (t - n)} \\right)}}{{\\pi (t - n)}}}$$ The sinc function is chosen so that its Fourier transform is the ideal lowpass filter given in Equation 13.11 . (13.11) $${\\mathscr{F}}\\left\\{ {\\frac{{\\sin (\\pi t)}}{{\\pi t}}} \\right\\} = \\left\\{ {\\begin{array}{*{20}{l}} 1&{\\left| \\omega \\right| < \\pi }\\\\ 0&{\\left| \\omega \\right| > \\pi } \\end{array}} \\right.$$ Using \\(T = 1\\) implies that: (13.12) $$Y(\\omega ) = {\\mathscr{F}}\\left\\{ {y(t)} \\right\\} = \\left\\{ {\\begin{array}{*{20}{l}} {X(\\Omega = \\omega )}&{\\left| \\omega \\right| < \\pi }\\\\ 0&{\\left| \\omega \\right| > \\pi } \\end{array}} \\right.$$ In words, the ideal lowpass filter guarantees that \\(Y(\\omega )\\) is the baseband spectrum of the periodic spectrum \\(X(\\Omega ).\\) For the proof of the Uncertainty Principle, it is essential that \\(y(t)\\) is square-integrable, that it is in \\({L^2}.\\) This follows from: (13.13) $$\\begin{array}{l} \\int\\limits_{ - \\infty }^{ + \\infty } {{{\\left| {y(t)} \\right|}^2}dt} \\\\ \\,\\,\\,\\,\\,\\, = \\int\\limits_{ - \\infty }^{ + \\infty } {\\left( {\\sum\\limits_{n = - \\infty }^{ + \\infty } {x[n]{\\rm{sinc}}(t - n)} } \\right){{\\left( {\\sum\\limits_{k = - \\infty }^{ + \\infty } {x[k]{\\rm{sinc}}(t - k)} } \\right)}^*}dt} \\\\ \\,\\,\\,\\,\\, = \\sum\\limits_{n = - \\infty }^{ + \\infty } {\\sum\\limits_{k = - \\infty }^{ + \\infty } {x[n]} } {x^*}[k]\\int\\limits_{ - \\infty }^{ + \\infty } {{\\rm{sinc}}(t - n){\\rm{sinc}}(t - k)dt} \\\\ \\,\\,\\,\\,\\, = \\sum\\limits_{n = - \\infty }^{ + \\infty } {{{\\left| {x[n]} \\right|}^2} = 1} \\end{array}$$ We use the orthonormality of the sinc functions and the assumption in Equation 13.5 to reach the last line in Equation 13.13 . We conclude that \\(y(t)\\) is, indeed, in \\({L^2}.\\) The two signals \\(ty(t)\\) and \\(y'(t),\\) which we will now use, are either in \\({L^2}\\) or they are not. The situation when they are not in \\({L^2}\\) will be discussed later. In fact, whether or not \\(ty(t)\\) or \\(y'(t)\\) is in \\({L^2},\\) the Uncertainty Principle is satisfied. If they are in \\({L^2},\\) then the Folland technique can be directly applied to \\(\\int {ty(t){y^*}(t)dt}\\) leading to: (13.14) $$\\begin{array}{*{20}{l}} {\\int\\limits_{ - \\infty }^{ + \\infty } {{{\\left| {y(t)} \\right|}^2}dt} }&{ = - 2{\\mathop{\\rm Re}\\nolimits} \\left\\{ {\\int\\limits_{ - \\infty }^{ + \\infty } {{{\\left( {ty(t)} \\right)}^*}y'(t)dt} } \\right\\} + \\left. {t{{\\left| {y(t)} \\right|}^2}} \\right|_{ - \\infty }^{ + \\infty }}\\\\ {\\,\\,\\,}&{ = - 2{\\mathop{\\rm Re}\\nolimits} \\left\\{ {\\int\\limits_{ - \\infty }^{ + \\infty } {{{\\left( {ty(t)} \\right)}^*}y'(t)dt} } \\right\\}} \\end{array}$$ Because of the way \\(y(t)\\) is formed Equation 13.10 , the term \\(t{\\left| {y(t)} \\right|^2}\\) in the first line of Equation 13.14 vanishes at \\(t = \\pm \\infty.\\) Applying the Cauchy-Schwartz inequality then leads to 3 : (13.15) $${\\left( {\\int\\limits_{ - \\infty }^{ + \\infty } {{{\\left| {y(t)} \\right|}^2}dt} } \\right)^2} \\le 4\\left( {\\int\\limits_{ - \\infty }^{ + \\infty } {{t^2}{{\\left| {y(t)} \\right|}^2}dt} } \\right)\\left( {\\int\\limits_{ - \\infty }^{ + \\infty } {{{\\left| {y'(t)} \\right|}^2}dt} } \\right)$$ which means: (13.16) $$\\left( {\\int\\limits_{ - \\infty }^{ + \\infty } {{t^2}{{\\left| {y(t)} \\right|}^2}dt} } \\right)\\left( {\\int\\limits_{ - \\infty }^{ + \\infty } {{{\\left| {y'(t)} \\right|}^2}dt} } \\right) \\ge \\frac{1}{4}$$ We now use the Fourier property \\(y'(t) = {\\mathscr{F}^{ - 1}}\\left\\{ {j\\omega Y\\left( \\omega \\right)} \\right\\},\\) Parseval\u2019s relation Equation 13.4 , and the relation between the continuous-time spectrum \\(Y(\\omega )\\) and the discrete-time spectrum \\(X(\\Omega )\\) given in Equation 13.12 . From Equation 13.12 and Equation 13.8 we have: (13.17) $$\\begin{array}{*{20}{l}} {\\int\\limits_{ - \\infty }^{ + \\infty } {{{\\left| {y'(t)} \\right|}^2}dt} }&{ = \\frac{1}{{2\\pi }}\\int\\limits_{ - \\infty }^{ + \\infty } {{\\omega ^2}{{\\left| {Y(\\omega )} \\right|}^2}d\\omega } }\\\\ {\\,\\,\\,}&{ = \\frac{1}{{2\\pi }}\\int\\limits_{ - \\pi }^{ + \\pi } {{\\Omega ^2}{{\\left| {X(\\Omega )} \\right|}^2}d\\Omega } }\\\\ {\\,\\,\\,}&{ = {{\\left( {\\Delta {\\Omega _{rms}}} \\right)}^2}} \\end{array}$$ Substituting in Equation 13.16 gives: (13.18) $$\\left( {\\int\\limits_{ - \\infty }^{ + \\infty } {{t^2}{{\\left| {y(t)} \\right|}^2}dt} } \\right){\\left( {\\Delta {\\Omega _{rms}}} \\right)^2} \\ge \\frac{1}{4}$$ It only remains to show that \\(\\int {{t^2}{{\\left| {y(t)} \\right|}^2}} dt =\\) \\(\\sum {{n^2}{{\\left| {x[n]} \\right|}^2} = }\\) \\({\\left( {\\Delta {n_{rms}}} \\right)^2}.\\) We know that \\(y(t)\\) is bandlimited because of the way it is formed, Equation 13.10 . Again using Parseval\u2019s relation Equation 13.4 and the relation between the continuous-time spectrum \\(Y(\\omega )\\) and the discrete-time spectrum \\(X(\\Omega )\\) given in Equation 13.12 , this implies that \\(ty(t)\\) is also bandlimited and that the \u201cenergy\u201d in \\(ty(t)\\) is given by: (13.19) $$\\begin{array}{*{20}{l}} {\\int\\limits_{ - \\infty }^{ + \\infty } {{t^2}{{\\left| {y(t)} \\right|}^2}dt} }&{ = \\frac{1}{{2\\pi }}\\int\\limits_{ - \\infty }^{ + \\infty } {{\\omega ^2}{{\\left| {Y(\\omega )} \\right|}^2}d\\omega } }\\\\ {\\,\\,\\,}&{ = \\frac{1}{{2\\pi }}\\int\\limits_{ - \\pi }^{ + \\pi } {{\\omega ^2}{{\\left| {Y(\\omega )} \\right|}^2}d\\omega } }\\\\ {\\,\\,\\,}&{ = \\frac{1}{{2\\pi }}\\int\\limits_{ - \\pi }^{ + \\pi } {{\\Omega ^2}{{\\left| {X(\\Omega )} \\right|}^2}d\\Omega } }\\\\ {\\,\\,\\,}&{ = \\sum\\limits_{n = - \\infty }^{ + \\infty } {{n^2}{{\\left| {x[n]} \\right|}^2}} }\\\\ {\\,\\,\\,}&{ = {{\\left( {\\Delta {n_{rms}}} \\right)}^2}} \\end{array}$$ Throughout this derivation we use \\(T = 1\\) which is the proper value for analyzing the Uncertainty Principle. Should we wish to use this result in other applications where the sampling interval could be shorter, a higher sampling frequency, then the appropriate formulation is: (13.20) $$\\frac{1}{T}\\int\\limits_{ - \\infty }^{ + \\infty } {{t^2}{{\\left| {y(t)} \\right|}^2}dt} = \\sum\\limits_{n = - \\infty }^{ + \\infty } {{n^2}{{\\left| {x[n]} \\right|}^2}}$$ Substituting the result in Equation 13.19 into Equation 13.18 leads to the desired result: (13.21) $${\\left( {\\Delta {n_{rms}}} \\right)^2}{\\left( {\\Delta {\\Omega _{rms}}} \\right)^2} \\ge \\frac{1}{4}\\,\\,\\,\\,\\, \\Rightarrow \\,\\,\\,\\,\\,\\left( {\\Delta {n_{rms}}} \\right)\\left( {\\Delta {\\Omega _{rms}}} \\right) \\ge \\frac{1}{2}$$ We return to the discussion of the two signals \\(ty(t)\\) and \\(y'(t)\\) when either of the signals is not in \\({L^2}.\\) If \\(ty(t)\\) is not in \\({L^2}\\) then, from Equation 13.19 , we have that \\({\\left( {\\Delta {n_{rms}}} \\right)^2}\\) is unbounded and Equation 13.21 is automatically satisfied. Similarly if \\(y'(t)\\) is not in \\({L^2}\\) then, from Equation 13.17 , \\({\\left( {\\Delta {\\Omega _{rms}}} \\right)^2}\\) is unbounded and Equation 13.21 is again satisfied. Epilogue \u00b6 Our goal in this iBook has been twofold. First, we have attempted to present the basic concepts of stochastic (random) signal processing in the setting of discrete-time signal processing and with a number of examples that indicate the power of this approach. Second, we have tried to make use of modern technology to change a textbook from a static entity to a dynamic one. The ability to hear signals before and after processing, the ability to see the dynamics of signal processing and the possibility to link to the outside world can, we believe, improve the learning process. In the end, the best description of the goal of a textbook was given by Professor Y.W. Lee of the Massachusetts Institute of Technology when he wrote 4 : \u201cIn writing this book I have been guided by the idea that a teacher should not attempt to cover the subject of study but should attempt to uncover it for the student.\u201d Ted Young Ronald Ligteringen Delft, The Netherlands July, 2020 Papoulis, A. (1977). Signal Analysis. New York, McGraw-Hill \u21a9 Folland, G. B. (1992). Fourier Analysis and its Applications. Pacific Grove, California, Wadsworth $ Brooks/Cole \u21a9 The essential part of Folland\u2019s approach starts with integration-by-parts: \\(\\int {u(t)v'(t)dt = }\\) \\(u(t)v(t) -\\) \\(\\int {v(t)u'(t)dt}.\\) We then set \\(u(t) = t{y^*}(t)\\) and \\(v'(t) = y'(t).\\) Careful application of the integration rule\u2014together with the observation that \\(q(t) + {q^*}(t) = 2\\operatorname{Re} \\left\\{ {q(t)} \\right\\}\\) and that for any complex \\(q,\\) \\(\\operatorname{Re} \\left\\{ q \\right\\} \\leqslant \\left| q \\right|\\) \u2014yields the desired result. \u21a9 Lee, Y. W. (1960). Statistical Theory of Communication. New York, John Wiley & Sons \u21a9","title":"Appendices"},{"location":"Chap_13.html#appendices","text":"","title":"Appendices"},{"location":"Chap_13.html#appendix-i-mean-square-error-minimization","text":"We wish to estimate a random variable \\(x\\) as a linear combination \\({x_e}\\) of other random variables \\(r.\\) The weighting coefficients in the linear combination are \\(h.\\) These coefficients are not random. The linear combination is: (13.1) $${x_e} = \\sum\\limits_k {{h_k}{r_k}}$$ The difference between the estimated value \\({x_e}\\) and the true value \\(x\\) represents the error of the estimation procedure \\(error = {x_e} - x.\\) If this term is greater than zero we have an overestimate and if it less than zero we have an underestimate. We will consider both cases as equally objectionable. To accomplish this we consider the squared error \\({\\left( {{x_e} - x} \\right)^2}.\\) The mean-square error is then given by: (13.2) $$e = E\\left\\{ {{{\\left( {{x_e} - x} \\right)}^2}} \\right\\} = E\\left\\{ {{{\\left( {\\sum\\limits_k {{h_k}{r_k}} - x} \\right)}^2}} \\right\\}$$ We seek the value of the coefficient set \\(h\\) that minimizes this mean-square error. Taking the derivative with respect to one of the coefficients \\({{h_i}}\\) gives: (13.3) $$0 = \\frac{{\\partial e}}{{\\partial {h_i}}} = \\left( {\\frac{{\\partial e}}{{\\partial q}}} \\right)\\left( {\\frac{{\\partial q}}{{\\partial {h_i}}}} \\right) = 2E\\left\\{ {\\left( {\\sum\\limits_k {{h_k}{r_k} - x} } \\right){r_i}} \\right\\}$$ where we have (temporarily) set \\(q = \\left( {\\sum\\nolimits_k {{h_k}{r_k} - x} } \\right).\\) Note the critical step of exchanging the order of differentiation \\(\\partial \\left( \\bullet \\right)/\\partial {h_i}\\) and expectation \\(E\\left\\{ \\bullet \\right\\}.\\) See Equation 4.13 and Equation 4.14 . The result in Equation 13.3 must be simultaneously applied for every coefficient \\({h_i}\\) to produce the minimum mean-square error. This leads to a set of simultaneous equations which in some textbooks (Papoulis 1 ) is formulated as a vector equation. In that vector formulation the data vector \\({\\bf{r}}\\) is orthogonal to the error vector, \\({\\bf{e}} = {{\\bf{x}}_{\\bf{e}}} - {\\bf{x}},\\) as their inner product\u2014as exemplified by Equation 13.3 \u2014is zero. We, however, shall use the formulation shown above.","title":"Appendix I: Mean-Square Error Minimization"},{"location":"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle","text":"We begin with a discrete-time signal \\(x[n]\\) whose Fourier transform exists and is given by \\(X(\\Omega ) = {\\mathscr{F}}\\left\\{ {x[n]} \\right\\}.\\) We note that \\(X(\\Omega - \\pi ) = X(\\Omega + \\pi )\\) ; the spectrum is periodic. We will make use of Parseval\u2019s relation in both discrete and continuous time, Equation 13.4 . (13.4) $$\\begin{array}{*{20}{l}} {\\sum\\limits_{n = - \\infty }^{ + \\infty } {{{\\left| {x[n]} \\right|}^2} = \\frac{1}{{2\\pi }}\\int\\limits_{ - \\pi }^{ + \\pi } {{{\\left| {X(\\Omega )} \\right|}^2}d\\Omega } } }\\\\ {\\int\\limits_{ - \\infty }^{ + \\infty } {{{\\left| {x(t)} \\right|}^2}dt} = \\frac{1}{{2\\pi }}\\int\\limits_{ - \\infty }^{ + \\infty } {{{\\left| {X(\\omega )} \\right|}^2}d\\omega } } \\end{array}$$ Without loss of generality we assume that: (13.5) $$\\sum\\limits_{n = - \\infty }^{ + \\infty } {{{\\left| {x[n]} \\right|}^2}} = 1$$ (13.6) $$\\sum\\limits_{n = - \\infty }^{ + \\infty } {n{{\\left| {x[n]} \\right|}^2}} = 0$$ These two assumptions mean that the terms \\(\\left\\{ {{{\\left| {x[n]} \\right|}^2}} \\right\\}\\) are real, positive, and normalized for all \\(n.\\) They can be thought of as probabilities ( Equation 13.5 ) and that the average value of these probabilities is zero ( Equation 13.6 ). The general case, where the average is not zero, can be treated with a straightforward change of variable. Our proof is based upon the one given in Folland 2 . We start with the definitions of the squared signal-duration Equation 13.7 and the squared signal-bandwidth Equation 13.8 . (13.7) $$\\begin{array}{*{20}{l}} {{{\\left( {\\Delta {n_{rms}}} \\right)}^2}}&{ = \\left( {\\sum\\limits_{n = - \\infty }^{ + \\infty } {{n^2}{{\\left| {x[n]} \\right|}^2}} } \\right)/\\sum\\limits_{n = - \\infty }^{ + \\infty } {{{\\left| {x[n]} \\right|}^2}} }\\\\ {\\,\\,\\,}&{ = \\sum\\limits_{n = - \\infty }^{ + \\infty } {{n^2}{{\\left| {x[n]} \\right|}^2}} } \\end{array}$$ (13.8) $$\\begin{array}{*{20}{l}} {{{\\left( {\\Delta {\\Omega _{rms}}} \\right)}^2}}&{ = \\left( {\\int\\limits_{ - \\pi }^{ + \\pi } {{\\Omega ^2}{{\\left| {X(\\Omega )} \\right|}^2}d\\Omega } } \\right)/\\left( {\\int\\limits_{ - \\pi }^{ + \\pi } {{{\\left| {X(\\Omega )} \\right|}^2}d\\Omega } } \\right)}\\\\ {\\,\\,\\,}&{ = \\frac{1}{{2\\pi }}\\int\\limits_{ - \\pi }^{ + \\pi } {{\\Omega ^2}{{\\left| {X(\\Omega )} \\right|}^2}d\\Omega } } \\end{array}$$ We intend to show that: (13.9) $${\\left( {\\Delta {n_{rms}}} \\right)^2}{\\left( {\\Delta {\\Omega _{rms}}} \\right)^2} \\ge \\frac{1}{4}\\,\\,\\,\\,\\, \\Rightarrow \\,\\,\\,\\,\\,\\left( {\\Delta {n_{rms}}} \\right)\\left( {\\Delta {\\Omega _{rms}}} \\right) \\ge \\frac{1}{2}$$ We begin by forming a continuous and piecewise-smooth, continuous-time signal \\(y(t)\\) from the discrete-time signal \\(x[n].\\) By construction, \\(y(t = k) = x[k]\\) with a sampling interval of \\(T = 1.\\) (13.10) $$y(t) = \\sum\\limits_{n = - \\infty }^{ + \\infty } {x[n]{\\rm{sinc}}(t - n)} = \\sum\\limits_{n = - \\infty }^{ + \\infty } {x[n]\\frac{{\\sin \\left( {\\pi (t - n)} \\right)}}{{\\pi (t - n)}}}$$ The sinc function is chosen so that its Fourier transform is the ideal lowpass filter given in Equation 13.11 . (13.11) $${\\mathscr{F}}\\left\\{ {\\frac{{\\sin (\\pi t)}}{{\\pi t}}} \\right\\} = \\left\\{ {\\begin{array}{*{20}{l}} 1&{\\left| \\omega \\right| < \\pi }\\\\ 0&{\\left| \\omega \\right| > \\pi } \\end{array}} \\right.$$ Using \\(T = 1\\) implies that: (13.12) $$Y(\\omega ) = {\\mathscr{F}}\\left\\{ {y(t)} \\right\\} = \\left\\{ {\\begin{array}{*{20}{l}} {X(\\Omega = \\omega )}&{\\left| \\omega \\right| < \\pi }\\\\ 0&{\\left| \\omega \\right| > \\pi } \\end{array}} \\right.$$ In words, the ideal lowpass filter guarantees that \\(Y(\\omega )\\) is the baseband spectrum of the periodic spectrum \\(X(\\Omega ).\\) For the proof of the Uncertainty Principle, it is essential that \\(y(t)\\) is square-integrable, that it is in \\({L^2}.\\) This follows from: (13.13) $$\\begin{array}{l} \\int\\limits_{ - \\infty }^{ + \\infty } {{{\\left| {y(t)} \\right|}^2}dt} \\\\ \\,\\,\\,\\,\\,\\, = \\int\\limits_{ - \\infty }^{ + \\infty } {\\left( {\\sum\\limits_{n = - \\infty }^{ + \\infty } {x[n]{\\rm{sinc}}(t - n)} } \\right){{\\left( {\\sum\\limits_{k = - \\infty }^{ + \\infty } {x[k]{\\rm{sinc}}(t - k)} } \\right)}^*}dt} \\\\ \\,\\,\\,\\,\\, = \\sum\\limits_{n = - \\infty }^{ + \\infty } {\\sum\\limits_{k = - \\infty }^{ + \\infty } {x[n]} } {x^*}[k]\\int\\limits_{ - \\infty }^{ + \\infty } {{\\rm{sinc}}(t - n){\\rm{sinc}}(t - k)dt} \\\\ \\,\\,\\,\\,\\, = \\sum\\limits_{n = - \\infty }^{ + \\infty } {{{\\left| {x[n]} \\right|}^2} = 1} \\end{array}$$ We use the orthonormality of the sinc functions and the assumption in Equation 13.5 to reach the last line in Equation 13.13 . We conclude that \\(y(t)\\) is, indeed, in \\({L^2}.\\) The two signals \\(ty(t)\\) and \\(y'(t),\\) which we will now use, are either in \\({L^2}\\) or they are not. The situation when they are not in \\({L^2}\\) will be discussed later. In fact, whether or not \\(ty(t)\\) or \\(y'(t)\\) is in \\({L^2},\\) the Uncertainty Principle is satisfied. If they are in \\({L^2},\\) then the Folland technique can be directly applied to \\(\\int {ty(t){y^*}(t)dt}\\) leading to: (13.14) $$\\begin{array}{*{20}{l}} {\\int\\limits_{ - \\infty }^{ + \\infty } {{{\\left| {y(t)} \\right|}^2}dt} }&{ = - 2{\\mathop{\\rm Re}\\nolimits} \\left\\{ {\\int\\limits_{ - \\infty }^{ + \\infty } {{{\\left( {ty(t)} \\right)}^*}y'(t)dt} } \\right\\} + \\left. {t{{\\left| {y(t)} \\right|}^2}} \\right|_{ - \\infty }^{ + \\infty }}\\\\ {\\,\\,\\,}&{ = - 2{\\mathop{\\rm Re}\\nolimits} \\left\\{ {\\int\\limits_{ - \\infty }^{ + \\infty } {{{\\left( {ty(t)} \\right)}^*}y'(t)dt} } \\right\\}} \\end{array}$$ Because of the way \\(y(t)\\) is formed Equation 13.10 , the term \\(t{\\left| {y(t)} \\right|^2}\\) in the first line of Equation 13.14 vanishes at \\(t = \\pm \\infty.\\) Applying the Cauchy-Schwartz inequality then leads to 3 : (13.15) $${\\left( {\\int\\limits_{ - \\infty }^{ + \\infty } {{{\\left| {y(t)} \\right|}^2}dt} } \\right)^2} \\le 4\\left( {\\int\\limits_{ - \\infty }^{ + \\infty } {{t^2}{{\\left| {y(t)} \\right|}^2}dt} } \\right)\\left( {\\int\\limits_{ - \\infty }^{ + \\infty } {{{\\left| {y'(t)} \\right|}^2}dt} } \\right)$$ which means: (13.16) $$\\left( {\\int\\limits_{ - \\infty }^{ + \\infty } {{t^2}{{\\left| {y(t)} \\right|}^2}dt} } \\right)\\left( {\\int\\limits_{ - \\infty }^{ + \\infty } {{{\\left| {y'(t)} \\right|}^2}dt} } \\right) \\ge \\frac{1}{4}$$ We now use the Fourier property \\(y'(t) = {\\mathscr{F}^{ - 1}}\\left\\{ {j\\omega Y\\left( \\omega \\right)} \\right\\},\\) Parseval\u2019s relation Equation 13.4 , and the relation between the continuous-time spectrum \\(Y(\\omega )\\) and the discrete-time spectrum \\(X(\\Omega )\\) given in Equation 13.12 . From Equation 13.12 and Equation 13.8 we have: (13.17) $$\\begin{array}{*{20}{l}} {\\int\\limits_{ - \\infty }^{ + \\infty } {{{\\left| {y'(t)} \\right|}^2}dt} }&{ = \\frac{1}{{2\\pi }}\\int\\limits_{ - \\infty }^{ + \\infty } {{\\omega ^2}{{\\left| {Y(\\omega )} \\right|}^2}d\\omega } }\\\\ {\\,\\,\\,}&{ = \\frac{1}{{2\\pi }}\\int\\limits_{ - \\pi }^{ + \\pi } {{\\Omega ^2}{{\\left| {X(\\Omega )} \\right|}^2}d\\Omega } }\\\\ {\\,\\,\\,}&{ = {{\\left( {\\Delta {\\Omega _{rms}}} \\right)}^2}} \\end{array}$$ Substituting in Equation 13.16 gives: (13.18) $$\\left( {\\int\\limits_{ - \\infty }^{ + \\infty } {{t^2}{{\\left| {y(t)} \\right|}^2}dt} } \\right){\\left( {\\Delta {\\Omega _{rms}}} \\right)^2} \\ge \\frac{1}{4}$$ It only remains to show that \\(\\int {{t^2}{{\\left| {y(t)} \\right|}^2}} dt =\\) \\(\\sum {{n^2}{{\\left| {x[n]} \\right|}^2} = }\\) \\({\\left( {\\Delta {n_{rms}}} \\right)^2}.\\) We know that \\(y(t)\\) is bandlimited because of the way it is formed, Equation 13.10 . Again using Parseval\u2019s relation Equation 13.4 and the relation between the continuous-time spectrum \\(Y(\\omega )\\) and the discrete-time spectrum \\(X(\\Omega )\\) given in Equation 13.12 , this implies that \\(ty(t)\\) is also bandlimited and that the \u201cenergy\u201d in \\(ty(t)\\) is given by: (13.19) $$\\begin{array}{*{20}{l}} {\\int\\limits_{ - \\infty }^{ + \\infty } {{t^2}{{\\left| {y(t)} \\right|}^2}dt} }&{ = \\frac{1}{{2\\pi }}\\int\\limits_{ - \\infty }^{ + \\infty } {{\\omega ^2}{{\\left| {Y(\\omega )} \\right|}^2}d\\omega } }\\\\ {\\,\\,\\,}&{ = \\frac{1}{{2\\pi }}\\int\\limits_{ - \\pi }^{ + \\pi } {{\\omega ^2}{{\\left| {Y(\\omega )} \\right|}^2}d\\omega } }\\\\ {\\,\\,\\,}&{ = \\frac{1}{{2\\pi }}\\int\\limits_{ - \\pi }^{ + \\pi } {{\\Omega ^2}{{\\left| {X(\\Omega )} \\right|}^2}d\\Omega } }\\\\ {\\,\\,\\,}&{ = \\sum\\limits_{n = - \\infty }^{ + \\infty } {{n^2}{{\\left| {x[n]} \\right|}^2}} }\\\\ {\\,\\,\\,}&{ = {{\\left( {\\Delta {n_{rms}}} \\right)}^2}} \\end{array}$$ Throughout this derivation we use \\(T = 1\\) which is the proper value for analyzing the Uncertainty Principle. Should we wish to use this result in other applications where the sampling interval could be shorter, a higher sampling frequency, then the appropriate formulation is: (13.20) $$\\frac{1}{T}\\int\\limits_{ - \\infty }^{ + \\infty } {{t^2}{{\\left| {y(t)} \\right|}^2}dt} = \\sum\\limits_{n = - \\infty }^{ + \\infty } {{n^2}{{\\left| {x[n]} \\right|}^2}}$$ Substituting the result in Equation 13.19 into Equation 13.18 leads to the desired result: (13.21) $${\\left( {\\Delta {n_{rms}}} \\right)^2}{\\left( {\\Delta {\\Omega _{rms}}} \\right)^2} \\ge \\frac{1}{4}\\,\\,\\,\\,\\, \\Rightarrow \\,\\,\\,\\,\\,\\left( {\\Delta {n_{rms}}} \\right)\\left( {\\Delta {\\Omega _{rms}}} \\right) \\ge \\frac{1}{2}$$ We return to the discussion of the two signals \\(ty(t)\\) and \\(y'(t)\\) when either of the signals is not in \\({L^2}.\\) If \\(ty(t)\\) is not in \\({L^2}\\) then, from Equation 13.19 , we have that \\({\\left( {\\Delta {n_{rms}}} \\right)^2}\\) is unbounded and Equation 13.21 is automatically satisfied. Similarly if \\(y'(t)\\) is not in \\({L^2}\\) then, from Equation 13.17 , \\({\\left( {\\Delta {\\Omega _{rms}}} \\right)^2}\\) is unbounded and Equation 13.21 is again satisfied.","title":"Appendix II: The Discrete-Time Uncertainty Principle"},{"location":"Chap_13.html#epilogue","text":"Our goal in this iBook has been twofold. First, we have attempted to present the basic concepts of stochastic (random) signal processing in the setting of discrete-time signal processing and with a number of examples that indicate the power of this approach. Second, we have tried to make use of modern technology to change a textbook from a static entity to a dynamic one. The ability to hear signals before and after processing, the ability to see the dynamics of signal processing and the possibility to link to the outside world can, we believe, improve the learning process. In the end, the best description of the goal of a textbook was given by Professor Y.W. Lee of the Massachusetts Institute of Technology when he wrote 4 : \u201cIn writing this book I have been guided by the idea that a teacher should not attempt to cover the subject of study but should attempt to uncover it for the student.\u201d Ted Young Ronald Ligteringen Delft, The Netherlands July, 2020 Papoulis, A. (1977). Signal Analysis. New York, McGraw-Hill \u21a9 Folland, G. B. (1992). Fourier Analysis and its Applications. Pacific Grove, California, Wadsworth $ Brooks/Cole \u21a9 The essential part of Folland\u2019s approach starts with integration-by-parts: \\(\\int {u(t)v'(t)dt = }\\) \\(u(t)v(t) -\\) \\(\\int {v(t)u'(t)dt}.\\) We then set \\(u(t) = t{y^*}(t)\\) and \\(v'(t) = y'(t).\\) Careful application of the integration rule\u2014together with the observation that \\(q(t) + {q^*}(t) = 2\\operatorname{Re} \\left\\{ {q(t)} \\right\\}\\) and that for any complex \\(q,\\) \\(\\operatorname{Re} \\left\\{ q \\right\\} \\leqslant \\left| q \\right|\\) \u2014yields the desired result. \u21a9 Lee, Y. W. (1960). Statistical Theory of Communication. New York, John Wiley & Sons \u21a9","title":"Epilogue"},{"location":"Chap_2.html","text":"Prologue \u00b6 Many of the physical processes that give rise to signals can be described as deterministic. By this we mean that the value of a \u201csignal\u201d\u2014measured in volts, meters, Euros, kilograms, Pascals, etc.\u2014can be described at every point in time. There are, however, many physical processes where the value of a physical variable is not predictable. The underlying physical processes may be inherently stochastic 1 (i.e. random), as in processes closely allied to quantum physics such as photon production. Alternatively, the physical processes may be so complex and involve so many variables that we are not capable of describing them in such a way that we can predict completely the time course of events. One well-known example is speech and another is the weather with physical variables being the temperature as a function of time or the wind velocity or wind direction as a function of time. Two examples are given in Chapter 5 . Nevertheless, we should like to be able to use the tools of signal processing to filter, control, or analyze such physical variables. The goal of this iBook is to extend the domain of signal processing tools to include stochastic signals, in particular, those signals that are a function of time. Modern textbooks that develop and describe signal processing frequently present both continuous-time and discrete-time approaches to convolution, Fourier analysis, filtering, modulation, complex exponential transforms, and feedback systems. Further, continuous-time and discrete-time considerations are tied together through considerations of sampling and reconstruction which are frequently developed in the context of the Nyquist sampling theorem after Dr. Harry Nyquist (1889-1976). In this iBook we introduce stochastic signal processing in the context of discrete-time signals and discrete-time systems, what is frequently termed digital signal processing. We do so because modern use of these techniques, with only a few exceptions, is in the discrete domain. When appropriate, as in Chapter 7 , we will develop, refer to, and/or use concepts from continuous-time signal processing but, in general, we will focus on discrete-time processing. Finally, we will occasionally ask the question \u201c What does it mean ?\u201d. The pioneer of this question in the 20 th century was Professor Irwin Corey , the World\u2019s Foremost Authority. After a monologue on a particular topic he would, in a plaintive voice, ask this question. It took us a long time in education to realize that he was on to something and that students (and their teachers) have to repeatedly ask this question. To get you started, consider Problem 2.1 . Problems \u00b6 Problem 2.1 \u00b6 A well-known result in linear, time-invariant signal processing is that convolution is commutative , that is, \\(h[n] \\otimes x[n] = x[n] \\otimes h[n]\\) where \u201c \\(\\otimes\\) \u201d is the convolution operation. What does this mean ? What opportunities are represented through the commutative property of convolution? From the Oxford English Dictionary: Stochastic \u2013 randomly determined; that follows some random probability distribution or pattern, so that its behaviour may be analysed statistically but not predicted precisely; From the Greek: to aim at a mark, to guess. \u21a9","title":"2. Prologue"},{"location":"Chap_2.html#prologue","text":"Many of the physical processes that give rise to signals can be described as deterministic. By this we mean that the value of a \u201csignal\u201d\u2014measured in volts, meters, Euros, kilograms, Pascals, etc.\u2014can be described at every point in time. There are, however, many physical processes where the value of a physical variable is not predictable. The underlying physical processes may be inherently stochastic 1 (i.e. random), as in processes closely allied to quantum physics such as photon production. Alternatively, the physical processes may be so complex and involve so many variables that we are not capable of describing them in such a way that we can predict completely the time course of events. One well-known example is speech and another is the weather with physical variables being the temperature as a function of time or the wind velocity or wind direction as a function of time. Two examples are given in Chapter 5 . Nevertheless, we should like to be able to use the tools of signal processing to filter, control, or analyze such physical variables. The goal of this iBook is to extend the domain of signal processing tools to include stochastic signals, in particular, those signals that are a function of time. Modern textbooks that develop and describe signal processing frequently present both continuous-time and discrete-time approaches to convolution, Fourier analysis, filtering, modulation, complex exponential transforms, and feedback systems. Further, continuous-time and discrete-time considerations are tied together through considerations of sampling and reconstruction which are frequently developed in the context of the Nyquist sampling theorem after Dr. Harry Nyquist (1889-1976). In this iBook we introduce stochastic signal processing in the context of discrete-time signals and discrete-time systems, what is frequently termed digital signal processing. We do so because modern use of these techniques, with only a few exceptions, is in the discrete domain. When appropriate, as in Chapter 7 , we will develop, refer to, and/or use concepts from continuous-time signal processing but, in general, we will focus on discrete-time processing. Finally, we will occasionally ask the question \u201c What does it mean ?\u201d. The pioneer of this question in the 20 th century was Professor Irwin Corey , the World\u2019s Foremost Authority. After a monologue on a particular topic he would, in a plaintive voice, ask this question. It took us a long time in education to realize that he was on to something and that students (and their teachers) have to repeatedly ask this question. To get you started, consider Problem 2.1 .","title":"Prologue"},{"location":"Chap_2.html#problems","text":"","title":"Problems"},{"location":"Chap_2.html#problem-21","text":"A well-known result in linear, time-invariant signal processing is that convolution is commutative , that is, \\(h[n] \\otimes x[n] = x[n] \\otimes h[n]\\) where \u201c \\(\\otimes\\) \u201d is the convolution operation. What does this mean ? What opportunities are represented through the commutative property of convolution? From the Oxford English Dictionary: Stochastic \u2013 randomly determined; that follows some random probability distribution or pattern, so that its behaviour may be analysed statistically but not predicted precisely; From the Greek: to aim at a mark, to guess. \u21a9","title":"Problem 2.1"},{"location":"Chap_3.html","text":"Introduction \u00b6 In introductory studies of signals and systems we look at the class of input signals known as \u201cdeterministic\u201d signals, signals where the value of the time function is known, by definition, for every time point \\(x[n]\\) . With the results derived in such studies we can calculate the outputs for linear, time-invariant (LTI) systems with impulse response \\(h[n]\\) either through time domain convolution Equation 3.1 : (3.1) $$ y[n] = x[n] \\otimes h[n] \\triangleq \\sum\\limits_{k = - \\infty }^{ + \\infty } x [k]h[n - k] $$ or through frequency domain multiplication: (3.2) $$ Y(\\Omega)=X(\\Omega)H(\\Omega) $$ We assume an introductory level knowledge of signal processing and linear system theory. Such an introduction can be found in \u201cSignals and Systems\u201d 1 . The basics \u00b6 The time domain \\(n\\) and the frequency domain \\(\\Omega\\) representations of signals are related through the Fourier transform pair: (3.3) $$ \\begin{aligned} X(\\Omega)&=\\sum_{n={-\\infty}}^{+\\infty}x[n]e^{{-j}\\Omega n}\\\\ x[n]&=\\frac{1}{2\\pi}\\int\\limits_{-\\pi}^{+\\pi}X(\\Omega)e^{+j\\Omega n}d\\Omega \\end{aligned} $$ In shorthand notation, \\(X(\\Omega)=\\mathscr{F}\\left\\{x[n]\\right\\}\\) and \\(x[n]=\\mathscr{F}^{-1}\\left\\{X(\\Omega)\\right\\}\\) where \\(\\mathscr{F}\\left\\{\u2022\\right\\}\\) is the Fourier transform operator. It is important that you are familiar with the computation and properties of Fourier transforms and inverse Fourier transforms and with convolution. The exercises in Problem 3.1 and Problem 3.3 review this material. The first eight problems, in fact, are review problems in linear system theory and probability theory. If you find them difficult then you should review the textbooks in these disciplines. Several textbooks are listed below 1 , 2 , 3 . What is a random signal? \u00b6 For an important class of input signals, however, the value of the signal at each time point is not known. Only very general properties of the input signal, referred to as averages , are available and it is with these averages that we must try to describe what happens at the output end of an LTI system. These signals are called stochastic or random signals and we can distinguish between two classes: Random signals carrying information\u2014e.g. speech, music, radio astronomy; Random signals without information\u2014noise. We will describe both types of random signals in this iBook but, to do so, we must first develop some basic concepts concerning random signals and various averages of random signals. After that we will show how these concepts of stochastic signals can be used. We assume that you are familiar with basic probability theory but to review this material there is \u201cProbability, Random Variables, and Stochastic Processes\u201d 2 and the classical \u201cMathematical Methods of Statistics\u201d 3 . The exercises in Problem 3.4 review this material. We will develop several important themes including: Signal-to-noise ratio (SNR) characterizations of systems; Choosing linear filters for noise reduction; Problems in estimation of Fourier spectra. We begin with a simple model for generating a random signal in Example \u201cDon\u2019t bet on it\u201d . Example: Don\u2019t bet on it \u00b6 We throw a die once per second (discrete time) and the amplitude of the signal is the number of dots showing on the top die face. If at time \\(n=n_0\\) the result is then: (3.4) $$x[n_0]=6\\delta[n-n_0]$$ If the die is \u201cfair\u201d then the probability of die face # \\(i\\) appearing on top, \\(p(i)\\) , will be the same for all faces and thus \\(p(1)=p(2)=\\dots=p(6)=\\frac{1}{6}\\) . This is just an example of the general requirements for a set of probabilities that could be associated with the six faces of a die. (3.5) $$\\sum_{i=0}^{6}p(i)=1\\text{ with }p(i)\\geq 0 $$ Over a period of time, that is a number of seconds, we can generate a random signal as shown in Figure 3.1 . Figure 3.1: First realization of 31 random throws of a fair die. This is just one realization of a random signal where the amplitudes are governed by a specific probability function. Performing the experiment again might lead to another realization as shown in Figure 3.2 . Figure 3.2: Second realization of 31 random throws of a fair die. This concept will be illustrated, later, in Laboratory Exercise 4.1 . We can continue this procedure to generate an infinite number of realizations each governed by the same generating rule, throwing a fair die once per second and using the top face as a signal amplitude at that second. The possible collection of waveforms ( \\(x_1[n]\\) , \\(x_2[n]\\) , \\(x_3[n]\\) , \\(x_4[n]\\) ,\u2026) together with the probability function for the amplitudes at time \\(n\\) form a random process . Instead of having the amplitudes governed by the throw of a die, we might find that the amplitudes are taken from the values on the continuous real line between \\({-a}\\) and \\(+a\\) with probability density function: (3.6) $$p(\\alpha)= \\begin{cases} \\frac{1}{2a} & \\lvert\\alpha\\rvert\\leq a\\\\ 0 & \\lvert\\alpha\\rvert > a\\\\ \\end{cases} $$ A graph of this probability function is given in Figure 3.3 . Figure 3.3: A uniform probability density function, \\(p(\\alpha)\\) . All realizations between \\(-a\\) and \\(+a\\) are equally likely. The total probability (area under the curve) is 1. It should be clear that at no time point will \\(\\lvert x[n]\\rvert > a.\\) (Can you see why?) Thus \\(\\vert x[n]\\rvert \\leq a.\\) But the probability of the amplitude taking on the exact values \\(x[n]=+a\\) or \\(x[n]={-a}\\) is zero. (The proof of this is left to you; see Problem 3.5 .) We might also consider that the amplitudes could be governed by the probability density function ( pdf ): (3.7) $$p(\\alpha ) = \\frac{1}{{\\sigma \\sqrt {2\\pi } }}{e^{ - {\\alpha ^2}/2{\\sigma ^2}}}\\quad {\\kern 1pt} - \\infty \\leqslant \\alpha \\leqslant + \\infty $$ This is perhaps the most well-known and well-studied continuous probability density function, the Gaussian (or normal) function. A graph of this probability function is given in Figure 3.4 . Figure 3.4: A Gaussian (normal) probability density function, \\(p(\\alpha).\\) Again, the total area under the curve is 1. Examples of realizations from two random processes, one governed by a uniform probability density function and one by a Gaussian probability density function, are shown in Figure 3.5 and Figure 3.6 . See Problem 3.6 . Figure 3.5: Example of samples from a Uniform density function ( \\(\\mu=1.0, \\sigma=1/\\sqrt{12}\\) ) Figure 3.6: Example of samples from a Gaussian density function ( \\(\\mu=1.0, \\sigma=1/\\sqrt{12}\\) ) Further, we could envision the situation where the random signal is generated by the composite rule from two distributions: \\[ \\begin{aligned} n\\text{ even }(n=\\dots, -4, -2, 0, 2, \\dots)\\rightarrow p(x[n])&=\\text{ throw die}\\\\ n\\text{ odd }(n=\\dots, -3, -1, 1, 3, \\dots)\\rightarrow p(x[n])&=\\text{ choose from Gaussian} \\end{aligned} \\] Of course, we can also talk about continuous-time random signals \\(x(t)\\) where, for every instant \\(t,\\) a rule is used to generate the value \\(x(t)\\) leading to a random signal, a collection ( ensemble ) of realizations, and thus, together with the probability rule, a random process. In our formulation of the random process based upon die throwing, we assumed that all throws were independent of each other, that is, independent events . Thus the outcome of throw n had no influence on the outcome of throw m and vice-versa. According to basic probability theory this means: (3.8) $$p(x[n]=i,x[m]=j)=p(x[n]=i)p(x[m]=j)\\quad n\\neq m;\\quad i,j=1,\\dots,6 $$ Two variables, \\(x\\) and \\(y,\\) are said to be statistically independent if \\(p_{x,y}(\\alpha, \\beta)=p_{x}(\\alpha)p_{y}(\\beta).\\) Thus the die throwing described above forms a random process composed of statistically independent (SI) events. See Problem 3.7 . In summary and in preparing to do the following problems you should remember that this is neither an introductory textbook in signal processing nor an introductory textbook in probability theory. Should you have difficulties with these concepts, you should review one of the many textbooks available on these two subjects. Problems \u00b6 Problem 3.1 \u00b6 Compute the Fourier transform \\(X(\\Omega)\\) of the following signals: \\(x[n]=\\delta[n]=\\begin{cases}1&n=0\\\\0&n\\neq 0\\end{cases}\\) \\(x[n]=\\delta[n-10]\\) \\(x[n]=e^{{-j}\\Omega_{0}n}\\) \\(x[n]=\\sin(\\Omega_{0}n)\\) \\(x[n]=e^{{-j}\\Omega_{0}n}\\sin(\\Omega_{0}n)\\) \\(x[n]=\\left(\\frac{1}{2}\\right)^{-n}u[n]+2^{n}u[{-n}]-\\delta[n]\\) \\(x[n]=\\begin{cases}1&\\lvert n\\rvert\\leq N\\\\0&\\lvert n\\rvert >N\\end{cases}\\) \\(x[n]=\\frac{\\sin(n)}{\\pi n}\\otimes\\frac{\\sin(2n)}{\\pi n}\\text{ where}\\otimes\\text{ is convolution.}\\) Problem 3.2 \u00b6 Compute the signal \\(x[n]\\) described by the following Fourier transforms. Note that as all discrete-time Fourier transforms are periodic, \\(X(\\Omega)=X(\\Omega+2\\pi),\\) we describe the transform in the exercises below in the interval \\(- \\pi \\lt \\Omega \\le + \\pi,\\) the baseband . \\(X(\\Omega ) = \\delta (\\Omega )\\) \\(X(\\Omega)=\\frac{1}{\\left(1-\\frac{1}{2}e^{{-j}\\Omega}\\right)\\left(1-\\frac{1}{3}e ^{{-j}\\Omega}\\right)}\\) \\(X(\\Omega)=\\left(\\frac{\\sin(5\\Omega/2)}{\\sin(\\Omega/2)}\\right)^2\\) \\(X(\\Omega)=\\frac{1}{2}(1+\\cos^2(\\Omega))\\) Problem 3.3 \u00b6 For each of the examples given below \\(x[n]\\) represents an input signal with Fourier transform \\(X(\\Omega),\\) \\(h[n]\\) represents an impulse response of an LTI system with Fourier transform \\(H(\\Omega),\\) and \\(y[n]\\) represents the output signal of the LTI system with Fourier transform \\(Y(\\Omega).\\) Given the description of the input and the LTI system below, determine the output \\(y[n].\\) \\(x[n]=\\delta[n]\\qquad h[n]=\\frac{\\sin(\\Omega_0n)}{(\\pi n)}\\) \\(x[n]=\\delta[n-2]\\qquad h[n]=\\delta[n+3]\\) \\(\\begin{aligned}x[n]&=\\alpha^n u[n]\\qquad\\lvert\\alpha\\rvert<1\\\\h[n]&=\\beta^n u[n]\\qquad\\lvert\\beta\\rvert<1\\end{aligned}\\qquad \\alpha \\neq \\beta\\) \\(x[n]=e^{{-j}3n}\\qquad h[n]=\\frac{\\sin(2n)}{(\\pi n)}\\) \\(\\begin{aligned}x[n]&=\\alpha^n u[n]\\qquad\\lvert\\alpha\\rvert<1\\\\h[n]&=\\beta^n u[{-n}]\\qquad\\lvert\\beta\\rvert>1\\end{aligned}\\qquad \\alpha \\neq \\beta\\) \\(x[n]=\\left(\\frac{1}{7}\\right)^n u[n]\\qquad h[n]=\\delta[n]-\\frac{1}{7}\\delta[n-1]\\) \\(X(\\Omega)=\\left(\\frac{\\sin(5\\Omega/2)}{\\sin(\\Omega/2)}\\right)\\qquad H(\\Omega)=\\left(\\frac{\\sin(3\\Omega/2)}{\\sin(\\Omega/2)}\\right)\\) \\(\\begin{aligned}x[n]&=\\alpha^n u[{-n}]\\qquad \\lvert\\alpha\\rvert>1\\\\h[n]&=\\beta^n u[{-n}]\\qquad \\lvert\\beta\\rvert>1\\end{aligned}\\qquad \\alpha \\neq \\beta\\) Problem 3.4 \u00b6 Each of the functions given below is intended to be a probability density function \\(p(x)\\) in the continuous variable \\(x\\) or a probability mass function \\(p(n)\\) in the discrete variable \\(n.\\) For each function determine the value of the constant \\(A,\\) the value of the mean \\(\\mu,\\) and the value of the standard deviation \\(\\sigma.\\) \\(p(n)=A\\delta(n-q)=\\begin{cases}A&n=q\\\\0&n\\neq q\\end{cases}\\quad n,q\\in\\mathbb{R}\\) \\(p(x)=\\begin{cases}Ae^{{-Bx}}&x\\geq0\\\\0&x<0\\end{cases}\\quad B\\in\\mathbb{R}\\text{ and }B>0\\) \\(p(n)=A\\frac{\\lambda^{n}e^{{-\\lambda}}}{n!}\\qquad n\\geq0\\text{ and }n\\in\\mathbb{Z}\\) \\(p(x)=\\frac{A}{4+x^2}\\qquad{-\\infty}\\leq x\\leq{+\\infty}\\) \\(p(x)=\\begin{cases}Axe^{-x^2/2}&x\\geq 0\\\\0&x<0\\end{cases}\\) Problem 3.5 \u00b6 A uniform probability density function is defined in Equation 3.7 . What is the probability that the random variable \\(\\alpha\\) will lie in an interval of width \\(\\Delta a\\) where the interval is wholly contained in the region where \\(\\left| \\alpha \\right| < a?\\) What is the probability that \\(\\alpha\\) will lie in an interval of width \\(\\Delta a\\) where the interval is wholly contained in the region where \\(\\left| \\alpha \\right| > a?\\) Determine the mean \\(m_\\alpha\\) and the standard deviation \\(\\sigma_\\alpha\\) of the random variable \\(\\alpha\\) for this uniform density function. Problem 3.6 \u00b6 Determine mathematical formulas for the two probability density functions shown in Figure 3.5 and Figure 3.6 . Your formulas should not involve any undefined parameters; all parameters should have a numerical value. Problem 3.7 \u00b6 We throw two independent, fair dice as described in Example: Don\u2019t bet on it producing the numbers \\(i\\) and \\(j.\\) Determine the probability that \\(i+j=11.\\) Determine the probability mass function \\(p(r)\\) where \\(r=\\sqrt{i^2+j^2}\\) . That is, what are the values of \\(\\left\\{ p(\\sqrt{2}),p(\\sqrt{5}),p(\\sqrt{8}),\\dots,p(6\\sqrt{2}) \\right\\}\\) ? Determine the mean value of \\(r,\\) \\(m_r,\\) and the standard deviation of \\(r,\\) \\(\\sigma_r.\\) Problem 3.8 \u00b6 An even signal is defined by \\(x_e[n]=x_e[{-n}]\\) and an odd signal is defined by \\(x_o[n]=-x_o[{-n}].\\) Even and odd are symmetry properties. Answer each of the following: Let \\(x[n]\\) be an arbitrary signal. Determine the formulas that give the even part of \\(x[n]\\) and the odd part of \\(x[n].\\) Show that \\(x[n]\\) can be represented by the sum of the even signal and the odd signal. What is \\(x_o[n=0]?\\) What is \\(\\sum\\limits_{n={-\\infty}}^{+\\infty}x_o[n]?\\) What is \\(\\sum\\limits_{n={-\\infty}}^{+\\infty}x_e[n]x_o[n]?\\) Express \\(\\sum\\limits_{n={-\\infty}}^{+\\infty}\\lvert x[n]\\rvert^2\\) in terms of \\(x_e[n]\\) and \\(x_o[n].\\) Simplify your answer as much as possible. Is \\(x_e[n]\\cos(\\Omega n)\\) an even function of \\(n?\\) What symmetry property is associated with the frequency variable \\(\\Omega?\\) Repeat the previous part for \\(x_e[n]\\sin(\\Omega n),\\) \\(x_o[n]\\cos(\\Omega n)\\) and \\(x_o[n]\\sin(\\Omega n).\\) What symmetry properties can be associated with the Fourier transform \\(X(\\Omega)\\) of an arbitrary signal \\(x[n]?\\) What properties can be expected if \\(x[n]\\) is a real signal (as opposed to complex)? Problem 3.9 \u00b6 The unit step function \\(u[n]\\) has a Fourier transform given by: \\[U(\\Omega)=\\mathscr{F}\\left\\{u[n]\\right\\}=\\left(\\frac{1}{1-e^{{-j}\\Omega}}\\right) +\\pi\\delta(\\Omega)\\] where, once again, the periodic spectrum is specified in the baseband \\(- \\pi \\lt \\Omega \\le + \\pi.\\) This will be discussed in a section in Chapter 5 . Determine the spectrum of the even part of \\(u[n]\\) and the odd part of \\(u[n],\\) that is, \\(U_e(\\Omega)=\\mathscr{F}\\left\\{u_e[n]\\right\\}\\) and \\(U_o(\\Omega)=\\mathscr{F}\\left\\{u_o[n]\\right\\}.\\) Does \\(U_o(\\Omega)\\) have the properties one should expect from the odd part of a real signal? Explain your answer. Problem 3.10 \u00b6 This problem is in continuous time instead of discrete time but is, nevertheless, important because it has a link to probability theory. Full disclosure : We wrote this problem for the 2014 Dutch Physics Olympiad. Caveat emptor! A linear, time-invariant system has impulse response \\(h(t),\\) that is, when the input is \\(x(t)=\\delta(t),\\) the output is \\(y(t)=h(t).\\) The output of this system can then be used as the input for one or more identical systems as shown below. Figure 3.7: Concatenation of LTI systems. The impulse response is given by: \\[ h(t)=\\begin{cases}\\frac{1}{2\\sqrt{3}}&\\lvert t\\rvert\\leq\\sqrt{3}\\\\0&\\lvert t\\rvert>\\sqrt{3}\\end{cases} \\] Determine and sketch \\(H(\\omega),\\) the Fourier transform of \\(h(t).\\) Your sketch should include labels and numerical values where possible. Determine and sketch \\(y_1(t)\\) and \\(y_2(t)\\) when \\(x(t)=\\delta(t).\\) Again, your sketch should include labels and numerical values. Sketch \\(y_3(t)\\) and \\(y_{100}(t).\\) You do not have to work out the analytical forms (unless you want to). And, yes, that is \\(N=100.\\) Describe in words your result for \\(N=100.\\) Be as precise as possible in your reasoning. If we consider the class of signals that are everywhere non-negative, the center of a signal \\(y_c\\) can be defined in the same way as the \u201ccenter-of-gravity\u201d. That is: \\[ y_c=\\frac{\\int\\limits_{-\\infty}^{+\\infty}ty(t)dt}{\\int\\limits_{-\\infty}^{+\\infty}y(t)dt} \\] The root-mean-square width of a signal \\(y_{rms}\\) can be similarly defined as: \\[ y_{rms}=\\sqrt{\\frac{\\int\\limits_{-\\infty}^{+\\infty}(t-y_c)^2y(t)dt}{\\int\\limits_{-\\infty}^{+\\infty}y(t)dt}} \\] Determine \\(y_c\\) and \\(y_{rms}\\) for \\(y_1(t),\\) \\(y_2(t)\\) and the general case \\(y_N(t).\\) Reduce your answers to the simplest possible form. The impulse response is now replaced by a new impulse response: \\[ h(t)= \\begin{cases} \\cos(5\\pi t)&\\lvert t\\rvert\\leq\\sqrt{3}\\\\ 0&\\lvert t\\rvert>\\sqrt{3} \\end{cases} \\] Determine and sketch the new \\(H(\\omega),\\) the Fourier transform of the new \\(h(t).\\) Your sketch should include labels and numerical values where possible. Sketch \\(y_1(t)\\) and \\(y_2(t)\\) when \\(x(t)=\\delta(t).\\) Again, your sketch should include labels and numerical values. You do not have to give the analytical form for either signal. Sketch \\(y_{100}(t).\\) Again, you do not have to work out the analytical form (unless you want to). And, once again, that is \\(N=100.\\) Oppenheim, A. V., A. S. Willsky and S. H. Nawab (1996). Signals and Systems. Upper Saddle River, New Jersey, Prentice-Hall \u21a9 \u21a9 Papoulis, A. and S. U. Pillai (2002). Probability, Random Variables, and Stochastic Processes. New York, McGraw-Hill \u21a9 \u21a9 Cram\u00e9r, H. (1946). Mathematical Methods of Statistics. Princeton, New Jersey, Princeton University Press \u21a9 \u21a9","title":"3. Introduction"},{"location":"Chap_3.html#introduction","text":"In introductory studies of signals and systems we look at the class of input signals known as \u201cdeterministic\u201d signals, signals where the value of the time function is known, by definition, for every time point \\(x[n]\\) . With the results derived in such studies we can calculate the outputs for linear, time-invariant (LTI) systems with impulse response \\(h[n]\\) either through time domain convolution Equation 3.1 : (3.1) $$ y[n] = x[n] \\otimes h[n] \\triangleq \\sum\\limits_{k = - \\infty }^{ + \\infty } x [k]h[n - k] $$ or through frequency domain multiplication: (3.2) $$ Y(\\Omega)=X(\\Omega)H(\\Omega) $$ We assume an introductory level knowledge of signal processing and linear system theory. Such an introduction can be found in \u201cSignals and Systems\u201d 1 .","title":"Introduction"},{"location":"Chap_3.html#the-basics","text":"The time domain \\(n\\) and the frequency domain \\(\\Omega\\) representations of signals are related through the Fourier transform pair: (3.3) $$ \\begin{aligned} X(\\Omega)&=\\sum_{n={-\\infty}}^{+\\infty}x[n]e^{{-j}\\Omega n}\\\\ x[n]&=\\frac{1}{2\\pi}\\int\\limits_{-\\pi}^{+\\pi}X(\\Omega)e^{+j\\Omega n}d\\Omega \\end{aligned} $$ In shorthand notation, \\(X(\\Omega)=\\mathscr{F}\\left\\{x[n]\\right\\}\\) and \\(x[n]=\\mathscr{F}^{-1}\\left\\{X(\\Omega)\\right\\}\\) where \\(\\mathscr{F}\\left\\{\u2022\\right\\}\\) is the Fourier transform operator. It is important that you are familiar with the computation and properties of Fourier transforms and inverse Fourier transforms and with convolution. The exercises in Problem 3.1 and Problem 3.3 review this material. The first eight problems, in fact, are review problems in linear system theory and probability theory. If you find them difficult then you should review the textbooks in these disciplines. Several textbooks are listed below 1 , 2 , 3 .","title":"The basics"},{"location":"Chap_3.html#what-is-a-random-signal","text":"For an important class of input signals, however, the value of the signal at each time point is not known. Only very general properties of the input signal, referred to as averages , are available and it is with these averages that we must try to describe what happens at the output end of an LTI system. These signals are called stochastic or random signals and we can distinguish between two classes: Random signals carrying information\u2014e.g. speech, music, radio astronomy; Random signals without information\u2014noise. We will describe both types of random signals in this iBook but, to do so, we must first develop some basic concepts concerning random signals and various averages of random signals. After that we will show how these concepts of stochastic signals can be used. We assume that you are familiar with basic probability theory but to review this material there is \u201cProbability, Random Variables, and Stochastic Processes\u201d 2 and the classical \u201cMathematical Methods of Statistics\u201d 3 . The exercises in Problem 3.4 review this material. We will develop several important themes including: Signal-to-noise ratio (SNR) characterizations of systems; Choosing linear filters for noise reduction; Problems in estimation of Fourier spectra. We begin with a simple model for generating a random signal in Example \u201cDon\u2019t bet on it\u201d .","title":"What is a random signal?"},{"location":"Chap_3.html#example-dont-bet-on-it","text":"We throw a die once per second (discrete time) and the amplitude of the signal is the number of dots showing on the top die face. If at time \\(n=n_0\\) the result is then: (3.4) $$x[n_0]=6\\delta[n-n_0]$$ If the die is \u201cfair\u201d then the probability of die face # \\(i\\) appearing on top, \\(p(i)\\) , will be the same for all faces and thus \\(p(1)=p(2)=\\dots=p(6)=\\frac{1}{6}\\) . This is just an example of the general requirements for a set of probabilities that could be associated with the six faces of a die. (3.5) $$\\sum_{i=0}^{6}p(i)=1\\text{ with }p(i)\\geq 0 $$ Over a period of time, that is a number of seconds, we can generate a random signal as shown in Figure 3.1 . Figure 3.1: First realization of 31 random throws of a fair die. This is just one realization of a random signal where the amplitudes are governed by a specific probability function. Performing the experiment again might lead to another realization as shown in Figure 3.2 . Figure 3.2: Second realization of 31 random throws of a fair die. This concept will be illustrated, later, in Laboratory Exercise 4.1 . We can continue this procedure to generate an infinite number of realizations each governed by the same generating rule, throwing a fair die once per second and using the top face as a signal amplitude at that second. The possible collection of waveforms ( \\(x_1[n]\\) , \\(x_2[n]\\) , \\(x_3[n]\\) , \\(x_4[n]\\) ,\u2026) together with the probability function for the amplitudes at time \\(n\\) form a random process . Instead of having the amplitudes governed by the throw of a die, we might find that the amplitudes are taken from the values on the continuous real line between \\({-a}\\) and \\(+a\\) with probability density function: (3.6) $$p(\\alpha)= \\begin{cases} \\frac{1}{2a} & \\lvert\\alpha\\rvert\\leq a\\\\ 0 & \\lvert\\alpha\\rvert > a\\\\ \\end{cases} $$ A graph of this probability function is given in Figure 3.3 . Figure 3.3: A uniform probability density function, \\(p(\\alpha)\\) . All realizations between \\(-a\\) and \\(+a\\) are equally likely. The total probability (area under the curve) is 1. It should be clear that at no time point will \\(\\lvert x[n]\\rvert > a.\\) (Can you see why?) Thus \\(\\vert x[n]\\rvert \\leq a.\\) But the probability of the amplitude taking on the exact values \\(x[n]=+a\\) or \\(x[n]={-a}\\) is zero. (The proof of this is left to you; see Problem 3.5 .) We might also consider that the amplitudes could be governed by the probability density function ( pdf ): (3.7) $$p(\\alpha ) = \\frac{1}{{\\sigma \\sqrt {2\\pi } }}{e^{ - {\\alpha ^2}/2{\\sigma ^2}}}\\quad {\\kern 1pt} - \\infty \\leqslant \\alpha \\leqslant + \\infty $$ This is perhaps the most well-known and well-studied continuous probability density function, the Gaussian (or normal) function. A graph of this probability function is given in Figure 3.4 . Figure 3.4: A Gaussian (normal) probability density function, \\(p(\\alpha).\\) Again, the total area under the curve is 1. Examples of realizations from two random processes, one governed by a uniform probability density function and one by a Gaussian probability density function, are shown in Figure 3.5 and Figure 3.6 . See Problem 3.6 . Figure 3.5: Example of samples from a Uniform density function ( \\(\\mu=1.0, \\sigma=1/\\sqrt{12}\\) ) Figure 3.6: Example of samples from a Gaussian density function ( \\(\\mu=1.0, \\sigma=1/\\sqrt{12}\\) ) Further, we could envision the situation where the random signal is generated by the composite rule from two distributions: \\[ \\begin{aligned} n\\text{ even }(n=\\dots, -4, -2, 0, 2, \\dots)\\rightarrow p(x[n])&=\\text{ throw die}\\\\ n\\text{ odd }(n=\\dots, -3, -1, 1, 3, \\dots)\\rightarrow p(x[n])&=\\text{ choose from Gaussian} \\end{aligned} \\] Of course, we can also talk about continuous-time random signals \\(x(t)\\) where, for every instant \\(t,\\) a rule is used to generate the value \\(x(t)\\) leading to a random signal, a collection ( ensemble ) of realizations, and thus, together with the probability rule, a random process. In our formulation of the random process based upon die throwing, we assumed that all throws were independent of each other, that is, independent events . Thus the outcome of throw n had no influence on the outcome of throw m and vice-versa. According to basic probability theory this means: (3.8) $$p(x[n]=i,x[m]=j)=p(x[n]=i)p(x[m]=j)\\quad n\\neq m;\\quad i,j=1,\\dots,6 $$ Two variables, \\(x\\) and \\(y,\\) are said to be statistically independent if \\(p_{x,y}(\\alpha, \\beta)=p_{x}(\\alpha)p_{y}(\\beta).\\) Thus the die throwing described above forms a random process composed of statistically independent (SI) events. See Problem 3.7 . In summary and in preparing to do the following problems you should remember that this is neither an introductory textbook in signal processing nor an introductory textbook in probability theory. Should you have difficulties with these concepts, you should review one of the many textbooks available on these two subjects.","title":"Example: Don\u2019t bet on it"},{"location":"Chap_3.html#problems","text":"","title":"Problems"},{"location":"Chap_3.html#problem-31","text":"Compute the Fourier transform \\(X(\\Omega)\\) of the following signals: \\(x[n]=\\delta[n]=\\begin{cases}1&n=0\\\\0&n\\neq 0\\end{cases}\\) \\(x[n]=\\delta[n-10]\\) \\(x[n]=e^{{-j}\\Omega_{0}n}\\) \\(x[n]=\\sin(\\Omega_{0}n)\\) \\(x[n]=e^{{-j}\\Omega_{0}n}\\sin(\\Omega_{0}n)\\) \\(x[n]=\\left(\\frac{1}{2}\\right)^{-n}u[n]+2^{n}u[{-n}]-\\delta[n]\\) \\(x[n]=\\begin{cases}1&\\lvert n\\rvert\\leq N\\\\0&\\lvert n\\rvert >N\\end{cases}\\) \\(x[n]=\\frac{\\sin(n)}{\\pi n}\\otimes\\frac{\\sin(2n)}{\\pi n}\\text{ where}\\otimes\\text{ is convolution.}\\)","title":"Problem 3.1"},{"location":"Chap_3.html#problem-32","text":"Compute the signal \\(x[n]\\) described by the following Fourier transforms. Note that as all discrete-time Fourier transforms are periodic, \\(X(\\Omega)=X(\\Omega+2\\pi),\\) we describe the transform in the exercises below in the interval \\(- \\pi \\lt \\Omega \\le + \\pi,\\) the baseband . \\(X(\\Omega ) = \\delta (\\Omega )\\) \\(X(\\Omega)=\\frac{1}{\\left(1-\\frac{1}{2}e^{{-j}\\Omega}\\right)\\left(1-\\frac{1}{3}e ^{{-j}\\Omega}\\right)}\\) \\(X(\\Omega)=\\left(\\frac{\\sin(5\\Omega/2)}{\\sin(\\Omega/2)}\\right)^2\\) \\(X(\\Omega)=\\frac{1}{2}(1+\\cos^2(\\Omega))\\)","title":"Problem 3.2"},{"location":"Chap_3.html#problem-33","text":"For each of the examples given below \\(x[n]\\) represents an input signal with Fourier transform \\(X(\\Omega),\\) \\(h[n]\\) represents an impulse response of an LTI system with Fourier transform \\(H(\\Omega),\\) and \\(y[n]\\) represents the output signal of the LTI system with Fourier transform \\(Y(\\Omega).\\) Given the description of the input and the LTI system below, determine the output \\(y[n].\\) \\(x[n]=\\delta[n]\\qquad h[n]=\\frac{\\sin(\\Omega_0n)}{(\\pi n)}\\) \\(x[n]=\\delta[n-2]\\qquad h[n]=\\delta[n+3]\\) \\(\\begin{aligned}x[n]&=\\alpha^n u[n]\\qquad\\lvert\\alpha\\rvert<1\\\\h[n]&=\\beta^n u[n]\\qquad\\lvert\\beta\\rvert<1\\end{aligned}\\qquad \\alpha \\neq \\beta\\) \\(x[n]=e^{{-j}3n}\\qquad h[n]=\\frac{\\sin(2n)}{(\\pi n)}\\) \\(\\begin{aligned}x[n]&=\\alpha^n u[n]\\qquad\\lvert\\alpha\\rvert<1\\\\h[n]&=\\beta^n u[{-n}]\\qquad\\lvert\\beta\\rvert>1\\end{aligned}\\qquad \\alpha \\neq \\beta\\) \\(x[n]=\\left(\\frac{1}{7}\\right)^n u[n]\\qquad h[n]=\\delta[n]-\\frac{1}{7}\\delta[n-1]\\) \\(X(\\Omega)=\\left(\\frac{\\sin(5\\Omega/2)}{\\sin(\\Omega/2)}\\right)\\qquad H(\\Omega)=\\left(\\frac{\\sin(3\\Omega/2)}{\\sin(\\Omega/2)}\\right)\\) \\(\\begin{aligned}x[n]&=\\alpha^n u[{-n}]\\qquad \\lvert\\alpha\\rvert>1\\\\h[n]&=\\beta^n u[{-n}]\\qquad \\lvert\\beta\\rvert>1\\end{aligned}\\qquad \\alpha \\neq \\beta\\)","title":"Problem 3.3"},{"location":"Chap_3.html#problem-34","text":"Each of the functions given below is intended to be a probability density function \\(p(x)\\) in the continuous variable \\(x\\) or a probability mass function \\(p(n)\\) in the discrete variable \\(n.\\) For each function determine the value of the constant \\(A,\\) the value of the mean \\(\\mu,\\) and the value of the standard deviation \\(\\sigma.\\) \\(p(n)=A\\delta(n-q)=\\begin{cases}A&n=q\\\\0&n\\neq q\\end{cases}\\quad n,q\\in\\mathbb{R}\\) \\(p(x)=\\begin{cases}Ae^{{-Bx}}&x\\geq0\\\\0&x<0\\end{cases}\\quad B\\in\\mathbb{R}\\text{ and }B>0\\) \\(p(n)=A\\frac{\\lambda^{n}e^{{-\\lambda}}}{n!}\\qquad n\\geq0\\text{ and }n\\in\\mathbb{Z}\\) \\(p(x)=\\frac{A}{4+x^2}\\qquad{-\\infty}\\leq x\\leq{+\\infty}\\) \\(p(x)=\\begin{cases}Axe^{-x^2/2}&x\\geq 0\\\\0&x<0\\end{cases}\\)","title":"Problem 3.4"},{"location":"Chap_3.html#problem-35","text":"A uniform probability density function is defined in Equation 3.7 . What is the probability that the random variable \\(\\alpha\\) will lie in an interval of width \\(\\Delta a\\) where the interval is wholly contained in the region where \\(\\left| \\alpha \\right| < a?\\) What is the probability that \\(\\alpha\\) will lie in an interval of width \\(\\Delta a\\) where the interval is wholly contained in the region where \\(\\left| \\alpha \\right| > a?\\) Determine the mean \\(m_\\alpha\\) and the standard deviation \\(\\sigma_\\alpha\\) of the random variable \\(\\alpha\\) for this uniform density function.","title":"Problem 3.5"},{"location":"Chap_3.html#problem-36","text":"Determine mathematical formulas for the two probability density functions shown in Figure 3.5 and Figure 3.6 . Your formulas should not involve any undefined parameters; all parameters should have a numerical value.","title":"Problem 3.6"},{"location":"Chap_3.html#problem-37","text":"We throw two independent, fair dice as described in Example: Don\u2019t bet on it producing the numbers \\(i\\) and \\(j.\\) Determine the probability that \\(i+j=11.\\) Determine the probability mass function \\(p(r)\\) where \\(r=\\sqrt{i^2+j^2}\\) . That is, what are the values of \\(\\left\\{ p(\\sqrt{2}),p(\\sqrt{5}),p(\\sqrt{8}),\\dots,p(6\\sqrt{2}) \\right\\}\\) ? Determine the mean value of \\(r,\\) \\(m_r,\\) and the standard deviation of \\(r,\\) \\(\\sigma_r.\\)","title":"Problem 3.7"},{"location":"Chap_3.html#problem-38","text":"An even signal is defined by \\(x_e[n]=x_e[{-n}]\\) and an odd signal is defined by \\(x_o[n]=-x_o[{-n}].\\) Even and odd are symmetry properties. Answer each of the following: Let \\(x[n]\\) be an arbitrary signal. Determine the formulas that give the even part of \\(x[n]\\) and the odd part of \\(x[n].\\) Show that \\(x[n]\\) can be represented by the sum of the even signal and the odd signal. What is \\(x_o[n=0]?\\) What is \\(\\sum\\limits_{n={-\\infty}}^{+\\infty}x_o[n]?\\) What is \\(\\sum\\limits_{n={-\\infty}}^{+\\infty}x_e[n]x_o[n]?\\) Express \\(\\sum\\limits_{n={-\\infty}}^{+\\infty}\\lvert x[n]\\rvert^2\\) in terms of \\(x_e[n]\\) and \\(x_o[n].\\) Simplify your answer as much as possible. Is \\(x_e[n]\\cos(\\Omega n)\\) an even function of \\(n?\\) What symmetry property is associated with the frequency variable \\(\\Omega?\\) Repeat the previous part for \\(x_e[n]\\sin(\\Omega n),\\) \\(x_o[n]\\cos(\\Omega n)\\) and \\(x_o[n]\\sin(\\Omega n).\\) What symmetry properties can be associated with the Fourier transform \\(X(\\Omega)\\) of an arbitrary signal \\(x[n]?\\) What properties can be expected if \\(x[n]\\) is a real signal (as opposed to complex)?","title":"Problem 3.8"},{"location":"Chap_3.html#problem-39","text":"The unit step function \\(u[n]\\) has a Fourier transform given by: \\[U(\\Omega)=\\mathscr{F}\\left\\{u[n]\\right\\}=\\left(\\frac{1}{1-e^{{-j}\\Omega}}\\right) +\\pi\\delta(\\Omega)\\] where, once again, the periodic spectrum is specified in the baseband \\(- \\pi \\lt \\Omega \\le + \\pi.\\) This will be discussed in a section in Chapter 5 . Determine the spectrum of the even part of \\(u[n]\\) and the odd part of \\(u[n],\\) that is, \\(U_e(\\Omega)=\\mathscr{F}\\left\\{u_e[n]\\right\\}\\) and \\(U_o(\\Omega)=\\mathscr{F}\\left\\{u_o[n]\\right\\}.\\) Does \\(U_o(\\Omega)\\) have the properties one should expect from the odd part of a real signal? Explain your answer.","title":"Problem 3.9"},{"location":"Chap_3.html#problem-310","text":"This problem is in continuous time instead of discrete time but is, nevertheless, important because it has a link to probability theory. Full disclosure : We wrote this problem for the 2014 Dutch Physics Olympiad. Caveat emptor! A linear, time-invariant system has impulse response \\(h(t),\\) that is, when the input is \\(x(t)=\\delta(t),\\) the output is \\(y(t)=h(t).\\) The output of this system can then be used as the input for one or more identical systems as shown below. Figure 3.7: Concatenation of LTI systems. The impulse response is given by: \\[ h(t)=\\begin{cases}\\frac{1}{2\\sqrt{3}}&\\lvert t\\rvert\\leq\\sqrt{3}\\\\0&\\lvert t\\rvert>\\sqrt{3}\\end{cases} \\] Determine and sketch \\(H(\\omega),\\) the Fourier transform of \\(h(t).\\) Your sketch should include labels and numerical values where possible. Determine and sketch \\(y_1(t)\\) and \\(y_2(t)\\) when \\(x(t)=\\delta(t).\\) Again, your sketch should include labels and numerical values. Sketch \\(y_3(t)\\) and \\(y_{100}(t).\\) You do not have to work out the analytical forms (unless you want to). And, yes, that is \\(N=100.\\) Describe in words your result for \\(N=100.\\) Be as precise as possible in your reasoning. If we consider the class of signals that are everywhere non-negative, the center of a signal \\(y_c\\) can be defined in the same way as the \u201ccenter-of-gravity\u201d. That is: \\[ y_c=\\frac{\\int\\limits_{-\\infty}^{+\\infty}ty(t)dt}{\\int\\limits_{-\\infty}^{+\\infty}y(t)dt} \\] The root-mean-square width of a signal \\(y_{rms}\\) can be similarly defined as: \\[ y_{rms}=\\sqrt{\\frac{\\int\\limits_{-\\infty}^{+\\infty}(t-y_c)^2y(t)dt}{\\int\\limits_{-\\infty}^{+\\infty}y(t)dt}} \\] Determine \\(y_c\\) and \\(y_{rms}\\) for \\(y_1(t),\\) \\(y_2(t)\\) and the general case \\(y_N(t).\\) Reduce your answers to the simplest possible form. The impulse response is now replaced by a new impulse response: \\[ h(t)= \\begin{cases} \\cos(5\\pi t)&\\lvert t\\rvert\\leq\\sqrt{3}\\\\ 0&\\lvert t\\rvert>\\sqrt{3} \\end{cases} \\] Determine and sketch the new \\(H(\\omega),\\) the Fourier transform of the new \\(h(t).\\) Your sketch should include labels and numerical values where possible. Sketch \\(y_1(t)\\) and \\(y_2(t)\\) when \\(x(t)=\\delta(t).\\) Again, your sketch should include labels and numerical values. You do not have to give the analytical form for either signal. Sketch \\(y_{100}(t).\\) Again, you do not have to work out the analytical form (unless you want to). And, once again, that is \\(N=100.\\) Oppenheim, A. V., A. S. Willsky and S. H. Nawab (1996). Signals and Systems. Upper Saddle River, New Jersey, Prentice-Hall \u21a9 \u21a9 Papoulis, A. and S. U. Pillai (2002). Probability, Random Variables, and Stochastic Processes. New York, McGraw-Hill \u21a9 \u21a9 Cram\u00e9r, H. (1946). Mathematical Methods of Statistics. Princeton, New Jersey, Princeton University Press \u21a9 \u21a9","title":"Problem 3.10"},{"location":"Chap_4.html","text":"Characterization of Random Signals \u00b6 Because it is impossible for us to specify what a random signal will be at any one instant, let alone for all \\(t\\) or \\(n\\) , we have to settle for a description based upon average properties of the signal. There are a variety of definitions associated with the use of the word \u201caverage\u201d (including \u201cnot very good\u201d). In the context of this book we will focus on the concept as related to a number or property that is considered as representative of a collection of numbers such as those encountered in a signal. Consider, for example, the flipping of a coin. Example: Fair chance \u00b6 We map Heads into +1 and Tails into \u20131 giving: Figure 4.1: One realization of a coin-flipping experiment with Heads mapped to +1 and Tails mapped to \u20131 We might imagine computing the (arithmetic) average 1 over \\(2N + 1\\) samples as: (4.1) $$ < x[n]{ > _{2N + 1}} = \\frac{1}{{2N + 1}}\\left( {\\sum\\limits_{n = - N}^{ + N} {x[n]} } \\right) $$ In the above example: For \\(N = 1 \\to < x[n]{ > _3} = 1\\) For \\(N = 2 \\to < x[n]{ > _5} = 1/5\\) For \\(N = 3 \\to < x[n]{ > _7} = 3/7\\) We \u201cexpect\u201d for a \u201cfair coin\u201d that if \\(N\\) is large then \\(< x[n]{ > _{2N + 1}} \\approx 0\\) because there will be just as many +1\u2019s in the sum as \u20131\u2019s. Another way to compute the average is based upon knowledge of the distribution of \\(p(x[n])\\) and is termed ensemble averaging . Instead of flipping one coin \\(N\\) times we could flip \\(N\\) coins once. We then count the number of Heads \\(\\left( {{n_H}} \\right)\\) and the number of Tails \\(\\left( {{n_T} = N - {n_H}} \\right)\\) . Our estimate of the probability of Heads would then be \\(p(H) = {n_H}/N\\) and the probability of Tails as \\(p(T) = {n_T}/N = 1 - {n_H}/N\\) . Again for large values of \\(N\\) and a \u201cfair coin\u201d we expect just as many Heads as Tails and this means \\(p(H) = p(T) = 1/2\\) . This method and stochastic signals associated with this method are explored in Laboratory Exercise 4.1 . By examining the probability of all the possible outcomes\u2014in this case with a coin just two but in the case of a die six\u2014we can develop a model for a probability distribution that describes the possible values of our random variable. And by associating numerical values to the variable, such as Heads \\(\\rightarrow\\) +1 and Tails \\(\\rightarrow\\) \u20131, we can compute averages. Describing the ensemble average \u00b6 How do we do this? Returning to a statement above, we seek a number that is representative of a collection of random numbers. Let us assume that we have either a formal mathematical model of the random process that has generated the random numbers or we have collected sufficient data to have an excellent estimate of that probability distribution (or density) function. Either way we can depict\u2014with confidence\u2014the probability that the random variable \\(x\\) can take on a specific value \\(m\\) at time \\(n\\) . Such a probability distribution is shown in Figure 4.2 . Figure 4.2: Determining a representative number from a probability distribution. The distribution shown is a Poisson distribution. If a single number is to characterize this distribution, a reasonable requirement is that the number provides a \u201cbalanced\u201d description. From the domain of physics this has a specific meaning, the center-of-mass of a body with mass distribution, \\(m(\\vec p).\\) The classical distribution of mass, as we know, is a non-negative function of the position vector \\(\\vec p.\\) In that sense it is similar to a probability distribution. Finding the center-of-mass is equivalent to finding the position where the mass can be balanced. This is illustrated in Figure 4.3 . Figure 4.3: Determining a representative number from a mass (or probability) distribution. When the mass is distributed around the center-of-mass the object is balanced. When another position is chosen, unexpected and possibly unpleasant things can happen. The mathematics associated with the calculation of the center-of-mass involve either \\(\\int {\\vec p} \\,m(\\vec p)d\\vec p\\) for a continuous (in space) distribution of mass or \\(\\sum {{{\\vec p}_i}} \\,m({\\vec p_i})\\) for a discrete (in space) distribution of mass. See Sections I-18 and I-19 of Feynman 2 . It is but a short step to replace mass distribution (continuous or discrete) with a probability distribution (continuous or discrete) to define a number, the average, which is representative of a collection of random numbers. Indeed, this is the approach presented in Section 15.2 of Cram\u00e9r 3 . This leads to a formal definition of averaging as: (4.2) $$ E \\left\\{ {x[n]} \\right\\} = \\int\\limits_{ - \\infty }^{ + \\infty } {x\\,{p_{x[n]}}(x,n)dx = {m_{x[n]}}} $$ When the determination of an average is based upon the use of the probability distribution, it is referred to as an ensemble average 4 . Here we take into consideration that the average or mean may depend on \\(n.\\) (See, for instance, the even / odd mixed example above. In that example the probability distribution that is to be used in computing the average depends upon whether \\(n\\) is even or odd.) It may seem strange to see an integral in Equation 4.2 when we are talking about discrete-time signals. We should remember, however, that although time is discrete the values of the random variable need not be. They can, in principle, be complex numbers \\({\\Bbb C}\\) , real numbers \\({\\Bbb R}\\) , or integers \\({\\Bbb Z}\\) . The average value is computed over all possible values of the random variable of the amplitude \\(x\\) . It is possible that a sum can be used instead of an integral. In Example: Average Experience , we see that the possible values of the random variable are indexed \\(i = 1, \\ldots ,6\\) in which case a sum is used. Another example is given in Problem 4.1 where \\(i = - \\infty , \\ldots ,0, \\ldots , + \\infty\\) and a sum is again required. But in the most general formulation of averaging an integral is used 5 . For many problems that occur\u2014 including those that we plan to focus on here \u2014the random processes are stationary . This means that averages are in an equilibrium condition that is invariant to a shift in time. In a stationary die experiment we should obtain the same results (averages) whether the experiment is performed yesterday, today, or next year. For the mean value given above this would imply a value independent of the time origin: (4.3) $$ {m_{x[n]}} = {m_{x[n + k]}} = {m_{x[\\ell ]}} = {m_x} $$ The mean value of the random process \\(x[n]\\) at time \\(n\\) is the same as at time \\(n + k.\\) But this second time has its own \u201cname\u201d \\(\\ell.\\) This implies that the mean value is independent of time and is simply \\({m_x},\\) that is, stationary. Example: Average experience \u00b6 For our die experiment, where the number of possible outcomes can be indexed, we can use a version of the average based upon a sum: (4.4) $$ E\\left\\{ x \\right\\} = \\sum\\limits_{i = 1}^6 {{x_i}p({x_i})} = 1\\left( {\\frac{1}{6}} \\right) + 2\\left( {\\frac{1}{6}} \\right) + \\ldots + 6\\left( {\\frac{1}{6}} \\right) = \\frac{7}{2} = {m_x} $$ Other averages \u00b6 Other averages might, in general, be written as: (4.5) $$ Mean\\;square = E\\left\\{ {{x^2}[n]} \\right\\} = \\int\\limits_{ - \\infty }^{ + \\infty } {{x^2}p(x[n])dx} $$ (4.6) $$ E\\left\\{ {g\\left( {x[n]} \\right)} \\right\\} = \\int\\limits_{ - \\infty }^{ + \\infty } {g(x)p(x[n])dx} $$ To repeat, while \\(n\\) is discrete, the random variable \\(x\\) can have any value. For stationary processes these averages would reduce to: (4.7) $$ \\begin{array}{l} E\\left\\{ {{x^2}} \\right\\} = \\int\\limits_{ - \\infty }^{ + \\infty } {{x^2}p(x)dx} \\\\ E\\left\\{ {g(x)} \\right\\} = \\int\\limits_{ - \\infty }^{ + \\infty } {g(x)p(x)dx} \\end{array} $$ We apply these concepts to the example of throwing a die. Example: Dice & money \u00b6 (4.8) $$ E\\left\\{ {{x^2}} \\right\\} = {1^2}\\left( {\\frac{1}{6}} \\right) + {2^2}\\left( {\\frac{1}{6}} \\right) + {3^2}\\left( {\\frac{1}{6}} \\right) + \\ldots + {6^2}\\left( {\\frac{1}{6}} \\right) = 15\\frac{1}{6} $$ If we use a function \\(g( \\bullet )\\) defined on the random variable \\(x\\) : (4.9) $$ g(x) = \\left\\{ {\\begin{array}{*{20}{l}} { + 1}&{x\\;{\\rm{even}}\\;2,\\;4,\\;6}\\\\ { - 1}&{x\\;{\\rm{odd}}\\;1,\\;3,\\;5} \\end{array}} \\right. $$ Then the average value of this function of a random variable is: (4.10) $$ E\\left\\{ {g(x)} \\right\\} = 0 $$ We see through this choice of \\(g(x)\\) that it is possible to use the die experiment to model the coin-flipping experiment. It is also important to realize that although we have chosen integer values for the random variable \\(x\\) in Example: Fair chance , Example: Average experience and Example: Dice money , in general the variable can take on any complex value. The time index \\(n,\\) of course, will remain discrete, that is, an integer. We may also use two random variables \\(x[n]\\) and \\(y[k]\\) with an associated joint probability given by \\(p(x[n],y[k])\\) and take the average: (4.11) $$ E\\left\\{ {x[n]y[k]} \\right\\} = \\int\\limits_{}^{} {\\int\\limits_{}^{} {x\\,y\\,p(x[n],y[k])dxdy} } $$ The more general function of the two random variables leads to an average: (4.12) $$ E\\left\\{ {g\\left( {x[n],y[k]} \\right)} \\right\\} = \\int\\limits_{}^{} {\\int\\limits_{}^{} {g(x,y)p(x[n],y[k])dxdy} } $$ We should remember that it is possible that \\(p(x[n],y[k])\\) has a complicated behavior. The signal \\(x[n]\\) may be based upon flipping a coin and the signal \\(y[n]\\) may be based upon throwing a die. If these two types of events are independent, fair and stationary ( caveat emptor! ), then: \\[ p(x[n] = - 1,y[k] = 5) = p(x[n] = - 1)\\,p(y[k] = 5) = \\left( {\\frac{1}{2}} \\right)\\left( {\\frac{1}{6}} \\right) = \\frac{1}{{12}}\\,. \\] While we have explicitly chosen two distinct time instances \\(n \\ne k,\\) this does not matter for calculation of the probability because we have also assumed that both signals are stationary. See Problem 4.2 . As we can infer from Figure 4.4 , it is also possible that \\(y[k]\\) is just the signal \\(x[n]\\) at time \\(k.\\) That is, if there is anything to be gained, there is nothing to prevent us from considering the case where \\(y[n] = x[n].\\) Figure 4.4: Two samples \\((x[n\\rbrack,x[k\\rbrack)\\) can come from one realization of a random process. One sample is at time \\(n\\) and the other at time \\(k.\\) Properties of averaging \u00b6 At this point, several well-known properties based upon linearity of averaging are useful to have available: (4.13) $$ E\\left\\{ {x[n] + y[n]} \\right\\} = E\\left\\{ {x[n]} \\right\\} + E\\left\\{ {y[n]} \\right\\} $$ (4.14) $$ E\\left\\{ {ax[n]} \\right\\} = aE\\left\\{ {x[n]} \\right\\} $$ (4.15) $$E\\left\\{ {x[n] + c} \\right\\} = E\\left\\{ {x[n]} \\right\\} + c$$ We will prove Equation 4.14 and leave the proofs of Equation 4.13 and Equation 4.15 for you at the end of this chapter. See Problem 4.3 . We start from Equation 4.2 and substitute \\(a\\,x[n]\\) where the constant \\(a\\) is a deterministic\u2014not random (!)\u2014number: (4.16) $$\\begin{array}{*{20}{l}} {E\\left\\{ {a\\,x[n]} \\right\\}}&{ = \\int\\limits_{ - \\infty }^{ + \\infty } {a\\,x\\,p(x[n])dx} = a\\int\\limits_{ - \\infty }^{ + \\infty } {x\\,p(x[n])dx} = a\\,{m_{x[n]}}}\\\\ {}&{ = a\\,E\\left\\{ {x[n]} \\right\\}} \\end{array}$$ The first two properties, Equation 4.13 and Equation 4.14 , indicate that the averaging operation is a linear operation. The average of a weighted sum of random variables, \\(x_1\\) and \\(x_2,\\) is the weighted sum of their averages, \\(E\\left\\{ {a\\,{x_1} + b\\,{x_2}} \\right\\} = a\\,E\\left\\{ {{x_1}} \\right\\} + b\\,E\\left\\{ {{x_2}} \\right\\}.\\) As simple as each of these properties may seem, it is important that you understand how to prove each one and what each one means . We have already looked at the averages mean and mean-square . Another important and therefore common average is the variance : (4.17) $$\\begin{array}{*{20}{l}} {Variance\\left\\{ {x[n]} \\right\\}}&{ = \\sigma _{x[n]}^2}\\\\ {}&{ = E\\left\\{ {{{\\left( {x[n] - {m_{x[n]}}} \\right)}^2}} \\right\\}}\\\\ {}&{ = E\\left\\{ {{x^2}[n]} \\right\\} - {{\\left( {{m_{x[n]}}} \\right)}^2}} \\end{array}$$ which in the stationary form is given by: (4.18) $$Var\\left( x \\right) = \\sigma _x^2 = E\\left\\{ {{{\\left( {x[n] - {m_x}} \\right)}^2}} \\right\\} = E\\left\\{ {{x^2}[n]} \\right\\} - m_x^2$$ We introduce here the notation \\(Var(x)\\) to indicate the variance of the random variable \\(x.\\) The term \\(\\sigma,\\) the positive square root of the variance, is called the standard deviation . Note that when the physical process generating \\(x[n]\\) has a certain unit such as meters, then the standard deviation \\(\\sigma\\) has the same unit. The issue of units will be important later in this iBook when we discuss topics such as signal-to-noise ratio. Correlation \u2013 the workhorse \u00b6 These averages only describe what happens at a single time point of a random process even if the process is stationary. A more general and very useful average is the autocorrelation that describes the joint behavior of a random process at two points in time. The motivation for examining this issue is that we would like to know if knowledge at one time point can help us predict or understand behavior at another time point. If a stochastic signal is increasing now, is it possible to predict that it might be decreasing 180 days from now? Autocorrelation \u00b6 In discrete time the definition of autocorrelation is: (4.19) $$\\begin{array}{*{20}{l}} {{\\varphi _{xx}}[n,k]}&{ = E\\left\\{ {x[n]\\,{x^*}[k]} \\right\\} = E\\left\\{ {x[n]\\,{x^*}[n + m]} \\right\\}}\\\\ {}&{ = {\\varphi _{xx}}[n,n + m]} \\end{array}$$ The procedure should be clear. We take the random variable at time \\(n\\) and the random variable at time \\(k\\) with their associated joint probability. We then ask: what is the expected value of their product? The mechanics of correlations \u00b6 As an example we compute the expected value of the maximum temperature in Rotterdam, The Netherlands on 18 May 2013 multiplied by the maximum temperature in Rotterdam on 16 August 2013. We use data from the Royal Netherlands Meteorological Institute ( KNMI ). Their recordings for more than a century provide extensive information concerning what we frequently describe as \u201cunpredictable weather\u201d. The maximum temperatures in Rotterdam for these two dates were 12.4 \u00baC and 26.4 \u00baC, respectively. But this is not enough. The result is not simply 327.36 \u00baC \\(^2,\\) the product of the two numbers. We need to know the joint probability distribution of the two temperatures on those two specific days that are 90 days apart so that we can correctly compute the expected value. Estimating the joint probability distribution may not be easy. As data collection in Rotterdam started in 1956, at the time of this writing only 60 years of data are available. Each year yields exactly one data pair \\(\\left( {{T_{18 - May}},{T_{16 - Apr}}} \\right).\\) With a 0.1 \u00baC resolution and a potential temperature range of 20 \u00baC this means that approximately \\(200^2\\) = 40,000 \u201ccells\u201d in a two-dimensional histogram are available. Any estimate based upon just 60 data points within 40,000 cells will be flawed. There is no underlying physical model (e.g. bivariate Gaussian) that we might wish to use. What should we do? Our experience might suggest that within a one-week interval the temperature range is essentially the same with only statistical fluctuations. See \u201cPredicting the natural climate \u2013 a case study\u201d in Chapter 5. But this would yield only 7 \u00d7 60 = 420 values for our 40,000 cells. Estimating the joint probability distribution \\(p\\left( {{T_{18 - May}},{T_{16 - Apr}}} \\right)\\) is difficult. Further, the maximum temperature values that we should expect will obviously be different if we choose instead 11 November 2013 and 9 February 2014 which are also 90 days apart. The maximum temperatures in Rotterdam for these last two days were 9.8 \u00baC and 7.6 \u00baC. The random process is not stationary. It should also be clear that we could look at the temperature in Rotterdam on 18 May 2013 and the temperature at Amsterdam Airport (Schiphol) on that same day. These temperatures were 12.4 \u00baC and 12.5 \u00baC, respectively. The issue here is that the indices \\(n\\) and \\(k\\) need not be time; they could be spatial position. Once again we would need the joint probability distribution for these two temperature measurements at different spatial locations. We emphasize that we have not invoked the assumption of stationarity, neither in time nor in space. The consequence of this is that we have two independent instances \\(n\\) and \\(k.\\) But we can always write \\(k\\) as \\(n + m.\\) (If \\(k = 10\\) and \\(n = 7,\\) then the difference between them is \\(m = + 3.\\) ) The description of the probabilities and the averages derived with these probabilities will remain dependent on \\((n,k)\\) or \\((n,n + m)\\) and not simply the difference \\(m.\\) Further, the use of the complex-conjugate notation \\(\\left( {^ * } \\right)\\) as in Equation 4.19 implies that, unless otherwise indicated, we will be considering complex stochastic signals as well as real stochastic signals. Auto-covariance \u00b6 The auto-covariance is defined as: (4.20) $$\\begin{array}{*{20}{l}} {{\\gamma _{xx}}[n,k]}&{ = E\\left\\{ {\\left( {x[n] - {m_{x[n]}}} \\right){{\\left( {x[k] - {m_{x[k]}}} \\right)}^*}} \\right\\}}\\\\ {}&{ = {\\varphi _{xx}}[n,k] - {m_{x[n]}}m_{x[k]}^*}\\\\ {}&{ = {\\varphi _{xx}}[n,n + m] - {m_{x[n]}}m_{x[n + m]}^*} \\end{array}$$ We leave it to you to derive the second line from the first line. See Problem 4.6 . Cross-correlation \u00b6 Following on the idea introduced in Equation 4.11 , that we can consider two signals \\(x[n]\\) and \\(y[k],\\) we also introduce the cross-correlation : (4.21) $$\\begin{array}{*{20}{l}} {{\\varphi _{xy}}[n,k]}&{ = E\\left\\{ {x[n]{y^*}[k]} \\right\\} = E\\left\\{ {x[n]{y^*}[n + m]} \\right\\}}\\\\ {}&{ = {\\varphi _{xy}}[n,n + m]} \\end{array}$$ Cross-covariance \u00b6 Similarly, there is the cross-covariance for complex stochastic signals: (4.22) $$\\begin{array}{*{20}{l}} {{\\gamma _{xy}}[n,k]}&{ = E\\left\\{ {\\left( {x[n] - {m_{x[n]}}} \\right){{\\left( {y[k] - {m_{y[k]}}} \\right)}^*}} \\right\\}}\\\\ {}&{ = {\\varphi _{xy}}[n,k] - {m_{x[n]}}m_{y[k]}^*}\\\\ {}&{ = {\\varphi _{xy}}[n,n + m] - {m_{x[n]}}m_{y[n + m]}^*} \\end{array}$$ We can immediately make the following observations: 1) In general \\({\\varphi _{xx}}[n,k],\\) \\({\\varphi _{xy}}[n,k],\\) \\({\\gamma _{xx}}[n,k]\\) and \\({\\gamma _{xy}}[n,k]\\) are all functions of two variables, and, 2) If \\(n = k,\\) then (4.23) $$\\begin{array}{l} {\\varphi _{xx}}[n,k] = E\\left\\{ {{{\\left| {x[n]} \\right|}^2}} \\right\\}\\\\ {\\gamma _{xx}}[n,k] = E\\left\\{ {{{\\left| {x[n] - {m_{{x_n}}}} \\right|}^2}} \\right\\} = \\sigma _{{x_n}}^2\\\\ {\\varphi _{xy}}[n,k] = E\\left\\{ {x[n]{y^*}[n]} \\right\\} \\end{array}$$ If the process is stationary then the precise values of \\(n\\) and \\(k\\) are not important. Instead only \\(m = k - n,\\) the time difference between them, is significant. Thus we have: (4.24) $$\\begin{array}{l} {\\varphi _{xx}}[n,k] = {\\varphi _{xx}}[n,n + m] = E\\left\\{ {x[n]{x^*}[n + m]} \\right\\} = {\\varphi _{xx}}[m]\\\\ {\\varphi _{xy}}[n,k] = {\\varphi _{xy}}[n,n + m] = E\\left\\{ {x[n]{y^*}[n + m]} \\right\\} = {\\varphi _{xy}}[m] \\end{array}$$ Notice that by definition we subtract the first index \\(n\\) from the second \\(n + m\\) to give \\(\\left( {n + m} \\right) - n = m.\\) Example: Is that coin fair? \u00b6 We return once again to the coin-flipping experiment for an example. We assume that the probability of Heads, \\(p(H),\\) will be \\(p\\) and the probability of Tails, \\(p(T),\\) will be \\(1 \u2013 p.\\) We associate with the occurrence of Heads a signal of +1 and with Tails a signal of \u20131. We note in passing that as \\(p(H)\\) is not a function of time, this immediately implies that the random process is stationary. See also Problem 4.7 . We can now generate various realizations of this random process. Various averages, defined previously, can be determined as follows using the assumption that tosses of the coin occurring at differing instances of time will be statistically independent. (4.25) $${m_x} = ( + 1)(p)\\; + \\;( - 1)(1 - p) = 2p-1$$ (4.26) $$E\\left\\{ {{x^2}} \\right\\} = {( + 1)^2}(p)\\; + \\;{( - 1)^2}(1 - p) = 1$$ (4.27) $$\\sigma _x^2 = 1 - {(2p - 1)^2} = 4p(1 - p)$$ (4.28) $$\\begin{array}{*{20}{l}} {{\\varphi _{xx}}[k]}&{ = E\\left\\{ {x[n]{x^*}[n + k]} \\right\\}}\\\\ {}&{ = \\left\\{ {\\begin{array}{*{20}{l}} {k = 0\\;\\; \\Rightarrow }&{E\\left\\{ {{x^2}[n]} \\right\\} = 1}\\\\ {k \\ne 0\\;\\; \\Rightarrow }&{E\\left\\{ {x[n]} \\right\\} \\bullet E\\left\\{ {x[n + k]} \\right\\} = m_x^2} \\end{array}} \\right.} \\end{array}$$ Notice how the assumption of statistical independence of the coin flips allows us to write in the bottom line of Equation 4.28 that the average of the product equals the product of the averages. For \\(p = 1/2\\) (a fair coin where Heads is just as likely as Tails), we have \\({m_x} = 0,\\) \\(\\sigma _x^2 = 1,\\) and \\({\\varphi _{xx}}[k] = A\\,\\delta [k],\\) the unit, discrete-time impulse. This last random signal \\(\\left( {p = 1/2} \\right)\\) with independent and identically distributed signal values is pure noise and is termed white noise because the zero-mean, autocorrelation function is of the form \\({\\varphi _{xx}}[k] = A\\,\\delta [k]\\) or, in the continuous-time case, \\({\\varphi _{xx}}(\\tau ) = A\\,\\delta (\\tau )\\) where \\(A\\) is a positive, real number. There are various definitions of white noise; we follow the description given in Section 2.5 of Porat 6 and in Oppenheim 7 . Later in this iBook we will explain why this particular form of stochastic signal is termed \u201cwhite\u201d noise. Describing the time average \u00b6 As mentioned earlier it is also possible to compute the average of a signal as a time average: (4.29) $$< x[n] > \\; = \\mathop {\\lim }\\limits_{N \\to \\infty } \\frac{1}{{2N + 1}}\\sum\\limits_{n = - N}^{ + N} {x[n]}$$ and the autocorrelation as: (4.30) $$< x[n]{x^*}[n + k] > \\; = \\mathop {\\lim }\\limits_{N \\to \\infty } \\frac{1}{{2N + 1}}\\sum\\limits_{n = - N}^{ + N} {x[n]{x^*}[n + k]}$$ These two formulas both use a symmetric interval, \\(- N \\leq n \\leq + N,\\) because we wish to capture the complete discrete-time series in our computation of an average: the past, the present and the future. For certain random processes, the following relations hold between the time average of a random process and the probabilistic average (ensemble average) of that same random process. (4.31) $${m_x} = E\\left\\{ {x[n]} \\right\\} = \\; < x[n] >$$ (4.32) $$\\begin{array}{*{20}{l}} {{\\varphi _{xx}}[k]}&{ = E\\left\\{ {x[n]{x^*}[n + k]} \\right\\}}\\\\ {}&{ = \\; < x[n]{x^*}[n + k] > } \\end{array}$$ Such a random process, where the time average equals the ensemble average, is known as an ergodic process 8 . The ergodic process \u00b6 One consequence of ergodicity is that it does not matter when computing an average\u2014any average\u2014whether one flips one coin \\(N\\) times or \\(N\\) coins once. From the definitions of time averages given above, it is clear that one condition that a random process must fulfill in order to be ergodic is that the process be stationary. All ergodic processes are stationary processes. For an ergodic process the above result implies that, given a data record of finite length \\({ x[n] },\\) we can use finite-interval time averages to estimate the signal average and autocorrelation function even when the probability function is not explicitly known. The first step is to replace the limits in Equation 4.31 and Equation 4.32 with finite sums: (4.33) $${m_x} = \\;{\\kern 1pt} < x[n]{ > _{2N + 1}}\\;{\\kern 1pt} = \\frac{1}{{2N + 1}}\\sum\\limits_{n = - N}^{ + N} {x[n]} $$ (4.34) $$\\begin{array}{*{20}{l}} {{\\varphi _{xx}}[k]}&{ = \\; < x[n]{x^*}[n + k]{ > _{2N + 1}}\\;}\\\\ {}&{ = \\frac{1}{{2N + 1}}\\sum\\limits_{n = - N}^{ + N} {x[n]{x^*}[n + k]} } \\end{array}$$ In the following chapters we will make extensive use of the results from this chapter. In particular, in Chapter 5 we will further refine these equations. It is important to note that while Equation 4.33 and Equation 4.34 are estimates of statistical properties of an ergodic process, this does not mean that they are good estimates. This issue will be discussed in greater detail in Chapter 11 . Problems \u00b6 Problem 4.1 \u00b6 Consider the probability distribution described as follows: \\[p(i) = \\left\\{ {\\begin{array}{*{20}{l}} {A{{\\left( {\\frac{1}{2}} \\right)}^i}}&{i > 0}\\\\ 0&{i \\le 0} \\end{array}} \\right.\\] where \\(i\\) is an integer. Determine the value of A . Let the random variable \\(x\\) associated with index i be given by \\({2^{ - i}}.\\) Determine the expected value \\(E\\{ x\\}.\\) Problem 4.2 \u00b6 Schr\u00f6dinger\u2019s cat is back in the box. This time he is accompanied by two atoms each of a different isotope. The first isotope, 11 Be, has a half-life of \\({t_{1/2}} = 13.81\\) s and its radioactive decay\u2014a stochastic process\u2014involves an electron \\(\\left( {{\\beta ^ - }} \\right)\\) emission. The second isotope, 10 C, has a half-life of \\({t_{1/2}} = 19.29\\) s and its radioactive decay involves a positron \\(\\left( {{\\beta ^ + }} \\right)\\) emission. Detectors inside the box can distinguish between these emitted particles. If the 11 Be atom emits an electron, then poison gas will be released and the cat will immediately die. If the 10 C isotope emits a positron, then the cat will be immediately released from the box and live. What is the probability that after 20 seconds the cat will be released and survive? Hint : The probability, \\(p(t),\\) that an atom will decay either through electron or positron emission in the interval \\(0 \\leqslant t \\leqslant T\\) seconds is given by: \\[P(0 \\leqslant t \\leqslant T) = 1 - {e^{ - T/\\tau }}\\] where \\(\\tau = {t_{1/2}}/\\ln 2.\\) Problem 4.3 \u00b6 Prove Equation 4.13 and Equation 4.15 . Problem 4.4 \u00b6 In Equation 4.13 , Equation 4.14 , and Equation 4.15 we presented three important properties of averaging. The consequences when applied to the calculation of means should be obvious. There are, however, other averages and in this problem we look at the variance of a random variable. Let \\(x\\) be a random variable that has both a mean \\({\\mu _x}\\) and a variance \\(\\sigma _x^2.\\) By this we mean that both \\({\\mu _x}\\) and \\(\\sigma _x^2\\) exist and are finite. The random variable \\(y\\) is related to \\(x\\) by \\(y = a\\,x + b\\) where \\(a\\) and \\(b\\) are deterministic\u2014not random\u2014variables (or constants). Determine the mean \\({\\mu _y}\\) and variance \\(\\sigma _y^2.\\) What does this mean? Explain in words the meaning of the result for variance in relation to \\(b.\\) How would this, for example, be reflected in a graph of the probability density function of \\(y\\) relative to \\(x?\\) If the coefficient-of-variation \\(C{V_x}\\) of the random variable \\(x\\) is given by \\(C{V_x} = {\\sigma _x}/{\\mu _x},\\) where \\({\\mu _x} \\ne 0,\\) determine \\(C{V_y}\\) in terms of the parameters given. Problem 4.5 \u00b6 Let \\(x[n]\\) be a sample from a random process \\(x\\) with an underlying probability distribution that is stationary. The mean of the process is \\({\\mu _x}\\) and the variance is \\(\\sigma _x^2.\\) The process \\(y\\) is formed by \\(y[n] = x[n]\\cos \\left( {\\Omega n} \\right).\\) What is the mean of process \\(y?\\) What is the variance of process \\(y?\\) Is process \\(y\\) stationary? Problem 4.6 \u00b6 Prove Equation 4.20 . Problem 4.7 \u00b6 We assume that when someone \u201cflips\u201d a coin that the \\(p(H) = p(T) = 1/2,\\) what we call a \u201cfair\u201d coin. But with practice one could in principle learn to alter these probabilities. Fast Eddie has been practicing and he is learning. After \\(m\\) practice sessions, his \\(p(H)\\) is given by: \\[p(H) = \\frac{1}{2}\\left( {2 - {{\\left( {\\frac{1}{2}} \\right)}^m}} \\right)\\] Every time Heads ( \\(H\\) ) comes up, Eddie pays out $1; every time Tails ( \\(T\\) ) comes up, Eddie receives $1. What is Eddie\u2019s expected result with no training, that is, \\(m = 0?\\) What is Eddie\u2019s expected result after \\(m = 10\\) training sessions? Is Eddie working with a stationary random process? Is Eddie \u201cplaying with a full deck\u201d, that is, is he a rational player? Problem 4.8 \u00b6 We are given a sample of an ergodic, continuous-time , white-noise random process, \\(x(t).\\) We want to use samples of this continuous-time process to drive (as input to) a discrete-time system. Discuss the following proposition and its consequences: \u201cThere does not exist a finite sampling frequency, \\({\\omega _s} = 2\\pi {f_s},\\) that satisfies the Nyquist sampling theorem for x(t).\u201d Problem 4.9 \u00b6 In many discussions of random variables we encounter a phrase such as \u201cwithout loss of generality we use the standardized (or normalized) random variable \\(z = \\left( {x - {\\mu _x}} \\right)/{\\sigma _x}\\) \u201d where \\({\\mu _x}\\) and \\({\\sigma _x}\\) are the mean and standard deviation, respectively, of the random variable \\(x.\\) Based upon what mathematical conditions is this statement justifiable? What are the mean \\({\\mu _z}\\) and the standard deviation \\({\\sigma _z}\\) of the random variable \\(z\\) if the conditions from part ( a ) have been satisfied? Why is the expression \u201cwithout loss of generality\u2026\u201d so frequently used? Laboratory Exercises \u00b6 Laboratory Exercise 4.1 \u00b6 Flipping (tossing) a coin is a well-known way to describe the generation of random events. If the coin is \u201cfair\u201d then we expect just as many occurrences of \u201cHeads\u201d as \u201cTails\u201d. In this experiment we flip a coin N times with 1 \u2264 N \u2264 81 and a probability of Heads where 0 \u2264 p \u2264 1. The number of Heads n H and the number of Tails n T that result from N tosses of the coin will be displayed as a bar chart known as a histogram. You will also see a stochastic signal that is based upon your outcome and a lot of coins. To start the exercise, click on the icon to the left. Laboratory Exercise 4.2 \u00b6 An N \u00d7 N image consists of N 2 pixels. We can choose the grey-level brightness for each pixel from almost any distribution provided that the chosen value is real and non-negative. To start the exercise, click on the icon to the left. There are other definitions of a \u201cmean\u201d than just the arithmetic mean. These are discussed briefly here . \u21a9 Feynman, R. P., R. B. Leighton and M. Sands (1963). The Feynman Lectures on Physics: Mainly Mechanics, Radiation, and Heat. Reading, Massachusetts, Addison-Wesley, Vol. I \u21a9 Cram\u00e9r, H. (1946). Mathematical Methods of Statistics. Princeton, New Jersey, Princeton University Press \u21a9 For economy of notation, we will express \\({{p_{x[n]}}(x,n)}\\) (and similar forms) as \\(p(x[n])\\) . \u21a9 The sum formulation can be included within the integral formulation by describing the probability with the aid of impulse functions. In the die example, we would write the probability density function on the continuous variable \\(x\\) as \\(p(x) = \\sum\\limits_{i = 1}^6 {\\left( {\\frac{1}{6}} \\right)} \\,\\delta (x - i).\\) \u21a9 Porat, B. (1994). Digital Processing of Random Signals: Theory & Methods. Englewood Cliffs, New Jersey, Prentice-Hall \u21a9 Oppenheim, A. V., R. W. Schafer and J. R. Buck (1999). Discrete-Time Signal Processing. Upper Saddle River, New Jersey, Prentice-Hall, Section 2.10 \u21a9 The word ergodic originated in the 20th century to describe the mathematical concept of a system or process with the property that, given sufficient time, it \u201cvisits\u201d all points in a given space. Using the dictionary function of this iBook you can see the complete definition. \u21a9","title":"4. Characterization of Random Signals"},{"location":"Chap_4.html#characterization-of-random-signals","text":"Because it is impossible for us to specify what a random signal will be at any one instant, let alone for all \\(t\\) or \\(n\\) , we have to settle for a description based upon average properties of the signal. There are a variety of definitions associated with the use of the word \u201caverage\u201d (including \u201cnot very good\u201d). In the context of this book we will focus on the concept as related to a number or property that is considered as representative of a collection of numbers such as those encountered in a signal. Consider, for example, the flipping of a coin.","title":"Characterization of Random Signals"},{"location":"Chap_4.html#example-fair-chance","text":"We map Heads into +1 and Tails into \u20131 giving: Figure 4.1: One realization of a coin-flipping experiment with Heads mapped to +1 and Tails mapped to \u20131 We might imagine computing the (arithmetic) average 1 over \\(2N + 1\\) samples as: (4.1) $$ < x[n]{ > _{2N + 1}} = \\frac{1}{{2N + 1}}\\left( {\\sum\\limits_{n = - N}^{ + N} {x[n]} } \\right) $$ In the above example: For \\(N = 1 \\to < x[n]{ > _3} = 1\\) For \\(N = 2 \\to < x[n]{ > _5} = 1/5\\) For \\(N = 3 \\to < x[n]{ > _7} = 3/7\\) We \u201cexpect\u201d for a \u201cfair coin\u201d that if \\(N\\) is large then \\(< x[n]{ > _{2N + 1}} \\approx 0\\) because there will be just as many +1\u2019s in the sum as \u20131\u2019s. Another way to compute the average is based upon knowledge of the distribution of \\(p(x[n])\\) and is termed ensemble averaging . Instead of flipping one coin \\(N\\) times we could flip \\(N\\) coins once. We then count the number of Heads \\(\\left( {{n_H}} \\right)\\) and the number of Tails \\(\\left( {{n_T} = N - {n_H}} \\right)\\) . Our estimate of the probability of Heads would then be \\(p(H) = {n_H}/N\\) and the probability of Tails as \\(p(T) = {n_T}/N = 1 - {n_H}/N\\) . Again for large values of \\(N\\) and a \u201cfair coin\u201d we expect just as many Heads as Tails and this means \\(p(H) = p(T) = 1/2\\) . This method and stochastic signals associated with this method are explored in Laboratory Exercise 4.1 . By examining the probability of all the possible outcomes\u2014in this case with a coin just two but in the case of a die six\u2014we can develop a model for a probability distribution that describes the possible values of our random variable. And by associating numerical values to the variable, such as Heads \\(\\rightarrow\\) +1 and Tails \\(\\rightarrow\\) \u20131, we can compute averages.","title":"Example: Fair chance"},{"location":"Chap_4.html#describing-the-ensemble-average","text":"How do we do this? Returning to a statement above, we seek a number that is representative of a collection of random numbers. Let us assume that we have either a formal mathematical model of the random process that has generated the random numbers or we have collected sufficient data to have an excellent estimate of that probability distribution (or density) function. Either way we can depict\u2014with confidence\u2014the probability that the random variable \\(x\\) can take on a specific value \\(m\\) at time \\(n\\) . Such a probability distribution is shown in Figure 4.2 . Figure 4.2: Determining a representative number from a probability distribution. The distribution shown is a Poisson distribution. If a single number is to characterize this distribution, a reasonable requirement is that the number provides a \u201cbalanced\u201d description. From the domain of physics this has a specific meaning, the center-of-mass of a body with mass distribution, \\(m(\\vec p).\\) The classical distribution of mass, as we know, is a non-negative function of the position vector \\(\\vec p.\\) In that sense it is similar to a probability distribution. Finding the center-of-mass is equivalent to finding the position where the mass can be balanced. This is illustrated in Figure 4.3 . Figure 4.3: Determining a representative number from a mass (or probability) distribution. When the mass is distributed around the center-of-mass the object is balanced. When another position is chosen, unexpected and possibly unpleasant things can happen. The mathematics associated with the calculation of the center-of-mass involve either \\(\\int {\\vec p} \\,m(\\vec p)d\\vec p\\) for a continuous (in space) distribution of mass or \\(\\sum {{{\\vec p}_i}} \\,m({\\vec p_i})\\) for a discrete (in space) distribution of mass. See Sections I-18 and I-19 of Feynman 2 . It is but a short step to replace mass distribution (continuous or discrete) with a probability distribution (continuous or discrete) to define a number, the average, which is representative of a collection of random numbers. Indeed, this is the approach presented in Section 15.2 of Cram\u00e9r 3 . This leads to a formal definition of averaging as: (4.2) $$ E \\left\\{ {x[n]} \\right\\} = \\int\\limits_{ - \\infty }^{ + \\infty } {x\\,{p_{x[n]}}(x,n)dx = {m_{x[n]}}} $$ When the determination of an average is based upon the use of the probability distribution, it is referred to as an ensemble average 4 . Here we take into consideration that the average or mean may depend on \\(n.\\) (See, for instance, the even / odd mixed example above. In that example the probability distribution that is to be used in computing the average depends upon whether \\(n\\) is even or odd.) It may seem strange to see an integral in Equation 4.2 when we are talking about discrete-time signals. We should remember, however, that although time is discrete the values of the random variable need not be. They can, in principle, be complex numbers \\({\\Bbb C}\\) , real numbers \\({\\Bbb R}\\) , or integers \\({\\Bbb Z}\\) . The average value is computed over all possible values of the random variable of the amplitude \\(x\\) . It is possible that a sum can be used instead of an integral. In Example: Average Experience , we see that the possible values of the random variable are indexed \\(i = 1, \\ldots ,6\\) in which case a sum is used. Another example is given in Problem 4.1 where \\(i = - \\infty , \\ldots ,0, \\ldots , + \\infty\\) and a sum is again required. But in the most general formulation of averaging an integral is used 5 . For many problems that occur\u2014 including those that we plan to focus on here \u2014the random processes are stationary . This means that averages are in an equilibrium condition that is invariant to a shift in time. In a stationary die experiment we should obtain the same results (averages) whether the experiment is performed yesterday, today, or next year. For the mean value given above this would imply a value independent of the time origin: (4.3) $$ {m_{x[n]}} = {m_{x[n + k]}} = {m_{x[\\ell ]}} = {m_x} $$ The mean value of the random process \\(x[n]\\) at time \\(n\\) is the same as at time \\(n + k.\\) But this second time has its own \u201cname\u201d \\(\\ell.\\) This implies that the mean value is independent of time and is simply \\({m_x},\\) that is, stationary.","title":"Describing the ensemble average"},{"location":"Chap_4.html#example-average-experience","text":"For our die experiment, where the number of possible outcomes can be indexed, we can use a version of the average based upon a sum: (4.4) $$ E\\left\\{ x \\right\\} = \\sum\\limits_{i = 1}^6 {{x_i}p({x_i})} = 1\\left( {\\frac{1}{6}} \\right) + 2\\left( {\\frac{1}{6}} \\right) + \\ldots + 6\\left( {\\frac{1}{6}} \\right) = \\frac{7}{2} = {m_x} $$","title":"Example: Average experience"},{"location":"Chap_4.html#other-averages","text":"Other averages might, in general, be written as: (4.5) $$ Mean\\;square = E\\left\\{ {{x^2}[n]} \\right\\} = \\int\\limits_{ - \\infty }^{ + \\infty } {{x^2}p(x[n])dx} $$ (4.6) $$ E\\left\\{ {g\\left( {x[n]} \\right)} \\right\\} = \\int\\limits_{ - \\infty }^{ + \\infty } {g(x)p(x[n])dx} $$ To repeat, while \\(n\\) is discrete, the random variable \\(x\\) can have any value. For stationary processes these averages would reduce to: (4.7) $$ \\begin{array}{l} E\\left\\{ {{x^2}} \\right\\} = \\int\\limits_{ - \\infty }^{ + \\infty } {{x^2}p(x)dx} \\\\ E\\left\\{ {g(x)} \\right\\} = \\int\\limits_{ - \\infty }^{ + \\infty } {g(x)p(x)dx} \\end{array} $$ We apply these concepts to the example of throwing a die.","title":"Other averages"},{"location":"Chap_4.html#example-dice-money","text":"(4.8) $$ E\\left\\{ {{x^2}} \\right\\} = {1^2}\\left( {\\frac{1}{6}} \\right) + {2^2}\\left( {\\frac{1}{6}} \\right) + {3^2}\\left( {\\frac{1}{6}} \\right) + \\ldots + {6^2}\\left( {\\frac{1}{6}} \\right) = 15\\frac{1}{6} $$ If we use a function \\(g( \\bullet )\\) defined on the random variable \\(x\\) : (4.9) $$ g(x) = \\left\\{ {\\begin{array}{*{20}{l}} { + 1}&{x\\;{\\rm{even}}\\;2,\\;4,\\;6}\\\\ { - 1}&{x\\;{\\rm{odd}}\\;1,\\;3,\\;5} \\end{array}} \\right. $$ Then the average value of this function of a random variable is: (4.10) $$ E\\left\\{ {g(x)} \\right\\} = 0 $$ We see through this choice of \\(g(x)\\) that it is possible to use the die experiment to model the coin-flipping experiment. It is also important to realize that although we have chosen integer values for the random variable \\(x\\) in Example: Fair chance , Example: Average experience and Example: Dice money , in general the variable can take on any complex value. The time index \\(n,\\) of course, will remain discrete, that is, an integer. We may also use two random variables \\(x[n]\\) and \\(y[k]\\) with an associated joint probability given by \\(p(x[n],y[k])\\) and take the average: (4.11) $$ E\\left\\{ {x[n]y[k]} \\right\\} = \\int\\limits_{}^{} {\\int\\limits_{}^{} {x\\,y\\,p(x[n],y[k])dxdy} } $$ The more general function of the two random variables leads to an average: (4.12) $$ E\\left\\{ {g\\left( {x[n],y[k]} \\right)} \\right\\} = \\int\\limits_{}^{} {\\int\\limits_{}^{} {g(x,y)p(x[n],y[k])dxdy} } $$ We should remember that it is possible that \\(p(x[n],y[k])\\) has a complicated behavior. The signal \\(x[n]\\) may be based upon flipping a coin and the signal \\(y[n]\\) may be based upon throwing a die. If these two types of events are independent, fair and stationary ( caveat emptor! ), then: \\[ p(x[n] = - 1,y[k] = 5) = p(x[n] = - 1)\\,p(y[k] = 5) = \\left( {\\frac{1}{2}} \\right)\\left( {\\frac{1}{6}} \\right) = \\frac{1}{{12}}\\,. \\] While we have explicitly chosen two distinct time instances \\(n \\ne k,\\) this does not matter for calculation of the probability because we have also assumed that both signals are stationary. See Problem 4.2 . As we can infer from Figure 4.4 , it is also possible that \\(y[k]\\) is just the signal \\(x[n]\\) at time \\(k.\\) That is, if there is anything to be gained, there is nothing to prevent us from considering the case where \\(y[n] = x[n].\\) Figure 4.4: Two samples \\((x[n\\rbrack,x[k\\rbrack)\\) can come from one realization of a random process. One sample is at time \\(n\\) and the other at time \\(k.\\)","title":"Example: Dice &amp; money"},{"location":"Chap_4.html#properties-of-averaging","text":"At this point, several well-known properties based upon linearity of averaging are useful to have available: (4.13) $$ E\\left\\{ {x[n] + y[n]} \\right\\} = E\\left\\{ {x[n]} \\right\\} + E\\left\\{ {y[n]} \\right\\} $$ (4.14) $$ E\\left\\{ {ax[n]} \\right\\} = aE\\left\\{ {x[n]} \\right\\} $$ (4.15) $$E\\left\\{ {x[n] + c} \\right\\} = E\\left\\{ {x[n]} \\right\\} + c$$ We will prove Equation 4.14 and leave the proofs of Equation 4.13 and Equation 4.15 for you at the end of this chapter. See Problem 4.3 . We start from Equation 4.2 and substitute \\(a\\,x[n]\\) where the constant \\(a\\) is a deterministic\u2014not random (!)\u2014number: (4.16) $$\\begin{array}{*{20}{l}} {E\\left\\{ {a\\,x[n]} \\right\\}}&{ = \\int\\limits_{ - \\infty }^{ + \\infty } {a\\,x\\,p(x[n])dx} = a\\int\\limits_{ - \\infty }^{ + \\infty } {x\\,p(x[n])dx} = a\\,{m_{x[n]}}}\\\\ {}&{ = a\\,E\\left\\{ {x[n]} \\right\\}} \\end{array}$$ The first two properties, Equation 4.13 and Equation 4.14 , indicate that the averaging operation is a linear operation. The average of a weighted sum of random variables, \\(x_1\\) and \\(x_2,\\) is the weighted sum of their averages, \\(E\\left\\{ {a\\,{x_1} + b\\,{x_2}} \\right\\} = a\\,E\\left\\{ {{x_1}} \\right\\} + b\\,E\\left\\{ {{x_2}} \\right\\}.\\) As simple as each of these properties may seem, it is important that you understand how to prove each one and what each one means . We have already looked at the averages mean and mean-square . Another important and therefore common average is the variance : (4.17) $$\\begin{array}{*{20}{l}} {Variance\\left\\{ {x[n]} \\right\\}}&{ = \\sigma _{x[n]}^2}\\\\ {}&{ = E\\left\\{ {{{\\left( {x[n] - {m_{x[n]}}} \\right)}^2}} \\right\\}}\\\\ {}&{ = E\\left\\{ {{x^2}[n]} \\right\\} - {{\\left( {{m_{x[n]}}} \\right)}^2}} \\end{array}$$ which in the stationary form is given by: (4.18) $$Var\\left( x \\right) = \\sigma _x^2 = E\\left\\{ {{{\\left( {x[n] - {m_x}} \\right)}^2}} \\right\\} = E\\left\\{ {{x^2}[n]} \\right\\} - m_x^2$$ We introduce here the notation \\(Var(x)\\) to indicate the variance of the random variable \\(x.\\) The term \\(\\sigma,\\) the positive square root of the variance, is called the standard deviation . Note that when the physical process generating \\(x[n]\\) has a certain unit such as meters, then the standard deviation \\(\\sigma\\) has the same unit. The issue of units will be important later in this iBook when we discuss topics such as signal-to-noise ratio.","title":"Properties of averaging"},{"location":"Chap_4.html#correlation-the-workhorse","text":"These averages only describe what happens at a single time point of a random process even if the process is stationary. A more general and very useful average is the autocorrelation that describes the joint behavior of a random process at two points in time. The motivation for examining this issue is that we would like to know if knowledge at one time point can help us predict or understand behavior at another time point. If a stochastic signal is increasing now, is it possible to predict that it might be decreasing 180 days from now?","title":"Correlation \u2013 the workhorse"},{"location":"Chap_4.html#autocorrelation","text":"In discrete time the definition of autocorrelation is: (4.19) $$\\begin{array}{*{20}{l}} {{\\varphi _{xx}}[n,k]}&{ = E\\left\\{ {x[n]\\,{x^*}[k]} \\right\\} = E\\left\\{ {x[n]\\,{x^*}[n + m]} \\right\\}}\\\\ {}&{ = {\\varphi _{xx}}[n,n + m]} \\end{array}$$ The procedure should be clear. We take the random variable at time \\(n\\) and the random variable at time \\(k\\) with their associated joint probability. We then ask: what is the expected value of their product?","title":"Autocorrelation"},{"location":"Chap_4.html#the-mechanics-of-correlations","text":"As an example we compute the expected value of the maximum temperature in Rotterdam, The Netherlands on 18 May 2013 multiplied by the maximum temperature in Rotterdam on 16 August 2013. We use data from the Royal Netherlands Meteorological Institute ( KNMI ). Their recordings for more than a century provide extensive information concerning what we frequently describe as \u201cunpredictable weather\u201d. The maximum temperatures in Rotterdam for these two dates were 12.4 \u00baC and 26.4 \u00baC, respectively. But this is not enough. The result is not simply 327.36 \u00baC \\(^2,\\) the product of the two numbers. We need to know the joint probability distribution of the two temperatures on those two specific days that are 90 days apart so that we can correctly compute the expected value. Estimating the joint probability distribution may not be easy. As data collection in Rotterdam started in 1956, at the time of this writing only 60 years of data are available. Each year yields exactly one data pair \\(\\left( {{T_{18 - May}},{T_{16 - Apr}}} \\right).\\) With a 0.1 \u00baC resolution and a potential temperature range of 20 \u00baC this means that approximately \\(200^2\\) = 40,000 \u201ccells\u201d in a two-dimensional histogram are available. Any estimate based upon just 60 data points within 40,000 cells will be flawed. There is no underlying physical model (e.g. bivariate Gaussian) that we might wish to use. What should we do? Our experience might suggest that within a one-week interval the temperature range is essentially the same with only statistical fluctuations. See \u201cPredicting the natural climate \u2013 a case study\u201d in Chapter 5. But this would yield only 7 \u00d7 60 = 420 values for our 40,000 cells. Estimating the joint probability distribution \\(p\\left( {{T_{18 - May}},{T_{16 - Apr}}} \\right)\\) is difficult. Further, the maximum temperature values that we should expect will obviously be different if we choose instead 11 November 2013 and 9 February 2014 which are also 90 days apart. The maximum temperatures in Rotterdam for these last two days were 9.8 \u00baC and 7.6 \u00baC. The random process is not stationary. It should also be clear that we could look at the temperature in Rotterdam on 18 May 2013 and the temperature at Amsterdam Airport (Schiphol) on that same day. These temperatures were 12.4 \u00baC and 12.5 \u00baC, respectively. The issue here is that the indices \\(n\\) and \\(k\\) need not be time; they could be spatial position. Once again we would need the joint probability distribution for these two temperature measurements at different spatial locations. We emphasize that we have not invoked the assumption of stationarity, neither in time nor in space. The consequence of this is that we have two independent instances \\(n\\) and \\(k.\\) But we can always write \\(k\\) as \\(n + m.\\) (If \\(k = 10\\) and \\(n = 7,\\) then the difference between them is \\(m = + 3.\\) ) The description of the probabilities and the averages derived with these probabilities will remain dependent on \\((n,k)\\) or \\((n,n + m)\\) and not simply the difference \\(m.\\) Further, the use of the complex-conjugate notation \\(\\left( {^ * } \\right)\\) as in Equation 4.19 implies that, unless otherwise indicated, we will be considering complex stochastic signals as well as real stochastic signals.","title":"The mechanics of correlations"},{"location":"Chap_4.html#auto-covariance","text":"The auto-covariance is defined as: (4.20) $$\\begin{array}{*{20}{l}} {{\\gamma _{xx}}[n,k]}&{ = E\\left\\{ {\\left( {x[n] - {m_{x[n]}}} \\right){{\\left( {x[k] - {m_{x[k]}}} \\right)}^*}} \\right\\}}\\\\ {}&{ = {\\varphi _{xx}}[n,k] - {m_{x[n]}}m_{x[k]}^*}\\\\ {}&{ = {\\varphi _{xx}}[n,n + m] - {m_{x[n]}}m_{x[n + m]}^*} \\end{array}$$ We leave it to you to derive the second line from the first line. See Problem 4.6 .","title":"Auto-covariance"},{"location":"Chap_4.html#cross-correlation","text":"Following on the idea introduced in Equation 4.11 , that we can consider two signals \\(x[n]\\) and \\(y[k],\\) we also introduce the cross-correlation : (4.21) $$\\begin{array}{*{20}{l}} {{\\varphi _{xy}}[n,k]}&{ = E\\left\\{ {x[n]{y^*}[k]} \\right\\} = E\\left\\{ {x[n]{y^*}[n + m]} \\right\\}}\\\\ {}&{ = {\\varphi _{xy}}[n,n + m]} \\end{array}$$","title":"Cross-correlation"},{"location":"Chap_4.html#cross-covariance","text":"Similarly, there is the cross-covariance for complex stochastic signals: (4.22) $$\\begin{array}{*{20}{l}} {{\\gamma _{xy}}[n,k]}&{ = E\\left\\{ {\\left( {x[n] - {m_{x[n]}}} \\right){{\\left( {y[k] - {m_{y[k]}}} \\right)}^*}} \\right\\}}\\\\ {}&{ = {\\varphi _{xy}}[n,k] - {m_{x[n]}}m_{y[k]}^*}\\\\ {}&{ = {\\varphi _{xy}}[n,n + m] - {m_{x[n]}}m_{y[n + m]}^*} \\end{array}$$ We can immediately make the following observations: 1) In general \\({\\varphi _{xx}}[n,k],\\) \\({\\varphi _{xy}}[n,k],\\) \\({\\gamma _{xx}}[n,k]\\) and \\({\\gamma _{xy}}[n,k]\\) are all functions of two variables, and, 2) If \\(n = k,\\) then (4.23) $$\\begin{array}{l} {\\varphi _{xx}}[n,k] = E\\left\\{ {{{\\left| {x[n]} \\right|}^2}} \\right\\}\\\\ {\\gamma _{xx}}[n,k] = E\\left\\{ {{{\\left| {x[n] - {m_{{x_n}}}} \\right|}^2}} \\right\\} = \\sigma _{{x_n}}^2\\\\ {\\varphi _{xy}}[n,k] = E\\left\\{ {x[n]{y^*}[n]} \\right\\} \\end{array}$$ If the process is stationary then the precise values of \\(n\\) and \\(k\\) are not important. Instead only \\(m = k - n,\\) the time difference between them, is significant. Thus we have: (4.24) $$\\begin{array}{l} {\\varphi _{xx}}[n,k] = {\\varphi _{xx}}[n,n + m] = E\\left\\{ {x[n]{x^*}[n + m]} \\right\\} = {\\varphi _{xx}}[m]\\\\ {\\varphi _{xy}}[n,k] = {\\varphi _{xy}}[n,n + m] = E\\left\\{ {x[n]{y^*}[n + m]} \\right\\} = {\\varphi _{xy}}[m] \\end{array}$$ Notice that by definition we subtract the first index \\(n\\) from the second \\(n + m\\) to give \\(\\left( {n + m} \\right) - n = m.\\)","title":"Cross-covariance"},{"location":"Chap_4.html#example-is-that-coin-fair","text":"We return once again to the coin-flipping experiment for an example. We assume that the probability of Heads, \\(p(H),\\) will be \\(p\\) and the probability of Tails, \\(p(T),\\) will be \\(1 \u2013 p.\\) We associate with the occurrence of Heads a signal of +1 and with Tails a signal of \u20131. We note in passing that as \\(p(H)\\) is not a function of time, this immediately implies that the random process is stationary. See also Problem 4.7 . We can now generate various realizations of this random process. Various averages, defined previously, can be determined as follows using the assumption that tosses of the coin occurring at differing instances of time will be statistically independent. (4.25) $${m_x} = ( + 1)(p)\\; + \\;( - 1)(1 - p) = 2p-1$$ (4.26) $$E\\left\\{ {{x^2}} \\right\\} = {( + 1)^2}(p)\\; + \\;{( - 1)^2}(1 - p) = 1$$ (4.27) $$\\sigma _x^2 = 1 - {(2p - 1)^2} = 4p(1 - p)$$ (4.28) $$\\begin{array}{*{20}{l}} {{\\varphi _{xx}}[k]}&{ = E\\left\\{ {x[n]{x^*}[n + k]} \\right\\}}\\\\ {}&{ = \\left\\{ {\\begin{array}{*{20}{l}} {k = 0\\;\\; \\Rightarrow }&{E\\left\\{ {{x^2}[n]} \\right\\} = 1}\\\\ {k \\ne 0\\;\\; \\Rightarrow }&{E\\left\\{ {x[n]} \\right\\} \\bullet E\\left\\{ {x[n + k]} \\right\\} = m_x^2} \\end{array}} \\right.} \\end{array}$$ Notice how the assumption of statistical independence of the coin flips allows us to write in the bottom line of Equation 4.28 that the average of the product equals the product of the averages. For \\(p = 1/2\\) (a fair coin where Heads is just as likely as Tails), we have \\({m_x} = 0,\\) \\(\\sigma _x^2 = 1,\\) and \\({\\varphi _{xx}}[k] = A\\,\\delta [k],\\) the unit, discrete-time impulse. This last random signal \\(\\left( {p = 1/2} \\right)\\) with independent and identically distributed signal values is pure noise and is termed white noise because the zero-mean, autocorrelation function is of the form \\({\\varphi _{xx}}[k] = A\\,\\delta [k]\\) or, in the continuous-time case, \\({\\varphi _{xx}}(\\tau ) = A\\,\\delta (\\tau )\\) where \\(A\\) is a positive, real number. There are various definitions of white noise; we follow the description given in Section 2.5 of Porat 6 and in Oppenheim 7 . Later in this iBook we will explain why this particular form of stochastic signal is termed \u201cwhite\u201d noise.","title":"Example: Is that coin fair?"},{"location":"Chap_4.html#describing-the-time-average","text":"As mentioned earlier it is also possible to compute the average of a signal as a time average: (4.29) $$< x[n] > \\; = \\mathop {\\lim }\\limits_{N \\to \\infty } \\frac{1}{{2N + 1}}\\sum\\limits_{n = - N}^{ + N} {x[n]}$$ and the autocorrelation as: (4.30) $$< x[n]{x^*}[n + k] > \\; = \\mathop {\\lim }\\limits_{N \\to \\infty } \\frac{1}{{2N + 1}}\\sum\\limits_{n = - N}^{ + N} {x[n]{x^*}[n + k]}$$ These two formulas both use a symmetric interval, \\(- N \\leq n \\leq + N,\\) because we wish to capture the complete discrete-time series in our computation of an average: the past, the present and the future. For certain random processes, the following relations hold between the time average of a random process and the probabilistic average (ensemble average) of that same random process. (4.31) $${m_x} = E\\left\\{ {x[n]} \\right\\} = \\; < x[n] >$$ (4.32) $$\\begin{array}{*{20}{l}} {{\\varphi _{xx}}[k]}&{ = E\\left\\{ {x[n]{x^*}[n + k]} \\right\\}}\\\\ {}&{ = \\; < x[n]{x^*}[n + k] > } \\end{array}$$ Such a random process, where the time average equals the ensemble average, is known as an ergodic process 8 .","title":"Describing the time average"},{"location":"Chap_4.html#the-ergodic-process","text":"One consequence of ergodicity is that it does not matter when computing an average\u2014any average\u2014whether one flips one coin \\(N\\) times or \\(N\\) coins once. From the definitions of time averages given above, it is clear that one condition that a random process must fulfill in order to be ergodic is that the process be stationary. All ergodic processes are stationary processes. For an ergodic process the above result implies that, given a data record of finite length \\({ x[n] },\\) we can use finite-interval time averages to estimate the signal average and autocorrelation function even when the probability function is not explicitly known. The first step is to replace the limits in Equation 4.31 and Equation 4.32 with finite sums: (4.33) $${m_x} = \\;{\\kern 1pt} < x[n]{ > _{2N + 1}}\\;{\\kern 1pt} = \\frac{1}{{2N + 1}}\\sum\\limits_{n = - N}^{ + N} {x[n]} $$ (4.34) $$\\begin{array}{*{20}{l}} {{\\varphi _{xx}}[k]}&{ = \\; < x[n]{x^*}[n + k]{ > _{2N + 1}}\\;}\\\\ {}&{ = \\frac{1}{{2N + 1}}\\sum\\limits_{n = - N}^{ + N} {x[n]{x^*}[n + k]} } \\end{array}$$ In the following chapters we will make extensive use of the results from this chapter. In particular, in Chapter 5 we will further refine these equations. It is important to note that while Equation 4.33 and Equation 4.34 are estimates of statistical properties of an ergodic process, this does not mean that they are good estimates. This issue will be discussed in greater detail in Chapter 11 .","title":"The ergodic process"},{"location":"Chap_4.html#problems","text":"","title":"Problems"},{"location":"Chap_4.html#problem-41","text":"Consider the probability distribution described as follows: \\[p(i) = \\left\\{ {\\begin{array}{*{20}{l}} {A{{\\left( {\\frac{1}{2}} \\right)}^i}}&{i > 0}\\\\ 0&{i \\le 0} \\end{array}} \\right.\\] where \\(i\\) is an integer. Determine the value of A . Let the random variable \\(x\\) associated with index i be given by \\({2^{ - i}}.\\) Determine the expected value \\(E\\{ x\\}.\\)","title":"Problem 4.1"},{"location":"Chap_4.html#problem-42","text":"Schr\u00f6dinger\u2019s cat is back in the box. This time he is accompanied by two atoms each of a different isotope. The first isotope, 11 Be, has a half-life of \\({t_{1/2}} = 13.81\\) s and its radioactive decay\u2014a stochastic process\u2014involves an electron \\(\\left( {{\\beta ^ - }} \\right)\\) emission. The second isotope, 10 C, has a half-life of \\({t_{1/2}} = 19.29\\) s and its radioactive decay involves a positron \\(\\left( {{\\beta ^ + }} \\right)\\) emission. Detectors inside the box can distinguish between these emitted particles. If the 11 Be atom emits an electron, then poison gas will be released and the cat will immediately die. If the 10 C isotope emits a positron, then the cat will be immediately released from the box and live. What is the probability that after 20 seconds the cat will be released and survive? Hint : The probability, \\(p(t),\\) that an atom will decay either through electron or positron emission in the interval \\(0 \\leqslant t \\leqslant T\\) seconds is given by: \\[P(0 \\leqslant t \\leqslant T) = 1 - {e^{ - T/\\tau }}\\] where \\(\\tau = {t_{1/2}}/\\ln 2.\\)","title":"Problem 4.2"},{"location":"Chap_4.html#problem-43","text":"Prove Equation 4.13 and Equation 4.15 .","title":"Problem 4.3"},{"location":"Chap_4.html#problem-44","text":"In Equation 4.13 , Equation 4.14 , and Equation 4.15 we presented three important properties of averaging. The consequences when applied to the calculation of means should be obvious. There are, however, other averages and in this problem we look at the variance of a random variable. Let \\(x\\) be a random variable that has both a mean \\({\\mu _x}\\) and a variance \\(\\sigma _x^2.\\) By this we mean that both \\({\\mu _x}\\) and \\(\\sigma _x^2\\) exist and are finite. The random variable \\(y\\) is related to \\(x\\) by \\(y = a\\,x + b\\) where \\(a\\) and \\(b\\) are deterministic\u2014not random\u2014variables (or constants). Determine the mean \\({\\mu _y}\\) and variance \\(\\sigma _y^2.\\) What does this mean? Explain in words the meaning of the result for variance in relation to \\(b.\\) How would this, for example, be reflected in a graph of the probability density function of \\(y\\) relative to \\(x?\\) If the coefficient-of-variation \\(C{V_x}\\) of the random variable \\(x\\) is given by \\(C{V_x} = {\\sigma _x}/{\\mu _x},\\) where \\({\\mu _x} \\ne 0,\\) determine \\(C{V_y}\\) in terms of the parameters given.","title":"Problem 4.4"},{"location":"Chap_4.html#problem-45","text":"Let \\(x[n]\\) be a sample from a random process \\(x\\) with an underlying probability distribution that is stationary. The mean of the process is \\({\\mu _x}\\) and the variance is \\(\\sigma _x^2.\\) The process \\(y\\) is formed by \\(y[n] = x[n]\\cos \\left( {\\Omega n} \\right).\\) What is the mean of process \\(y?\\) What is the variance of process \\(y?\\) Is process \\(y\\) stationary?","title":"Problem 4.5"},{"location":"Chap_4.html#problem-46","text":"Prove Equation 4.20 .","title":"Problem 4.6"},{"location":"Chap_4.html#problem-47","text":"We assume that when someone \u201cflips\u201d a coin that the \\(p(H) = p(T) = 1/2,\\) what we call a \u201cfair\u201d coin. But with practice one could in principle learn to alter these probabilities. Fast Eddie has been practicing and he is learning. After \\(m\\) practice sessions, his \\(p(H)\\) is given by: \\[p(H) = \\frac{1}{2}\\left( {2 - {{\\left( {\\frac{1}{2}} \\right)}^m}} \\right)\\] Every time Heads ( \\(H\\) ) comes up, Eddie pays out $1; every time Tails ( \\(T\\) ) comes up, Eddie receives $1. What is Eddie\u2019s expected result with no training, that is, \\(m = 0?\\) What is Eddie\u2019s expected result after \\(m = 10\\) training sessions? Is Eddie working with a stationary random process? Is Eddie \u201cplaying with a full deck\u201d, that is, is he a rational player?","title":"Problem 4.7"},{"location":"Chap_4.html#problem-48","text":"We are given a sample of an ergodic, continuous-time , white-noise random process, \\(x(t).\\) We want to use samples of this continuous-time process to drive (as input to) a discrete-time system. Discuss the following proposition and its consequences: \u201cThere does not exist a finite sampling frequency, \\({\\omega _s} = 2\\pi {f_s},\\) that satisfies the Nyquist sampling theorem for x(t).\u201d","title":"Problem 4.8"},{"location":"Chap_4.html#problem-49","text":"In many discussions of random variables we encounter a phrase such as \u201cwithout loss of generality we use the standardized (or normalized) random variable \\(z = \\left( {x - {\\mu _x}} \\right)/{\\sigma _x}\\) \u201d where \\({\\mu _x}\\) and \\({\\sigma _x}\\) are the mean and standard deviation, respectively, of the random variable \\(x.\\) Based upon what mathematical conditions is this statement justifiable? What are the mean \\({\\mu _z}\\) and the standard deviation \\({\\sigma _z}\\) of the random variable \\(z\\) if the conditions from part ( a ) have been satisfied? Why is the expression \u201cwithout loss of generality\u2026\u201d so frequently used?","title":"Problem 4.9"},{"location":"Chap_4.html#laboratory-exercises","text":"","title":"Laboratory Exercises"},{"location":"Chap_4.html#laboratory-exercise-41","text":"Flipping (tossing) a coin is a well-known way to describe the generation of random events. If the coin is \u201cfair\u201d then we expect just as many occurrences of \u201cHeads\u201d as \u201cTails\u201d. In this experiment we flip a coin N times with 1 \u2264 N \u2264 81 and a probability of Heads where 0 \u2264 p \u2264 1. The number of Heads n H and the number of Tails n T that result from N tosses of the coin will be displayed as a bar chart known as a histogram. You will also see a stochastic signal that is based upon your outcome and a lot of coins. To start the exercise, click on the icon to the left.","title":"Laboratory Exercise 4.1"},{"location":"Chap_4.html#laboratory-exercise-42","text":"An N \u00d7 N image consists of N 2 pixels. We can choose the grey-level brightness for each pixel from almost any distribution provided that the chosen value is real and non-negative. To start the exercise, click on the icon to the left. There are other definitions of a \u201cmean\u201d than just the arithmetic mean. These are discussed briefly here . \u21a9 Feynman, R. P., R. B. Leighton and M. Sands (1963). The Feynman Lectures on Physics: Mainly Mechanics, Radiation, and Heat. Reading, Massachusetts, Addison-Wesley, Vol. I \u21a9 Cram\u00e9r, H. (1946). Mathematical Methods of Statistics. Princeton, New Jersey, Princeton University Press \u21a9 For economy of notation, we will express \\({{p_{x[n]}}(x,n)}\\) (and similar forms) as \\(p(x[n])\\) . \u21a9 The sum formulation can be included within the integral formulation by describing the probability with the aid of impulse functions. In the die example, we would write the probability density function on the continuous variable \\(x\\) as \\(p(x) = \\sum\\limits_{i = 1}^6 {\\left( {\\frac{1}{6}} \\right)} \\,\\delta (x - i).\\) \u21a9 Porat, B. (1994). Digital Processing of Random Signals: Theory & Methods. Englewood Cliffs, New Jersey, Prentice-Hall \u21a9 Oppenheim, A. V., R. W. Schafer and J. R. Buck (1999). Discrete-Time Signal Processing. Upper Saddle River, New Jersey, Prentice-Hall, Section 2.10 \u21a9 The word ergodic originated in the 20th century to describe the mathematical concept of a system or process with the property that, given sufficient time, it \u201cvisits\u201d all points in a given space. Using the dictionary function of this iBook you can see the complete definition. \u21a9","title":"Laboratory Exercise 4.2"},{"location":"Chap_5.html","text":"Correlations and Spectra \u00b6 Let \\(x[n]\\) and \\(y[n]\\) be two ergodic random processes. As stated in Chapter 4 , this means that both processes are stationary. Correlations: simple and complex \u00b6 Based upon Equation 4.19 and Equation 4.21 , we have that the autocorrelation function of the random process \\(x\\) and the cross-correlation function between processes \\(x\\) and \\(y\\) are: (5.1) $$\\begin{array}{l} {\\varphi _{xx}}[k] = E\\left\\{ {x[n]{x^*}[n + k]} \\right\\}\\\\ {\\varphi _{xy}}[k] = E\\left\\{ {x[n]{y^*}[n + k]} \\right\\} \\end{array}$$ While \\(x\\) and \\(y\\) are random processes, the auto- and cross-correlation functions are just ordinary, deterministic (not random) functions of the variable \\(k.\\) Why is that? Because, like the mean \\(\\left( \\mu \\right)\\) and standard deviation \\(\\left( \\sigma \\right)\\) of familiar probability distributions, the correlations and covariances describe parameters\u2014characteristics\u2014of the probability distributions that generate random variables but are, themselves, not random. The auto- and cross-covariance functions are given by: (5.2) $$\\begin{array}{l} {\\gamma _{xx}}[k] = {\\varphi _{xx}}[k] - {\\left| {{m_x}} \\right|^2}\\\\ {\\gamma _{xy}}[k] = {\\varphi _{xy}}[k] - {m_x}m_y^* \\end{array}$$ By setting \\(k = 0,\\) we see that (5.3) $${\\varphi _{xx}}[0] = E\\left\\{ {{{\\left| {x[n]} \\right|}^2}} \\right\\} = mean{\\text -}square\\;of\\;process\\; \\ge 0$$ and (5.4) $${\\gamma _{xx}}[0] = \\sigma _x^2 \\ge 0$$ Further, we have: (5.5) $$\\begin{array}{l} {\\varphi _{xx}}[k] = \\varphi _{xx}^*[ - k]\\\\ {\\gamma _{xx}}[k] = \\gamma _{xx}^*[ - k] \\end{array}$$ (5.6) $$\\begin{array}{l} {\\varphi _{xy}}[k] = \\varphi _{yx}^*[ - k]\\\\ {\\gamma _{xy}}[k] = \\gamma _{yx}^*[ - k] \\end{array}$$ It is straightforward and, therefore, left to you to show in Problem 5.1 that Equation 5.5 and the second part of Equation 5.6 are correct. The proof of the first part of Equation 5.6 is given below. We start from the second part of Equation 5.1 and replace \\(n + k\\) with \\(m\\) : \\[\\begin{array}{*{20}{l}} {{\\varphi _{xy}}[k]}&{ = E\\left\\{ {x[n]\\,{y^*}[n + k]} \\right\\}\\mathop \\Rightarrow \\limits^{m = n + k} }\\\\ {}&\\begin{array}{l} = E\\left\\{ {x[m - k]\\,{y^*}[m]} \\right\\}\\\\ = {\\left( {E\\left\\{ {y[m]\\,{x^*}[m - k]} \\right\\}} \\right)^*} \\end{array}\\\\ {}&{ = \\varphi _{yx}^*[ - k]} \\end{array}\\] which proves the first part of Equation 5.6 . Example: Delayed effect \u00b6 As a simple example we consider the case where \\(y[n] = x[n - {n_o}],\\) a delayed version of \\(x[n].\\) Then: (5.7) $$\\begin{array}{*{20}{l}} {{\\varphi _{yy}}[k]}&{ = E\\left\\{ {y[n]\\,{y^*}[n + k]} \\right\\}}\\\\ {}&{ = E\\left\\{ {x[n - {n_0}]\\,{x^*}[n - {n_0} + k]} \\right\\}}\\\\ {}&{ = {\\varphi _{xx}}[k]} \\end{array}$$ What does this mean ? The conclusion associated with this example is that the autocorrelation of a time signal is independent of any time shift. Correlations and memory \u00b6 We would now like to consider what may happen to the correlation between \\(x[n]\\) and \\(x[n + k]\\) as \\(k\\) becomes larger. For many processes, as \\(k \\to \\infty ,\\) the value of the random signal at time \\(n\\) becomes less dependent upon the value at time \\(n + k.\\) A simple example might be that the weather today is similar to the weather yesterday but less similar to the weather of four weeks ago. As \\(k \\to \\infty ,\\) we have (5.8) $$\\begin{array}{l} \\mathop {\\lim }\\limits_{k \\to \\infty } \\left\\{ {{\\varphi _{xx}}[k] = E\\left\\{ {x[n]{x^*}[n + k]} \\right\\}} \\right\\}\\\\ \\,\\,\\,\\,\\,\\,\\,\\,\\,\\, = E\\left\\{ {x[n]} \\right\\}E\\left\\{ {{x^*}[n + k]} \\right\\} = {\\left| {{m_x}} \\right|^2} \\end{array}$$ This result frequently holds as well for the cross-correlation giving: (5.9) $$\\mathop {\\lim }\\limits_{k \\to \\infty } {\\varphi _{xy}}[k] = {m_x}m_y^*$$ Finally these two results may be used to show that for many important cases: (5.10) $$\\begin{array}{l} \\mathop {\\lim }\\limits_{k \\to \\infty } {\\gamma _{xx}}[k] = 0\\\\ \\mathop {\\lim }\\limits_{k \\to \\infty } {\\gamma _{xy}}[k] = 0 \\end{array}$$ As \\(k \\to \\infty ,\\) correlations and covariances can exhibit a form of memory loss, of forgetting their relation to earlier values. These results provide us with tools that can help us estimate the long term correlation and variation of one or more random processes. We have specifically stated \u201cmany processes\u201d but not \u201call processes\u201d. See Problem 5.2 to explore this. The mechanics of correlations - redux \u00b6 An issue that we have avoided until now is: how do we actually calculate the autocorrelation or cross-correlation of a random signal? According to Equation 4.24 , we need to know the joint probability distributions at two points \\(n\\) and \\(n + m.\\) Under the assumption of stationarity this reduces from \\(\\varphi [n,n + m]\\) to \\(\\varphi [m].\\) But given an actual random process such as air pressure, internet traffic, or radioactive emissions, we almost never know the joint probability distribution including the values of all of its parameters. Under the assumption of ergodicity, as described in Chapter 4 here and here , an alternative method is available to us. When considering the autocorrelation function, for example, instead of using Equation 4.24 we can use Equation 4.30 . Both of these equations are repeated below in Equation 5.11 and they illustrate that for ergodic processes ensemble averages can be exchanged for time averages. (5.11) $$\\begin{array}{*{20}{l}} {{\\varphi _{xx}}[k]}&{ = E\\left\\{ {x[n]\\,{x^*}[n + k]} \\right\\}}\\\\ {}&{ = \\; < x[n]\\,{x^*}[n + k] > }\\\\ {}&{ = \\mathop {\\lim }\\limits_{N \\to \\infty } \\frac{1}{{2N + 1}}\\sum\\limits_{n = - N}^{ + N} {x[n]\\,{x^*}[n + k]} } \\end{array}$$ Even with this reformulation there remains a problem. We never have an infinite amount of recorded data; \\(N\\) never goes to infinity. This brings us instead to Equation 4.34 where a finite amount of data is used to estimate a correlation function. This means that we can use the following formulation. (5.12) $$\\begin{array}{l} {\\varphi _{xx}}[k] = \\;\\frac{1}{{2N + 1}}\\sum\\limits_{n = - N}^{ + N} {x[n]\\,{x^*}[n + k]} \\\\ {\\varphi _{xy}}[k] = \\;\\frac{1}{{2N + 1}}\\sum\\limits_{n = - N}^{ + N} {x[n]\\,{y^*}[n + k]} \\end{array}$$ As the term \\(1/\\left( {2N + 1} \\right)\\) is only a scale factor\u2014albeit an important one when comparing estimates of correlation functions based upon data sets of different lengths\u2014we further simplify this to: (5.13) $$\\begin{array}{l} {\\varphi _{xx}}[k] = \\;\\sum\\limits_{n = - N}^{ + N} {x[n]\\,{x^*}[n + k]} \\\\ {\\varphi _{xy}}[k] = \\;\\sum\\limits_{n = - N}^{ + N} {x[n]\\,{y^*}[n + k]} \\end{array}$$ The formulas for calculating the autocorrelation and crosscorrelation of stochastic signals are now similar to the ones for deterministic signals Oppenheim 1 . To summarize, if the processes we are studying are ergodic, we use finite data sets to calculate correlation functions (and means and covariance functions). Papoulis 2 stated this in a most succinct way: \u201cx(t) is ergodic in the most general form if (with probability 1) all its statistics can be determined from a single function x(t,\u03b6) of the process.\u201d This, of course, holds for discrete-time ergodic processes as well. Fourier description of correlation functions \u00b6 We now look at the Fourier transform of the autocorrelation function for the complex ergodic random process \\(x[n].\\) We should remember that \\({\\varphi _{xx}}[k]\\) is not a random process. The Fourier transform of the autocorrelation function\u2014if it exists\u2014is called the power spectrum (or power density spectrum) of the random process. This name will be explained later. Existence of the Fourier transform is not a trivial matter. A random process \\(x[n]\\) might be ergodic but it need not be absolutely integrable, a condition for the existence of its Fourier spectrum; see Section 5.1.3 of Oppenheim 1 . The same holds for the autocorrelation function associated with \\(x[n].\\) A digression \u00b6 Ignoring the issue of convergence can lead to surprising results. Consider, for example, the deterministic signal given by: (5.14) $$x[n] = \\left( {1 - {{\\left( {\\frac{1}{2}} \\right)}^n}} \\right)u[n]$$ This signal is depicted in Figure 5.1 . Figure 5.1: A deterministic signal \\(x\\lbrack n\\rbrack\\) that starts at 0 and reaches an asymptotic value of 1. As mentioned before, the autocorrelation of a deterministic signal is defined by Oppenheim 1 : (5.15) $${\\varphi _{xx}}[k] = \\sum\\limits_{n = - \\infty }^{ + \\infty } {x[n]{x^*}[n + k]}$$ Substituting the specific signal Equation 5.14 into Equation 5.15 gives: (5.16) $${\\varphi _{xx}}[k] = \\sum\\limits_{n = - \\infty }^{ + \\infty } {\\left( {1 - {{\\left( {\\frac{1}{2}} \\right)}^n}} \\right)\\left( {1 - {{\\left( {\\frac{1}{2}} \\right)}^{n + k}}} \\right)u[n]u[n + k]}$$ The two step functions \\(u[n]\\) and \\(u[n + k]\\) both \u201cstart\u201d\u2014go from 0 to 1\u2014at some finite time and then remain at 1 as \\(n\\) increases. Their product starts at \\(\\max \\left( {0, - k} \\right).\\) If \\(k \\ge 0,\\) then the start time of the product is \\(n = 0.\\) If \\(k < 0,\\) then the start time of the product is \\(n = - k.\\) From Equation 5.5 we know that the autocorrelation of a signal, whether it is deterministic or stochastic, is an even function. This means we only have to evaluate Equation 5.16 for \\(k \\ge 0.\\) The rest will follow from the even symmetry. Multiplying the various terms in Equation 5.16 , the first of which yields \\(\\sum\\nolimits_n 1,\\) it should be obvious that this sum diverges. To study the behavior of Equation 5.16 we introduce a window function, \\(w[n]\\) : (5.17) $$w[n] = \\left\\{ {\\begin{array}{*{20}{c}} 1&{\\left| n \\right| \\le N}\\\\ 0&{\\left| n \\right| > N} \\end{array}} \\right.$$ such that \\(x[n]\\) is replaced by \\(x[n]\\,w[n].\\) Eventually we will let \\(N \\to \\infty.\\) The autocorrelation is then rewritten for \\(k \\ge 0\\) as: (5.18) $$\\begin{array}{l} {\\varphi _{xx}}[k] = \\sum\\limits_{n = - \\infty }^\\infty {\\left( {1 - {{\\left( {\\frac{1}{2}} \\right)}^n}} \\right)w[n]\\left( {1 - {{\\left( {\\frac{1}{2}} \\right)}^{n + k}}} \\right)} w[n + k]\\\\ \\,\\,\\,\\,\\,\\, = \\sum\\limits_{n = 0}^{N - k} {\\left( {1 - {{\\left( {\\frac{1}{2}} \\right)}^n}} \\right)\\left( {1 - {{\\left( {\\frac{1}{2}} \\right)}^{n + k}}} \\right)} \\end{array}$$ Notice how the limits on the sum have changed. Four terms are involved in this sum, the last three of which are \u201cwell-behaved\u201d; they converge as \\(N \\to \\infty.\\) The result including the even symmetry is: (5.19) $${\\varphi _{xx}}[k] = \\left( {\\mathop {\\lim }\\limits_{N \\to \\infty } N} \\right) - \\left| k \\right| - \\left( {\\frac{2}{3}} \\right){\\left( {\\frac{1}{2}} \\right)^{\\left| k \\right|}} - 1$$ The result is shown in Figure 5.2 . Figure 5.2: Autocorrelation function of \\(x[n\\rbrack\\) in Equation 5.14 plotted for \\(\\left| k \\right| \\le 10.\\) The value of \\({\\varphi _{xx}}[k = 0\\rbrack = N - 5/3\\) where \\(N\\) describes the width of window \\(w[n\\rbrack\\) . In this calculation \\(N = 20,000.\\) The seemingly simple deterministic signal \\(x[n]\\) \u2014a signal which is not a pathological oddity but, in fact, describes a variety of common, physical processes\u2014does not have a simple autocorrelation function. Why is this? In the time domain it is obvious from Figure 5.1 that \\(x[n]\\) is summable in neither the absolute sense ( L 1 \u2013norm) nor the quadratic sense ( L 2 \u2013norm). Thus the sum in Equation 5.16 is, formally, not possible. The Fourier transform of \\(x[n]\\) also provides insight into the problem. The spectrum \\(X\\left( \\Omega \\right)\\) is given by: (5.20) $$\\begin{array}{*{20}{l}} {X(\\Omega )}&{ = \\sum\\limits_{n = - \\infty }^{ + \\infty } {x[n]{e^{ - j\\Omega n}}} = \\sum\\limits_{n = - \\infty }^{ + \\infty } {\\left( {1 - {{\\left( {\\frac{1}{2}} \\right)}^n}} \\right)u[n]{e^{ - j\\Omega n}}} }\\\\ {}&{ = \\sum\\limits_{n = - \\infty }^{ + \\infty } {u[n]{e^{ - j\\Omega n}}} - \\sum\\limits_{n = - \\infty }^{ + \\infty } {{{\\left( {\\frac{1}{2}} \\right)}^n}u[n]{e^{ - j\\Omega n}}} }\\\\ {}&{ = {\\rm{ }}{\\mathscr{F}}\\left\\{ {u[n]} \\right\\} - \\sum\\limits_{n = 0}^{ + \\infty } {{{\\left( {\\frac{1}{2}} \\right)}^n}{e^{ - j\\Omega n}}} }\\\\ {}&{ = {\\rm{ }}{\\mathscr{F}}\\left\\{ {u[n]} \\right\\} - \\left( {\\frac{1}{{1 - \\frac{1}{2}{e^{ - j\\Omega }}}}} \\right)} \\end{array}$$ The difficulty originates in the first term, the Fourier transform of a unit step function. This transform is known Oppenheim 1 and Oppenheim 3 and is given in the baseband \\(- \\pi \\lt \\Omega \\le + \\pi\\) by: (5.21) $${\\mathscr{F}}\\left\\{ {u[n]} \\right\\} = \\left( {\\frac{1}{{1 - {e^{ - j\\Omega }}}}} \\right) + \\pi \\,\\delta (\\Omega )$$ This spectrum of a discrete-time signal is, of course, periodic and is specified in Equation 5.21 in the baseband frequency range, \\(- \\pi \\lt \\Omega \\le + \\pi.\\) Both terms in Equation 5.21 diverge for \\(\\Omega = 0\\) and the behavior of \\({\\left| {X(\\Omega )} \\right|^2}\\) \u2014whose relevance will be discussed later\u2014becomes intractable. This may all seem like \u201cmuch ado about nothing\u201d but that is not the case. We will make extensive use of the Fourier representation of stochastic signals as in the example in Chapter 5 and, as we shall see in Chapter 7 , the divergence \u201cproblem\u201d shown above may provide insights into the behavior of physical processes. The power density spectrum and its properties \u00b6 When the autocorrelation function exists, the power density spectrum is given by: (5.22) $${S_{xx}}(\\Omega ) = {\\mathscr{F}}\\left\\{ {{\\varphi _{xx}}[k]} \\right\\} = \\sum\\limits_{k = - \\infty }^{ + \\infty } {{\\varphi _{xx}}[k]{e^{ - j\\Omega k}}}$$ Standard Fourier theory gives the inverse transform as: (5.23) $${\\varphi _{xx}}[k] = {\\mathscr{F}^{ - 1}}\\left\\{ {{S_{xx}}(\\Omega )} \\right\\} = \\frac{1}{{2\\pi }}\\int\\limits_{ - \\pi }^{ + \\pi } {{S_{xx}}(\\Omega )} {e^{ + j\\Omega k}}d\\Omega$$ Note that \\({S_{xx}}(\\Omega )\\) does not require the convergence condition to perform the inverse transform in Equation 5.23 as it is periodic in the frequency domain and the integral involves the interval from \\(- \\pi\\) to \\(+ \\pi.\\) When the convergence conditions in the time-domain are satisfied then we can describe and use the Fourier transform pair \\(\\left\\{ {{\\varphi _{xx}}[k],{S_{xx}}(\\Omega )} \\right\\}\\) as shown in the Wiener-Khinchin theorem. If we now substitute Equation 5.13 into Equation 5.22 , the power density spectrum of the ergodic signal \\(x[n]\\) can be written as: (5.24) $$\\begin{array}{*{20}{l}} {{S_{xx}}(\\Omega )}&{ = \\sum\\limits_{k = - \\infty }^{ + \\infty } {{\\varphi _{xx}}[k]{e^{ - j\\Omega k}}} }\\\\ {}&{ = \\;\\sum\\limits_k {\\left( {\\sum\\limits_n {x[n]{x^*}[n + k]} } \\right)} {e^{ - j\\Omega k}}}\\\\ {}&{ = \\;\\sum\\limits_n {x[n]\\sum\\limits_k {{x^*}[n + k]{e^{ - j\\Omega k}}} } }\\\\ {}&{ = \\sum\\limits_n {x[n]{e^{j\\Omega n}}\\sum\\limits_m {{x^*}[m]{e^{ - j\\Omega m}}} } }\\\\ {}&{ = X( - \\Omega ){X^*}( - \\Omega ) = {{\\left| {X( - \\Omega )} \\right|}^2}} \\end{array}$$ Several remarks are appropriate. First, note the crucial interchange of the order of summation of \\(n\\) and \\(k\\) in the third line. The implicit assumption is that this is permitted because both sums converge. Second, notice that the power density spectrum is related to the Fourier transform of the finite length data record \\(x[n].\\) Third, we have assumed that \\(x[n]\\) is complex and we use the Fourier properties that if \\(X(\\Omega ) = {\\mathscr{F}}\\left\\{ {x[n]} \\right\\}\\) then: \\(X( - \\Omega )\\) is the Fourier transform of \\(x[ - n]\\) ; \\({X^*}( - \\Omega )\\) is the Fourier transform of \\({x^*}[n],\\) and; \\(X(\\Omega ){e^{j\\Omega k}}\\) is the Fourier transform of \\(x[n + k].\\) Finally, using property (a) above, we see that \\({\\mathscr{F}}\\left\\{ {{\\varphi _{xx}}[ - k]} \\right\\} = {\\left| {X(\\Omega )} \\right|^2}.\\) Note that because \\(x[n]\\) is complex, \\({\\mathscr{F}}\\left\\{ {{\\varphi _{xx}}[ - k]} \\right\\} \\ne {\\mathscr{F}}\\left\\{ {{\\varphi _{xx}}[k]} \\right\\}.\\) The auto-correlation function is not even but conjugate symmetric: \\({\\varphi _{xx}}[k] = \\varphi _{xx}^*[ - k].\\) See Equation 5.5 . Using several of the properties derived above plus properties of the Fourier transform we can show: 1. Because \\({\\varphi _{xx}}[0] = E\\left\\{ {{{\\left| {x[n]} \\right|}^2}} \\right\\} \\ge 0,\\) we have as a consequence of setting \\(k = 0\\) in Equation 5.23 : (5.25) $${\\varphi _{xx}}[0] = \\frac{1}{{2\\pi }}\\int\\limits_{ - \\pi }^{ + \\pi } {{S_{xx}}(\\Omega )} d\\Omega \\,\\,\\, \\ge \\,\\,\\,0$$ 2. From the conjugate-symmetry property of autocorrelation functions for complex signals presented in equation Equation 5.5 and the properties of the Fourier transform given above, we know that the power density spectrum \\({S_{xx}}(\\Omega )\\) must be real. Starting from \\({S_{xx}}(\\Omega ) = {\\mathscr{F}}\\left\\{ {{\\varphi _{xx}}[k]} \\right\\},\\) the proof is: (5.26) $$\\begin{array}{*{20}{l}} {S_{xx}^*( - \\Omega )}&{ = {\\mathscr{F}}\\{ \\varphi _{xx}^*[k]\\} }&{\\left( {property\\,b} \\right)}\\\\ {S_{xx}^*(\\Omega )}&{ = {\\mathscr{F}}\\{ \\varphi _{xx}^*[ - k]\\} }&{\\left( {property\\,a} \\right)}\\\\ {{\\varphi _{xx}}[k]}&{ = \\varphi _{xx}^*[ - k]}&{\\left( {Eq.\\,\\,5.5} \\right)}\\\\ \\downarrow &{\\,\\,\\,\\,\\, \\downarrow }&{}\\\\ {{S_{xx}}(\\Omega )}&{ = S_{xx}^*(\\Omega )}&{}\\\\ { \\Rightarrow {S_{xx}}(\\Omega )\\,\\,is\\,\\,real}&{}&{} \\end{array}$$ 3. If the random process \\(x[n]\\) is also real, then \\({\\varphi _{xx}}[k]\\) will be real and even meaning that \\({S_{xx}}(\\Omega )\\) will also be real and even. The proof of this last statement is considered in Problem 5.4 . We can also define a cross-power spectrum for two complex ergodic signals, \\(x[n]\\) and \\(y[n]\\) as: (5.27) $${S_{xy}}(\\Omega ) = {\\mathscr{F}}\\left\\{ {{\\varphi _{xy}}[k]} \\right\\} = \\sum\\limits_{k = - \\infty }^{ + \\infty } {{\\varphi _{xy}}[k]{e^{ - j\\Omega k}}}$$ and (5.28) $${\\varphi _{xy}}[k] = {\\mathscr{F}^{ - 1}}\\left\\{ {{S_{xy}}(\\Omega )} \\right\\} = \\frac{1}{{2\\pi }}\\int\\limits_{ - \\pi }^{ + \\pi } {{S_{xy}}(\\Omega )} {e^{ + j\\Omega k}}d\\Omega$$ Using the same steps as in Equation 5.24 we can show that the cross power spectral density is given by: (5.29) $$\\begin{array}{*{20}{l}} {{S_{xy}}(\\Omega )}&{ = \\sum\\limits_{k = - \\infty }^{ + \\infty } {{\\varphi _{xy}}[k]{e^{ - j\\Omega k}}} }\\\\ {}&{ = \\;\\sum\\limits_k {\\left( {\\sum\\limits_n {x[n]{y^*}[n + k]} } \\right)} {e^{ - j\\Omega k}}}\\\\ {}&{ = \\sum\\limits_n {x[n]{e^{j\\Omega n}}\\sum\\limits_m {{y^*}[m]{e^{ - j\\Omega m}}} } }\\\\ {}&{ = X( - \\Omega ){Y^*}( - \\Omega )} \\end{array}$$ We will make use of all of these definitions later when we discuss several applications. First, however, it is useful to look at several examples. In Chapter 6 we will then develop a description of how random signals are processed by linear, time-invariant (LTI) systems. Summarizing we have for complex signals: (5.30) $$\\begin{array}{*{20}{l}} {{S_{xx}}(\\Omega )}&{ = {{\\left| {X( - \\Omega )} \\right|}^2}}\\\\ {{S_{xy}}(\\Omega )}&{ = X( - \\Omega ){Y^*}( - \\Omega )} \\end{array}$$ and for real signals: (5.31) $$\\begin{array}{*{20}{l}} {{S_{xx}}(\\Omega )}&{ = {{\\left| {X(\\Omega )} \\right|}^2}}\\\\ {{S_{xy}}(\\Omega )}&{ = X(\\Omega ){Y^*}(\\Omega )} \\end{array}$$ Examples of power spectra \u00b6 Example: White noise \u00b6 Consider an autocorrelation function of the form (5.32) $${\\varphi _{xx}}[k] = I\\,\\delta [k]$$ The power spectrum is given by (5.33) $${S_{xx}}(\\Omega ) = {\\mathscr{F}}\\left\\{ {I\\,\\delta [k]} \\right\\} = I\\sum\\limits_{k = - \\infty }^{ + \\infty } {\\delta [k]{e^{ - j\\Omega k}}} = I$$ We see that the spectrum has the same amplitude for all frequencies; if we graph \\({S_{xx}}(\\Omega ) = I\\) versus \\(\\Omega,\\) it is \u201cflat\u201d. Because no particular frequency dominates the spectrum we say that the spectrum is \u201cwhite\u201d. This is the origin of the term white noise 4 . See Porat 5 and Oppenheim 6 . Example: Pink noise \u00b6 Let the autocorrelation function of a random process be given by: (5.34) $${\\varphi _{xx}}[k] = {\\left( {\\frac{1}{2}} \\right)^{\\left| k \\right|}}$$ The power spectrum is given by: (5.35) $$\\begin{array}{*{20}{l}} {{S_{xx}}(\\Omega )}&{ = \\sum\\limits_{k = - \\infty }^{ + \\infty } {{{\\left( {\\frac{1}{2}} \\right)}^{\\left| k \\right|}}{e^{ - j\\Omega k}}} }\\\\ {\\,\\,\\,}&{ = \\sum\\limits_{k = - \\infty }^0 {{{\\left( {\\frac{1}{2}} \\right)}^{ - k}}{e^{ - j\\Omega k}}} + \\sum\\limits_{k = 0}^{ + \\infty } {{{\\left( {\\frac{1}{2}} \\right)}^k}{e^{ - j\\Omega k}}} - 1}\\\\ {\\,\\,\\,}&{ = \\frac{3}{{5 - 4\\cos \\Omega }}} \\end{array}$$ This random process is not white as the spectrum is certainly not flat. We can use other properties we have developed to determine the average value \\({m_x}\\) and the mean-square \\(E\\left\\{ {{{\\left| {x[n]} \\right|}^2}} \\right\\}.\\) As \\(k \\to \\infty\\) we have from Equation 5.8 that \\({\\varphi _{xx}}[k] \\to {\\left| {{m_x}} \\right|^2}.\\) For this example \\({m_x} = 0\\) and the mean-square \\(E\\left\\{ {{{\\left| {x[n]} \\right|}^2}} \\right\\}\\) is given by \\({\\varphi _{xx}}[0] = 1.\\) The spectra from these two examples are illustrated in Figure 5.3 . ( a ) White noise spectrum ( b ) Pink noise spectrum Figure 5.3: Spectra of two noise processes. Note that we plot the spectra between \\(- \\pi \\lt \\Omega \\le + \\Omega\\) for the simple reason that the Fourier spectrum for any discrete time signal is periodic, that is, \\(X(\\Omega ) = X(\\Omega + 2\\pi ).\\) Thus it is sufficient to show or describe only one period. Predicting the natural climate - a case study \u00b6 We have developed a collection of powerful tools, in particular, the power density spectrum and the correlation function. Let us see how they can be used to gain insight into a well-known stochastic physical phenomenon, the weather. On the cover of this iBook we show three basic concepts that have been discussed until now: a stochastic signal, its correlation function, and its power spectral density. Let us now look at some real data to see what insights these tools can give us. We again use data from the Royal Netherlands Meteorological Institute ( KNMI ). We use their data concerning the average daily temperature and the average daily air pressure. We begin with the original data. For temperature, the data start at 1 January 1901 and we use the measurements until 31 December 2009. This consists of \\({N_T} = 39,812\\) days. For the air pressure, we use the data at the first available date which is 1 January 1902 and then (again) until 31 December 2009. This represents \\({N_P} = 39,447\\) days. The data are displayed in Figure 5.4 . Figure 5.4: ( top ) Average daily air temperature and ( bottom ) average daily air pressure measured at De Bilt, The Netherlands over a period exceeding 100 years. The power spectral densities, \\({S_{TT}}\\left( \\Omega \\right)\\) and \\({S_{PP}}\\left( \\Omega \\right),\\) for each of these stochastic signals, \\(T[n]\\) and \\(P[n],\\) can be computed using the techniques described above Equation 5.24 and in Chapter 12 . They are shown in Figure 5.5 . The resulting spectra reveal an interesting difference. The temperature spectrum, \\({S_{TT}}\\left( \\Omega \\right),\\) shows a clear spectral peak\u2014a significant amount of power\u2014at frequency \\({\\Omega _k} = k\\left( {2\\pi /{N_T}} \\right)\\) with \\(k = 109.\\) This translates to a period of \\({N_T}/k = 39812/109 = 365.248\\) days, a familiar value. The pressure spectrum, \\({S_{PP}}\\left( \\Omega \\right),\\) shows no such peak. Figure 5.5: The \\({\\log _{10}}\\left( \\bullet \\right)\\) of the power spectral densities for ( top ) air temperature \\({S_{TT}}\\left( \\Omega \\right)\\) and (bottom) air pressure \\({S_{PP}}\\left( \\Omega \\right).\\) The spectra are displayed for \\(0 \\lt \\Omega \\le \\pi /40.\\) Note the strong peak in \\({S_{TT}}\\left( \\Omega \\right).\\) The unit of \\(\\Omega\\) is \\(2\\pi /days.\\) The autocorrelation functions, \\({\\varphi _{TT}}[k]\\) and \\({\\varphi _{PP}}[k],\\) can also be computed. See Figure 5.6 . Due to the size of the data sets, we really do compute first the power spectral densities and then the autocorrelation functions as the computational efficiency of the FFT can then be exploited. (Can you estimate how much more efficient it is to use the \u201cFFT route\u201d to compute the autocorrelation function as opposed to a direct application of Equation 5.13 ?) The spectral peak identified in the power density spectrum is clearly reflected in the sinusoidal behavior of the autocorrelation function \\({\\varphi _{TT}}[k]\\) and the one year period is obvious. A weather period of one year in daily temperatures is hardly surprising. But being able to use yearly, stochastic variations in temperature to estimate the length of the solar year with high accuracy might be surprising. The value given above, 365.248 days is only 0.002% above the currently accepted value for the solar year of 365.242 days. What may also be surprising is the impulse-like autocorrelation function associated with air pressure, \\({\\varphi _{PP}}[k].\\) At the scale shown in Figure 5.6 , we have essentially \\({\\varphi _{PP}}[k] = A\\,\\delta [k].\\) There is virtually no month-to-month or year-to-year correlation in air pressure. If one is to be sought it should be at much shorter time scales than a one-month period. ( a ) Autocorrelation of temperature , ${\\varphi _{TT}}\\lbrack k\\rbrack,$ five year interval ( b ) Autocorrelation of temperature , ${\\varphi _{TT}}\\lbrack k\\rbrack,$ first ten weeks interval ( c ) Autocorrelation of pressure , ${\\varphi _{PP}}\\lbrack k\\rbrack,$ five year interval ( d ) Autocorrelation of pressure , ${\\varphi _{PP}}\\lbrack k\\rbrack,$ first three weeks interval Figure 5.6: Autocorrelation functions for temperature \\({\\varphi _{TT}}\\lbrack k\\rbrack\\) and pressure \\({\\varphi _{PP}}\\lbrack k\\rbrack\\) for the two stochastic signals \\(T[n\\rbrack\\) and \\(P[n\\rbrack.\\) On a shorter time scale we do see short-term correlations. The average daily air temperature correlation falls to 50% of its maximum value, see Figure 5.6b , after 49.4 days. Given four seasons each of about 91 days, this is about half a season. The average daily air pressure correlation, however, falls to 50% of its maximum value after only 3.4 days, half a week. Put another way, the average daily air pressure is correlated over a significantly shorter time scale than the average daily air temperature. We emphasize through these examples that correlation functions and spectral densities are tools and that they can be useful in understanding the structure of complex data. Problems \u00b6 Problem 5.1 \u00b6 Prove Equation 5.5 and the second part of Equation 5.6 . Problem 5.2 \u00b6 In the text we state: For many processes, as \\(k \\to \\infty,\\) the value of the random signal at time \\(n\\) becomes less dependent upon the value at time \\(n + k.\\) Describe a common, random process that would not have this property. Based upon this example, for what class of random processes would you expect that \\(\\mathop {\\lim }\\limits_{x \\to \\infty } \\,{\\gamma _{xx}}[k] \\ne 0?\\) Problem 5.3 \u00b6 Consider the following statement: For the ergodic random process with a mean \\({m_x}\\) and a variance \\(\\sigma _x^2,\\) we have: (5.36) $$\\sigma _x^2 = {\\varphi _{xx}}[k = 0] - {\\varphi _{xx}}[k = \\infty ]$$ Discuss the applicability of this statement. When is it valid and when can its use lead to problems? Problem 5.4 \u00b6 Show that if \\(x[n]\\) is a real, ergodic process then its autocorrelation function \\({\\varphi _{xx}}[k]\\) will be real and even. Show that if \\({\\varphi _{xx}}[k]\\) is real and even then \\({S_{xx}}(\\Omega )\\) will also be real and even. Problem 5.5 \u00b6 The cross-correlation, \\({\\varphi _{xy}}[k],\\) between two real, deterministic signals, \\(x[n]\\) and \\(y[n],\\) is given by: \\[{\\varphi _{xy}}[k] = \\sum\\limits_{n = - \\infty }^{ + \\infty } {x[n]\\,{y^*}[n + k] = } \\sum\\limits_{n = - \\infty }^{ + \\infty } {x[n]\\,y[n + k]}\\] Is the cross-correlation function \\({\\varphi _{xy}}[k]\\) even? That is, does \\({\\varphi _{xy}}[k] = {\\varphi _{xy}}[ - k]?\\) Explain your answer. Determine a general expression for \\({S_{xy}}(\\Omega ) = {\\mathscr{F}}\\left\\{ {{\\varphi _{xy}}[k]} \\right\\}\\) in terms of \\(X(\\Omega )\\) and \\(Y(\\Omega ).\\) Determine and sketch \\({\\varphi _{xy}}[k]\\) if \\(x[n] = {a^n}u[n]\\) where \\(\\left| a \\right| < 1\\) and \\(y[n] = u[n - 2].\\) Problem 5.6 \u00b6 The following statement was found in an old textbook: Let \\({\\varphi _{xx}}[k]\\) be the autocorrelation function of an ergodic process and \\({S_{xx}}(f)\\) its power density spectrum where \\(\\Omega = 2\\pi f.\\) Then the following relations hold: \\[\\begin{array}{l} {S_{xx}}(f) = {\\varphi _{xx}}[0] + 2\\sum\\limits_{k = 1}^{ + \\infty } {{\\varphi _{xx}}[k]\\cos \\left( {2\\pi fk} \\right)} \\\\ {\\varphi _{xx}}[k] = 2\\int\\limits_0^{ + \\pi } {{S_{xx}}(f)} \\cos \\left( {2\\pi fk} \\right)df \\end{array}\\] Under what circumstances are these two relations correct? Explain your reasoning. Laboratory Exercises \u00b6 Laboratory Exercise 5.1 \u00b6 We review your understanding of the difference between convolution and correlation. To start the exercise, click on the icon to the left. Oppenheim, A. V., A. S. Willsky and S. H. Nawab (1996). Signals and Systems. Upper Saddle River, New Jersey, Prentice-Hall \u21a9 \u21a9 \u21a9 \u21a9 Papoulis, A. (1965). Probability, Random Variables, and Stochastic Processes. New York, McGraw-Hill, p. 327 \u21a9 Oppenheim, A. V., R. W. Schafer and J. R. Buck (1999). Discrete-Time Signal Processing. Upper Saddle River, New Jersey, Prentice-Hall, Section 2.9 \u21a9 Actually there are some semantic issues here because white usually refers to color. If an object has a flat spectrum over the wavelength range 400 nm \u2264 \\(\\lambda\\) \u2264 750 nm, we refer to its color as white as perceived by the average observer. Frequency and wavelength are related, however, by \\(f = c/\\lambda.\\) If the spectrum described in wavelength is flat then the frequency spectrum is not flat. The use of the term \u201cwhite noise\u201d is thus one of convention (or convenience) as opposed to color \u21a9 Porat, B. (1994). Digital Processing of Random Signals: Theory & Methods. Englewood Cliffs, New Jersey, Prentice-Hall, Section 2.5 \u21a9 Oppenheim, A. V., R. W. Schafer and J. R. Buck (1999). Discrete-Time Signal Processing. Upper Saddle River, New Jersey, Prentice-Hall, Section 2.10 \u21a9","title":"5. Correlations and Spectra"},{"location":"Chap_5.html#correlations-and-spectra","text":"Let \\(x[n]\\) and \\(y[n]\\) be two ergodic random processes. As stated in Chapter 4 , this means that both processes are stationary.","title":"Correlations and Spectra"},{"location":"Chap_5.html#correlations-simple-and-complex","text":"Based upon Equation 4.19 and Equation 4.21 , we have that the autocorrelation function of the random process \\(x\\) and the cross-correlation function between processes \\(x\\) and \\(y\\) are: (5.1) $$\\begin{array}{l} {\\varphi _{xx}}[k] = E\\left\\{ {x[n]{x^*}[n + k]} \\right\\}\\\\ {\\varphi _{xy}}[k] = E\\left\\{ {x[n]{y^*}[n + k]} \\right\\} \\end{array}$$ While \\(x\\) and \\(y\\) are random processes, the auto- and cross-correlation functions are just ordinary, deterministic (not random) functions of the variable \\(k.\\) Why is that? Because, like the mean \\(\\left( \\mu \\right)\\) and standard deviation \\(\\left( \\sigma \\right)\\) of familiar probability distributions, the correlations and covariances describe parameters\u2014characteristics\u2014of the probability distributions that generate random variables but are, themselves, not random. The auto- and cross-covariance functions are given by: (5.2) $$\\begin{array}{l} {\\gamma _{xx}}[k] = {\\varphi _{xx}}[k] - {\\left| {{m_x}} \\right|^2}\\\\ {\\gamma _{xy}}[k] = {\\varphi _{xy}}[k] - {m_x}m_y^* \\end{array}$$ By setting \\(k = 0,\\) we see that (5.3) $${\\varphi _{xx}}[0] = E\\left\\{ {{{\\left| {x[n]} \\right|}^2}} \\right\\} = mean{\\text -}square\\;of\\;process\\; \\ge 0$$ and (5.4) $${\\gamma _{xx}}[0] = \\sigma _x^2 \\ge 0$$ Further, we have: (5.5) $$\\begin{array}{l} {\\varphi _{xx}}[k] = \\varphi _{xx}^*[ - k]\\\\ {\\gamma _{xx}}[k] = \\gamma _{xx}^*[ - k] \\end{array}$$ (5.6) $$\\begin{array}{l} {\\varphi _{xy}}[k] = \\varphi _{yx}^*[ - k]\\\\ {\\gamma _{xy}}[k] = \\gamma _{yx}^*[ - k] \\end{array}$$ It is straightforward and, therefore, left to you to show in Problem 5.1 that Equation 5.5 and the second part of Equation 5.6 are correct. The proof of the first part of Equation 5.6 is given below. We start from the second part of Equation 5.1 and replace \\(n + k\\) with \\(m\\) : \\[\\begin{array}{*{20}{l}} {{\\varphi _{xy}}[k]}&{ = E\\left\\{ {x[n]\\,{y^*}[n + k]} \\right\\}\\mathop \\Rightarrow \\limits^{m = n + k} }\\\\ {}&\\begin{array}{l} = E\\left\\{ {x[m - k]\\,{y^*}[m]} \\right\\}\\\\ = {\\left( {E\\left\\{ {y[m]\\,{x^*}[m - k]} \\right\\}} \\right)^*} \\end{array}\\\\ {}&{ = \\varphi _{yx}^*[ - k]} \\end{array}\\] which proves the first part of Equation 5.6 .","title":"Correlations: simple and complex"},{"location":"Chap_5.html#example-delayed-effect","text":"As a simple example we consider the case where \\(y[n] = x[n - {n_o}],\\) a delayed version of \\(x[n].\\) Then: (5.7) $$\\begin{array}{*{20}{l}} {{\\varphi _{yy}}[k]}&{ = E\\left\\{ {y[n]\\,{y^*}[n + k]} \\right\\}}\\\\ {}&{ = E\\left\\{ {x[n - {n_0}]\\,{x^*}[n - {n_0} + k]} \\right\\}}\\\\ {}&{ = {\\varphi _{xx}}[k]} \\end{array}$$ What does this mean ? The conclusion associated with this example is that the autocorrelation of a time signal is independent of any time shift.","title":"Example: Delayed effect"},{"location":"Chap_5.html#correlations-and-memory","text":"We would now like to consider what may happen to the correlation between \\(x[n]\\) and \\(x[n + k]\\) as \\(k\\) becomes larger. For many processes, as \\(k \\to \\infty ,\\) the value of the random signal at time \\(n\\) becomes less dependent upon the value at time \\(n + k.\\) A simple example might be that the weather today is similar to the weather yesterday but less similar to the weather of four weeks ago. As \\(k \\to \\infty ,\\) we have (5.8) $$\\begin{array}{l} \\mathop {\\lim }\\limits_{k \\to \\infty } \\left\\{ {{\\varphi _{xx}}[k] = E\\left\\{ {x[n]{x^*}[n + k]} \\right\\}} \\right\\}\\\\ \\,\\,\\,\\,\\,\\,\\,\\,\\,\\, = E\\left\\{ {x[n]} \\right\\}E\\left\\{ {{x^*}[n + k]} \\right\\} = {\\left| {{m_x}} \\right|^2} \\end{array}$$ This result frequently holds as well for the cross-correlation giving: (5.9) $$\\mathop {\\lim }\\limits_{k \\to \\infty } {\\varphi _{xy}}[k] = {m_x}m_y^*$$ Finally these two results may be used to show that for many important cases: (5.10) $$\\begin{array}{l} \\mathop {\\lim }\\limits_{k \\to \\infty } {\\gamma _{xx}}[k] = 0\\\\ \\mathop {\\lim }\\limits_{k \\to \\infty } {\\gamma _{xy}}[k] = 0 \\end{array}$$ As \\(k \\to \\infty ,\\) correlations and covariances can exhibit a form of memory loss, of forgetting their relation to earlier values. These results provide us with tools that can help us estimate the long term correlation and variation of one or more random processes. We have specifically stated \u201cmany processes\u201d but not \u201call processes\u201d. See Problem 5.2 to explore this.","title":"Correlations and memory"},{"location":"Chap_5.html#the-mechanics-of-correlations-redux","text":"An issue that we have avoided until now is: how do we actually calculate the autocorrelation or cross-correlation of a random signal? According to Equation 4.24 , we need to know the joint probability distributions at two points \\(n\\) and \\(n + m.\\) Under the assumption of stationarity this reduces from \\(\\varphi [n,n + m]\\) to \\(\\varphi [m].\\) But given an actual random process such as air pressure, internet traffic, or radioactive emissions, we almost never know the joint probability distribution including the values of all of its parameters. Under the assumption of ergodicity, as described in Chapter 4 here and here , an alternative method is available to us. When considering the autocorrelation function, for example, instead of using Equation 4.24 we can use Equation 4.30 . Both of these equations are repeated below in Equation 5.11 and they illustrate that for ergodic processes ensemble averages can be exchanged for time averages. (5.11) $$\\begin{array}{*{20}{l}} {{\\varphi _{xx}}[k]}&{ = E\\left\\{ {x[n]\\,{x^*}[n + k]} \\right\\}}\\\\ {}&{ = \\; < x[n]\\,{x^*}[n + k] > }\\\\ {}&{ = \\mathop {\\lim }\\limits_{N \\to \\infty } \\frac{1}{{2N + 1}}\\sum\\limits_{n = - N}^{ + N} {x[n]\\,{x^*}[n + k]} } \\end{array}$$ Even with this reformulation there remains a problem. We never have an infinite amount of recorded data; \\(N\\) never goes to infinity. This brings us instead to Equation 4.34 where a finite amount of data is used to estimate a correlation function. This means that we can use the following formulation. (5.12) $$\\begin{array}{l} {\\varphi _{xx}}[k] = \\;\\frac{1}{{2N + 1}}\\sum\\limits_{n = - N}^{ + N} {x[n]\\,{x^*}[n + k]} \\\\ {\\varphi _{xy}}[k] = \\;\\frac{1}{{2N + 1}}\\sum\\limits_{n = - N}^{ + N} {x[n]\\,{y^*}[n + k]} \\end{array}$$ As the term \\(1/\\left( {2N + 1} \\right)\\) is only a scale factor\u2014albeit an important one when comparing estimates of correlation functions based upon data sets of different lengths\u2014we further simplify this to: (5.13) $$\\begin{array}{l} {\\varphi _{xx}}[k] = \\;\\sum\\limits_{n = - N}^{ + N} {x[n]\\,{x^*}[n + k]} \\\\ {\\varphi _{xy}}[k] = \\;\\sum\\limits_{n = - N}^{ + N} {x[n]\\,{y^*}[n + k]} \\end{array}$$ The formulas for calculating the autocorrelation and crosscorrelation of stochastic signals are now similar to the ones for deterministic signals Oppenheim 1 . To summarize, if the processes we are studying are ergodic, we use finite data sets to calculate correlation functions (and means and covariance functions). Papoulis 2 stated this in a most succinct way: \u201cx(t) is ergodic in the most general form if (with probability 1) all its statistics can be determined from a single function x(t,\u03b6) of the process.\u201d This, of course, holds for discrete-time ergodic processes as well.","title":"The mechanics of correlations - redux"},{"location":"Chap_5.html#fourier-description-of-correlation-functions","text":"We now look at the Fourier transform of the autocorrelation function for the complex ergodic random process \\(x[n].\\) We should remember that \\({\\varphi _{xx}}[k]\\) is not a random process. The Fourier transform of the autocorrelation function\u2014if it exists\u2014is called the power spectrum (or power density spectrum) of the random process. This name will be explained later. Existence of the Fourier transform is not a trivial matter. A random process \\(x[n]\\) might be ergodic but it need not be absolutely integrable, a condition for the existence of its Fourier spectrum; see Section 5.1.3 of Oppenheim 1 . The same holds for the autocorrelation function associated with \\(x[n].\\)","title":"Fourier description of correlation functions"},{"location":"Chap_5.html#a-digression","text":"Ignoring the issue of convergence can lead to surprising results. Consider, for example, the deterministic signal given by: (5.14) $$x[n] = \\left( {1 - {{\\left( {\\frac{1}{2}} \\right)}^n}} \\right)u[n]$$ This signal is depicted in Figure 5.1 . Figure 5.1: A deterministic signal \\(x\\lbrack n\\rbrack\\) that starts at 0 and reaches an asymptotic value of 1. As mentioned before, the autocorrelation of a deterministic signal is defined by Oppenheim 1 : (5.15) $${\\varphi _{xx}}[k] = \\sum\\limits_{n = - \\infty }^{ + \\infty } {x[n]{x^*}[n + k]}$$ Substituting the specific signal Equation 5.14 into Equation 5.15 gives: (5.16) $${\\varphi _{xx}}[k] = \\sum\\limits_{n = - \\infty }^{ + \\infty } {\\left( {1 - {{\\left( {\\frac{1}{2}} \\right)}^n}} \\right)\\left( {1 - {{\\left( {\\frac{1}{2}} \\right)}^{n + k}}} \\right)u[n]u[n + k]}$$ The two step functions \\(u[n]\\) and \\(u[n + k]\\) both \u201cstart\u201d\u2014go from 0 to 1\u2014at some finite time and then remain at 1 as \\(n\\) increases. Their product starts at \\(\\max \\left( {0, - k} \\right).\\) If \\(k \\ge 0,\\) then the start time of the product is \\(n = 0.\\) If \\(k < 0,\\) then the start time of the product is \\(n = - k.\\) From Equation 5.5 we know that the autocorrelation of a signal, whether it is deterministic or stochastic, is an even function. This means we only have to evaluate Equation 5.16 for \\(k \\ge 0.\\) The rest will follow from the even symmetry. Multiplying the various terms in Equation 5.16 , the first of which yields \\(\\sum\\nolimits_n 1,\\) it should be obvious that this sum diverges. To study the behavior of Equation 5.16 we introduce a window function, \\(w[n]\\) : (5.17) $$w[n] = \\left\\{ {\\begin{array}{*{20}{c}} 1&{\\left| n \\right| \\le N}\\\\ 0&{\\left| n \\right| > N} \\end{array}} \\right.$$ such that \\(x[n]\\) is replaced by \\(x[n]\\,w[n].\\) Eventually we will let \\(N \\to \\infty.\\) The autocorrelation is then rewritten for \\(k \\ge 0\\) as: (5.18) $$\\begin{array}{l} {\\varphi _{xx}}[k] = \\sum\\limits_{n = - \\infty }^\\infty {\\left( {1 - {{\\left( {\\frac{1}{2}} \\right)}^n}} \\right)w[n]\\left( {1 - {{\\left( {\\frac{1}{2}} \\right)}^{n + k}}} \\right)} w[n + k]\\\\ \\,\\,\\,\\,\\,\\, = \\sum\\limits_{n = 0}^{N - k} {\\left( {1 - {{\\left( {\\frac{1}{2}} \\right)}^n}} \\right)\\left( {1 - {{\\left( {\\frac{1}{2}} \\right)}^{n + k}}} \\right)} \\end{array}$$ Notice how the limits on the sum have changed. Four terms are involved in this sum, the last three of which are \u201cwell-behaved\u201d; they converge as \\(N \\to \\infty.\\) The result including the even symmetry is: (5.19) $${\\varphi _{xx}}[k] = \\left( {\\mathop {\\lim }\\limits_{N \\to \\infty } N} \\right) - \\left| k \\right| - \\left( {\\frac{2}{3}} \\right){\\left( {\\frac{1}{2}} \\right)^{\\left| k \\right|}} - 1$$ The result is shown in Figure 5.2 . Figure 5.2: Autocorrelation function of \\(x[n\\rbrack\\) in Equation 5.14 plotted for \\(\\left| k \\right| \\le 10.\\) The value of \\({\\varphi _{xx}}[k = 0\\rbrack = N - 5/3\\) where \\(N\\) describes the width of window \\(w[n\\rbrack\\) . In this calculation \\(N = 20,000.\\) The seemingly simple deterministic signal \\(x[n]\\) \u2014a signal which is not a pathological oddity but, in fact, describes a variety of common, physical processes\u2014does not have a simple autocorrelation function. Why is this? In the time domain it is obvious from Figure 5.1 that \\(x[n]\\) is summable in neither the absolute sense ( L 1 \u2013norm) nor the quadratic sense ( L 2 \u2013norm). Thus the sum in Equation 5.16 is, formally, not possible. The Fourier transform of \\(x[n]\\) also provides insight into the problem. The spectrum \\(X\\left( \\Omega \\right)\\) is given by: (5.20) $$\\begin{array}{*{20}{l}} {X(\\Omega )}&{ = \\sum\\limits_{n = - \\infty }^{ + \\infty } {x[n]{e^{ - j\\Omega n}}} = \\sum\\limits_{n = - \\infty }^{ + \\infty } {\\left( {1 - {{\\left( {\\frac{1}{2}} \\right)}^n}} \\right)u[n]{e^{ - j\\Omega n}}} }\\\\ {}&{ = \\sum\\limits_{n = - \\infty }^{ + \\infty } {u[n]{e^{ - j\\Omega n}}} - \\sum\\limits_{n = - \\infty }^{ + \\infty } {{{\\left( {\\frac{1}{2}} \\right)}^n}u[n]{e^{ - j\\Omega n}}} }\\\\ {}&{ = {\\rm{ }}{\\mathscr{F}}\\left\\{ {u[n]} \\right\\} - \\sum\\limits_{n = 0}^{ + \\infty } {{{\\left( {\\frac{1}{2}} \\right)}^n}{e^{ - j\\Omega n}}} }\\\\ {}&{ = {\\rm{ }}{\\mathscr{F}}\\left\\{ {u[n]} \\right\\} - \\left( {\\frac{1}{{1 - \\frac{1}{2}{e^{ - j\\Omega }}}}} \\right)} \\end{array}$$ The difficulty originates in the first term, the Fourier transform of a unit step function. This transform is known Oppenheim 1 and Oppenheim 3 and is given in the baseband \\(- \\pi \\lt \\Omega \\le + \\pi\\) by: (5.21) $${\\mathscr{F}}\\left\\{ {u[n]} \\right\\} = \\left( {\\frac{1}{{1 - {e^{ - j\\Omega }}}}} \\right) + \\pi \\,\\delta (\\Omega )$$ This spectrum of a discrete-time signal is, of course, periodic and is specified in Equation 5.21 in the baseband frequency range, \\(- \\pi \\lt \\Omega \\le + \\pi.\\) Both terms in Equation 5.21 diverge for \\(\\Omega = 0\\) and the behavior of \\({\\left| {X(\\Omega )} \\right|^2}\\) \u2014whose relevance will be discussed later\u2014becomes intractable. This may all seem like \u201cmuch ado about nothing\u201d but that is not the case. We will make extensive use of the Fourier representation of stochastic signals as in the example in Chapter 5 and, as we shall see in Chapter 7 , the divergence \u201cproblem\u201d shown above may provide insights into the behavior of physical processes.","title":"A digression"},{"location":"Chap_5.html#the-power-density-spectrum-and-its-properties","text":"When the autocorrelation function exists, the power density spectrum is given by: (5.22) $${S_{xx}}(\\Omega ) = {\\mathscr{F}}\\left\\{ {{\\varphi _{xx}}[k]} \\right\\} = \\sum\\limits_{k = - \\infty }^{ + \\infty } {{\\varphi _{xx}}[k]{e^{ - j\\Omega k}}}$$ Standard Fourier theory gives the inverse transform as: (5.23) $${\\varphi _{xx}}[k] = {\\mathscr{F}^{ - 1}}\\left\\{ {{S_{xx}}(\\Omega )} \\right\\} = \\frac{1}{{2\\pi }}\\int\\limits_{ - \\pi }^{ + \\pi } {{S_{xx}}(\\Omega )} {e^{ + j\\Omega k}}d\\Omega$$ Note that \\({S_{xx}}(\\Omega )\\) does not require the convergence condition to perform the inverse transform in Equation 5.23 as it is periodic in the frequency domain and the integral involves the interval from \\(- \\pi\\) to \\(+ \\pi.\\) When the convergence conditions in the time-domain are satisfied then we can describe and use the Fourier transform pair \\(\\left\\{ {{\\varphi _{xx}}[k],{S_{xx}}(\\Omega )} \\right\\}\\) as shown in the Wiener-Khinchin theorem. If we now substitute Equation 5.13 into Equation 5.22 , the power density spectrum of the ergodic signal \\(x[n]\\) can be written as: (5.24) $$\\begin{array}{*{20}{l}} {{S_{xx}}(\\Omega )}&{ = \\sum\\limits_{k = - \\infty }^{ + \\infty } {{\\varphi _{xx}}[k]{e^{ - j\\Omega k}}} }\\\\ {}&{ = \\;\\sum\\limits_k {\\left( {\\sum\\limits_n {x[n]{x^*}[n + k]} } \\right)} {e^{ - j\\Omega k}}}\\\\ {}&{ = \\;\\sum\\limits_n {x[n]\\sum\\limits_k {{x^*}[n + k]{e^{ - j\\Omega k}}} } }\\\\ {}&{ = \\sum\\limits_n {x[n]{e^{j\\Omega n}}\\sum\\limits_m {{x^*}[m]{e^{ - j\\Omega m}}} } }\\\\ {}&{ = X( - \\Omega ){X^*}( - \\Omega ) = {{\\left| {X( - \\Omega )} \\right|}^2}} \\end{array}$$ Several remarks are appropriate. First, note the crucial interchange of the order of summation of \\(n\\) and \\(k\\) in the third line. The implicit assumption is that this is permitted because both sums converge. Second, notice that the power density spectrum is related to the Fourier transform of the finite length data record \\(x[n].\\) Third, we have assumed that \\(x[n]\\) is complex and we use the Fourier properties that if \\(X(\\Omega ) = {\\mathscr{F}}\\left\\{ {x[n]} \\right\\}\\) then: \\(X( - \\Omega )\\) is the Fourier transform of \\(x[ - n]\\) ; \\({X^*}( - \\Omega )\\) is the Fourier transform of \\({x^*}[n],\\) and; \\(X(\\Omega ){e^{j\\Omega k}}\\) is the Fourier transform of \\(x[n + k].\\) Finally, using property (a) above, we see that \\({\\mathscr{F}}\\left\\{ {{\\varphi _{xx}}[ - k]} \\right\\} = {\\left| {X(\\Omega )} \\right|^2}.\\) Note that because \\(x[n]\\) is complex, \\({\\mathscr{F}}\\left\\{ {{\\varphi _{xx}}[ - k]} \\right\\} \\ne {\\mathscr{F}}\\left\\{ {{\\varphi _{xx}}[k]} \\right\\}.\\) The auto-correlation function is not even but conjugate symmetric: \\({\\varphi _{xx}}[k] = \\varphi _{xx}^*[ - k].\\) See Equation 5.5 . Using several of the properties derived above plus properties of the Fourier transform we can show: 1. Because \\({\\varphi _{xx}}[0] = E\\left\\{ {{{\\left| {x[n]} \\right|}^2}} \\right\\} \\ge 0,\\) we have as a consequence of setting \\(k = 0\\) in Equation 5.23 : (5.25) $${\\varphi _{xx}}[0] = \\frac{1}{{2\\pi }}\\int\\limits_{ - \\pi }^{ + \\pi } {{S_{xx}}(\\Omega )} d\\Omega \\,\\,\\, \\ge \\,\\,\\,0$$ 2. From the conjugate-symmetry property of autocorrelation functions for complex signals presented in equation Equation 5.5 and the properties of the Fourier transform given above, we know that the power density spectrum \\({S_{xx}}(\\Omega )\\) must be real. Starting from \\({S_{xx}}(\\Omega ) = {\\mathscr{F}}\\left\\{ {{\\varphi _{xx}}[k]} \\right\\},\\) the proof is: (5.26) $$\\begin{array}{*{20}{l}} {S_{xx}^*( - \\Omega )}&{ = {\\mathscr{F}}\\{ \\varphi _{xx}^*[k]\\} }&{\\left( {property\\,b} \\right)}\\\\ {S_{xx}^*(\\Omega )}&{ = {\\mathscr{F}}\\{ \\varphi _{xx}^*[ - k]\\} }&{\\left( {property\\,a} \\right)}\\\\ {{\\varphi _{xx}}[k]}&{ = \\varphi _{xx}^*[ - k]}&{\\left( {Eq.\\,\\,5.5} \\right)}\\\\ \\downarrow &{\\,\\,\\,\\,\\, \\downarrow }&{}\\\\ {{S_{xx}}(\\Omega )}&{ = S_{xx}^*(\\Omega )}&{}\\\\ { \\Rightarrow {S_{xx}}(\\Omega )\\,\\,is\\,\\,real}&{}&{} \\end{array}$$ 3. If the random process \\(x[n]\\) is also real, then \\({\\varphi _{xx}}[k]\\) will be real and even meaning that \\({S_{xx}}(\\Omega )\\) will also be real and even. The proof of this last statement is considered in Problem 5.4 . We can also define a cross-power spectrum for two complex ergodic signals, \\(x[n]\\) and \\(y[n]\\) as: (5.27) $${S_{xy}}(\\Omega ) = {\\mathscr{F}}\\left\\{ {{\\varphi _{xy}}[k]} \\right\\} = \\sum\\limits_{k = - \\infty }^{ + \\infty } {{\\varphi _{xy}}[k]{e^{ - j\\Omega k}}}$$ and (5.28) $${\\varphi _{xy}}[k] = {\\mathscr{F}^{ - 1}}\\left\\{ {{S_{xy}}(\\Omega )} \\right\\} = \\frac{1}{{2\\pi }}\\int\\limits_{ - \\pi }^{ + \\pi } {{S_{xy}}(\\Omega )} {e^{ + j\\Omega k}}d\\Omega$$ Using the same steps as in Equation 5.24 we can show that the cross power spectral density is given by: (5.29) $$\\begin{array}{*{20}{l}} {{S_{xy}}(\\Omega )}&{ = \\sum\\limits_{k = - \\infty }^{ + \\infty } {{\\varphi _{xy}}[k]{e^{ - j\\Omega k}}} }\\\\ {}&{ = \\;\\sum\\limits_k {\\left( {\\sum\\limits_n {x[n]{y^*}[n + k]} } \\right)} {e^{ - j\\Omega k}}}\\\\ {}&{ = \\sum\\limits_n {x[n]{e^{j\\Omega n}}\\sum\\limits_m {{y^*}[m]{e^{ - j\\Omega m}}} } }\\\\ {}&{ = X( - \\Omega ){Y^*}( - \\Omega )} \\end{array}$$ We will make use of all of these definitions later when we discuss several applications. First, however, it is useful to look at several examples. In Chapter 6 we will then develop a description of how random signals are processed by linear, time-invariant (LTI) systems. Summarizing we have for complex signals: (5.30) $$\\begin{array}{*{20}{l}} {{S_{xx}}(\\Omega )}&{ = {{\\left| {X( - \\Omega )} \\right|}^2}}\\\\ {{S_{xy}}(\\Omega )}&{ = X( - \\Omega ){Y^*}( - \\Omega )} \\end{array}$$ and for real signals: (5.31) $$\\begin{array}{*{20}{l}} {{S_{xx}}(\\Omega )}&{ = {{\\left| {X(\\Omega )} \\right|}^2}}\\\\ {{S_{xy}}(\\Omega )}&{ = X(\\Omega ){Y^*}(\\Omega )} \\end{array}$$","title":"The power density spectrum and its properties"},{"location":"Chap_5.html#examples-of-power-spectra","text":"","title":"Examples of power spectra"},{"location":"Chap_5.html#example-white-noise","text":"Consider an autocorrelation function of the form (5.32) $${\\varphi _{xx}}[k] = I\\,\\delta [k]$$ The power spectrum is given by (5.33) $${S_{xx}}(\\Omega ) = {\\mathscr{F}}\\left\\{ {I\\,\\delta [k]} \\right\\} = I\\sum\\limits_{k = - \\infty }^{ + \\infty } {\\delta [k]{e^{ - j\\Omega k}}} = I$$ We see that the spectrum has the same amplitude for all frequencies; if we graph \\({S_{xx}}(\\Omega ) = I\\) versus \\(\\Omega,\\) it is \u201cflat\u201d. Because no particular frequency dominates the spectrum we say that the spectrum is \u201cwhite\u201d. This is the origin of the term white noise 4 . See Porat 5 and Oppenheim 6 .","title":"Example: White noise"},{"location":"Chap_5.html#example-pink-noise","text":"Let the autocorrelation function of a random process be given by: (5.34) $${\\varphi _{xx}}[k] = {\\left( {\\frac{1}{2}} \\right)^{\\left| k \\right|}}$$ The power spectrum is given by: (5.35) $$\\begin{array}{*{20}{l}} {{S_{xx}}(\\Omega )}&{ = \\sum\\limits_{k = - \\infty }^{ + \\infty } {{{\\left( {\\frac{1}{2}} \\right)}^{\\left| k \\right|}}{e^{ - j\\Omega k}}} }\\\\ {\\,\\,\\,}&{ = \\sum\\limits_{k = - \\infty }^0 {{{\\left( {\\frac{1}{2}} \\right)}^{ - k}}{e^{ - j\\Omega k}}} + \\sum\\limits_{k = 0}^{ + \\infty } {{{\\left( {\\frac{1}{2}} \\right)}^k}{e^{ - j\\Omega k}}} - 1}\\\\ {\\,\\,\\,}&{ = \\frac{3}{{5 - 4\\cos \\Omega }}} \\end{array}$$ This random process is not white as the spectrum is certainly not flat. We can use other properties we have developed to determine the average value \\({m_x}\\) and the mean-square \\(E\\left\\{ {{{\\left| {x[n]} \\right|}^2}} \\right\\}.\\) As \\(k \\to \\infty\\) we have from Equation 5.8 that \\({\\varphi _{xx}}[k] \\to {\\left| {{m_x}} \\right|^2}.\\) For this example \\({m_x} = 0\\) and the mean-square \\(E\\left\\{ {{{\\left| {x[n]} \\right|}^2}} \\right\\}\\) is given by \\({\\varphi _{xx}}[0] = 1.\\) The spectra from these two examples are illustrated in Figure 5.3 . ( a ) White noise spectrum ( b ) Pink noise spectrum Figure 5.3: Spectra of two noise processes. Note that we plot the spectra between \\(- \\pi \\lt \\Omega \\le + \\Omega\\) for the simple reason that the Fourier spectrum for any discrete time signal is periodic, that is, \\(X(\\Omega ) = X(\\Omega + 2\\pi ).\\) Thus it is sufficient to show or describe only one period.","title":"Example: Pink noise"},{"location":"Chap_5.html#predicting-the-natural-climate-a-case-study","text":"We have developed a collection of powerful tools, in particular, the power density spectrum and the correlation function. Let us see how they can be used to gain insight into a well-known stochastic physical phenomenon, the weather. On the cover of this iBook we show three basic concepts that have been discussed until now: a stochastic signal, its correlation function, and its power spectral density. Let us now look at some real data to see what insights these tools can give us. We again use data from the Royal Netherlands Meteorological Institute ( KNMI ). We use their data concerning the average daily temperature and the average daily air pressure. We begin with the original data. For temperature, the data start at 1 January 1901 and we use the measurements until 31 December 2009. This consists of \\({N_T} = 39,812\\) days. For the air pressure, we use the data at the first available date which is 1 January 1902 and then (again) until 31 December 2009. This represents \\({N_P} = 39,447\\) days. The data are displayed in Figure 5.4 . Figure 5.4: ( top ) Average daily air temperature and ( bottom ) average daily air pressure measured at De Bilt, The Netherlands over a period exceeding 100 years. The power spectral densities, \\({S_{TT}}\\left( \\Omega \\right)\\) and \\({S_{PP}}\\left( \\Omega \\right),\\) for each of these stochastic signals, \\(T[n]\\) and \\(P[n],\\) can be computed using the techniques described above Equation 5.24 and in Chapter 12 . They are shown in Figure 5.5 . The resulting spectra reveal an interesting difference. The temperature spectrum, \\({S_{TT}}\\left( \\Omega \\right),\\) shows a clear spectral peak\u2014a significant amount of power\u2014at frequency \\({\\Omega _k} = k\\left( {2\\pi /{N_T}} \\right)\\) with \\(k = 109.\\) This translates to a period of \\({N_T}/k = 39812/109 = 365.248\\) days, a familiar value. The pressure spectrum, \\({S_{PP}}\\left( \\Omega \\right),\\) shows no such peak. Figure 5.5: The \\({\\log _{10}}\\left( \\bullet \\right)\\) of the power spectral densities for ( top ) air temperature \\({S_{TT}}\\left( \\Omega \\right)\\) and (bottom) air pressure \\({S_{PP}}\\left( \\Omega \\right).\\) The spectra are displayed for \\(0 \\lt \\Omega \\le \\pi /40.\\) Note the strong peak in \\({S_{TT}}\\left( \\Omega \\right).\\) The unit of \\(\\Omega\\) is \\(2\\pi /days.\\) The autocorrelation functions, \\({\\varphi _{TT}}[k]\\) and \\({\\varphi _{PP}}[k],\\) can also be computed. See Figure 5.6 . Due to the size of the data sets, we really do compute first the power spectral densities and then the autocorrelation functions as the computational efficiency of the FFT can then be exploited. (Can you estimate how much more efficient it is to use the \u201cFFT route\u201d to compute the autocorrelation function as opposed to a direct application of Equation 5.13 ?) The spectral peak identified in the power density spectrum is clearly reflected in the sinusoidal behavior of the autocorrelation function \\({\\varphi _{TT}}[k]\\) and the one year period is obvious. A weather period of one year in daily temperatures is hardly surprising. But being able to use yearly, stochastic variations in temperature to estimate the length of the solar year with high accuracy might be surprising. The value given above, 365.248 days is only 0.002% above the currently accepted value for the solar year of 365.242 days. What may also be surprising is the impulse-like autocorrelation function associated with air pressure, \\({\\varphi _{PP}}[k].\\) At the scale shown in Figure 5.6 , we have essentially \\({\\varphi _{PP}}[k] = A\\,\\delta [k].\\) There is virtually no month-to-month or year-to-year correlation in air pressure. If one is to be sought it should be at much shorter time scales than a one-month period. ( a ) Autocorrelation of temperature , ${\\varphi _{TT}}\\lbrack k\\rbrack,$ five year interval ( b ) Autocorrelation of temperature , ${\\varphi _{TT}}\\lbrack k\\rbrack,$ first ten weeks interval ( c ) Autocorrelation of pressure , ${\\varphi _{PP}}\\lbrack k\\rbrack,$ five year interval ( d ) Autocorrelation of pressure , ${\\varphi _{PP}}\\lbrack k\\rbrack,$ first three weeks interval Figure 5.6: Autocorrelation functions for temperature \\({\\varphi _{TT}}\\lbrack k\\rbrack\\) and pressure \\({\\varphi _{PP}}\\lbrack k\\rbrack\\) for the two stochastic signals \\(T[n\\rbrack\\) and \\(P[n\\rbrack.\\) On a shorter time scale we do see short-term correlations. The average daily air temperature correlation falls to 50% of its maximum value, see Figure 5.6b , after 49.4 days. Given four seasons each of about 91 days, this is about half a season. The average daily air pressure correlation, however, falls to 50% of its maximum value after only 3.4 days, half a week. Put another way, the average daily air pressure is correlated over a significantly shorter time scale than the average daily air temperature. We emphasize through these examples that correlation functions and spectral densities are tools and that they can be useful in understanding the structure of complex data.","title":"Predicting the natural climate - a case study"},{"location":"Chap_5.html#problems","text":"","title":"Problems"},{"location":"Chap_5.html#problem-51","text":"Prove Equation 5.5 and the second part of Equation 5.6 .","title":"Problem 5.1"},{"location":"Chap_5.html#problem-52","text":"In the text we state: For many processes, as \\(k \\to \\infty,\\) the value of the random signal at time \\(n\\) becomes less dependent upon the value at time \\(n + k.\\) Describe a common, random process that would not have this property. Based upon this example, for what class of random processes would you expect that \\(\\mathop {\\lim }\\limits_{x \\to \\infty } \\,{\\gamma _{xx}}[k] \\ne 0?\\)","title":"Problem 5.2"},{"location":"Chap_5.html#problem-53","text":"Consider the following statement: For the ergodic random process with a mean \\({m_x}\\) and a variance \\(\\sigma _x^2,\\) we have: (5.36) $$\\sigma _x^2 = {\\varphi _{xx}}[k = 0] - {\\varphi _{xx}}[k = \\infty ]$$ Discuss the applicability of this statement. When is it valid and when can its use lead to problems?","title":"Problem 5.3"},{"location":"Chap_5.html#problem-54","text":"Show that if \\(x[n]\\) is a real, ergodic process then its autocorrelation function \\({\\varphi _{xx}}[k]\\) will be real and even. Show that if \\({\\varphi _{xx}}[k]\\) is real and even then \\({S_{xx}}(\\Omega )\\) will also be real and even.","title":"Problem 5.4"},{"location":"Chap_5.html#problem-55","text":"The cross-correlation, \\({\\varphi _{xy}}[k],\\) between two real, deterministic signals, \\(x[n]\\) and \\(y[n],\\) is given by: \\[{\\varphi _{xy}}[k] = \\sum\\limits_{n = - \\infty }^{ + \\infty } {x[n]\\,{y^*}[n + k] = } \\sum\\limits_{n = - \\infty }^{ + \\infty } {x[n]\\,y[n + k]}\\] Is the cross-correlation function \\({\\varphi _{xy}}[k]\\) even? That is, does \\({\\varphi _{xy}}[k] = {\\varphi _{xy}}[ - k]?\\) Explain your answer. Determine a general expression for \\({S_{xy}}(\\Omega ) = {\\mathscr{F}}\\left\\{ {{\\varphi _{xy}}[k]} \\right\\}\\) in terms of \\(X(\\Omega )\\) and \\(Y(\\Omega ).\\) Determine and sketch \\({\\varphi _{xy}}[k]\\) if \\(x[n] = {a^n}u[n]\\) where \\(\\left| a \\right| < 1\\) and \\(y[n] = u[n - 2].\\)","title":"Problem 5.5"},{"location":"Chap_5.html#problem-56","text":"The following statement was found in an old textbook: Let \\({\\varphi _{xx}}[k]\\) be the autocorrelation function of an ergodic process and \\({S_{xx}}(f)\\) its power density spectrum where \\(\\Omega = 2\\pi f.\\) Then the following relations hold: \\[\\begin{array}{l} {S_{xx}}(f) = {\\varphi _{xx}}[0] + 2\\sum\\limits_{k = 1}^{ + \\infty } {{\\varphi _{xx}}[k]\\cos \\left( {2\\pi fk} \\right)} \\\\ {\\varphi _{xx}}[k] = 2\\int\\limits_0^{ + \\pi } {{S_{xx}}(f)} \\cos \\left( {2\\pi fk} \\right)df \\end{array}\\] Under what circumstances are these two relations correct? Explain your reasoning.","title":"Problem 5.6"},{"location":"Chap_5.html#laboratory-exercises","text":"","title":"Laboratory Exercises"},{"location":"Chap_5.html#laboratory-exercise-51","text":"We review your understanding of the difference between convolution and correlation. To start the exercise, click on the icon to the left. Oppenheim, A. V., A. S. Willsky and S. H. Nawab (1996). Signals and Systems. Upper Saddle River, New Jersey, Prentice-Hall \u21a9 \u21a9 \u21a9 \u21a9 Papoulis, A. (1965). Probability, Random Variables, and Stochastic Processes. New York, McGraw-Hill, p. 327 \u21a9 Oppenheim, A. V., R. W. Schafer and J. R. Buck (1999). Discrete-Time Signal Processing. Upper Saddle River, New Jersey, Prentice-Hall, Section 2.9 \u21a9 Actually there are some semantic issues here because white usually refers to color. If an object has a flat spectrum over the wavelength range 400 nm \u2264 \\(\\lambda\\) \u2264 750 nm, we refer to its color as white as perceived by the average observer. Frequency and wavelength are related, however, by \\(f = c/\\lambda.\\) If the spectrum described in wavelength is flat then the frequency spectrum is not flat. The use of the term \u201cwhite noise\u201d is thus one of convention (or convenience) as opposed to color \u21a9 Porat, B. (1994). Digital Processing of Random Signals: Theory & Methods. Englewood Cliffs, New Jersey, Prentice-Hall, Section 2.5 \u21a9 Oppenheim, A. V., R. W. Schafer and J. R. Buck (1999). Discrete-Time Signal Processing. Upper Saddle River, New Jersey, Prentice-Hall, Section 2.10 \u21a9","title":"Laboratory Exercise 5.1"},{"location":"Chap_6.html","text":"Filtering of Stochastic Signals \u00b6 We now have the tools necessary to describe what happens when a stochastic signal is processed through a linear, time-invariant (LTI) system. These tools consist of measures on the random signals which describe and / or characterize the signals. The two most important of these are the mean value of the signal and the autocorrelation function of the signal. Further, we can characterize the relation between two random signals through the cross-correlation function. In all of our discussions we will assume that our random processes are complex as well as ergodic (and thus stationary) . We recall that: (6.1) $$\\begin{array}{*{20}{l}} {{\\varphi _{xx}}[k]}&{ = E\\left\\{ {x[n]\\,{x^*}[n + k]} \\right\\}}\\\\ {\\,\\,\\,}&{ = \\! < x[n]\\,{x^*}[n + k] > \\;}\\\\ {\\,\\,\\,}&\\begin{array}{l} = \\mathop {\\lim }\\limits_{N \\to \\infty } \\frac{1}{{2N + 1}}\\sum\\limits_{n = - N}^{ + N} {x[n]\\,{x^*}[n + k]} \\\\ \\,\\,\\, \\end{array} \\end{array}$$ (6.2) $$\\begin{array}{l} \\begin{array}{*{20}{l}} {{\\varphi _{xy}}[k]}&{ = E\\left\\{ {x[n]\\,{y^*}[n + k]} \\right\\}}\\\\ {\\,\\,\\,}&{ = \\! < x[n]\\,{y^*}[n + k] > \\;}\\\\ {\\,\\,\\,}&{ = \\mathop {\\lim }\\limits_{N \\to \\infty } \\frac{1}{{2N + 1}}\\sum\\limits_{n = - N}^{ + N} {x[n]\\,{y^*}[n + k]} } \\end{array}\\\\ \\,\\,\\, \\end{array}$$ (6.3) $$\\begin{array}{*{20}{l}} {{m_x}}&{ = E\\left\\{ {x[n]} \\right\\} = \\! < x[n] > }\\\\ {\\,\\,\\,}&{ = \\mathop {\\lim }\\limits_{N \\to \\infty } \\frac{1}{{2N + 1}}\\sum\\limits_{n = - N}^{ + N} {x[n]} } \\end{array}$$ To understand what happens when stochastic signals are processed by LTI systems, let us begin with discrete-time convolution. Interpretation of the convolution result \u00b6 First we can say that the relation between input and output is still given by the convolution sum, that is, we can write the input as: (6.4) $$x[n] = \\sum\\limits_{k = - \\infty }^{ + \\infty } {x[k]\\,\\delta [n - k]}$$ The total signal is a weighted sum of unit impulse functions where the weights \\(\\left\\{ {x[k]} \\right\\}\\) have random values according to some probability function. The basic concepts of convolution theory, as argued below, still hold. As a reminder of what Equation 6.4 means, see Figure 3.1 . The deterministic impulse function \\(\\delta [n]\\) produces the impulse response \\(h[n]\\) from the LTI system. A delayed version \\(\\delta [n - k]\\) produces a delayed output \\(h[n - k].\\) Multiplication of the input by a scale factor produces multiplication of the output by the same factor even if that factor is a random variable . Thus \\(x[k]\\,\\delta [n - k]\\) will produce \\(x[k]\\,h[n - k]\\) as an output. Because the input \\(x[n]\\) can be expressed as the sum of inputs of this form, we can apply the linearity conditions, Equation 4.13 and Equation 4.14 , to write the output as: (6.5) $$y[n] = \\sum\\limits_{k = - \\infty }^{ + \\infty } {x[k]\\,h[n - k]} = x[n] \\otimes h[n]$$ The model for this situation is shown in Figure 6.1 . Figure 6.1: A stochastic signal \\(x\\lbrack n\\rbrack\\) filtered by a deterministic LTI filter \\(h\\lbrack n\\rbrack\\) to produce a stochastic output signal \\(y\\lbrack n\\rbrack\\) . It is easy to see from Equation 6.5 that \\(y[n]\\) will be a stochastic signal if \\(x[n]\\) is a stochastic signal. The questions now arise: If the input mean is \\({m_x},\\) what is the output mean \\({m_y}?\\) If the input autocorrelation function is \\({\\varphi _{xx}}[k],\\) what form does the output autocorrelation function \\({\\varphi _{yy}}[k]\\) have? Assuming that the input is stationary, is the output also stationary? The mean \u00b6 Using the standard definition we have: (6.6) $$\\begin{array}{*{20}{l}} {{m_y}}&{ = E\\left\\{ {y[n]} \\right\\} = E\\left\\{ {\\sum\\limits_{k = - \\infty }^{ + \\infty } {x[k]\\,h[n - k]} } \\right\\}}\\\\ {\\,\\,\\,}&{ = \\sum\\limits_{k = - \\infty }^{ + \\infty } {E\\left\\{ {x[k]\\,h[n - k]} \\right\\}} } \\end{array}$$ This last statement is true because, as we have observed earlier in Equation 4.13 , the averaging operator (or expectation operator) distributes over addition. Only the weights \\(\\left\\{ {x[k]} \\right\\}\\) are random variables. The impulse response, \\(h[n],\\) of the LTI system is not random and the term \\(h[n - k]\\) is a constant with respect to the averaging process over the random variable \\(x[k].\\) We can, therefore, rewrite this equation as: (6.7) $${m_y} = \\sum\\limits_{k = - \\infty }^{ + \\infty } {E\\left\\{ {x[k]\\,h[n - k]} \\right\\}} = \\sum\\limits_{k = - \\infty }^{ + \\infty } {E\\left\\{ {x[k]} \\right\\}\\,} h[n - k]$$ Because the random process \\(\\left\\{ {x[k]} \\right\\}\\) is stationary (independent of \\(n\\) ) we have: (6.8) $$\\begin{array}{*{20}{l}} {{m_y}}&{ = \\sum\\limits_{k = - \\infty }^{ + \\infty } {E\\left\\{ {x[k]} \\right\\}h[n - k]} = \\sum\\limits_{k = - \\infty }^{ + \\infty } {{m_x}h[n - k]} }\\\\ {\\,\\,\\,}&{ = {m_x}\\sum\\limits_{k = - \\infty }^{ + \\infty } {h[n - k]} } \\end{array}$$ Using the Fourier transform of the impulse response \\(H(\\Omega ) = {\\mathscr{F}}\\left\\{ {h[n]} \\right\\}\\) ( Equation 3.3 ), this expression simplifies to: (6.9) $$\\begin{array}{*{20}{l}} {{m_y}}&{ = {m_x}\\sum\\limits_{k = - \\infty }^{ + \\infty } {h[n - k]} = {m_x}\\sum\\limits_{n = - \\infty }^{ + \\infty } {h[n]} }\\\\ {\\,\\,\\,}&{ = {m_x}H(\\Omega = 0)} \\end{array}$$ What does this mean? From our knowledge of LTI filter theory, the expression \\({m_y} = {m_x}H(\\Omega = 0)\\) makes sense. The expression says the average value of the input random signal is multiplied by the constant gain factor\u2014the gain at ( \\(\\Omega = 0\\) )\u2014of the linear filter. Because the average value is, indeed, just a constant (DC) value, the non-fluctuating component, this is a realistic result. Note that \\(H(\\Omega ),\\) \\({m_x}\\) and \\({m_y}\\) are all complex in this derivation. We also see through this derivation that, because the input average is stationary, the output average is also stationary. The autocorrelation function \u00b6 The development of the output correlation proceeds along similar lines: (6.10) $$\\begin{array}{l} {\\varphi _{yy}}[n,n + k] = E\\left\\{ {y[n]{y^*}[n + k]} \\right\\}\\\\ \\,\\,\\,\\,\\,\\,\\,\\, = E\\left\\{ {\\left( {\\sum\\limits_{m = - \\infty }^{ + \\infty } {h[m ]x[n - m ]} } \\right)\\left( {\\sum\\limits_{r = - \\infty }^{ + \\infty } {{h^*}[r]{x^*}[n + k - r]} } \\right)} \\right\\}\\\\ \\,\\,\\,\\,\\,\\,\\,\\, = E\\left\\{ {\\sum\\limits_{m = - \\infty }^{ + \\infty } {\\sum\\limits_{r = - \\infty }^{ + \\infty } {h[m ]{h^*}[r]x[n - m ]{x^*}[n + k - r]} } } \\right\\} \\end{array}$$ Using the distributive property once again: (6.11) $${\\varphi _{yy}}[n,n + k] = \\sum\\limits_{m = - \\infty }^{ + \\infty } {\\sum\\limits_{r = - \\infty }^{ + \\infty } {h[m ]{h^*}[r]E\\left\\{ {x[n - m ]{x^*}[n + k - r]} \\right\\}} }$$ The term within the expectation braces \\(E\\left\\{ \\bullet \\right\\}\\) yields \\({\\varphi _{xx}}[k + m - r]\\) producing: (6.12) $${\\varphi _{yy}}[n,n + k] = \\sum\\limits_{m = - \\infty }^{ + \\infty } {\\sum\\limits_{r = - \\infty }^{ + \\infty } {h[m ]{h^*}[r]{\\varphi _{xx}}[k + m - r]} }$$ Because \\(m\\) and \\(r\\) in Equation 6.12 are simply dummy variables that disappear when the two sums are performed, the result of the double sum, \\({\\varphi _{yy}},\\) will only be a function of \\(k\\) and, of course, the precise forms of the impulse response \\(h[n]\\) and the autocorrelation function \\({\\varphi _{xx}}.\\) If the right side of Equation 6.12 is only a function of \\(k\\) then the left side is only a function of \\(k,\\) as well, and we have: (6.13) $${\\varphi _{yy}}[n,n + k] = {\\varphi _{yy}}[k] = \\sum\\limits_{m = - \\infty }^{ + \\infty } {\\sum\\limits_{r = - \\infty }^{ + \\infty } {h[m ]{h^*}[r]{\\varphi _{xx}}[k + m - r]} }$$ From this we can conclude that if \\({\\varphi _{xx}}[ \\bullet ]\\) is stationary then \\({\\varphi _{yy}}[ \\bullet ]\\) is stationary. We can go further. If we set \\(n = r - m,\\) then: (6.14) $$\\begin{array}{*{20}{l}} {{\\varphi _{yy}}[k]}&{ = \\sum\\limits_{m = - \\infty }^{ + \\infty } {\\sum\\limits_{n = - \\infty }^{ + \\infty } {h[m]{h^*}[m + n]{\\varphi _{xx}}[k - n]} } }\\\\ {\\,\\,\\,}&{ = \\sum\\limits_{n = - \\infty }^{ + \\infty } {{\\varphi _{xx}}[k - n]} \\left( {\\sum\\limits_{m = - \\infty }^{ + \\infty } {h[m]{h^*}[m + n]} } \\right)} \\end{array}$$ We recognize from ordinary (deterministic) signal processing theory that the term within parentheses is the autocorrelation of the impulse response. If this autocorrelation is \\({\\varphi _{hh}}[m]\\) then: (6.15) $${\\varphi _{yy}}[k] = \\sum\\limits_{m = - \\infty }^{ + \\infty } {{\\varphi _{xx}}[k - m]} {\\varphi _{hh}}[m] = {\\varphi _{xx}}[k] \\otimes {\\varphi _{hh}}[k]$$ Our conclusion is that the autocorrelation of the output is stationary and is the convolution of the autocorrelation function of the (random) input signal with the autocorrelation function of the (deterministic) impulse response. The cross-correlation function \u00b6 Finally we can derive the cross-correlation between the input and output as: (6.16) $$\\begin{array}{*{20}{l}} {{\\varphi _{xy}}[k]}&{ = E\\left\\{ {x[n]{y^*}[n + k]} \\right\\}}\\\\ {\\,\\,\\,}&{ = E\\left\\{ {x[n]\\left( {\\sum\\limits_{m = - \\infty }^{ + \\infty } {{h^*}[m ]{x^*}[n + k - m]} } \\right)} \\right\\}}\\\\ {\\,\\,\\,}&{ = \\sum\\limits_{m = - \\infty }^{ + \\infty } {{h^*}[m ]E\\left\\{ {x[n]{x^*}[n + k - m]} \\right\\}} } \\end{array}$$ Once again, the term within the expectation braces gives the stationary autocorrelation function \\({\\varphi _{xx}}[k - m].\\) Continuing, (6.17) $${\\varphi _{xy}}[k] = \\sum\\limits_{m = - \\infty }^{ + \\infty } {{h^*}[m]} {\\varphi _{hh}}[k - m] = {h^*}[k] \\otimes {\\varphi _{xx}}[k]$$ The cross-correlation function is stationary and is the convolution of the complex conjugate of the (deterministic) impulse response with the autocorrelation function of the (random) input signal. We can now express the Fourier transforms of \\({\\varphi _{xx}}[k]\\) and \\({\\varphi _{yy}}[k]\\) in terms of known quantities. (6.18) $$\\begin{array}{*{20}{l}} {{S_{yy}}(\\Omega )}&{ = {\\mathscr{F}}\\left\\{ {{\\varphi _{yy}}[k]} \\right\\} = {\\mathscr{F}}\\left\\{ {{\\varphi _{xx}}[k] \\otimes {\\varphi _{hh}}[k]} \\right\\}}\\\\ {\\,\\,\\,}&{ = {S_{xx}}(\\Omega )\\;{S_{hh}}(\\Omega )} \\end{array}$$ But using the result from Fourier theory that \\({\\mathscr{F}}\\left\\{ {{h^*}[n]} \\right\\} = {H^*}\\left( { - \\Omega } \\right)\\) gives: (6.19) $$\\begin{array}{*{20}{l}} {{S_{hh}}(\\Omega )}&{ = {\\mathscr{F}}\\left\\{ {\\sum\\limits_{m = - \\infty }^{ + \\infty } {h[m]{h^*}[m + n]} } \\right\\}}\\\\ {\\,\\,\\,}&{ = H( - \\Omega )\\;{H^*}( - \\Omega ) = {{\\left| {H( - \\Omega )} \\right|}^2}} \\end{array}$$ Therefore, (6.20) $${S_{yy}}(\\Omega ) = {\\left| {H( - \\Omega )} \\right|^2}{S_{xx}}(\\Omega )$$ If the impulse response \\(h[n]\\) of the deterministic system is real , then this is equivalent to: (6.21) $${S_{yy}}(\\Omega ) = {\\left| {H(\\Omega )} \\right|^2}{S_{xx}}(\\Omega )$$ Returning to the complex form of \\(h[n],\\) the cross power density spectrum can be similarly shown to be: (6.22) $${S_{xy}}(\\Omega ) = {H^*}( - \\Omega ){S_{xx}}(\\Omega )$$ Again, if the impulse response \\(h[n]\\) of the deterministic system is real , then this is equivalent to: (6.23) $${S_{xy}}(\\Omega ) = H(\\Omega ){S_{xx}}(\\Omega )$$ Based upon the use of these results we are now in a position to provide an interpretation of the power spectrum \\({S_{xx}}(\\Omega ).\\) We see from Equation 5.3 that for \\(k = 0\\) : (6.24) $${\\varphi _{xx}}[0] = E\\left\\{ {x[n]{x^*}[n]} \\right\\}\\; = E\\left\\{ {{{\\left| {x[n]} \\right|}^2}} \\right\\}\\; \\ge 0$$ Similarly \\({\\varphi _{yy}}[k] \\ge 0\\) and (6.25) $$\\begin{array}{*{20}{l}} {{\\varphi _{yy}}[0]}&{ = \\frac{1}{{2\\pi }}\\int\\limits_{ - \\pi }^{ + \\pi } {{S_{yy}}(\\Omega )} d\\Omega }\\\\ {\\,\\,\\,}&{ = \\frac{1}{{2\\pi }}\\int\\limits_{ - \\pi }^{ + \\pi } {{{\\left| {H( - \\Omega )} \\right|}^2}{S_{xx}}(\\Omega )} d\\Omega } \\end{array}$$ Let \\(H(\\Omega )\\) be a (complex) bandpass filter (as shown in Figure 6.2 ) such that within the pass-band the spectrum \\({S_{xx}}(\\Omega )\\) is essentially constant. Figure 6.2: Power spectrum \\({S_{xx}}(\\Omega )\\) (n dark red) and a linear, bandpass filter \\({\\left| {H(\\Omega )} \\right|^2}\\) (in dark green). The filter has width \\(\\Delta \\Omega\\) and is centered at \\({\\Omega _o}.\\) For complex random processes \\({\\varphi _{xx}}[k] = \\varphi _{xx}^*[ - k],\\) Equation 5.5 , which means that \\({S_{xx}}(\\Omega )\\) is real Equation 5.26 . For a sufficiently small passband \\(\\Delta \\Omega,\\) we can write: (6.26) $$\\begin{array}{*{20}{l}} {{\\varphi _{yy}}[0]}&{ = \\frac{1}{{2\\pi }}{S_{yy}}(\\Omega = {\\Omega _0})\\Delta \\Omega }&{ \\ge 0}\\\\ {\\,\\,\\,}&{ = \\frac{1}{{2\\pi }}{{\\left| {H( - {\\Omega _0})} \\right|}^2}{S_{xx}}({\\Omega _0})\\Delta \\Omega }&{ \\ge 0} \\end{array}$$ Because \\({S_{xx}}(\\Omega )\\) is real, we immediately have that (6.27) $${S_{xx}}({\\Omega _0}) \\ge 0$$ for all choices of \\({\\Omega _0}.\\) Further \\({\\left| {y[n]} \\right|^2}\\) is (by definition) the instantaneous power in a signal (including random signals) and thus \\({\\varphi _{yy}}[0] = E\\left\\{ {{{\\left| {y[n]} \\right|}^2}} \\right\\}\\) is the expected power in the output signal at any instant. This means that: (6.28) $$\\begin{array}{*{20}{l}} {{\\varphi _{yy}}[0]}&{ = \\frac{1}{{2\\pi }}{S_{yy}}({\\Omega _0})\\Delta \\Omega }\\\\ {\\,\\,\\,}&{ = \\frac{1}{{2\\pi }}{{\\left| {H( - {\\Omega _0})} \\right|}^2}{S_{xx}}({\\Omega _0})\\Delta \\Omega } \\end{array}$$ has the unit of power [Watts]. \\({S_{xx}}(\\Omega )\\) like \\({S_{yy}}(\\Omega )\\) is, therefore, expressed in Watts per unit frequency [Watts/Hz] and is thus a power density spectrum . Other interesting and useful results can also be derived at this point: 1) We would like to show that the maximum value of the autocorrelation function occurs at \\(k = 0.\\) We begin with: (6.29) $${\\varphi _{xx}}[k] = \\frac{1}{{2\\pi }}\\int\\limits_{ - \\pi }^{ + \\pi } {{S_{xx}}(\\Omega )} {e^{j\\Omega k}}d\\Omega$$ Taking the absolute value of both sides: (6.30) $$\\begin{array}{*{20}{l}} {\\left| {{\\varphi _{xx}}[k]} \\right|}&{ = \\frac{1}{{2\\pi }}\\left| {\\int\\limits_{ - \\pi }^{ + \\pi } {{S_{xx}}(\\Omega )} {e^{j\\Omega k}}d\\Omega } \\right|}\\\\ {\\,\\,\\,}&{ \\le \\frac{1}{{2\\pi }}\\int\\limits_{ - \\pi }^{ + \\pi } {\\left| {{S_{xx}}(\\Omega )} \\right|} \\left| {{e^{j\\Omega k}}} \\right|d\\Omega } \\end{array}$$ The inequality holds because the absolute value of an integral is always less than (or equal to) the integral of the absolute value. This is easy to see if we consider the integral as a way of measuring the area under a curve. The total area will be greater if we first make all contributions positive. Because \\(\\left| {{e^{j\\Omega k}}} \\right| = 1\\) and because the power spectrum is real and everywhere positive, Equation 6.27 , we have: (6.31) $$\\begin{array}{*{20}{l}} {\\left| {{\\varphi _{xx}}[k]} \\right|}&{ \\le \\frac{1}{{2\\pi }}\\int\\limits_{ - \\pi }^{ + \\pi } {\\left| {{S_{xx}}(\\Omega )} \\right|} d\\Omega }\\\\ {\\,\\,\\,}&{ = \\frac{1}{{2\\pi }}\\int\\limits_{ - \\pi }^{ + \\pi } {{S_{xx}}(\\Omega )} d\\Omega = {\\varphi _{xx}}[0]} \\end{array}$$ Finally, (6.32) $$\\left| {{\\varphi _{xx}}[k]} \\right| \\le {\\varphi _{xx}}[0]$$ An alternative (and instructive) way to prove this result is developed in Problem 6.6 . 2) We might well ask under what circumstance can there be another value of \\(k\\) such that \\(\\left| {{\\varphi _{xx}}[k]} \\right| = {\\varphi _{xx}}[0].\\) The most common situation where equality is achieved is when the autocorrelation function contains a periodic component. That is, if \\({\\varphi _{xx}}[k] = {\\varphi _{xx}}[k + K]\\) then the maximum value will be repeated every \\(K\\) time instances. This is illustrated in the case study, Figure 5.6a . There are more elaborate ways of describing this situation but this will suffice for our introductory level. 3) Finally we can determine a bound on the average output power \\({\\varphi _{yy}}[0]\\) given the average input power and the LTI filter characteristic \\(H(\\Omega ).\\) (6.33) $$E\\left\\{ {{{\\left| {y[n]} \\right|}^2}} \\right\\} = {\\varphi _{yy}}[0] = \\frac{1}{{2\\pi }}\\int\\limits_{ - \\pi }^{ + \\pi } {{{\\left| {H( - \\Omega )} \\right|}^2}{S_{xx}}(\\Omega )d\\Omega }$$ Let \\({\\Omega _m}\\) be the frequency at which the filter has its maximum gain \\(\\left| {H( - {\\Omega _m})} \\right|.\\) This implies: (6.34) $$E\\left\\{ {{{\\left| {y[n]} \\right|}^2}} \\right\\} \\le \\frac{{{{\\left| {H( - {\\Omega _m})} \\right|}^2}}}{{2\\pi }}\\int\\limits_{ - \\pi }^{ + \\pi } {{S_{xx}}(\\Omega )d\\Omega }$$ (6.35) $${\\varphi _{yy}}[0] \\le {\\left| {H( - {\\Omega _m})} \\right|^2}{\\varphi _{xx}}[0]$$ The average output power will attain the maximum if and only if (6.36) $${S_{xx}}(\\Omega ) = B\\delta (\\Omega - {\\Omega _m}) + B\\delta (\\Omega + {\\Omega _m})$$ that is, if \\({\\varphi _{xx}}[k]\\) is of the form \\(\\cos \\left( {{\\Omega _m}k} \\right).\\) This follows directly from Equation 6.33 and Equation 6.34 . The only way for the maximum to be achieved is if all the spectral power is concentrated at the frequencies \\(\\pm {\\Omega _m}\\) where the filter has its maxima. Example: A world of random events - a case study \u00b6 The relationship described in Equation 6.32 might seem like a rather abstract result. In this example, we hope to show that use of the result can lead to useful insights into complex systems. The data shown in Figure 6.3 are the price at the \u201cwellhead\u201d of a barrel of oil (\u201cBrent crude\u201d), \\(c[n],\\) and the price of a liter of refined automobile gasoline (benzine) at the \u201cpump\u201d \\(g[n].\\) The graphs show the development of the price over a period of months. ( a ) Brent oil price per barrel starting 1 Jan 1990 ( b ) Brent price 2 Aug 1990 \u00b1 30 days ( c ) Gasoline price per liter starting 1 Jan 1990 Figure 6.3: Price evolution of crude oil \\(c[n\\rbrack\\) and refined gasoline \\(g[n\\rbrack\\) ( a ) Barrel price from 1 January 1990 to 16 October 1990 (289 days). The day of the event is indicated by the arrow. ( b ) Daily price evolution surrounding 2 August 1990, that is, day 214 \u00b1 30 days, ( c ) Liter price (to consumers) from 1 January 1990 to 16 October 1990 (289 days). The day of the event is indicated by the arrow. On 2 August 1990, the 214th day of that year, an event occurred in the Middle East that influenced the world-wide price of crude oil. The steep rise in price of a barrel of oil, shown in the middle panel of Figure 6.3 , attests to this. An increase in the price of a liter of gasoline at retail distribution points would also follow from this. The question we pose is: what is the delay between a rise in prices at the wellhead and a rise in prices at the \u201cpump\u201d? How many days does it take before the price rises in the retail sale of gasoline? To answer this we assume that the price of gasoline \\(g[n]\\) is a delayed version, that is function, of the price of crude oil \\(c[n].\\) But this cannot be expressed as simply \\(g[n] = c[n - k].\\) Between these two prices are complicated processes, some industrial and some marketplace. Nevertheless, one cannot help but being struck by the similarity of the top and bottom curves in Figure 6.3 . The cross-correlation between the two prices, under the assumption that the major effect is a time delay, can help us find the answer. Assuming that the system is a pure time delay, \\(h[n] = \\delta [n - k],\\) and using Equation 6.17 gives: (6.37) $$\\begin{array}{*{20}{l}} {{\\varphi _{cg}}[k]}&{ = {h^*}[k] \\otimes {\\varphi _{cc}}[k] = \\delta [n - k] \\otimes {\\varphi _{cc}}[k]}\\\\ {\\,\\,\\,}&{ = {\\varphi _{cc}}[n - k]} \\end{array}$$ A simple substitution, \\(m = n - k,\\) allows us to rewrite this as (6.38) $${\\varphi _{cg}}[n - m] = {\\varphi _{cc}}[m]$$ Applying Equation 6.32 to Equation 6.38 means that, given the model of a simple delay element, the time \\(m = 0\\) when the autocorrelation is a maximum is the same as the time \\(m = n\\) when the cross-correlation is a maximum. The cross-correlation is illustrated in Figure 6.4 . Figure 6.4: Cross-correlation \\({\\varphi _{cg}}[k\\rbrack\\) between the crude oil price and the gasoline pump price over an interval of 51 days. Day 0 is 2 August 1990, day 214 of the year. The position of maximum correlation is indicated by the arrow. The time at which the maximum occurs is day 18. Our estimate for the time delay between the wellhead and the gasoline pump, in the midst of all the stochastic variations and the (over)simplification of the model, is 18 days. Problems \u00b6 Problem 6.1 \u00b6 The input to a discrete-time, LTI system is a stochastic signal, \\(x[n].\\) At each time step the output is \\(+ \\delta [n - k]\\) with probability \\(p\\) or \\(- \\delta [n - k]\\) with probability \\(1 - p.\\) Thus we can write: \\[x[n] = \\sum\\limits_{k = --\\infty }^{ + \\infty } {{a_k}\\delta [n - k]}\\] where \\[{a_k} = \\left\\{ {\\begin{array}{*{20}{l}} { + 1}&{{\\mathop{\\rm with}\\nolimits} \\,probability\\,p}\\\\ { - 1}&{{\\mathop{\\rm with}\\nolimits} \\,probability\\,1 - p} \\end{array}} \\right.\\] The LTI system has \\(h[n] = {\\left( {\\frac{1}{4}} \\right)^n}u[n].\\) Draw and label one possible stochastic signal \\(x[n]\\) from this random process. Draw and label \\(y[n]\\) the output signal corre\u00adsponding to your choice of \\(x[n].\\) Determine \\({m_y} = E\\left\\{ {y[n]} \\right\\}.\\) Your answer should not contain any integrals or summations. Determine \\({\\varphi _{yy}}[k = 0] = {\\left. {E\\left\\{ {y[n]\\,{y^*}[n + k]} \\right\\}} \\right|_{k = 0}}.\\) Problem 6.2 \u00b6 The impulse response of a discrete-time, LTI system is given by: \\[h[n] = 3\\delta [n] - 8{\\left( {\\frac{1}{3}} \\right)^{n - 1}}u[n - 1]\\] The input signal is a real, ergodic signal \\(x[n]\\) where: \\[{\\varphi _{xx}}[k] = E\\left\\{ {x[n]\\,{x^*}[n + k]} \\right\\} = {\\left( {\\frac{1}{3}} \\right)^{ - \\left| k \\right|}}\\] The output signal of the LTI system is \\(y[n].\\) Determine \\({m_y} = E\\left\\{ {y[n]} \\right\\}.\\) Determine \\({\\varphi _{yy}}[k] = E\\left\\{ {y[n]\\,{y^*}[n + k]} \\right\\}.\\) Problem 6.3 \u00b6 Discuss the following proposition: The function \\(f[k]\\) given below cannot be the auto-correlation function of a stochastic signal. \\[f[k] = \\left\\{ {\\begin{array}{*{20}{l}} 1&{\\left| k \\right| \\le 7}\\\\ 0&{\\left| k \\right| > 7} \\end{array}} \\right.\\] Problem 6.4 \u00b6 When the discrete-time input signal \\(x[n]\\) is white noise with autocorrelation function \\({\\varphi _{xx}}[k] = \\delta [k],\\) the output signal from an LTI system is ergodic with power spectral density: \\[{S_{yy}}(\\Omega ) = \\frac{9}{{13 - 12\\cos (\\Omega )}}\\] Determine two possible causal, LTI filters \\({H_1}\\left( \\Omega \\right)\\) and \\({H_2}\\left( \\Omega \\right)\\) that could lead to this output power density spectrum. Given either of the filters, \\({H_1}\\left( \\Omega \\right)\\) or \\({H_2}\\left( \\Omega \\right),\\) from part ( a ), determine another, different noise signal \\(q[n]\\) that would yield the same \\({S_{yy}}(\\Omega )\\) as given in part ( a ). Problem 6.5 \u00b6 An ergodic process, \\(x[n],\\) is input to an LTI system with impulse response \\(h[n]\\) and Fourier transform \\(H(\\Omega ).\\) The output is \\(y[n].\\) It is known that \\(h[n = 0] \\ne 0.\\) Discuss the following proposition: If the mean of the input \\(E\\left\\{ {x[n]} \\right\\} = {m_x} \\ne 0\\) then \\(E\\left\\{ {y[n]} \\right\\} = {m_y} \\ne 0.\\) Problem 6.6 \u00b6 Consider the following expression for a real, ergodic signal \\(x[n]\\) : (6.39) $$E\\left\\{ {{{\\left| {x[n] \\pm x[n + k]} \\right|}^2}} \\right\\} \\geqslant 0$$ Why is this expected value non-negative? Use this expression to prove Equation 6.32 . Laboratory Exercises \u00b6 Laboratory Exercise 6.1 \u00b6 We now have the tools to analyze and discuss noise processes. We start with \u201cwhite noise\u201d. To start the exercise, click on the icon to the left. Laboratory Exercise 6.2 \u00b6 We continue the analysis and discussion of noise processes. We start with \u201cbinary noise\u201d, a process that can be generated by flipping a coin. To start the exercise, click on the icon to the left. Laboratory Exercise 6.3 \u00b6 Can you estimate the parameters of real, ergodic noise processes based upon information from their number of samples N , their estimated autocorrelation function ${\\varphi _{ \\bullet \\bullet }}[k]$, and/or their estimated power spectral density ${S_{ \\bullet \\bullet }}(\\Omega ).$ To start the exercise, click on the icon to the left. Laboratory Exercise 6.4 \u00b6 When studying stochastic processes you not only have the mathematical tools we have presented, you also have your eyes and ears. To start the exercise, click on the icon to the left. Laboratory Exercise 6.5 \u00b6 We continue studying stochastic processes using the mathematical tools we have presented and your eyes and ears. To start the exercise, click on the icon to the left. Laboratory Exercise 6.6 \u00b6 We continue studying stochastic processes using the mathematical tools we have presented and your eyes and ears. To start the exercise, click on the icon to the left. Laboratory Exercise 6.7 \u00b6 Let us explore the effect that filtering has on various types of noise. As tools, we will use the noise signal itself, its amplitude distribution, its autocorrelation function, its power density spectrum, and your eyes and ears. To start the exercise, click on the icon to the left. Laboratory Exercise 6.8 \u00b6 How much information can you glean from the mathematical tools we have developed? To start the exercise, click on the icon to the left.","title":"6. Filtering of Stochastic Signals"},{"location":"Chap_6.html#filtering-of-stochastic-signals","text":"We now have the tools necessary to describe what happens when a stochastic signal is processed through a linear, time-invariant (LTI) system. These tools consist of measures on the random signals which describe and / or characterize the signals. The two most important of these are the mean value of the signal and the autocorrelation function of the signal. Further, we can characterize the relation between two random signals through the cross-correlation function. In all of our discussions we will assume that our random processes are complex as well as ergodic (and thus stationary) . We recall that: (6.1) $$\\begin{array}{*{20}{l}} {{\\varphi _{xx}}[k]}&{ = E\\left\\{ {x[n]\\,{x^*}[n + k]} \\right\\}}\\\\ {\\,\\,\\,}&{ = \\! < x[n]\\,{x^*}[n + k] > \\;}\\\\ {\\,\\,\\,}&\\begin{array}{l} = \\mathop {\\lim }\\limits_{N \\to \\infty } \\frac{1}{{2N + 1}}\\sum\\limits_{n = - N}^{ + N} {x[n]\\,{x^*}[n + k]} \\\\ \\,\\,\\, \\end{array} \\end{array}$$ (6.2) $$\\begin{array}{l} \\begin{array}{*{20}{l}} {{\\varphi _{xy}}[k]}&{ = E\\left\\{ {x[n]\\,{y^*}[n + k]} \\right\\}}\\\\ {\\,\\,\\,}&{ = \\! < x[n]\\,{y^*}[n + k] > \\;}\\\\ {\\,\\,\\,}&{ = \\mathop {\\lim }\\limits_{N \\to \\infty } \\frac{1}{{2N + 1}}\\sum\\limits_{n = - N}^{ + N} {x[n]\\,{y^*}[n + k]} } \\end{array}\\\\ \\,\\,\\, \\end{array}$$ (6.3) $$\\begin{array}{*{20}{l}} {{m_x}}&{ = E\\left\\{ {x[n]} \\right\\} = \\! < x[n] > }\\\\ {\\,\\,\\,}&{ = \\mathop {\\lim }\\limits_{N \\to \\infty } \\frac{1}{{2N + 1}}\\sum\\limits_{n = - N}^{ + N} {x[n]} } \\end{array}$$ To understand what happens when stochastic signals are processed by LTI systems, let us begin with discrete-time convolution.","title":"Filtering of Stochastic Signals"},{"location":"Chap_6.html#interpretation-of-the-convolution-result","text":"First we can say that the relation between input and output is still given by the convolution sum, that is, we can write the input as: (6.4) $$x[n] = \\sum\\limits_{k = - \\infty }^{ + \\infty } {x[k]\\,\\delta [n - k]}$$ The total signal is a weighted sum of unit impulse functions where the weights \\(\\left\\{ {x[k]} \\right\\}\\) have random values according to some probability function. The basic concepts of convolution theory, as argued below, still hold. As a reminder of what Equation 6.4 means, see Figure 3.1 . The deterministic impulse function \\(\\delta [n]\\) produces the impulse response \\(h[n]\\) from the LTI system. A delayed version \\(\\delta [n - k]\\) produces a delayed output \\(h[n - k].\\) Multiplication of the input by a scale factor produces multiplication of the output by the same factor even if that factor is a random variable . Thus \\(x[k]\\,\\delta [n - k]\\) will produce \\(x[k]\\,h[n - k]\\) as an output. Because the input \\(x[n]\\) can be expressed as the sum of inputs of this form, we can apply the linearity conditions, Equation 4.13 and Equation 4.14 , to write the output as: (6.5) $$y[n] = \\sum\\limits_{k = - \\infty }^{ + \\infty } {x[k]\\,h[n - k]} = x[n] \\otimes h[n]$$ The model for this situation is shown in Figure 6.1 . Figure 6.1: A stochastic signal \\(x\\lbrack n\\rbrack\\) filtered by a deterministic LTI filter \\(h\\lbrack n\\rbrack\\) to produce a stochastic output signal \\(y\\lbrack n\\rbrack\\) . It is easy to see from Equation 6.5 that \\(y[n]\\) will be a stochastic signal if \\(x[n]\\) is a stochastic signal. The questions now arise: If the input mean is \\({m_x},\\) what is the output mean \\({m_y}?\\) If the input autocorrelation function is \\({\\varphi _{xx}}[k],\\) what form does the output autocorrelation function \\({\\varphi _{yy}}[k]\\) have? Assuming that the input is stationary, is the output also stationary?","title":"Interpretation of the convolution result"},{"location":"Chap_6.html#the-mean","text":"Using the standard definition we have: (6.6) $$\\begin{array}{*{20}{l}} {{m_y}}&{ = E\\left\\{ {y[n]} \\right\\} = E\\left\\{ {\\sum\\limits_{k = - \\infty }^{ + \\infty } {x[k]\\,h[n - k]} } \\right\\}}\\\\ {\\,\\,\\,}&{ = \\sum\\limits_{k = - \\infty }^{ + \\infty } {E\\left\\{ {x[k]\\,h[n - k]} \\right\\}} } \\end{array}$$ This last statement is true because, as we have observed earlier in Equation 4.13 , the averaging operator (or expectation operator) distributes over addition. Only the weights \\(\\left\\{ {x[k]} \\right\\}\\) are random variables. The impulse response, \\(h[n],\\) of the LTI system is not random and the term \\(h[n - k]\\) is a constant with respect to the averaging process over the random variable \\(x[k].\\) We can, therefore, rewrite this equation as: (6.7) $${m_y} = \\sum\\limits_{k = - \\infty }^{ + \\infty } {E\\left\\{ {x[k]\\,h[n - k]} \\right\\}} = \\sum\\limits_{k = - \\infty }^{ + \\infty } {E\\left\\{ {x[k]} \\right\\}\\,} h[n - k]$$ Because the random process \\(\\left\\{ {x[k]} \\right\\}\\) is stationary (independent of \\(n\\) ) we have: (6.8) $$\\begin{array}{*{20}{l}} {{m_y}}&{ = \\sum\\limits_{k = - \\infty }^{ + \\infty } {E\\left\\{ {x[k]} \\right\\}h[n - k]} = \\sum\\limits_{k = - \\infty }^{ + \\infty } {{m_x}h[n - k]} }\\\\ {\\,\\,\\,}&{ = {m_x}\\sum\\limits_{k = - \\infty }^{ + \\infty } {h[n - k]} } \\end{array}$$ Using the Fourier transform of the impulse response \\(H(\\Omega ) = {\\mathscr{F}}\\left\\{ {h[n]} \\right\\}\\) ( Equation 3.3 ), this expression simplifies to: (6.9) $$\\begin{array}{*{20}{l}} {{m_y}}&{ = {m_x}\\sum\\limits_{k = - \\infty }^{ + \\infty } {h[n - k]} = {m_x}\\sum\\limits_{n = - \\infty }^{ + \\infty } {h[n]} }\\\\ {\\,\\,\\,}&{ = {m_x}H(\\Omega = 0)} \\end{array}$$ What does this mean? From our knowledge of LTI filter theory, the expression \\({m_y} = {m_x}H(\\Omega = 0)\\) makes sense. The expression says the average value of the input random signal is multiplied by the constant gain factor\u2014the gain at ( \\(\\Omega = 0\\) )\u2014of the linear filter. Because the average value is, indeed, just a constant (DC) value, the non-fluctuating component, this is a realistic result. Note that \\(H(\\Omega ),\\) \\({m_x}\\) and \\({m_y}\\) are all complex in this derivation. We also see through this derivation that, because the input average is stationary, the output average is also stationary.","title":"The mean"},{"location":"Chap_6.html#the-autocorrelation-function","text":"The development of the output correlation proceeds along similar lines: (6.10) $$\\begin{array}{l} {\\varphi _{yy}}[n,n + k] = E\\left\\{ {y[n]{y^*}[n + k]} \\right\\}\\\\ \\,\\,\\,\\,\\,\\,\\,\\, = E\\left\\{ {\\left( {\\sum\\limits_{m = - \\infty }^{ + \\infty } {h[m ]x[n - m ]} } \\right)\\left( {\\sum\\limits_{r = - \\infty }^{ + \\infty } {{h^*}[r]{x^*}[n + k - r]} } \\right)} \\right\\}\\\\ \\,\\,\\,\\,\\,\\,\\,\\, = E\\left\\{ {\\sum\\limits_{m = - \\infty }^{ + \\infty } {\\sum\\limits_{r = - \\infty }^{ + \\infty } {h[m ]{h^*}[r]x[n - m ]{x^*}[n + k - r]} } } \\right\\} \\end{array}$$ Using the distributive property once again: (6.11) $${\\varphi _{yy}}[n,n + k] = \\sum\\limits_{m = - \\infty }^{ + \\infty } {\\sum\\limits_{r = - \\infty }^{ + \\infty } {h[m ]{h^*}[r]E\\left\\{ {x[n - m ]{x^*}[n + k - r]} \\right\\}} }$$ The term within the expectation braces \\(E\\left\\{ \\bullet \\right\\}\\) yields \\({\\varphi _{xx}}[k + m - r]\\) producing: (6.12) $${\\varphi _{yy}}[n,n + k] = \\sum\\limits_{m = - \\infty }^{ + \\infty } {\\sum\\limits_{r = - \\infty }^{ + \\infty } {h[m ]{h^*}[r]{\\varphi _{xx}}[k + m - r]} }$$ Because \\(m\\) and \\(r\\) in Equation 6.12 are simply dummy variables that disappear when the two sums are performed, the result of the double sum, \\({\\varphi _{yy}},\\) will only be a function of \\(k\\) and, of course, the precise forms of the impulse response \\(h[n]\\) and the autocorrelation function \\({\\varphi _{xx}}.\\) If the right side of Equation 6.12 is only a function of \\(k\\) then the left side is only a function of \\(k,\\) as well, and we have: (6.13) $${\\varphi _{yy}}[n,n + k] = {\\varphi _{yy}}[k] = \\sum\\limits_{m = - \\infty }^{ + \\infty } {\\sum\\limits_{r = - \\infty }^{ + \\infty } {h[m ]{h^*}[r]{\\varphi _{xx}}[k + m - r]} }$$ From this we can conclude that if \\({\\varphi _{xx}}[ \\bullet ]\\) is stationary then \\({\\varphi _{yy}}[ \\bullet ]\\) is stationary. We can go further. If we set \\(n = r - m,\\) then: (6.14) $$\\begin{array}{*{20}{l}} {{\\varphi _{yy}}[k]}&{ = \\sum\\limits_{m = - \\infty }^{ + \\infty } {\\sum\\limits_{n = - \\infty }^{ + \\infty } {h[m]{h^*}[m + n]{\\varphi _{xx}}[k - n]} } }\\\\ {\\,\\,\\,}&{ = \\sum\\limits_{n = - \\infty }^{ + \\infty } {{\\varphi _{xx}}[k - n]} \\left( {\\sum\\limits_{m = - \\infty }^{ + \\infty } {h[m]{h^*}[m + n]} } \\right)} \\end{array}$$ We recognize from ordinary (deterministic) signal processing theory that the term within parentheses is the autocorrelation of the impulse response. If this autocorrelation is \\({\\varphi _{hh}}[m]\\) then: (6.15) $${\\varphi _{yy}}[k] = \\sum\\limits_{m = - \\infty }^{ + \\infty } {{\\varphi _{xx}}[k - m]} {\\varphi _{hh}}[m] = {\\varphi _{xx}}[k] \\otimes {\\varphi _{hh}}[k]$$ Our conclusion is that the autocorrelation of the output is stationary and is the convolution of the autocorrelation function of the (random) input signal with the autocorrelation function of the (deterministic) impulse response.","title":"The autocorrelation function"},{"location":"Chap_6.html#the-cross-correlation-function","text":"Finally we can derive the cross-correlation between the input and output as: (6.16) $$\\begin{array}{*{20}{l}} {{\\varphi _{xy}}[k]}&{ = E\\left\\{ {x[n]{y^*}[n + k]} \\right\\}}\\\\ {\\,\\,\\,}&{ = E\\left\\{ {x[n]\\left( {\\sum\\limits_{m = - \\infty }^{ + \\infty } {{h^*}[m ]{x^*}[n + k - m]} } \\right)} \\right\\}}\\\\ {\\,\\,\\,}&{ = \\sum\\limits_{m = - \\infty }^{ + \\infty } {{h^*}[m ]E\\left\\{ {x[n]{x^*}[n + k - m]} \\right\\}} } \\end{array}$$ Once again, the term within the expectation braces gives the stationary autocorrelation function \\({\\varphi _{xx}}[k - m].\\) Continuing, (6.17) $${\\varphi _{xy}}[k] = \\sum\\limits_{m = - \\infty }^{ + \\infty } {{h^*}[m]} {\\varphi _{hh}}[k - m] = {h^*}[k] \\otimes {\\varphi _{xx}}[k]$$ The cross-correlation function is stationary and is the convolution of the complex conjugate of the (deterministic) impulse response with the autocorrelation function of the (random) input signal. We can now express the Fourier transforms of \\({\\varphi _{xx}}[k]\\) and \\({\\varphi _{yy}}[k]\\) in terms of known quantities. (6.18) $$\\begin{array}{*{20}{l}} {{S_{yy}}(\\Omega )}&{ = {\\mathscr{F}}\\left\\{ {{\\varphi _{yy}}[k]} \\right\\} = {\\mathscr{F}}\\left\\{ {{\\varphi _{xx}}[k] \\otimes {\\varphi _{hh}}[k]} \\right\\}}\\\\ {\\,\\,\\,}&{ = {S_{xx}}(\\Omega )\\;{S_{hh}}(\\Omega )} \\end{array}$$ But using the result from Fourier theory that \\({\\mathscr{F}}\\left\\{ {{h^*}[n]} \\right\\} = {H^*}\\left( { - \\Omega } \\right)\\) gives: (6.19) $$\\begin{array}{*{20}{l}} {{S_{hh}}(\\Omega )}&{ = {\\mathscr{F}}\\left\\{ {\\sum\\limits_{m = - \\infty }^{ + \\infty } {h[m]{h^*}[m + n]} } \\right\\}}\\\\ {\\,\\,\\,}&{ = H( - \\Omega )\\;{H^*}( - \\Omega ) = {{\\left| {H( - \\Omega )} \\right|}^2}} \\end{array}$$ Therefore, (6.20) $${S_{yy}}(\\Omega ) = {\\left| {H( - \\Omega )} \\right|^2}{S_{xx}}(\\Omega )$$ If the impulse response \\(h[n]\\) of the deterministic system is real , then this is equivalent to: (6.21) $${S_{yy}}(\\Omega ) = {\\left| {H(\\Omega )} \\right|^2}{S_{xx}}(\\Omega )$$ Returning to the complex form of \\(h[n],\\) the cross power density spectrum can be similarly shown to be: (6.22) $${S_{xy}}(\\Omega ) = {H^*}( - \\Omega ){S_{xx}}(\\Omega )$$ Again, if the impulse response \\(h[n]\\) of the deterministic system is real , then this is equivalent to: (6.23) $${S_{xy}}(\\Omega ) = H(\\Omega ){S_{xx}}(\\Omega )$$ Based upon the use of these results we are now in a position to provide an interpretation of the power spectrum \\({S_{xx}}(\\Omega ).\\) We see from Equation 5.3 that for \\(k = 0\\) : (6.24) $${\\varphi _{xx}}[0] = E\\left\\{ {x[n]{x^*}[n]} \\right\\}\\; = E\\left\\{ {{{\\left| {x[n]} \\right|}^2}} \\right\\}\\; \\ge 0$$ Similarly \\({\\varphi _{yy}}[k] \\ge 0\\) and (6.25) $$\\begin{array}{*{20}{l}} {{\\varphi _{yy}}[0]}&{ = \\frac{1}{{2\\pi }}\\int\\limits_{ - \\pi }^{ + \\pi } {{S_{yy}}(\\Omega )} d\\Omega }\\\\ {\\,\\,\\,}&{ = \\frac{1}{{2\\pi }}\\int\\limits_{ - \\pi }^{ + \\pi } {{{\\left| {H( - \\Omega )} \\right|}^2}{S_{xx}}(\\Omega )} d\\Omega } \\end{array}$$ Let \\(H(\\Omega )\\) be a (complex) bandpass filter (as shown in Figure 6.2 ) such that within the pass-band the spectrum \\({S_{xx}}(\\Omega )\\) is essentially constant. Figure 6.2: Power spectrum \\({S_{xx}}(\\Omega )\\) (n dark red) and a linear, bandpass filter \\({\\left| {H(\\Omega )} \\right|^2}\\) (in dark green). The filter has width \\(\\Delta \\Omega\\) and is centered at \\({\\Omega _o}.\\) For complex random processes \\({\\varphi _{xx}}[k] = \\varphi _{xx}^*[ - k],\\) Equation 5.5 , which means that \\({S_{xx}}(\\Omega )\\) is real Equation 5.26 . For a sufficiently small passband \\(\\Delta \\Omega,\\) we can write: (6.26) $$\\begin{array}{*{20}{l}} {{\\varphi _{yy}}[0]}&{ = \\frac{1}{{2\\pi }}{S_{yy}}(\\Omega = {\\Omega _0})\\Delta \\Omega }&{ \\ge 0}\\\\ {\\,\\,\\,}&{ = \\frac{1}{{2\\pi }}{{\\left| {H( - {\\Omega _0})} \\right|}^2}{S_{xx}}({\\Omega _0})\\Delta \\Omega }&{ \\ge 0} \\end{array}$$ Because \\({S_{xx}}(\\Omega )\\) is real, we immediately have that (6.27) $${S_{xx}}({\\Omega _0}) \\ge 0$$ for all choices of \\({\\Omega _0}.\\) Further \\({\\left| {y[n]} \\right|^2}\\) is (by definition) the instantaneous power in a signal (including random signals) and thus \\({\\varphi _{yy}}[0] = E\\left\\{ {{{\\left| {y[n]} \\right|}^2}} \\right\\}\\) is the expected power in the output signal at any instant. This means that: (6.28) $$\\begin{array}{*{20}{l}} {{\\varphi _{yy}}[0]}&{ = \\frac{1}{{2\\pi }}{S_{yy}}({\\Omega _0})\\Delta \\Omega }\\\\ {\\,\\,\\,}&{ = \\frac{1}{{2\\pi }}{{\\left| {H( - {\\Omega _0})} \\right|}^2}{S_{xx}}({\\Omega _0})\\Delta \\Omega } \\end{array}$$ has the unit of power [Watts]. \\({S_{xx}}(\\Omega )\\) like \\({S_{yy}}(\\Omega )\\) is, therefore, expressed in Watts per unit frequency [Watts/Hz] and is thus a power density spectrum . Other interesting and useful results can also be derived at this point: 1) We would like to show that the maximum value of the autocorrelation function occurs at \\(k = 0.\\) We begin with: (6.29) $${\\varphi _{xx}}[k] = \\frac{1}{{2\\pi }}\\int\\limits_{ - \\pi }^{ + \\pi } {{S_{xx}}(\\Omega )} {e^{j\\Omega k}}d\\Omega$$ Taking the absolute value of both sides: (6.30) $$\\begin{array}{*{20}{l}} {\\left| {{\\varphi _{xx}}[k]} \\right|}&{ = \\frac{1}{{2\\pi }}\\left| {\\int\\limits_{ - \\pi }^{ + \\pi } {{S_{xx}}(\\Omega )} {e^{j\\Omega k}}d\\Omega } \\right|}\\\\ {\\,\\,\\,}&{ \\le \\frac{1}{{2\\pi }}\\int\\limits_{ - \\pi }^{ + \\pi } {\\left| {{S_{xx}}(\\Omega )} \\right|} \\left| {{e^{j\\Omega k}}} \\right|d\\Omega } \\end{array}$$ The inequality holds because the absolute value of an integral is always less than (or equal to) the integral of the absolute value. This is easy to see if we consider the integral as a way of measuring the area under a curve. The total area will be greater if we first make all contributions positive. Because \\(\\left| {{e^{j\\Omega k}}} \\right| = 1\\) and because the power spectrum is real and everywhere positive, Equation 6.27 , we have: (6.31) $$\\begin{array}{*{20}{l}} {\\left| {{\\varphi _{xx}}[k]} \\right|}&{ \\le \\frac{1}{{2\\pi }}\\int\\limits_{ - \\pi }^{ + \\pi } {\\left| {{S_{xx}}(\\Omega )} \\right|} d\\Omega }\\\\ {\\,\\,\\,}&{ = \\frac{1}{{2\\pi }}\\int\\limits_{ - \\pi }^{ + \\pi } {{S_{xx}}(\\Omega )} d\\Omega = {\\varphi _{xx}}[0]} \\end{array}$$ Finally, (6.32) $$\\left| {{\\varphi _{xx}}[k]} \\right| \\le {\\varphi _{xx}}[0]$$ An alternative (and instructive) way to prove this result is developed in Problem 6.6 . 2) We might well ask under what circumstance can there be another value of \\(k\\) such that \\(\\left| {{\\varphi _{xx}}[k]} \\right| = {\\varphi _{xx}}[0].\\) The most common situation where equality is achieved is when the autocorrelation function contains a periodic component. That is, if \\({\\varphi _{xx}}[k] = {\\varphi _{xx}}[k + K]\\) then the maximum value will be repeated every \\(K\\) time instances. This is illustrated in the case study, Figure 5.6a . There are more elaborate ways of describing this situation but this will suffice for our introductory level. 3) Finally we can determine a bound on the average output power \\({\\varphi _{yy}}[0]\\) given the average input power and the LTI filter characteristic \\(H(\\Omega ).\\) (6.33) $$E\\left\\{ {{{\\left| {y[n]} \\right|}^2}} \\right\\} = {\\varphi _{yy}}[0] = \\frac{1}{{2\\pi }}\\int\\limits_{ - \\pi }^{ + \\pi } {{{\\left| {H( - \\Omega )} \\right|}^2}{S_{xx}}(\\Omega )d\\Omega }$$ Let \\({\\Omega _m}\\) be the frequency at which the filter has its maximum gain \\(\\left| {H( - {\\Omega _m})} \\right|.\\) This implies: (6.34) $$E\\left\\{ {{{\\left| {y[n]} \\right|}^2}} \\right\\} \\le \\frac{{{{\\left| {H( - {\\Omega _m})} \\right|}^2}}}{{2\\pi }}\\int\\limits_{ - \\pi }^{ + \\pi } {{S_{xx}}(\\Omega )d\\Omega }$$ (6.35) $${\\varphi _{yy}}[0] \\le {\\left| {H( - {\\Omega _m})} \\right|^2}{\\varphi _{xx}}[0]$$ The average output power will attain the maximum if and only if (6.36) $${S_{xx}}(\\Omega ) = B\\delta (\\Omega - {\\Omega _m}) + B\\delta (\\Omega + {\\Omega _m})$$ that is, if \\({\\varphi _{xx}}[k]\\) is of the form \\(\\cos \\left( {{\\Omega _m}k} \\right).\\) This follows directly from Equation 6.33 and Equation 6.34 . The only way for the maximum to be achieved is if all the spectral power is concentrated at the frequencies \\(\\pm {\\Omega _m}\\) where the filter has its maxima.","title":"The cross-correlation function"},{"location":"Chap_6.html#example-a-world-of-random-events-a-case-study","text":"The relationship described in Equation 6.32 might seem like a rather abstract result. In this example, we hope to show that use of the result can lead to useful insights into complex systems. The data shown in Figure 6.3 are the price at the \u201cwellhead\u201d of a barrel of oil (\u201cBrent crude\u201d), \\(c[n],\\) and the price of a liter of refined automobile gasoline (benzine) at the \u201cpump\u201d \\(g[n].\\) The graphs show the development of the price over a period of months. ( a ) Brent oil price per barrel starting 1 Jan 1990 ( b ) Brent price 2 Aug 1990 \u00b1 30 days ( c ) Gasoline price per liter starting 1 Jan 1990 Figure 6.3: Price evolution of crude oil \\(c[n\\rbrack\\) and refined gasoline \\(g[n\\rbrack\\) ( a ) Barrel price from 1 January 1990 to 16 October 1990 (289 days). The day of the event is indicated by the arrow. ( b ) Daily price evolution surrounding 2 August 1990, that is, day 214 \u00b1 30 days, ( c ) Liter price (to consumers) from 1 January 1990 to 16 October 1990 (289 days). The day of the event is indicated by the arrow. On 2 August 1990, the 214th day of that year, an event occurred in the Middle East that influenced the world-wide price of crude oil. The steep rise in price of a barrel of oil, shown in the middle panel of Figure 6.3 , attests to this. An increase in the price of a liter of gasoline at retail distribution points would also follow from this. The question we pose is: what is the delay between a rise in prices at the wellhead and a rise in prices at the \u201cpump\u201d? How many days does it take before the price rises in the retail sale of gasoline? To answer this we assume that the price of gasoline \\(g[n]\\) is a delayed version, that is function, of the price of crude oil \\(c[n].\\) But this cannot be expressed as simply \\(g[n] = c[n - k].\\) Between these two prices are complicated processes, some industrial and some marketplace. Nevertheless, one cannot help but being struck by the similarity of the top and bottom curves in Figure 6.3 . The cross-correlation between the two prices, under the assumption that the major effect is a time delay, can help us find the answer. Assuming that the system is a pure time delay, \\(h[n] = \\delta [n - k],\\) and using Equation 6.17 gives: (6.37) $$\\begin{array}{*{20}{l}} {{\\varphi _{cg}}[k]}&{ = {h^*}[k] \\otimes {\\varphi _{cc}}[k] = \\delta [n - k] \\otimes {\\varphi _{cc}}[k]}\\\\ {\\,\\,\\,}&{ = {\\varphi _{cc}}[n - k]} \\end{array}$$ A simple substitution, \\(m = n - k,\\) allows us to rewrite this as (6.38) $${\\varphi _{cg}}[n - m] = {\\varphi _{cc}}[m]$$ Applying Equation 6.32 to Equation 6.38 means that, given the model of a simple delay element, the time \\(m = 0\\) when the autocorrelation is a maximum is the same as the time \\(m = n\\) when the cross-correlation is a maximum. The cross-correlation is illustrated in Figure 6.4 . Figure 6.4: Cross-correlation \\({\\varphi _{cg}}[k\\rbrack\\) between the crude oil price and the gasoline pump price over an interval of 51 days. Day 0 is 2 August 1990, day 214 of the year. The position of maximum correlation is indicated by the arrow. The time at which the maximum occurs is day 18. Our estimate for the time delay between the wellhead and the gasoline pump, in the midst of all the stochastic variations and the (over)simplification of the model, is 18 days.","title":"Example: A world of random events - a case study"},{"location":"Chap_6.html#problems","text":"","title":"Problems"},{"location":"Chap_6.html#problem-61","text":"The input to a discrete-time, LTI system is a stochastic signal, \\(x[n].\\) At each time step the output is \\(+ \\delta [n - k]\\) with probability \\(p\\) or \\(- \\delta [n - k]\\) with probability \\(1 - p.\\) Thus we can write: \\[x[n] = \\sum\\limits_{k = --\\infty }^{ + \\infty } {{a_k}\\delta [n - k]}\\] where \\[{a_k} = \\left\\{ {\\begin{array}{*{20}{l}} { + 1}&{{\\mathop{\\rm with}\\nolimits} \\,probability\\,p}\\\\ { - 1}&{{\\mathop{\\rm with}\\nolimits} \\,probability\\,1 - p} \\end{array}} \\right.\\] The LTI system has \\(h[n] = {\\left( {\\frac{1}{4}} \\right)^n}u[n].\\) Draw and label one possible stochastic signal \\(x[n]\\) from this random process. Draw and label \\(y[n]\\) the output signal corre\u00adsponding to your choice of \\(x[n].\\) Determine \\({m_y} = E\\left\\{ {y[n]} \\right\\}.\\) Your answer should not contain any integrals or summations. Determine \\({\\varphi _{yy}}[k = 0] = {\\left. {E\\left\\{ {y[n]\\,{y^*}[n + k]} \\right\\}} \\right|_{k = 0}}.\\)","title":"Problem 6.1"},{"location":"Chap_6.html#problem-62","text":"The impulse response of a discrete-time, LTI system is given by: \\[h[n] = 3\\delta [n] - 8{\\left( {\\frac{1}{3}} \\right)^{n - 1}}u[n - 1]\\] The input signal is a real, ergodic signal \\(x[n]\\) where: \\[{\\varphi _{xx}}[k] = E\\left\\{ {x[n]\\,{x^*}[n + k]} \\right\\} = {\\left( {\\frac{1}{3}} \\right)^{ - \\left| k \\right|}}\\] The output signal of the LTI system is \\(y[n].\\) Determine \\({m_y} = E\\left\\{ {y[n]} \\right\\}.\\) Determine \\({\\varphi _{yy}}[k] = E\\left\\{ {y[n]\\,{y^*}[n + k]} \\right\\}.\\)","title":"Problem 6.2"},{"location":"Chap_6.html#problem-63","text":"Discuss the following proposition: The function \\(f[k]\\) given below cannot be the auto-correlation function of a stochastic signal. \\[f[k] = \\left\\{ {\\begin{array}{*{20}{l}} 1&{\\left| k \\right| \\le 7}\\\\ 0&{\\left| k \\right| > 7} \\end{array}} \\right.\\]","title":"Problem 6.3"},{"location":"Chap_6.html#problem-64","text":"When the discrete-time input signal \\(x[n]\\) is white noise with autocorrelation function \\({\\varphi _{xx}}[k] = \\delta [k],\\) the output signal from an LTI system is ergodic with power spectral density: \\[{S_{yy}}(\\Omega ) = \\frac{9}{{13 - 12\\cos (\\Omega )}}\\] Determine two possible causal, LTI filters \\({H_1}\\left( \\Omega \\right)\\) and \\({H_2}\\left( \\Omega \\right)\\) that could lead to this output power density spectrum. Given either of the filters, \\({H_1}\\left( \\Omega \\right)\\) or \\({H_2}\\left( \\Omega \\right),\\) from part ( a ), determine another, different noise signal \\(q[n]\\) that would yield the same \\({S_{yy}}(\\Omega )\\) as given in part ( a ).","title":"Problem 6.4"},{"location":"Chap_6.html#problem-65","text":"An ergodic process, \\(x[n],\\) is input to an LTI system with impulse response \\(h[n]\\) and Fourier transform \\(H(\\Omega ).\\) The output is \\(y[n].\\) It is known that \\(h[n = 0] \\ne 0.\\) Discuss the following proposition: If the mean of the input \\(E\\left\\{ {x[n]} \\right\\} = {m_x} \\ne 0\\) then \\(E\\left\\{ {y[n]} \\right\\} = {m_y} \\ne 0.\\)","title":"Problem 6.5"},{"location":"Chap_6.html#problem-66","text":"Consider the following expression for a real, ergodic signal \\(x[n]\\) : (6.39) $$E\\left\\{ {{{\\left| {x[n] \\pm x[n + k]} \\right|}^2}} \\right\\} \\geqslant 0$$ Why is this expected value non-negative? Use this expression to prove Equation 6.32 .","title":"Problem 6.6"},{"location":"Chap_6.html#laboratory-exercises","text":"","title":"Laboratory Exercises"},{"location":"Chap_6.html#laboratory-exercise-61","text":"We now have the tools to analyze and discuss noise processes. We start with \u201cwhite noise\u201d. To start the exercise, click on the icon to the left.","title":"Laboratory Exercise 6.1"},{"location":"Chap_6.html#laboratory-exercise-62","text":"We continue the analysis and discussion of noise processes. We start with \u201cbinary noise\u201d, a process that can be generated by flipping a coin. To start the exercise, click on the icon to the left.","title":"Laboratory Exercise 6.2"},{"location":"Chap_6.html#laboratory-exercise-63","text":"Can you estimate the parameters of real, ergodic noise processes based upon information from their number of samples N , their estimated autocorrelation function ${\\varphi _{ \\bullet \\bullet }}[k]$, and/or their estimated power spectral density ${S_{ \\bullet \\bullet }}(\\Omega ).$ To start the exercise, click on the icon to the left.","title":"Laboratory Exercise 6.3"},{"location":"Chap_6.html#laboratory-exercise-64","text":"When studying stochastic processes you not only have the mathematical tools we have presented, you also have your eyes and ears. To start the exercise, click on the icon to the left.","title":"Laboratory Exercise 6.4"},{"location":"Chap_6.html#laboratory-exercise-65","text":"We continue studying stochastic processes using the mathematical tools we have presented and your eyes and ears. To start the exercise, click on the icon to the left.","title":"Laboratory Exercise 6.5"},{"location":"Chap_6.html#laboratory-exercise-66","text":"We continue studying stochastic processes using the mathematical tools we have presented and your eyes and ears. To start the exercise, click on the icon to the left.","title":"Laboratory Exercise 6.6"},{"location":"Chap_6.html#laboratory-exercise-67","text":"Let us explore the effect that filtering has on various types of noise. As tools, we will use the noise signal itself, its amplitude distribution, its autocorrelation function, its power density spectrum, and your eyes and ears. To start the exercise, click on the icon to the left.","title":"Laboratory Exercise 6.7"},{"location":"Chap_6.html#laboratory-exercise-68","text":"How much information can you glean from the mathematical tools we have developed? To start the exercise, click on the icon to the left.","title":"Laboratory Exercise 6.8"},{"location":"Chap_7.html","text":"The Langevin Equation \u2013 A Case Study \u00b6 In 1908 Prof. Paul Langevin described how a physical system modeled by a differential equation responds to a stochastic input. His work resulted in the concept of the Langevin equation . A particle of mass \\(m\\) is subject to random collision forces, \\(f(t),\\) from many small, molecules. The term \\(f(t)\\) is frequently described as the driving force. Further, the assumption is usually made that \\(f(t)\\) results from a stationary random process with a Gaussian probability density function and an autocorrelation function of the form \\({\\varphi _{ff}}(\\tau) = {F_o}\\delta (\\tau ).\\) Non-coincident time samples are uncorrelated. The mathematical description of \\(f(t)\\) is a Gaussian, white-noise, ergodic process. The motion of the particle is held back (retarded) by a viscous, frictional force that is proportional to the velocity of the particle. The equation of motion can be written for the velocity as a function of time or the position as a function of time: (7.1) $$\\begin{array}{l} m\\frac{{dv(t)}}{{dt}} = f(t) - \\lambda v\\\\ m\\frac{{{d^2}x(t)}}{{d{t^2}}} = f(t) - \\lambda \\frac{{dx(t)}}{{dt}} \\end{array}$$ where \\(\\lambda\\) is the viscous, damping coefficient and both \\(m\\) and \\(\\lambda\\) are greater than zero. This stochastic differential equation describes Brownian motion . We shall begin with the velocity, \\(v(t),\\) and consider only one spatial dimension. In this case-study our intention is to illustrate how the tools we have developed can be used to analyze this random process. (See also TPM .) The tools, however, have been developed in the context of discrete-time so the first step is to transform this first-order differential equation into a difference equation. As so many problems are studied, simulated, measured, and controlled with digital systems, this is not an unreasonable first step. From t to n \u00b6 There are several procedures to transform a continuous-time LTI system\u2014one that is based upon a linear differential equation with constant coefficients with input \\(f(t)\\) and output \\(v(t)\\) or \\(x(t)\\) \u2014into a discrete-time difference equation with input \\(f[n]\\) and output \\(v[n]\\) or \\(x[n].\\) These include 1) impulse-invariant sampling, 2) backward-difference equation, and 3) bilinear transformation. For a thorough discussion of this topic see Section 10.8 of Oppenheim 1 . Which one of the three techniques should we use? All three have advantages and disadvantages. For the purpose of this textbook, we will use the impulse-invariant sampling as it is easy to understand and leads to expressions that are easy to analyze in a case-study such as this. Impulse-invariant sampling \u00b6 If the impulse response is bandlimited, we sample the impulse response at an appropriate rate (above the Nyquist frequency) and then use z -transform techniques to produce the difference equation. Thus, if \\(h(t)\\) is the bandlimited impulse response of a Langevin equation whose samples are \\(h[n] = h\\left( {n{T_s}} \\right),\\) the transfer function will be given by: (7.2) $$H(z) = \\sum\\limits_{n = - \\infty }^{ + \\infty } {h[n]{z^{ - n}} = } \\sum\\limits_{n = - \\infty }^{ + \\infty } {h(n{T_s}){z^{ - n}}}$$ where \\({T_s}\\) is the suitably-chosen sampling period. The associated sampling frequency is, thereby, \\({\\omega _s} = 2\\pi /{T_s}.\\) The impulse response of the differential equation for velocity in Equation 7.1 is causal, stable, straightforward to determine, and given by: (7.3) $${h_v}(t) = \\left( {\\frac{1}{m}} \\right){e^{ - \\left( {\\lambda t/m} \\right)}}u(t) = \\left( {\\frac{1}{m}} \\right){e^{ - \\left( {t/\\theta } \\right)}}u(t)$$ We have introduced the time constant \\(\\theta = m/\\lambda\\) and will use it extensively. The sampled impulse response and its z -transform are given by: (7.4) $$\\begin{array}{l} {h_v}[n] = \\left( {\\frac{1}{m}} \\right){e^{ - \\left( {\\lambda {T_s}/m} \\right)n}}u[n]\\\\ {H_v}(z) = \\frac{{V(z)}}{{F(z)}} = \\sum\\limits_{n = - \\infty }^{ + \\infty } {\\left( {\\frac{1}{m}} \\right){e^{ - \\left( {\\lambda {T_s}/m} \\right)n}}u[n]\\,{z^{ - n}}} \\\\ {H_v}(z) = \\left( {\\frac{1}{m}} \\right)\\sum\\limits_{n = 0}^{ + \\infty } {{{\\left( {{e^{ - \\left( {\\lambda {T_s}/m} \\right)}}{z^{ - 1}}} \\right)}^n}} = \\frac{{1/m}}{{1 - {e^{ - \\left( {\\lambda {T_s}/m} \\right)}}{z^{ - 1}}}} \\end{array}$$ with a region-of-convergence (ROC) given by \\(\\left| z \\right| > {e^{ - \\lambda {T_s}/m}}.\\) This leads to the difference equation: (7.5) $$v[n] - \\left( {{e^{ - \\left( {\\lambda {T_s}/m} \\right)}}} \\right)v[n - 1] = \\left( {\\frac{1}{m}} \\right)f[n]$$ This is the discrete-time version of the Langevin equation, Equation 7.1 . The input \\(f[n]\\) is the Gaussian, white-noise process. See Problem 7.1 to explore an important issue related to Equation 7.5 . This all seems quite straightforward but we have neglected one significant detail. The impulse response must be bandlimited so that a finite \\({T_s}\\) can be chosen. But given a finite number of terms in the sum, no impulse response that is of the form \\(\\sum\\nolimits_k {{A_k}{e^{ - {s_k}t}}u(t)}\\) can be bandlimited . See Problem 7.2 . Unless the aliasing induced by the use of a finite sampling interval is negligible, the impulse invariant technique can lead to erroneous results and conclusions. This, in turn, implies that if we insist on using this technique we must sample at a very high rate. As we shall soon see, in the case of Equation 7.3 , a sampling frequency of \\({\\omega _s} \\ge 200\\left( {\\lambda /m} \\right) = 200/\\theta\\) is warranted. How big is big? How small is small? \u00b6 The Langevin equation is a description appropriate for a small particle that is being battered by even smaller particles. See Section 15.5 of Reif 2 for an elegant presentation of this model. To appreciate what this means let us examine the case of a gold sphere whose radius is 10 \\(\\mu\\) m in a water bath (test tube) at a temperature of \\(\\Psi\\) = 21 \u00baC. The radius of a water molecule is about 0.14 nm, about \\({10^{ - 5}}\\) that of the gold particle. After a period of time the gold particle will sink to the bottom of the test tube under the force of gravity. The terminal velocity of the gold particle is, however, only 4 mm/s so we will have a few seconds to perform our measurements. In that time we will focus on lateral motion ( \\(x\\) -direction) as opposed to axial ( \\(z\\) -direction) motion. In the time constant \\(\\theta = m/\\lambda\\) defined in Equation 7.3 , \\(\\lambda\\) is the damping factor and according to Stokes\u2019 Law given by: (7.6) $$\\lambda = 6\\pi \\eta R$$ The parameter \\(\\eta\\) is the dynamic viscosity of the fluid (water) and \\(R\\) is the \u201chydrodynamic\u201d radius of the particle (gold). Substituting the appropriate values ( \\(\\eta = 1.002\\) cP, \\(R = 10\\) \\(\\mu\\) m, \\(m = 81\\) ng) gives \\(\\lambda = 188.9\\) \\(\\mu\\) g/s and \\(\\theta\\) = 428 \\(\\mu\\) s. This is a long time compared to the average time interval between collisions of the gold sphere and water molecules which, to a rough approximation, is 10 fs. We can, therefore, consider the gold particle as being driven by a stochastic force with about \\({10^{10}}\\) collisions in one time constant \\(\\theta.\\) These collisions with the gold sphere occur from all possible directions (4 \\(\\pi\\) steradians) and the large number means that the Central Limit Theorem applies and the driving force \\(f(t),\\) the sum of all the independent collision forces, can be modeled as having a Gaussian amplitude distribution. Choosing the sampling period \u00b6 Based upon a value for \\(\\theta\\) that we can calculate, we now look at the appropriate value of the sampling interval \\({T_s}\\) for this example. The impulse response is not bandlimited so any sampling represents undersampling. As we shall see in Figure 7.1 , however, a finite choice for the sampling interval \\({T_s}\\) can be justified and in practice will appear to be oversampling. The \u201cLangevin filter\u201d associated with Equation 7.3 has a lowpass characteristic: (7.7) $$\\begin{array}{l} {h_v}(t) = \\left( {\\frac{1}{m}} \\right){e^{ - \\left( {\\lambda t/m} \\right)}}u(t)\\\\ \\left| {{H_v}(\\omega )} \\right| = \\left( {\\frac{1}{m}} \\right)\\frac{1}{{\\sqrt {{\\omega ^2} + {{\\left( {\\lambda /m} \\right)}^2}} }} \\end{array}$$ The frequency \\({\\omega _c}\\) at which the amplitude-squared is down by a factor of two from its value at \\(\\omega = 0\\) is given by \\({\\omega _c} = \\lambda /m\\) and might seem to qualify as a \u201chighest\u201d frequency. Using the Nyquist criterion and choosing \\({\\omega _s} = 2{\\omega _c} = 2\\lambda /m,\\) however, is not enough to avoid aliasing. To do so we must choose a higher frequency \\({\\omega _{\\max }}\\) in the spectrum than \\({\\omega _c}.\\) If we require that the filter amplitude-squared is down by a factor of 100 (not 2) from the filter value at \\(\\omega = 0,\\) then \\({\\omega _{\\max }} \\simeq 10{\\omega _c}.\\) The (Nyquist) sampling frequency is then approximated by \\({\\omega _s} = 2{\\omega _{\\max }} =\\) \\(2 \\bullet 10{\\omega _c} = 20\\lambda /m.\\) This sampling issue is illustrated in Figure 7.1[a,b] . ( a ) Sampling at ${\\omega _s} = 2\\pi /{T_s} = 2\\lambda /m.$ Langevin filter spectrum in blue , sampled Langevin filter spectrum in dark red ( b ) Sampling at ${\\omega _s} = 2\\pi /{T_s} = 20\\lambda /m.$ Sampled Langevin filter spectrum ( c ) Sampling at ${\\omega _s} = 2\\pi /{T_s} = 200\\lambda /m.$ Sampled Langevin filter spectrum Figure 7.1: Spectral magnitude \\(\\lvert {{H_v}\\left( \\omega \\right)} \\rvert\\) displayed in blue . Spectrum after sampling at various frequencies \\({\\omega _s} = 2\\pi /{T_s}\\) displayed in dark red . Note the change in the scale of the frequency axes between the three graphs. For the numerical values presented in the text, the value of \\(\\lambda /m\\) = 2334 rad/s (371 Hz). It should be clear that using a sampling frequency of \\(2\\lambda /m\\) or \\(20\\lambda /m\\) is insufficient to minimize aliasing. At \\({\\omega _s} = 200{\\omega _c} = 200\\lambda /m,\\) as illustrated in Figure 7.1c , the aliasing is perhaps acceptable. This is the value that we shall use in the remainder of this case-study. The sampling interval is, therefore, chosen as \\({T_s} = 2\\pi /{\\omega _s} = \\pi m/100\\lambda\\) = 13.4 \\(\\mu\\) s. The question of \u201cwhat is acceptable\u201d is a tricky one. Formally, there is no \u201chighest frequency\u201d and thus no Nyquist frequency. Practically, a sampling frequency as illustrated in Figure 7.1 c means that the damage (distortion) caused by aliasing is confined to the highest frequencies where the signal energy is already quite small. If this energy is small compared to the noise levels at these same frequencies, then the choice of \\({T_s}\\) can be considered \u201cacceptable\u201d. This is not a mathematical choice, however, but an engineering one. The comparison of signal energy and noise energy is the subject of Chapter 8 . The Langevin velocity equation \u00b6 Let us begin with the velocity equation, its original form, and our difference equation based upon the impulse-invariant transformation: (7.8) $$\\begin{array}{*{20}{l}} {m\\frac{{dv(t)}}{{dt}} + \\lambda v(t) = f(t)}\\\\ {v[n] - \\left( {{e^{ - \\left( {\\lambda {T_s}/m} \\right)}}} \\right)v[n - 1] = \\left( {\\frac{1}{m}} \\right)f[n]} \\end{array}$$ The driving force is Gaussian, white noise with the following characteristics: (7.9) $$\\begin{array}{l} {\\varphi _{ff}}[k] = {F_o}\\delta [k]\\\\ {S_{ff}}(\\Omega ) = {F_o} \\end{array}$$ We now appeal to Equation 5.8 , Equation 5.2 , and Equation 5.4 which are summarized below: (7.10) $$\\begin{array}{l} \\mathop {\\lim }\\limits_{k \\to \\infty } \\left\\{ {{\\varphi _{ff}}[k]} \\right\\} = {\\left| {{m_f}} \\right|^2}\\\\ {\\gamma _{ff}}[0] = {\\varphi _{ff}}[0] - {\\left| {{m_f}} \\right|^2} = \\sigma _f^2 \\end{array}$$ Substituting the values from Equation 7.9 into Equation 7.10 yields the results that \\({m_f} = \\left\\langle {f[n]} \\right\\rangle = 0\\) and \\({\\sigma _f} = \\sqrt {{F_o}}.\\) The average value of the driving force is zero. In this one-dimensional system there is\u2014on the average\u2014just as much force coming from the left as from the right. The standard deviation of the force is \\(\\sqrt {{F_o}}.\\) But this describes the input driving force. What are the characteristics of the random process that describes the particle velocity? Autocorrelation function \u00b6 To answer this question we need to compute the autocorrelation of the velocity \\({\\varphi _{vv}}[k]\\) and its power spectral density \\({S_{vv}}(\\Omega ).\\) The autocorrelation follows from Equation 6.15 , specifically \\({\\varphi _{vv}}[k] = {\\varphi _{ff}}[k] \\otimes {\\varphi _{hh}}[k]\\) where \\({\\varphi _{hh}}[k]\\) is the autocorrelation function of the deterministic impulse response of the Langevin filter. That impulse response follows from Equation 7.8 and is given by: (7.11) $${h_v}[n] = \\left( {\\frac{1}{m}} \\right){e^{ - (\\lambda {T_s}/m)n}}u[n] = \\left( {\\frac{1}{m}} \\right){\\rho ^n}u[n]$$ where we have set \\(\\rho = {e^{ - \\left( {\\lambda {T_s}/m} \\right)}}\\) and clearly \\(0 < \\rho < 1.\\) It follows that: (7.12) $$\\begin{array}{*{20}{l}} {{\\varphi _{hh}}[k]}&{ = {{\\left( {\\frac{1}{m}} \\right)}^2}\\sum\\limits_{n = 0}^{ + \\infty } {{\\rho ^{2n + \\left| k \\right|}}} }\\\\ {\\,\\,\\,}&{ = {{\\left( {\\frac{1}{m}} \\right)}^2}\\left( {\\frac{1}{{1 - {\\rho ^2}}}} \\right){\\rho ^{\\left| k \\right|}}} \\end{array}$$ At this point you should notice some similarities to calculations performed in Equation 5.18 and Equation 5.19 including the use of the evenness of the autocorrelation function. Power spectral density \u00b6 The power spectral density associated with the deterministic signal \\(h[n],\\) \\({S_{hh}}(\\Omega ) = {\\mathscr{F}}\\left\\{ {{\\varphi _{hh}}[k]} \\right\\},\\) is given by: (7.13) $$\\begin{array}{*{20}{l}} {{S_{hh}}(\\Omega )}&{ = {\\mathscr{F}}\\left\\{ {{{\\left( {\\frac{1}{m}} \\right)}^2}\\left( {\\frac{1}{{1 - {\\rho ^2}}}} \\right){\\rho ^{\\left| k \\right|}}} \\right\\}}\\\\ {\\,\\,\\,}&{ = {{\\left( {\\frac{1}{m}} \\right)}^2}\\left( {\\frac{1}{{1 + {\\rho ^2} - 2\\rho \\cos \\Omega }}} \\right)} \\end{array}$$ Note that the real and even autocorrelation function \\({{\\varphi _{hh}}[k]}\\) has led to a real and even power spectral density \\({S_{hh}}(\\Omega ).\\) The next step is to calculate \\({{\\varphi _{vv}}[k]}\\) and \\({S_{vv}}(\\Omega )\\) but that is straightforward given Equation 6.15 and Equation 7.9 . (7.14) $$\\begin{array}{*{20}{l}} {{\\varphi _{vv}}[k]}&{ = {\\varphi _{ff}}[k] \\otimes {\\varphi _{hh}}[k]}\\\\ {\\,\\,\\,}&{ = {F_o}\\delta [k] \\otimes {\\varphi _{hh}}[k] = {F_o}{\\varphi _{hh}}[k]}\\\\ {\\,\\,\\,}&{ = {{\\left( {\\frac{1}{m}} \\right)}^2}\\left( {\\frac{{{F_o}}}{{1 - {\\rho ^2}}}} \\right){\\rho ^{\\left| k \\right|}}}\\\\ {\\,\\,\\,}&{\\,\\,\\,}\\\\ {{S_{vv}}(\\Omega )}&{ = {S_{ff}}(\\Omega ){S_{hh}}(\\Omega ) = {F_o}{S_{hh}}(\\Omega )}\\\\ {\\,\\,\\,}&{ = {{\\left( {\\frac{1}{m}} \\right)}^2}\\left( {\\frac{{{F_o}}}{{1 + {\\rho ^2} - 2\\rho \\cos \\Omega }}} \\right)} \\end{array}$$ These two descriptions of the filtered random process\u2014a white, Gaussian process filtered through the Langevin velocity equation\u2014are illustrated in Figure 7.2 . ( a ) Autocorrelation ${{\\varphi _{vv}}[k\\rbrack}$ of the 1-D Langevin velocity process ( b ) Power spectral density ${{S_{vv}}(\\Omega )}$ of the 1-D Langevin velocity process Figure 7.2: The power spectral density is plotted for the baseband \\(- \\pi \\lt \\Omega \\le + \\pi.\\) Curves shown here are for two different values of \\(\\rho\\) : \\(\\rho = 0.5\\) (shown in dark red ) and \\(\\rho = 0.97\\) (shown in blue ). The latter choice will be encountered again, later in this chapter. All curves have been normalized to one at \\(k = 0\\) and \\(\\Omega = 0.\\) It should be clear that although the driving force is white noise, the velocity process is pink noise as described in Example: Pink Noise . Descriptive statistics \u2013 mean and standard deviation \u00b6 Having the autocorrelation function and the power spectral density, we can now calculate the mean and standard deviation of the filtered random process. There are two ways to arrive at the mean. We can use Equation 7.10 with Equation 7.12 and Equation 7.14 in which case we have: (7.15) $${\\left| {{m_v}} \\right|^2} = \\mathop {\\lim }\\limits_{k \\to \\infty } \\left\\{ {{\\varphi _{vv}}[k]} \\right\\} = 0$$ That is, the mean is 0. Alternatively, we can use Equation 6.9 and Equation 7.4 to give: (7.16) $$\\begin{array}{*{20}{l}} {{m_v}}&{ = {m_f}\\,{H_v}(\\Omega = 0) = {m_f}\\,{H_v}(z = 1)}\\\\ {\\,\\,\\,}&{ = 0\\left( {\\frac{{1/m}}{{1 - {e^{ - (\\lambda {T_s}/m)}}}}} \\right) = 0} \\end{array}$$ Either way, a mean of zero makes sense. The driving force pushes the particle left and right and the Langevin equation smooths this motion. But the smoothing does not change the average velocity. The standard deviation comes from: (7.17) $$\\begin{array}{*{20}{l}} {\\sigma _v^2}&{ = {\\gamma _{vv}}[0] = {\\varphi _{vv}}[0] - {{\\left| {{m_v}} \\right|}^2}}&{\\,\\,\\,}\\\\ {\\,\\,\\,}&{ = {\\varphi _{vv}}[0] = {{\\left( {\\frac{1}{m}} \\right)}^2}\\left( {\\frac{{{F_o}}}{{1 - {\\rho ^2}}}} \\right)}& \\Rightarrow \\\\ {{\\sigma _v}}&{ = \\frac{1}{m}\\sqrt {\\frac{{{F_o}}}{{1 - {e^{ - 2\\lambda {T_s}/m}}}}} }&{\\,\\,\\,} \\end{array}$$ The standard deviation changes, something we should expect from the filtering associated with the Langevin equation and our experience with Laboratory Exercise 6.1 in Chapter 6 . It is instructive to compare this discrete-time result to the continuous time result. We offer\u2014without proof\u2014that the various equations to describe the filtering of random processes and the calculation of various statistical descriptions are the same in continuous time as in discrete time. You are, of course, welcome to derive these results using the same methods we have used in the previous chapters. See Problem 7.3 . Starting from Equation 7.1 and Equation 7.3 we have the results summarized in Table 1 . Description Continuous-time Discrete-time ${h_v}$ $\\frac{1}{m}{e^{ - \\lambda t/m}}u(t)$ $\\frac{1}{m}{\\rho ^n}u[n]$ ${H_v}$ $\\frac{1}{{ms + \\lambda }}$ $\\frac{1}{m}\\left( {\\frac{1}{{1 - \\rho {z^{ - 1}}}}} \\right)$ ${\\varphi _{hh}}$ $\\left( {\\frac{1}{{2m\\lambda }}} \\right){e^{ - \\lambda \\lvert \\tau \\rvert/m}}$ ${\\left( {\\frac{1}{m}} \\right)^2}\\left( {\\frac{1}{{1 - {\\rho ^2}}}} \\right){\\rho ^{\\lvert k \\rvert}}$ ${\\varphi _{vv}}$ ${F_o}{\\varphi _{hh}}(\\tau )$ ${F_o}{\\varphi _{hh}}[k]$ ${S_{vv}}$ ${\\left( {\\frac{1}{m}} \\right)^2}\\frac{{{F_o}}}{{{\\omega ^2} + {{\\left( {\\lambda /m} \\right)}^2}}}$ ${\\left( {\\frac{1}{m}} \\right)^2}\\left( {\\frac{{{F_o}}}{{1 + {\\rho ^2} - 2\\rho \\cos \\Omega }}} \\right)$ ${\\lvert {{m_v}} \\rvert^2} = \\mathop {\\lim }\\limits_{\\tau ,\\,k \\to \\infty } \\left\\{ {{\\varphi _{vv}}} \\right\\}$ 0 0 $\\begin{aligned}\\sigma_v^2 &= \\left( \\varphi_{vv} - \\lvert m_v \\rvert^2 \\right) \\rvert_{\\tau ,k = 0}\\\\ &= \\langle v^2 \\rangle \\end{aligned}$ $\\frac{{{F_o}}}{{2m\\lambda }}$ ${\\left( {\\frac{1}{m}} \\right)^2}\\left( {\\frac{{{F_o}}}{{1 - {\\rho ^2}}}} \\right)$ Table 7.1: Comparison of continuous-time and discrete-time descriptions of the Langevin velocity process. The parameter \\(\\rho = {e^{ - (\\lambda {T_s}/m)}}.\\) The result for the average value of the velocity is the same; the mean value of the velocity is zero. The result for the continuous-time standard deviation (or variance \\(\\sigma _{v,a}^2\\) ) differs from the discrete-time standard deviation (or variance \\(\\sigma _{v,d}^2\\) ) where \u201c \\(a\\) \u201d stands for analog (continuous-time) and \u201c \\(d\\) \u201d for digital (discrete-time). (7.18) $$\\begin{array}{*{20}{l}} {\\sigma _{v,a}^2}&{ = \\frac{{{F_o}}}{{2m\\lambda }}}\\\\ {\\sigma _{v,d}^2}&{ = \\frac{1}{{{m^2}}}\\left( {\\frac{{{F_o}}}{{1 - {\\rho ^2}}}} \\right) = \\frac{1}{{{m^2}}}\\left( {\\frac{{{F_o}}}{{1 - {e^{ - 2\\lambda {T_s}/m}}}}} \\right)} \\end{array}$$ We pay a price for using discrete-time techniques, the perhaps unexpected term \\(1 - {\\rho ^2}\\) in the denominator of Equation 7.18 . This term can, however, asymptotically resemble the term in Table 7.1 . As the sampling rate increases, as \\({T_s} \\to 0,\\) we have: (7.19) $$\\begin{array}{*{20}{l}} {\\mathop {\\lim }\\limits_{{T_s} \\to 0} \\left\\{ {\\sigma _{v,d}^2} \\right\\}}&{ = \\mathop {\\lim }\\limits_{{T_s} \\to 0} \\left\\{ {\\frac{1}{{{m^2}}}\\left( {\\frac{{{F_o}}}{{1 - {e^{ - 2\\lambda {T_s}/m}}}}} \\right)} \\right\\}}\\\\ {\\,\\,\\,}&{ \\approx \\frac{{{F_o}}}{{{m^2}}}\\left( {\\frac{1}{{1 - (1 - 2\\lambda {T_s}/m)}}} \\right)}\\\\ {\\,\\,\\,}&{ \\approx \\frac{{{F_o}}}{{2m\\lambda {T_s}}} = \\frac{1}{{{T_s}}}\\sigma _{v,a}^2} \\end{array}$$ Note that we have used the Taylor series linearization of \\({\\rho ^2}\\) as \\({T_s} \\to 0.\\) This suggests using a sampling interval such that \\({T_s} < < m/2\\lambda = \\theta /2.\\) We have met this condition with our earlier choice of \\({T_s} = 2\\pi /{\\omega _s} = \\pi m/100\\lambda.\\) We can then calculate the variance of the physical (analog) velocity process from our (digital) data, \\(\\sigma _{v,a}^2 = {T_s}\\,\\sigma _{v,d}^2.\\) Before proceeding with the Langevin position equation, one more observation is in order. The variance of the continuous-time velocity is the mean-square velocity of the particle with mass \\(m\\) in the water bath at temperature \\(\\Psi.\\) The battering of the particle by water molecules is caused by the thermal motion of the molecules. Even though the particle is in thermal equilibrium with its surroundings, the battering continues. From the Equipartition Theorem of thermal physics we know that each degree-of-freedom of motion has as an average kinetic energy of \\({k_B}\\Psi /2\\) due to thermal effects\u2014see Feynman 3 \u2014where \\({k_B} = 1.380658 \\times {10^{ - 23}}\\) J/K is the Boltzmann constant. With \\(K{E_x}\\) denoting the average kinetic energy of translational motion in the \\(x\\) direction, this means: (7.20) $$\\begin{array}{*{20}{l}} {\\frac{{{F_o}}}{{2m\\lambda }}}&{ = \\sigma _{v,a}^2 = \\left\\langle {v_x^2} \\right\\rangle = \\frac{{2\\,K{E_x}}}{m} = \\frac{{{k_B}\\Psi }}{m}\\,\\,\\,\\, \\Rightarrow }\\\\ {{F_o}}&{ = 2\\lambda {k_B}\\Psi } \\end{array}$$ The second line in Equation 7.20 is important. Based upon the dynamic viscosity, the equilibrium temperature, and the Boltzmann constant, we can assign a specific physical value to \\({{F_o}},\\) a term that has, until now, been a simple scale factor. The Langevin position equation \u00b6 At first glance one might expect that analyzing the Langevin position equation might simply be \u201cmore of the same\u201d. As we shall see, however, this equation offers some important insights into phenomena such as Brownian motion. We start with the causal, stable position equation in continuous time: (7.21) $$\\begin{array}{l} m\\frac{{{d^2}x(t)}}{{d{t^2}}} = f(t) - \\lambda \\frac{{dx(t)}}{{dt}}\\\\ {H_x}(s) = \\frac{1}{{m{s^2} + \\lambda s}} \\end{array}$$ The impulse response \\({h_x}(t)\\) follows from: (7.22) $$\\begin{array}{l} {H_x}(s) = \\frac{1}{{m{s^2} + \\lambda s}} = \\frac{1}{\\lambda }\\left( {\\frac{1}{s} - \\frac{1}{{s + \\lambda /m}}} \\right)\\,\\,\\,\\,\\, \\Rightarrow \\\\ {h_x}(t) = \\frac{1}{\\lambda }u(t) - \\frac{1}{\\lambda }{e^{ - \\lambda t/m}}u(t) \\end{array}$$ Using the impulse-invariant technique yields: (7.23) $$\\begin{array}{*{20}{l}} {{h_x}[n]}&{ = \\frac{1}{\\lambda }u[n] - \\frac{1}{\\lambda }{{\\left( {{e^{ - \\lambda {T_s}/m}}} \\right)}^n}u[n]}&{}\\\\ {\\,\\,\\,}&{ = \\frac{1}{\\lambda }u[n] - \\frac{1}{\\lambda }{\\rho ^n}u[n]}& \\Rightarrow \\\\ {{H_x}(z)}&{ = \\frac{{1{\\rm{/}}\\lambda }}{{1 - {z^{ - 1}}}} - \\frac{{1{\\rm{/}}\\lambda }}{{1 - \\rho {z^{ - 1}}}}}&{}\\\\ {\\,\\,\\,}&{ = \\frac{1}{\\lambda }\\left( {\\frac{{{z^{ - 1}}(1 - \\rho )}}{{1 - {z^{ - 1}}(1 + \\rho ) + \\rho {z^{ - 2}}}}} \\right)}&{} \\end{array}$$ Again we have used \\(\\rho = {e^{ - (\\lambda {T_s}/m)}}.\\) The difference equation relating driving force \\(f[n]\\) to position \\(x[n]\\) is thus given by: (7.24) $$\\begin{array}{l} x[n] - (1 + \\rho )x[n - 1] + \\rho x[n - 2]\\\\ \\,\\,\\,\\,\\,\\,\\,\\, = \\left( {\\frac{{1 - \\rho }}{\\lambda }} \\right)f[n - 1] \\end{array}$$ Expected value \u00b6 The average value of the position \\({m_x},\\) using the property that \\(\\Omega = 0\\) corresponds to \\(z = {\\left. {{e^{j\\Omega }}} \\right|_{\\Omega = 0}} = 1,\\) is straightforward to calculate: (7.25) $$\\begin{array}{*{20}{l}} {{m_x}}&{ = {m_f}\\,{H_x}(\\Omega = 0) = {m_f}\\,{H_x}(z = 1)}\\\\ {\\,\\,\\,}&{ = 0\\left( {\\frac{{1 - \\rho }}{\\lambda }} \\right)\\left( {\\frac{1}{0}} \\right) = indeterminate} \\end{array}$$ What is happening here? First, this is not a consequence of the transformation from continuous time to discrete time. The value of \\({H_x}(\\omega )\\) is also indeterminate for \\(\\omega = 0.\\) We can better understand this result if we look at the impulse response of the difference equation, Equation 7.23 . (7.26) $${h_x}[n] = \\left( {\\frac{1}{\\lambda }} \\right)u[n] - \\left( {\\frac{1}{\\lambda }} \\right){\\rho ^n}u[n]$$ The form of this impulse response brings us back to the discussion in Chapter 5 . The first term is dependent on \\(u[n]\\) whose Fourier transform\u2014as we saw in Equation 5.21 \u2014has singularities at \\(\\Omega = 0.\\) It is these singularities that cause our problem. Nevertheless, our intuition suggests that the mean \\({m_x}\\) should be zero. The random process associated with \\(f[n]\\) has a zero mean, \\({m_f} = \\left\\langle {f[n]} \\right\\rangle = 0,\\) so the positive values should be \u201ccancelled\u201d by the negative values. As we have assumed that \\(f[n]\\) has a Gaussian probability density function \\(N\\left( {\\mu = 0,\\sigma = \\sqrt {{F_o}} } \\right),\\) we can show that this is an example of a filtered Gaussian random walk . The first term in \\({h_x}[n]\\) in Equation 7.26 , \\({h_1}[n] = \\left( {1/\\lambda } \\right)u[n]\\) implies that the position after \\(n\\) steps involves the sum of that number of independent steps: (7.27) $$\\begin{array}{*{20}{l}} {{x_1}[n]}&{ = \\left( {\\frac{1}{\\lambda }} \\right)u[n] \\otimes f[n] = \\left( {\\frac{1}{\\lambda }} \\right)\\sum\\limits_{k = - \\infty }^{ + \\infty } {f[k]u[n - k]} }\\\\ {\\,\\,\\,}&{ = \\left( {\\frac{1}{\\lambda }} \\right)\\sum\\limits_{k = 0}^n {f[k]} } \\end{array}$$ We assume here that the particle with mass \\(m\\) starts at position zero at time zero, \\(x[0] = 0,\\) and that the random driving force starts at time zero, \\(f[n] = 0\\) for \\(n < 0.\\) The term \\(\\sum\\nolimits_k {f[k]}\\) represents the sum of \\(n\\) independent, identically-distributed, Gaussian random variables: a Gaussian random walk. Random walks have been studied extensively and a lucid discussion can be found in Cox 4 . For a random walk where each step has an average value of zero, the expected value of the particle position after \\(n\\) steps is likewise zero. The second term in \\({h_x}[n]\\) in Equation 7.26 is easier; the output of this component of the Langevin filter has a mean of zero. This can be seen through application of Equation 6.9 with \\({m_f} = 0.\\) By identifying the first term in \\({h_x}[n]\\) ( Equation 7.26 ) as a Gaussian random walk problem, we have demonstrated that the mean value of the position in the Langevin position equation is zero, \\({m_x} = \\left\\langle {x[n]} \\right\\rangle = 0.\\) Autocorrelation function \u00b6 We are now in a position to work with the autocorrelation function. Again we refer to the methodology developed in Chapter 5 for a deterministic signal, specifically Equation 5.14 , and to the impulse response of the Langevin position equation, Equation 7.26 . For the deterministic signal we had: (7.28) $$x[n] = u[n] - {\\left( {\\frac{1}{2}} \\right)^n}u[n]$$ and for the Langevin position equation: (7.29) $${h_x}[n] = \\left( {\\frac{1}{\\lambda }} \\right)u[n] - \\left( {\\frac{1}{\\lambda }} \\right){\\rho ^n}u[n]$$ The similarity of the two equations should be clear. This means that, referring to Equation 5.19 and using the windowing function \\(w[n]\\) and Equation 7.14 , we can write the autocorrelation function as: (7.30) $${\\varphi _{xx}}[k] = \\frac{{{F_o}}}{{{\\lambda ^2}}}\\left( {\\mathop {\\lim }\\limits_{N \\to \\infty } N - \\left| k \\right| - \\left( {\\frac{{\\rho + {\\rho ^2} + {\\rho ^{\\left| k \\right| + 1}}}}{{1 - {\\rho ^2}}}} \\right)} \\right)$$ In order to show that \\({\\varphi _{xx}}[k]\\) grows linearly with \\(N\\) we do not replace it by its limit. The autocorrelation is displayed in Figure 7.3 . It is important to realize that while it may look quite similar to Figure 5.2 , it differs in an important way. The example that was developed in Chapter 5 was the autocorrelation function of a deterministic signal \\(x[n].\\) The result in Equation 7.30 is the autocorrelation function of the stochastic signal \\(x[n]\\) found through the Langevin equation. Figure 7.3: Autocorrelation function of \\(x[n\\rbrack\\) in Equation 7.30 plotted for \\(\\left| k \\right| < 10.\\) The parameter \\(\\rho = 1/2\\) and the value of \\({\\varphi _{xx}}[k = 0\\rbrack = \\left( {{F_o}/{\\lambda ^2}} \\right)\\left( {N - 5/3)} \\right).\\) \\(N\\) describes the width of window \\(w[n\\rbrack\\) and in this calculation \\(N = 20,000.\\) We have determined the mean value of the random process \\({m_x} = \\left\\langle {x[n]} \\right\\rangle = 0\\) and we now have the autocorrelation function of that random process in the form of Equation 7.30 . Power spectral density \u00b6 Starting from Equation 6.21 and Equation 7.29 we can compute the power spectral density \\({S_{xx}}(\\Omega ).\\) See Problem 7.6 . (7.31) $$\\begin{array}{*{20}{l}} {{S_{xx}}(\\Omega )}&{ = {{\\left| {{H_x}(\\Omega )} \\right|}^2}{S_{ff}}(\\Omega )\\; = {{\\left| {{H_x}(\\Omega )} \\right|}^2}{F_o}}\\\\ {\\,\\,\\,}&{ = \\frac{{{F_o}{{(1 - \\rho )}^2}{{\\csc }^2}(\\Omega /2)}}{{{{(2\\lambda )}^2}(1 + {\\rho ^2} - 2\\rho \\cos \\Omega )}}} \\end{array}$$ This result including its behavior at \\(\\Omega = 0\\) is shown in Figure 7.4 . Figure 7.4: Power spectral density \\({S_{xx}}(\\Omega )\\) of \\(x[n\\rbrack\\) in Equation 7.31 plotted for the baseband \\(- \\pi \\lt \\Omega \\le + \\pi.\\) The parameter \\(\\rho = 1/2\\) and the parameters \\({F_0}\\) and \\(\\lambda\\) each equal one. The width of \\(w[n\\rbrack\\) in this calculation \\(N = 20,000.\\) Using Equation 7.10 we can determine the variance\u2014the mean-square dispersion \\(\\left\\langle {{x^2}} \\right\\rangle\\) \u2014of the random process. (7.32) $$\\begin{array}{*{20}{l}} {\\sigma _x^2}&{ = {\\gamma _{xx}}[0] = {\\varphi _{xx}}[0] - {{\\left| {{m_x}} \\right|}^2} = {\\varphi _{xx}}[0] - {0^2}}\\\\ {\\,\\,\\,}&{ = \\frac{{{F_o}}}{{{\\lambda ^2}}}\\left( {\\mathop {\\lim }\\limits_{N \\to \\infty } N - \\left( {\\frac{{2\\rho + {\\rho ^2}}}{{1 - {\\rho ^2}}}} \\right)} \\right) = \\left\\langle {{x^2}} \\right\\rangle } \\end{array}$$ The size of the window and the number of independent steps that are added together in Equation 7.27 are the same, \\(N.\\) This means that for large values of \\(N,\\) the variance grows as \\(N\\) and the standard deviation grows as \\(\\sqrt N.\\) This coincides with our knowledge of the Gaussian random walk and Brownian motion, an average displacement of zero and a standard deviation that grows as \\(\\sqrt N\\) and is, therefore, unbounded. To repeat what we mentioned in Chapter 5 , the mathematics may indicate that we are dealing with an \u201cill-behaved\u201d mathematical problem but this problem can, in fact, be a description of a real physical system and amenable to analysis and interpretation. As we saw in Equation 7.19 , examining what happens as the sampling rate increases, as \\({T_s} \\to 0,\\) can provide additional insight into the relation between the analog world and the digital world. Using the same linearization procedure yields: (7.33) $$\\sigma _x^2 = \\frac{{{F_o}}}{{{\\lambda ^2}}}\\left( {\\mathop {\\lim }\\limits_{N \\to \\infty } N - \\left( {\\frac{{3m}}{{2\\lambda {T_s}}} - 2} \\right)} \\right)$$ In Figure 7.1 , we demonstrated that a sufficiently small value of the sampling interval is given by \\({T_s} = \\pi m/100\\lambda.\\) The approximation that we are in a region where the \\(\\sqrt N\\) behavior dominates is thus given by: (7.34) $$N > > \\frac{3}{2}\\left( {\\frac{m}{{\\lambda {T_s}}}} \\right) = \\frac{{150}}{\\pi }$$ The total amount of time, \\({T^*},\\) that passes before we are in this region is characterized by: (7.35) $${T^*} > > \\frac{3}{2}\\left( {\\frac{m}{{\\lambda {T_s}}}} \\right){T_s} = \\frac{3}{2}\\left( {\\frac{m}{\\lambda }} \\right) = \\frac{3}{2}\\theta$$ For the numerical example presented earlier where \\(\\theta = 428\\mu\\) s, this implies that starting at time zero where \\(x[0] = 0,\\) Brownian motion with its \\(\\sqrt N\\) behavior will dominate the digital data when \\({T^*} > > 642\\mu\\) s. As we saw with Table 7.1 , it can be instructive to compare our discrete-time results to their continuous-time counterparts. These are summarized in Table 7.2 . Description Continuous-time Discrete-time ${h_x}$ $\\frac{1}{\\lambda }u(t) - \\frac{1}{\\lambda }{e^{ - \\lambda t/m}}u(t)$ $\\frac{1}{\\lambda }u[n] - \\frac{1}{\\lambda }{\\left( {{e^{ - \\lambda {T_s}/m}}} \\right)^n}u[n]$ ${H_x}$ $\\frac{1}{{m{s^2} + \\lambda s}}$ $\\frac{1}{\\lambda }\\left( {\\frac{{{z^{ - 1}}(1 - \\rho )}}{{1 - {z^{ - 1}}(1 + \\rho ) + \\rho {z^{ - 2}}}}} \\right)$ ${\\varphi _{hh}}$ $\\frac{1}{{{\\lambda ^2}}}(\\mathop {\\lim }\\limits_{T \\to \\infty } T - \\lvert \\tau \\rvert$ $ - \\frac{m}{\\lambda }(2 + {e^{ - \\lambda \\lvert \\tau \\rvert/m}}))$ $\\frac{1}{{{\\lambda ^2}}}(\\mathop {\\lim }\\limits_{N \\to \\infty } N - \\lvert k \\rvert$ $ - (\\frac{{\\rho + {\\rho ^2} + {\\rho ^{\\lvert k \\rvert + 1}}}}{{1 - {\\rho ^2}}}))$ ${\\varphi _{xx}}$ ${F_o}{\\varphi _{hh}}(\\tau )$ ${F_o}{\\varphi _{hh}}[k]$ ${S_{xx}}$ $\\left( {\\frac{1}{{{m^2}}}} \\right)\\left( {\\frac{1}{{{\\omega ^2}}}} \\right)\\frac{{{F_o}}}{{{\\omega ^2} + {{\\left( {\\lambda /m} \\right)}^2}}}$ $\\frac{{{{(1 - \\rho )}^2}{{\\csc }^2}(\\Omega /2)}}{{{{(2\\lambda )}^2}(1 + {\\rho ^2} - 2\\rho \\cos \\Omega )}}$ ${\\lvert {{m_x}} \\rvert^2} = \\mathop {\\lim }\\limits_{\\tau ,\\,k \\to \\infty } \\left\\{ {{\\varphi _{xx}}} \\right\\}$ 0 0 $\\begin{aligned}\\sigma_x^2 &= \\left( \\varphi_{xx} - \\lvert m_x \\rvert^2 \\right) \\rvert_{\\tau ,k = 0}\\\\ &= \\langle x^2 \\rangle \\end{aligned}$ $\\frac{{{F_o}}}{{{\\lambda ^2}}}\\left( {\\mathop {\\lim }\\limits_{T \\to \\infty } T - \\left( {\\frac{{3m}}{\\lambda }} \\right)} \\right)$ $\\frac{{{F_o}}}{{{\\lambda ^2}}}\\left( {\\mathop {\\lim }\\limits_{N \\to \\infty } N - \\left( {\\frac{{2\\rho + {\\rho ^2}}}{{1 - {\\rho ^2}}}} \\right)} \\right)$ Table 7.2: Comparison of continuous-time and discrete-time descriptions of the Langevin position process. The parameter \\(\\rho = {e^{ - (\\lambda {T_s}/m)}}.\\) To compare the variance estimates as we did in Equation 7.19 , we look at the situation where \\({T_s} \\to 0.\\) (7.36) $$\\begin{array}{*{20}{l}} {\\sigma _{x,a}^2}&{ = \\frac{{{F_o}}}{{{\\lambda ^2}}}\\left( {\\mathop {\\lim }\\limits_{T \\to \\infty } T - \\left( {\\frac{{3m}}{\\lambda }} \\right)} \\right)}\\\\ {\\sigma _{x,d}^2}&{ = \\frac{{{F_o}}}{{{\\lambda ^2}}}\\left( {\\mathop {\\lim }\\limits_{N \\to \\infty } N - \\left( {\\frac{{3m}}{{2\\lambda {T_s}}} - 2} \\right)} \\right)} \\end{array}$$ The results are similar to what we saw before. The \\(\\sqrt T\\) or \\(\\sqrt N\\) behavior of the standard deviation dominates after a sufficient observation time. Further, the relative behavior of the two variances can be described by \\(\\sigma _{x,a}^2 \\propto {T_s}\\sigma _{x,d}^2.\\) This is the second time that we have seen this relation between the continuous-time and the discrete-time and it will appear in the next section as well. This may surprise you as it appears that the units of the stochastic variable are not compatible. If, on the left side, the variance has the unit \\({\\left( {m/s} \\right)^2}\\) as in the velocity equation Equation 7.19 , then it should have that same unit for the variance on the right side as well. And the same holds for position. If on the left side, the variance has the unit \\({m^2}\\) as in the position equation Equation 7.36 then it should also be \\({m^2}\\) for the variance on the right side. So how does the \\({T_s}\\) fit in? We will explore this issue in Problem 7.8 . Tethered particle motion \u00b6 While the Langevin equation was described more than 100 years ago, the concepts introduced are still used in modern studies. To further our appreciation for how the processing of stochastic signals can yield insights into, for example, the biophysical properties of DNA, let us look at how a variant of the Langevin equation is used. The motion of a gold particle in a fluid provides a mechanism to study the dynamic behavior of polymers such as double-stranded DNA (dsDNA). In dynamic studies one can see how DNA is affected by ionic concentrations (e.g. \\({\\rm{M}}{{\\rm{g}}^{ + + }}\\) ) or by repair and maintenance proteins such as RecA. In the original model embodied in the Langevin equation, Equation 7.1 , the particle is free to move in the fluid. If, however, the particle is attached to one end of a polymer \u2014a macromolecule that is composed of a chain of essentially identical subunits\u2014and the other end of the polymer is attached to a substrate, then the motion of the particle will no longer be free. This is referred to as tethered particle motion (TPM) and is illustrated in Figure 7.5 . See Lindner 5 . Figure 7.5: Tethered particle ( gold ) attached to one end of a macromolecule (DNA) which, in turn, is attached to a substrate ( red ). Courtesy of Garini, Lindner et al, Bar Ilan University. The tether constrains the particle from free motion through two mechanisms. First, the particle cannot move further away from the attachment point of the molecule than the total molecule length \\(L.\\) If the molecule has a length of \\(L = 1660\\) nm then the three-dimensional envelope of possible positions is a hemisphere of radius 1660 nm. (There is a small correction necessary because the particle cannot penetrate the substrate but we shall ignore this volume exclusion effect.) Second, within this hemisphere small displacements of the particle in the fluid due to thermal collisions with the water molecules are restrained by a spring-like (Hookean) force, \\({f_{mol}} = - kx\\) exerted by the macromolecule. This leads to the modification of the Langevin model presented in Equation 7.1 : (7.37) $$m\\frac{{{d^2}x(t)}}{{d{t^2}}} = f(t)\\,\\,\\,\\underbrace { - \\lambda \\frac{{dx(t)}}{{dt}}}_{frictional\\,force}\\,\\,\\,\\underbrace { - kx}_{Hookean\\,force}$$ where \\(k\\) is the spring constant associated with the macromolecule. The three parameters \\(\\left( {m,\\lambda ,k} \\right)\\) are all positive. Further, the first two deal with the particle and the fluid while the third one, \\(k,\\) is a direct property of the macromolecular tether and thus experiments with the tethered particle can reveal properties of the macromolecule. A simulation of the three-dimensional motion involved is shown in Movie 7.1 . See Lindner 5 . Movie 7.1: Simulation of the motion of a tethered sphere. In the first part of this simulation the DNA is unencumbered and moves through a large domain shown in green . In the second part of the simulation, two protein molecules attach themselves to the DNA and change the dynamics of the motion as indicated in blue . (Courtesy of Garini et al, Bar-Ilan University) Real data as recorded from an \\(R = 40\\) nm gold sphere through a darkfield microscope are shown in Movie 7.2 . See Dietrich 6 . Movie 7.2: Darkfield microscope movie recorded with a $50 \\times$ objective lens with an $NA = 0.8.$ It is important to remember that you are viewing an object that is so small that it can be considered as a point source and thus the image is the point spread function, i.e. the optical impulse response. Nevertheless, the position of the gold particle can be determined to a precision of $\\sigma = 3$ nm. It is the Langevin equation extended with a spring force that describes the motion seen in Movie 7.1 and Movie 7.2 . The transfer function of the modified Langevin equation is: (7.38) $${H_x}(s) = \\frac{1}{{m{s^2} + \\lambda s + k}}$$ As in the Langevin position equation, this is a second-order linear differential equation but this time containing the spring constant. This type of second-order system is well-known. See Section 6.5.2 of Oppenheim 7 . There are three types of possible behavior depending upon the value of the discriminant \\({\\left( {\\lambda /2m} \\right)^2} - \\left( {k/m} \\right).\\) These are: (7.39) $$\\begin{array}{*{20}{l}} {{{\\left( {\\lambda /2m} \\right)}^2} - \\left( {k/m} \\right) > 0}& \\Rightarrow &{overdamped\\,system}\\\\ {{{\\left( {\\lambda /2m} \\right)}^2} - \\left( {k/m} \\right) = 0}& \\Rightarrow &{critically\\,damped\\,system}\\\\ {{{\\left( {\\lambda /2m} \\right)}^2} - \\left( {k/m} \\right) < 0}& \\Rightarrow &{underdamped\\,system} \\end{array}$$ If the system is underdamped it will exhibit exponentially-decaying oscillatory behavior, something which is familiar to us in a mass-spring system. To focus our attention on a realistic system at this molecular scale, it is important to know which of the three situations in Equation 7.39 is the relevant one. We need to look at realistic values for \\(\\left( {m,\\lambda ,k} \\right).\\) How big is big? How small is small? \u2013 redux \u00b6 Various measurement modalities can be used to observe the motion of the particle. These can be based upon polystyrene beads that contain fluorescent dye and are observed with fluorescence microscopy, magnetic beads that can be manipulated and measured with magnetic fields ( magnetic tweezers ), and gold particles that can be observed with darkfield microscopy Dietrich 6 . To continue our previous numerical example, let us look at gold particles ( \\(R = 40\\) nm) that are attached to DNA of 4882 bp (basepairs) with a total (contour) length of \\(L = 1660\\) nm. This gold particle is significantly smaller than the one used above so several of the basic parameters are affected. The gold particle is \\(285 \\times\\) larger in radius than a water molecule. We can, therefore, continue to think of a big particle being battered by small molecules. The terminal velocity of a free gold particle is now 64 nm/s meaning that the particle will not sink to the bottom of the test chamber during the course of an experiment. The mass of the gold particle is \\(m = 5.18\\) fg. The damping factor \\(\\lambda = 6\\pi \\eta R = 7.55 \\times {10^{ - 10}}\\) kg/s = 755 ng/s. The time constant \\(\\theta = m/\\lambda = 6.86\\) ns. The smaller gold particle means a significantly shorter time constant for the simpler Langevin velocity analysis. Two of the three parameters in Equation 7.38 have now been estimated. The value for \\(k\\) remains to be determined. There is an accepted model for the elasticity of DNA, the \u201cworm-like chain model\u201d (WLC). See Dietrich 6 and Rubinstein 8 . This model says that for small displacements, \\(x < < L\\) the force exerted by the dsDNA on the particle is given by: (7.40) $${f_{mol}} = - kx = - \\left( {\\frac{{3{k_B}\\Psi }}{{2PL}}} \\right)x$$ where \\(P\\) is the persistence length of the dsDNA molecule. The persistence length represents a way of approximating a polymer such as dsDNA as a collection of straight line segments each of length \\(P.\\) Each segment is modeled as stiff and thus does not bend. According to the model, the change in direction of the polymer occurs at the juncture of two segments. A typical value of \\(P\\) is 50 nm. We shall see later, in the experimental data in Figure 7.10 , that the displacement \\(x\\) is on the order of a few nm while \\(L\\) is 1660 nm justifying the use of Equation 7.40 . When measured at \\(\\Psi = 21\\) \u00b0C and with \\(L = 1660\\) nm the spring constant, using Equation 7.40 , is \\(k = 0.073\\) pN/ \\(\\mu\\) m. Using the values we have found for the three parameters yields: (7.41) $$\\begin{array}{l} {\\left( {\\lambda /2m} \\right)^2} - \\left( {k/m} \\right) = 5.32 \\times {10^{15}}\\,\\,{\\left( {{\\rm{rad}}/{\\rm{s}}} \\right)^2} > 0\\\\ \\,\\,\\,\\,\\,\\,\\,\\,\\, \\Rightarrow underdamped\\,system \\end{array}$$ This second-order system has two poles both of which are on the real axis in the \\(s\\) -plane. A Bode (log-log) plot of the frequency response \\(\\left| {{H_x}(\\omega )} \\right|\\) of this biomolecular-mechanical system is shown in Figure 7.6 . Figure 7.6: Normalized Bode plot in black of the frequency response of the second-order system comprised of a gold particle attached to DNA which, in turn, is attached to a substrate. Note the slope change where the Bode curve with poles at \\(\\omega = 100\\) rad/s and \\(\\omega = {10^8}\\) rad/s deviates from a first-order, dark red , dashed, straight-line approximation. This system with two real poles, one at \\(s = - {\\sigma _1} < 0\\) and the other at \\(s = - {\\sigma _2} < 0,\\) has an impulse response given by: (7.42) $$\\begin{array}{*{20}{l}} {{h_x}(t)}&{ = \\frac{1}{{\\sqrt {{\\lambda ^2} - 4km} }}\\left( {{e^{ - {\\sigma _1}t}} - {e^{ - {\\sigma _2}t}}} \\right)u(t)}&{}\\\\ {{\\sigma _1}}&{ = \\left( {\\frac{\\lambda }{{2m}}} \\right) - \\sqrt {{{\\left( {\\frac{\\lambda }{{2m}}} \\right)}^2} - \\left( {\\frac{k}{m}} \\right)} }&{{\\tau _1} = 1/{\\sigma _1}}\\\\ {{\\sigma _2}}&{ = \\left( {\\frac{\\lambda }{{2m}}} \\right) + \\sqrt {{{\\left( {\\frac{\\lambda }{{2m}}} \\right)}^2} - \\left( {\\frac{k}{m}} \\right)} }&{{\\tau _2} = 1/{\\sigma _2}} \\end{array}$$ The time constants associated with each of these poles are as indicated. Note that since \\({\\sigma _1} < {\\sigma _2},\\) this means that \\({\\tau _1} > {\\tau _2}.\\) The numerical values associated with these time constants for the example presented above are \\({\\tau _1} = 10.3\\) ms and \\({\\tau _2} = 6.86\\) ns, an enormous difference. Choosing the sampling period \u00b6 We are now in a position to choose the sampling period \\({T_s}.\\) As in Figure 7.1 , we look at the effect of the sampling period on the spectrum of the sampled noise process. This is shown in Figure 7.7 . ( a ) Spectrum $\\left| {{H_x}(\\omega )} \\right|$ of the extended Langevin filter with spring force (harmonic potential) ( b ) ${\\omega _s} = 2\\pi /{T_s} = 20{\\omega _c}$ ( c ) ${\\omega _s} = 2\\pi /{T_s} = 200{\\omega _c}$ Figure 7.7: ( a ) Spectral magnitude of the extended Langevin filter \\(\\left| {{H_x}(\\omega )} \\right|.\\) ( b , c ) Spectrum after sampling at various frequencies \\({\\omega _s} = 2\\pi /{T_s}.\\) The \u201ccutoff\u201d frequency \\({\\omega _c}\\) is defined in the text. Note the change in the scale of the frequency axes between the graphs. Once again we use a definition of the \u201ccutoff\u201d frequency \\({\\omega _c}\\) as the frequency at which the amplitude-squared is down by a factor of two from its value at \\(\\omega = 0.\\) This (ungainly) frequency is given by: (7.43) $${\\omega _c} = \\sqrt {\\frac{k}{m} - \\frac{{{\\lambda ^2}}}{{2{m^2}}} + \\frac{{\\sqrt {8{k^2}{m^2} - 4km{\\lambda ^2} + {\\lambda ^4}} }}{{2{m^2}}}}$$ This is, as before, not the highest frequency; see Figure 7.7 a . As we see in Figure 7.7 b , choosing \\({\\omega _s} = 20{\\omega _c}\\) is not enough to avoid aliasing. As shown in Figure 7.7 c , however, choosing \\({\\omega _s} = 200{\\omega _c}\\) results in a periodic spectrum with negligible aliasing. This, in turn corresponds to a sampling frequency of \\({\\omega _s} = 19409\\) rad/s ( \\(\\,{f_s} = 3089\\) Hz) and a sampling period of \\({T_s} = 324\\) \\(\\mu\\) s. In studying the Langevin velocity equation ( Figure 7.1 ), the sampling frequency\u2014also defined on the basis of a frequency where the spectrum-squared was down by a factor of two from its value at \\(\\omega = 0\\) \u2014was chosen to be \\(200{\\omega _c}.\\) In this extended equation, \\(200{\\omega _c}\\) is also required. This will be discussed in Problem 7.9 . We are now ready to transform the differential equation into a difference equation. Repeating the steps that we used earlier: (7.44) $$\\begin{array}{l} m\\frac{{{d^2}x(t)}}{{d{t^2}}} + \\lambda \\frac{{dx(t)}}{{dt}} + kx(t) = f(t)\\,\\\\ {h_x}(t) = \\frac{1}{{\\sqrt {{\\lambda ^2} - 4km} }}\\left( {{e^{ - {\\sigma _1}t}} - {e^{ - {\\sigma _2}t}}} \\right)u(t)\\\\ {h_x}[n] = {h_x}(n{T_s}) = \\frac{1}{{\\sqrt {{\\lambda ^2} - 4km} }}\\left( {{{\\underbrace {\\left( {{e^{ - {\\sigma _1}{T_s}}}} \\right)}_{{\\rho _1}}}^n} - {{\\underbrace {\\left( {{e^{ - {\\sigma _2}{T_s}}}} \\right)}_{{\\rho _2}}}^n}} \\right)u[n]\\\\ {h_x}[n] = \\frac{1}{{\\sqrt {{\\lambda ^2} - 4km} }}\\left( {\\rho _1^n - \\rho _2^n} \\right)u[n] \\end{array}$$ Note the definitions of \\({\\rho _1}\\) and \\({\\rho _2}\\) both of which meet the condition \\(0 < {\\rho _1},{\\rho _2} < 1.\\) Further, we know from Equation 7.42 that \\({\\rho _1} \\ne {\\rho _2}.\\) Taking the \\(z\\) -transform and then converting to a difference equation: (7.45) $$\\begin{array}{l} {H_x}(z) = \\frac{1}{{\\sqrt {{\\lambda ^2} - 4km} }}\\left( {\\frac{1}{{1 - {\\rho _1}{z^{ - 1}}}} - \\frac{1}{{1 - {\\rho _2}{z^{ - 1}}}}} \\right)\\\\ \\,\\,\\,\\,\\,\\,\\,\\,\\, = \\frac{1}{{\\sqrt {{\\lambda ^2} - 4km} }}\\left( {\\frac{{({\\rho _1} - {\\rho _2}){z^{ - 1}}}}{{1 - ({\\rho _1} + {\\rho _2}){z^{ - 1}} + {\\rho _1}{\\rho _2}{z^{ - 2}}}}} \\right)\\,\\,\\,\\,\\, \\Rightarrow \\\\ \\,\\,\\,\\,\\,\\\\ x[n] - ({\\rho _1} + {\\rho _2})x[n - 1] + {\\rho _1}{\\rho _2}x[n - 2]\\\\ \\,\\,\\,\\,\\,\\,\\,\\,\\, = \\left( {\\frac{{({\\rho _1} - {\\rho _2})}}{{\\sqrt {{\\lambda ^2} - 4km} }}} \\right)f[n - 1] \\end{array}$$ Expected value \u00b6 Using Equation 6.9 we have: (7.46) $$\\begin{array}{*{20}{l}} {{m_x}}&{ = {m_f}{H_x}(\\Omega = 0) = {m_f}{H_x}(z = 1)}\\\\ {\\,\\,\\,}&{ = 0\\left( {\\frac{1}{{\\sqrt {{\\lambda ^2} - 4km} }}} \\right)\\left( {\\frac{{({\\rho _1} - {\\rho _2})}}{{1 - ({\\rho _1} + {\\rho _2}) + {\\rho _1}{\\rho _2}}}} \\right)}\\\\ {\\,\\,\\,}&{ = 0} \\end{array}$$ The mean position of the tethered particle remains zero. This should not be a surprise. Autocorrelation function \u00b6 Starting from Equation 7.44 , we can compute the autocorrelation function \\({\\varphi _{xx}}[k]\\) using the same procedures that we used with Equation 7.29 to obtain Equation 7.30 but with the distinction that the computation is easier because the problem is well-behaved, that is, \\(0 < {\\rho _1},{\\rho _2} < 1.\\) (7.47) $$\\begin{array}{l} {\\varphi _{xx}}[k] = {F_o}\\delta [k] \\otimes {\\varphi _{hh}}[k] = {F_o}\\sum\\limits_{n = - \\infty }^{ + \\infty } {{h_x}[n]{h_x}[n + k]} \\\\ \\,\\,\\,\\,\\,\\,\\, = A\\sum\\limits_{n = - \\infty }^{ + \\infty } {\\left( {(\\rho _1^n - \\rho _2^n)(\\rho _1^{n + k} - \\rho _2^{n + k})u[n]u[n + k]} \\right)} \\\\ \\,\\,\\,\\,\\,\\,\\, = A\\frac{{({\\rho _2} - {\\rho _1})\\left( {\\rho _2^{1 + \\left| k \\right|}(1 - \\rho _1^2) - \\rho _1^{1 + \\left| k \\right|}(1 - \\rho _2^2)} \\right)}}{{(1 - \\rho _1^2)(1 - {\\rho _1}{\\rho _2})(1 - \\rho _2^2)}} \\end{array}$$ where \\(A = {F_o}/\\left( {{\\lambda ^2} - 4km} \\right).\\) Equation 7.47 is complicated. Determining this final form of \\({\\varphi _{xx}}[k]\\) is, however, straightforward when we remember to use the property that the autocorrelation function is even. Notice that Equation 7.30 can be considered as a special case of Equation 7.47 when \\({\\rho _1} = 1.\\) Power spectral density \u00b6 The power spectral density \\({S_{xx}}(\\Omega ) = {\\mathscr{F}}\\left\\{ {{\\varphi _{xx}}[k]} \\right\\}\\) can be computed from Equation 6.21 and Equation 7.45 . (7.48) $${S_{xx}}(\\Omega ) = \\left( {\\frac{{{F_o}{{({\\rho _1} - {\\rho _2})}^2}}}{{({\\lambda ^2} - 4km)}}} \\right)\\left( {\\frac{1}{{(1 + \\rho _1^2 - 2{\\rho _1}\\cos \\Omega )(1 + \\rho _2^2 - 2{\\rho _2}\\cos \\Omega )}}} \\right)$$ The autocorrelation function \\({\\varphi _{xx}}[k]\\) and the power spectral density are shown in Figure 7.8 . ( a ) Autocorrelation ${{\\varphi _{xx}}[k]}$ of the 1-D Langevin position process ( b ) Power spectral density ${{S_{xx}}(\\Omega )}$ of the 1-D Langevin position process Figure 7.8: ( a ) Autocorrelation function \\({\\varphi _{xx}}[k\\rbrack\\) of the TPM position. The amplitude at \\(k = 0\\) has been normalized to one. ( b ) Power spectral density \\({S_{xx}}(\\Omega )\\) of the TPM position plotted for the baseband \\(- \\pi \\lt \\Omega \\le + \\pi.\\) The amplitude at \\(\\Omega = 0\\) has been normalized to one. Both graphs are for the numerical values given in the text. The numerical values that have been used to produce the graphs in Figure 7.8 are, as above, \\(m = 5.18\\) fg, \\(\\lambda = 755\\) ng/s, and \\(k = 0.073\\) pN/ \\(\\mu\\) m. This leads to poles at \\({\\sigma _1} = 97.1\\) rad/s ( \\(\\approx k/\\lambda\\) ) and \\({\\sigma _2} = 1.5 \\times {10^8}\\) rad/s ( \\(\\approx \\lambda /m\\) ). The sampling period was chosen as \\({T_s} = 2\\pi /200{\\omega _c} =\\) \\(\\pi /100{\\sigma _1} = 324\\) \\(\\mu\\) s. See Figure 7.7 . This means a major \u201cimbalance\u201d between \\({\\rho _1}\\) and \\({\\rho _2}\\) with \\({\\rho _1}\\) = 0.97 and \\({\\rho _2} \\approx 0.\\) See Problem 7.10 . Descriptive statistic \u2013 variance \u00b6 As we saw in our analysis of the Langevin position equation, the mean-square dispersion \\(\\left\\langle {{x^2}} \\right\\rangle\\) can provide useful information about a physical process. Further we have \\({m_x} = 0\\) and from Equation 7.32 : (7.49) $$\\begin{array}{l} \\left\\langle {{x^2}} \\right\\rangle = {\\varphi _{xx}}[k = 0]\\\\ \\,\\,\\,\\,\\,\\,\\, = A\\frac{{({\\rho _2} - {\\rho _1})\\left( {{\\rho _2}(1 - \\rho _1^2) - {\\rho _1}(1 - \\rho _2^2)} \\right)}}{{(1 - \\rho _1^2)(1 - {\\rho _1}{\\rho _2})(1 - \\rho _2^2)}}\\\\ \\,\\,\\,\\,\\,\\,\\, = \\left( {\\frac{{{F_o}}}{{{\\lambda ^2} - 4km}}} \\right)\\frac{{{{({\\rho _2} - {\\rho _1})}^2}\\left( {1 + {\\rho _1}{\\rho _2}} \\right)}}{{(1 - \\rho _1^2)(1 - {\\rho _1}{\\rho _2})(1 - \\rho _2^2)}} \\end{array}$$ From the definitions of \\({\\rho _1}\\) and \\({\\rho _2}\\) given in Equation 7.44 , we see that the mean-square dispersion is a function of the parameters \\(\\left( {m,\\lambda ,k} \\right)\\) and the sampling period \\({T_s}.\\) If we substitute that into Equation 7.49 the expression becomes (too) complex to appreciate its meaning. In Table 7.1 and Table 7.2 we examined this type of expression to see what effect the conversion from continuous-time to discrete-time had on measures as important as \\(\\left\\langle {{v^2}} \\right\\rangle\\) and \\(\\left\\langle {{x^2}} \\right\\rangle\\) Let us repeat that now for TPM. In continuous-time \\({m_x}\\) remains 0 and \\({\\left\\langle {{x^2}} \\right\\rangle _a}\\) can be written as the simple expression: (7.50) $${\\left\\langle {{x^2}} \\right\\rangle _a} = \\frac{{{F_o}}}{{2k\\lambda }}$$ Allowing the sampling interval to become smaller, \\({T_s} \\to 0,\\) in the discrete-time expression Equation 7.49 and using a series expansion, the equivalent expression\u2014see Problem 7.11 \u2014is: (7.51) $${\\left\\langle {{x^2}} \\right\\rangle _d} = \\frac{{{F_o}}}{{2k\\lambda {T_s}}} = \\frac{{{{\\left\\langle {{x^2}} \\right\\rangle }_a}}}{{{T_s}}}$$ The results of Equation 7.19 and Equation 7.36 are repeated for TPM. There is a simple relationship between the \u201canalog\u201d value and the \u201cdigital\u201d value if the sampling interval \\({T_s}\\) is sufficiently small, if the sampling rate is sufficiently high. Again, \\(\\sigma _{x,a}^2 = {T_s}\\sigma _{x,d}^2.\\) One step further \u00b6 We can substitute the description for \\({F_o}\\) Equation 7.20 that was given earlier. This gives: (7.52) $$\\begin{array}{l} {\\left\\langle {{x^2}} \\right\\rangle _d} = \\frac{{2\\lambda {k_B}\\Psi }}{{2k\\lambda {T_s}}} = \\frac{{{k_B}\\Psi }}{{k{T_s}}}\\,\\,\\,\\,\\, \\Rightarrow \\\\ \\,\\,\\,\\,\\,\\,\\,k = \\left( {\\frac{{{k_B}\\Psi }}{{{T_s}}}} \\right)\\frac{1}{{{{\\left\\langle {{x^2}} \\right\\rangle }_d}}} \\end{array}$$ The terms in Equation 7.52 are either constants or the parameters of an experiment: the Boltzmann constant ( \\({{k_B}}\\) ), the equilibrium temperature \\(\\Psi\\) of the fluid, and the sampling interval \\({T_s}.\\) By measuring the mean-square dispersion from a sequence of images as in Movie 7.2 , we can estimate the spring constant \\(k\\) of the macromolecule DNA. The spring constant can be used to infer a property of the DNA molecule such as the persistence length \\(P\\) ( Equation 7.40 ) or to follow a change in the macromolecule as it is exposed to proteins such as RecA. Figure 7.9 illustrates why a dynamic change in the spring constant might be expected after RecA is injected into a TPM test chamber containing \\(R = 40\\) nm gold particles tethered through DNA molecules to a substrate. Figure 7.9: Model of varying stages in the interaction of RecA with DNA. In Figure 7.10 , we see how the root-mean-square radial dispersion \\(\\sqrt {\\left\\langle {{r^2} = {x^2} + {y^2}} \\right\\rangle }\\) is affected. It should be obvious that while the analysis described at length above was for the lateral \\(x\\) motion, the lateral \\(y\\) motion can be measured and described in exactly the same way leading to a radial \\(r\\) description. Figure 7.10: Dynamic behavior of DNA due to injection of RecA at \\(t = 0.\\) All measurements and estimates were based upon discrete-time imagery (as in Movie 7.2) and with digital images. As indicated in the legend, two different concentrations of RecA were used and each measurement repeated twice for a total of four movies. After injection of RecA at \\(t = 0,\\) the binding of the protein to the DNA causes the rms radius to decrease from a first equilibrium state to a second, smaller equilibrium state. The higher the concentration of the protein, the faster the transition occurs. The time scale is on the order of minutes See Dietrich 9 . Why this case study \u00b6 A case study offers the opportunity to show how the ideas that have been developed can (and should) be used. There are many areas of application that lend themselves to a case study: speech processing, radar processing, and economic forecasting are but three examples. In the case study of TPM we have chosen for a more \u201cexotic\u201d application, the use of stochastic signal processing to measure physical phenomena at the molecular level and, in the case of tethered particle motion (TPM), analyzing one molecule at a time. We have seen that the description of such phenomena through the use of the descriptive statistics mean and variance ( \\(\\mu\\) and \\({\\sigma ^2}\\) ) and the functional descriptions autocorrelation and power spectral density ( \\(\\varphi [k]\\) and \\(S(\\Omega )\\) ) allows us to properly implement a discrete-time analysis of continuous-time processes and estimate relevant (bio)physical parameters. Although we are finished with our discussion of the Langevin equation and the extended variant represented in TPM, we are not finished developing tools that can be important in the implementation and application of stochastic signal processing. In the remaining chapters we shall develop these tools. Problems \u00b6 Problem 7.1 \u00b6 The physical situation represented in Equation 7.1 describes a stable, causal situation. Equation 7.5 describes the transformation to a description of that situation but in the discrete-time representation. Is this new description also stable and causal? Justify your answer. Problem 7.2 \u00b6 Consider a system described by a Laplace transform: \\[H(s) = \\sum\\limits_{k = 1}^K {\\frac{{{A_k}}}{{s + {s_k}}}}\\] where \\(K\\) is a finite, positive integer. Show that there does not exist a finite sampling interval \\({T_s}\\) for its impulse response h ( t ) that will satisfy the Nyquist sampling theorem. If this system is processing a stochastic (or deterministic) signal x ( t ) to produce an output signal y ( t ), under what circumstances might a finite sampling interval \\({T_s}\\) exist? Carefully explain your reasoning. Problem 7.3 \u00b6 Consider a continuous-time, linear, time-invariant system with impulse response \\(h(t)\\) and whose Fourier transform is \\(H(\\omega ).\\) The input to the system is an ergodic signal \\(x(t)\\) with a finite mean and a finite variance. The output of the system is a stochastic signal \\(y(t).\\) Is the output signal stationary? Determine a relation between the mean of the input \\({m_x}\\) and the mean of the output \\({m_y}.\\) Determine an expression for the output autocorrelation function \\({\\varphi _{yy}}(\\tau )\\) in terms of the autocorrelation function of the stochastic input and the autocorrelation function of the deterministic system. Determine an expression for the output power spectral density \\({S_{yy}}(\\omega )\\) in terms of the power spectral density of the stochastic input and \\(H(\\omega ).\\) Determine a relation between the variance of the input signal \\(x(t)\\) and the variance of the output signal \\(y(t).\\) Problem 7.4 \u00b6 Starting from Equation 7.11 show that the autocorrelation function for the velocity, \\({\\varphi _{vv}}[k],\\) is given by Equation 7.12 . Problem 7.5 \u00b6 Starting from Equation 7.12 show that the power spectral density for the velocity, \\({S_{vv}}(\\Omega ),\\) is given by Equation 7.13 . Problem 7.6 \u00b6 Starting from Equation 6.21 and Equation 7.29 show that the power spectral density for the position, \\({S_{xx}}(\\Omega ),\\) is given by Equation 7.31 . Problem 7.7 \u00b6 Consider a TPM experiment that has proceeded long enough so that the first term in Equation 7.36 describes the variance, that is, \\[\\sigma _{x,d}^2 = \\frac{{{F_o}}}{{{\\lambda ^2}}}\\left( {\\mathop {\\lim }\\limits_{N \\to \\infty } N} \\right) = \\frac{{{F_o}}}{{{\\lambda ^2}}}N\\] The Stokes-Einstein diffusion equation says that: (7.53) $$D = \\frac{{{k_B}\\Psi }}{{6\\pi \\eta R}}$$ where \\(D\\) is the diffusion coefficient and the other terms are defined in the text. Determine a simple relationship between the mean-square dispersion, \\(D\\) and \\(N.\\) Problem 7.8 \u00b6 Physical units\u2014dimensions\u2014are important! They can be seen as the link between the abstraction of our mathematics and the application in our physical world. If the left-hand side of an equation is in units of meters [m] or kilograms [kg] or volts [V] or dollars [$], then the right-hand side must be in the same units for the equation to be valid. If there is a discrepancy, then a mistake has been made. In the discussions concerning Equation 7.19 , Equation 7.36 , and Equation 7.51 , we have seen expressions of the form \\(\\sigma _{x,a}^2 = {T_s}\\sigma _{x,d}^2\\) where \u201c \\(a\\) \u201d denotes analog (continuous time) and \u201c \\(d\\) \u201d denotes digital (discrete time). If the variance of the continuous-time variable has units of, say, temperature [K], what is the unit of the variance of the discrete-time variable? And now the hard question: Where does your answer to part ( a ) originate? Where in the entire discussion in this chapter does the unit of the discrete-time variable get changed from the original unit of the continuous-time variable? Problem 7.9 \u00b6 One might expect that a spectrum with a very high frequency term\u2014as in Figure 7.6 \u2014would require a much higher sampling frequency that that of the Langevin velocity equation as shown in Figure 7.1 . At the end of the section t to n , however, we found a sampling period of \\({T_s} = 13.4\\) \\(\\mu\\) s while for TPM the value was \\({T_s} = 324\\) \\(\\mu\\) s, a longer time interval or lower sampling frequency. How much of this change is due to the change in the radius of the gold particle? Be as quantitative as possible. How much of this change is due to the change in the transfer function of the physical model? Be as quantitative as possible. Problem 7.10 \u00b6 Consider a TPM system as in Equation 7.37 . In Equation 7.41 we concluded that this was an overdamped system. We also concluded that the associated values, \\({\\rho _1}\\) and \\({\\rho _2},\\) were not \u201cbalanced\u201d; one was much greater than the other. Show that this means that one pole is located at \\(\\approx \\lambda /m\\) and the other at \\(\\approx k/\\lambda.\\) Which of the these two poles has the larger value? Explain your reasoning. Problem 7.11 \u00b6 Starting from Equation 7.49 and the definitions of \\({\\rho _1}\\) and \\({\\rho _2}\\) given in Equation 7.44 , show that when \\({T_s} \\to 0\\) the mean-square dispersion \\({\\left\\langle {{x^2}} \\right\\rangle _d}\\) becomes the expression given in Equation 7.51 . Oppenheim, A. V., A. S. Willsky and I. T. Young (1983). Signals and Systems. Englewood Cliffs, New Jersey, Prentice-Hall \u21a9 Reif, F. (1965). Fundamentals of Statistical and Thermal Physics. New York, McGraw-Hill \u21a9 Feynman, R. P., R. B. Leighton and M. Sands (1963). The Feynman Lectures on Physics: Mainly Mechanics, Radiation, and Heat. Reading, Massachusetts, Addison-Wesley \u21a9 Cox, D. R. and H. D. Miller (1965). The Theory of Stochastic Processes. New York, John Wiley & Sons Inc. \u21a9 Lindner, M., G. Nir, H. R. C. Dietrich, I. T. Young, E. Tauber, I. Bronshtein, L. Altman and Y. Garini (2009). \u201cStudies of single molecules in their natural form.\u201d Israel Journal of Chemistry 49(3-4): 283-291 \u21a9 \u21a9 Dietrich, H. R. C., B. Rieger, F. G. M. Wiertz, F. H. de Groote, H. A. Heering, I. T. Young and Y. Garini (2009). \u201cTethered particle motion mediated by scattering from gold nanoparticles and darkfield microscopy.\u201d J. Nanophotonics 3(031795): 1-17 \u21a9 \u21a9 \u21a9 Oppenheim, A. V., A. S. Willsky and S. H. Nawab (1996). Signals and Systems. Upper Saddle River, New Jersey, Prentice-Hall \u21a9 Rubinstein, M. and R. H. Colby (2003). Polymer Physics. Oxford, UK, Oxford University Press \u21a9 Dietrich, H. R. C., B. Vermolen, B. Rieger, I. T. Young and Y. Garini (2007). \u201cA New Optical Method for Characterizing Single Molecule Interactions based on Dark Field Microscopy.\u201d SPIE: Ultrasensitive and Single-Molecule Detection Technologies II 6444: 1-8 \u21a9","title":"7. The Langevin Equation \u2013 A Case Study"},{"location":"Chap_7.html#the-langevin-equation-a-case-study","text":"In 1908 Prof. Paul Langevin described how a physical system modeled by a differential equation responds to a stochastic input. His work resulted in the concept of the Langevin equation . A particle of mass \\(m\\) is subject to random collision forces, \\(f(t),\\) from many small, molecules. The term \\(f(t)\\) is frequently described as the driving force. Further, the assumption is usually made that \\(f(t)\\) results from a stationary random process with a Gaussian probability density function and an autocorrelation function of the form \\({\\varphi _{ff}}(\\tau) = {F_o}\\delta (\\tau ).\\) Non-coincident time samples are uncorrelated. The mathematical description of \\(f(t)\\) is a Gaussian, white-noise, ergodic process. The motion of the particle is held back (retarded) by a viscous, frictional force that is proportional to the velocity of the particle. The equation of motion can be written for the velocity as a function of time or the position as a function of time: (7.1) $$\\begin{array}{l} m\\frac{{dv(t)}}{{dt}} = f(t) - \\lambda v\\\\ m\\frac{{{d^2}x(t)}}{{d{t^2}}} = f(t) - \\lambda \\frac{{dx(t)}}{{dt}} \\end{array}$$ where \\(\\lambda\\) is the viscous, damping coefficient and both \\(m\\) and \\(\\lambda\\) are greater than zero. This stochastic differential equation describes Brownian motion . We shall begin with the velocity, \\(v(t),\\) and consider only one spatial dimension. In this case-study our intention is to illustrate how the tools we have developed can be used to analyze this random process. (See also TPM .) The tools, however, have been developed in the context of discrete-time so the first step is to transform this first-order differential equation into a difference equation. As so many problems are studied, simulated, measured, and controlled with digital systems, this is not an unreasonable first step.","title":"The Langevin Equation \u2013 A Case Study"},{"location":"Chap_7.html#from-t-to-n","text":"There are several procedures to transform a continuous-time LTI system\u2014one that is based upon a linear differential equation with constant coefficients with input \\(f(t)\\) and output \\(v(t)\\) or \\(x(t)\\) \u2014into a discrete-time difference equation with input \\(f[n]\\) and output \\(v[n]\\) or \\(x[n].\\) These include 1) impulse-invariant sampling, 2) backward-difference equation, and 3) bilinear transformation. For a thorough discussion of this topic see Section 10.8 of Oppenheim 1 . Which one of the three techniques should we use? All three have advantages and disadvantages. For the purpose of this textbook, we will use the impulse-invariant sampling as it is easy to understand and leads to expressions that are easy to analyze in a case-study such as this.","title":"From t to n"},{"location":"Chap_7.html#impulse-invariant-sampling","text":"If the impulse response is bandlimited, we sample the impulse response at an appropriate rate (above the Nyquist frequency) and then use z -transform techniques to produce the difference equation. Thus, if \\(h(t)\\) is the bandlimited impulse response of a Langevin equation whose samples are \\(h[n] = h\\left( {n{T_s}} \\right),\\) the transfer function will be given by: (7.2) $$H(z) = \\sum\\limits_{n = - \\infty }^{ + \\infty } {h[n]{z^{ - n}} = } \\sum\\limits_{n = - \\infty }^{ + \\infty } {h(n{T_s}){z^{ - n}}}$$ where \\({T_s}\\) is the suitably-chosen sampling period. The associated sampling frequency is, thereby, \\({\\omega _s} = 2\\pi /{T_s}.\\) The impulse response of the differential equation for velocity in Equation 7.1 is causal, stable, straightforward to determine, and given by: (7.3) $${h_v}(t) = \\left( {\\frac{1}{m}} \\right){e^{ - \\left( {\\lambda t/m} \\right)}}u(t) = \\left( {\\frac{1}{m}} \\right){e^{ - \\left( {t/\\theta } \\right)}}u(t)$$ We have introduced the time constant \\(\\theta = m/\\lambda\\) and will use it extensively. The sampled impulse response and its z -transform are given by: (7.4) $$\\begin{array}{l} {h_v}[n] = \\left( {\\frac{1}{m}} \\right){e^{ - \\left( {\\lambda {T_s}/m} \\right)n}}u[n]\\\\ {H_v}(z) = \\frac{{V(z)}}{{F(z)}} = \\sum\\limits_{n = - \\infty }^{ + \\infty } {\\left( {\\frac{1}{m}} \\right){e^{ - \\left( {\\lambda {T_s}/m} \\right)n}}u[n]\\,{z^{ - n}}} \\\\ {H_v}(z) = \\left( {\\frac{1}{m}} \\right)\\sum\\limits_{n = 0}^{ + \\infty } {{{\\left( {{e^{ - \\left( {\\lambda {T_s}/m} \\right)}}{z^{ - 1}}} \\right)}^n}} = \\frac{{1/m}}{{1 - {e^{ - \\left( {\\lambda {T_s}/m} \\right)}}{z^{ - 1}}}} \\end{array}$$ with a region-of-convergence (ROC) given by \\(\\left| z \\right| > {e^{ - \\lambda {T_s}/m}}.\\) This leads to the difference equation: (7.5) $$v[n] - \\left( {{e^{ - \\left( {\\lambda {T_s}/m} \\right)}}} \\right)v[n - 1] = \\left( {\\frac{1}{m}} \\right)f[n]$$ This is the discrete-time version of the Langevin equation, Equation 7.1 . The input \\(f[n]\\) is the Gaussian, white-noise process. See Problem 7.1 to explore an important issue related to Equation 7.5 . This all seems quite straightforward but we have neglected one significant detail. The impulse response must be bandlimited so that a finite \\({T_s}\\) can be chosen. But given a finite number of terms in the sum, no impulse response that is of the form \\(\\sum\\nolimits_k {{A_k}{e^{ - {s_k}t}}u(t)}\\) can be bandlimited . See Problem 7.2 . Unless the aliasing induced by the use of a finite sampling interval is negligible, the impulse invariant technique can lead to erroneous results and conclusions. This, in turn, implies that if we insist on using this technique we must sample at a very high rate. As we shall soon see, in the case of Equation 7.3 , a sampling frequency of \\({\\omega _s} \\ge 200\\left( {\\lambda /m} \\right) = 200/\\theta\\) is warranted.","title":"Impulse-invariant sampling"},{"location":"Chap_7.html#how-big-is-big-how-small-is-small","text":"The Langevin equation is a description appropriate for a small particle that is being battered by even smaller particles. See Section 15.5 of Reif 2 for an elegant presentation of this model. To appreciate what this means let us examine the case of a gold sphere whose radius is 10 \\(\\mu\\) m in a water bath (test tube) at a temperature of \\(\\Psi\\) = 21 \u00baC. The radius of a water molecule is about 0.14 nm, about \\({10^{ - 5}}\\) that of the gold particle. After a period of time the gold particle will sink to the bottom of the test tube under the force of gravity. The terminal velocity of the gold particle is, however, only 4 mm/s so we will have a few seconds to perform our measurements. In that time we will focus on lateral motion ( \\(x\\) -direction) as opposed to axial ( \\(z\\) -direction) motion. In the time constant \\(\\theta = m/\\lambda\\) defined in Equation 7.3 , \\(\\lambda\\) is the damping factor and according to Stokes\u2019 Law given by: (7.6) $$\\lambda = 6\\pi \\eta R$$ The parameter \\(\\eta\\) is the dynamic viscosity of the fluid (water) and \\(R\\) is the \u201chydrodynamic\u201d radius of the particle (gold). Substituting the appropriate values ( \\(\\eta = 1.002\\) cP, \\(R = 10\\) \\(\\mu\\) m, \\(m = 81\\) ng) gives \\(\\lambda = 188.9\\) \\(\\mu\\) g/s and \\(\\theta\\) = 428 \\(\\mu\\) s. This is a long time compared to the average time interval between collisions of the gold sphere and water molecules which, to a rough approximation, is 10 fs. We can, therefore, consider the gold particle as being driven by a stochastic force with about \\({10^{10}}\\) collisions in one time constant \\(\\theta.\\) These collisions with the gold sphere occur from all possible directions (4 \\(\\pi\\) steradians) and the large number means that the Central Limit Theorem applies and the driving force \\(f(t),\\) the sum of all the independent collision forces, can be modeled as having a Gaussian amplitude distribution.","title":"How big is big? How small is small?"},{"location":"Chap_7.html#choosing-the-sampling-period","text":"Based upon a value for \\(\\theta\\) that we can calculate, we now look at the appropriate value of the sampling interval \\({T_s}\\) for this example. The impulse response is not bandlimited so any sampling represents undersampling. As we shall see in Figure 7.1 , however, a finite choice for the sampling interval \\({T_s}\\) can be justified and in practice will appear to be oversampling. The \u201cLangevin filter\u201d associated with Equation 7.3 has a lowpass characteristic: (7.7) $$\\begin{array}{l} {h_v}(t) = \\left( {\\frac{1}{m}} \\right){e^{ - \\left( {\\lambda t/m} \\right)}}u(t)\\\\ \\left| {{H_v}(\\omega )} \\right| = \\left( {\\frac{1}{m}} \\right)\\frac{1}{{\\sqrt {{\\omega ^2} + {{\\left( {\\lambda /m} \\right)}^2}} }} \\end{array}$$ The frequency \\({\\omega _c}\\) at which the amplitude-squared is down by a factor of two from its value at \\(\\omega = 0\\) is given by \\({\\omega _c} = \\lambda /m\\) and might seem to qualify as a \u201chighest\u201d frequency. Using the Nyquist criterion and choosing \\({\\omega _s} = 2{\\omega _c} = 2\\lambda /m,\\) however, is not enough to avoid aliasing. To do so we must choose a higher frequency \\({\\omega _{\\max }}\\) in the spectrum than \\({\\omega _c}.\\) If we require that the filter amplitude-squared is down by a factor of 100 (not 2) from the filter value at \\(\\omega = 0,\\) then \\({\\omega _{\\max }} \\simeq 10{\\omega _c}.\\) The (Nyquist) sampling frequency is then approximated by \\({\\omega _s} = 2{\\omega _{\\max }} =\\) \\(2 \\bullet 10{\\omega _c} = 20\\lambda /m.\\) This sampling issue is illustrated in Figure 7.1[a,b] . ( a ) Sampling at ${\\omega _s} = 2\\pi /{T_s} = 2\\lambda /m.$ Langevin filter spectrum in blue , sampled Langevin filter spectrum in dark red ( b ) Sampling at ${\\omega _s} = 2\\pi /{T_s} = 20\\lambda /m.$ Sampled Langevin filter spectrum ( c ) Sampling at ${\\omega _s} = 2\\pi /{T_s} = 200\\lambda /m.$ Sampled Langevin filter spectrum Figure 7.1: Spectral magnitude \\(\\lvert {{H_v}\\left( \\omega \\right)} \\rvert\\) displayed in blue . Spectrum after sampling at various frequencies \\({\\omega _s} = 2\\pi /{T_s}\\) displayed in dark red . Note the change in the scale of the frequency axes between the three graphs. For the numerical values presented in the text, the value of \\(\\lambda /m\\) = 2334 rad/s (371 Hz). It should be clear that using a sampling frequency of \\(2\\lambda /m\\) or \\(20\\lambda /m\\) is insufficient to minimize aliasing. At \\({\\omega _s} = 200{\\omega _c} = 200\\lambda /m,\\) as illustrated in Figure 7.1c , the aliasing is perhaps acceptable. This is the value that we shall use in the remainder of this case-study. The sampling interval is, therefore, chosen as \\({T_s} = 2\\pi /{\\omega _s} = \\pi m/100\\lambda\\) = 13.4 \\(\\mu\\) s. The question of \u201cwhat is acceptable\u201d is a tricky one. Formally, there is no \u201chighest frequency\u201d and thus no Nyquist frequency. Practically, a sampling frequency as illustrated in Figure 7.1 c means that the damage (distortion) caused by aliasing is confined to the highest frequencies where the signal energy is already quite small. If this energy is small compared to the noise levels at these same frequencies, then the choice of \\({T_s}\\) can be considered \u201cacceptable\u201d. This is not a mathematical choice, however, but an engineering one. The comparison of signal energy and noise energy is the subject of Chapter 8 .","title":"Choosing the sampling period"},{"location":"Chap_7.html#the-langevin-velocity-equation","text":"Let us begin with the velocity equation, its original form, and our difference equation based upon the impulse-invariant transformation: (7.8) $$\\begin{array}{*{20}{l}} {m\\frac{{dv(t)}}{{dt}} + \\lambda v(t) = f(t)}\\\\ {v[n] - \\left( {{e^{ - \\left( {\\lambda {T_s}/m} \\right)}}} \\right)v[n - 1] = \\left( {\\frac{1}{m}} \\right)f[n]} \\end{array}$$ The driving force is Gaussian, white noise with the following characteristics: (7.9) $$\\begin{array}{l} {\\varphi _{ff}}[k] = {F_o}\\delta [k]\\\\ {S_{ff}}(\\Omega ) = {F_o} \\end{array}$$ We now appeal to Equation 5.8 , Equation 5.2 , and Equation 5.4 which are summarized below: (7.10) $$\\begin{array}{l} \\mathop {\\lim }\\limits_{k \\to \\infty } \\left\\{ {{\\varphi _{ff}}[k]} \\right\\} = {\\left| {{m_f}} \\right|^2}\\\\ {\\gamma _{ff}}[0] = {\\varphi _{ff}}[0] - {\\left| {{m_f}} \\right|^2} = \\sigma _f^2 \\end{array}$$ Substituting the values from Equation 7.9 into Equation 7.10 yields the results that \\({m_f} = \\left\\langle {f[n]} \\right\\rangle = 0\\) and \\({\\sigma _f} = \\sqrt {{F_o}}.\\) The average value of the driving force is zero. In this one-dimensional system there is\u2014on the average\u2014just as much force coming from the left as from the right. The standard deviation of the force is \\(\\sqrt {{F_o}}.\\) But this describes the input driving force. What are the characteristics of the random process that describes the particle velocity?","title":"The Langevin velocity equation"},{"location":"Chap_7.html#autocorrelation-function","text":"To answer this question we need to compute the autocorrelation of the velocity \\({\\varphi _{vv}}[k]\\) and its power spectral density \\({S_{vv}}(\\Omega ).\\) The autocorrelation follows from Equation 6.15 , specifically \\({\\varphi _{vv}}[k] = {\\varphi _{ff}}[k] \\otimes {\\varphi _{hh}}[k]\\) where \\({\\varphi _{hh}}[k]\\) is the autocorrelation function of the deterministic impulse response of the Langevin filter. That impulse response follows from Equation 7.8 and is given by: (7.11) $${h_v}[n] = \\left( {\\frac{1}{m}} \\right){e^{ - (\\lambda {T_s}/m)n}}u[n] = \\left( {\\frac{1}{m}} \\right){\\rho ^n}u[n]$$ where we have set \\(\\rho = {e^{ - \\left( {\\lambda {T_s}/m} \\right)}}\\) and clearly \\(0 < \\rho < 1.\\) It follows that: (7.12) $$\\begin{array}{*{20}{l}} {{\\varphi _{hh}}[k]}&{ = {{\\left( {\\frac{1}{m}} \\right)}^2}\\sum\\limits_{n = 0}^{ + \\infty } {{\\rho ^{2n + \\left| k \\right|}}} }\\\\ {\\,\\,\\,}&{ = {{\\left( {\\frac{1}{m}} \\right)}^2}\\left( {\\frac{1}{{1 - {\\rho ^2}}}} \\right){\\rho ^{\\left| k \\right|}}} \\end{array}$$ At this point you should notice some similarities to calculations performed in Equation 5.18 and Equation 5.19 including the use of the evenness of the autocorrelation function.","title":"Autocorrelation function"},{"location":"Chap_7.html#power-spectral-density","text":"The power spectral density associated with the deterministic signal \\(h[n],\\) \\({S_{hh}}(\\Omega ) = {\\mathscr{F}}\\left\\{ {{\\varphi _{hh}}[k]} \\right\\},\\) is given by: (7.13) $$\\begin{array}{*{20}{l}} {{S_{hh}}(\\Omega )}&{ = {\\mathscr{F}}\\left\\{ {{{\\left( {\\frac{1}{m}} \\right)}^2}\\left( {\\frac{1}{{1 - {\\rho ^2}}}} \\right){\\rho ^{\\left| k \\right|}}} \\right\\}}\\\\ {\\,\\,\\,}&{ = {{\\left( {\\frac{1}{m}} \\right)}^2}\\left( {\\frac{1}{{1 + {\\rho ^2} - 2\\rho \\cos \\Omega }}} \\right)} \\end{array}$$ Note that the real and even autocorrelation function \\({{\\varphi _{hh}}[k]}\\) has led to a real and even power spectral density \\({S_{hh}}(\\Omega ).\\) The next step is to calculate \\({{\\varphi _{vv}}[k]}\\) and \\({S_{vv}}(\\Omega )\\) but that is straightforward given Equation 6.15 and Equation 7.9 . (7.14) $$\\begin{array}{*{20}{l}} {{\\varphi _{vv}}[k]}&{ = {\\varphi _{ff}}[k] \\otimes {\\varphi _{hh}}[k]}\\\\ {\\,\\,\\,}&{ = {F_o}\\delta [k] \\otimes {\\varphi _{hh}}[k] = {F_o}{\\varphi _{hh}}[k]}\\\\ {\\,\\,\\,}&{ = {{\\left( {\\frac{1}{m}} \\right)}^2}\\left( {\\frac{{{F_o}}}{{1 - {\\rho ^2}}}} \\right){\\rho ^{\\left| k \\right|}}}\\\\ {\\,\\,\\,}&{\\,\\,\\,}\\\\ {{S_{vv}}(\\Omega )}&{ = {S_{ff}}(\\Omega ){S_{hh}}(\\Omega ) = {F_o}{S_{hh}}(\\Omega )}\\\\ {\\,\\,\\,}&{ = {{\\left( {\\frac{1}{m}} \\right)}^2}\\left( {\\frac{{{F_o}}}{{1 + {\\rho ^2} - 2\\rho \\cos \\Omega }}} \\right)} \\end{array}$$ These two descriptions of the filtered random process\u2014a white, Gaussian process filtered through the Langevin velocity equation\u2014are illustrated in Figure 7.2 . ( a ) Autocorrelation ${{\\varphi _{vv}}[k\\rbrack}$ of the 1-D Langevin velocity process ( b ) Power spectral density ${{S_{vv}}(\\Omega )}$ of the 1-D Langevin velocity process Figure 7.2: The power spectral density is plotted for the baseband \\(- \\pi \\lt \\Omega \\le + \\pi.\\) Curves shown here are for two different values of \\(\\rho\\) : \\(\\rho = 0.5\\) (shown in dark red ) and \\(\\rho = 0.97\\) (shown in blue ). The latter choice will be encountered again, later in this chapter. All curves have been normalized to one at \\(k = 0\\) and \\(\\Omega = 0.\\) It should be clear that although the driving force is white noise, the velocity process is pink noise as described in Example: Pink Noise .","title":"Power spectral density"},{"location":"Chap_7.html#descriptive-statistics-mean-and-standard-deviation","text":"Having the autocorrelation function and the power spectral density, we can now calculate the mean and standard deviation of the filtered random process. There are two ways to arrive at the mean. We can use Equation 7.10 with Equation 7.12 and Equation 7.14 in which case we have: (7.15) $${\\left| {{m_v}} \\right|^2} = \\mathop {\\lim }\\limits_{k \\to \\infty } \\left\\{ {{\\varphi _{vv}}[k]} \\right\\} = 0$$ That is, the mean is 0. Alternatively, we can use Equation 6.9 and Equation 7.4 to give: (7.16) $$\\begin{array}{*{20}{l}} {{m_v}}&{ = {m_f}\\,{H_v}(\\Omega = 0) = {m_f}\\,{H_v}(z = 1)}\\\\ {\\,\\,\\,}&{ = 0\\left( {\\frac{{1/m}}{{1 - {e^{ - (\\lambda {T_s}/m)}}}}} \\right) = 0} \\end{array}$$ Either way, a mean of zero makes sense. The driving force pushes the particle left and right and the Langevin equation smooths this motion. But the smoothing does not change the average velocity. The standard deviation comes from: (7.17) $$\\begin{array}{*{20}{l}} {\\sigma _v^2}&{ = {\\gamma _{vv}}[0] = {\\varphi _{vv}}[0] - {{\\left| {{m_v}} \\right|}^2}}&{\\,\\,\\,}\\\\ {\\,\\,\\,}&{ = {\\varphi _{vv}}[0] = {{\\left( {\\frac{1}{m}} \\right)}^2}\\left( {\\frac{{{F_o}}}{{1 - {\\rho ^2}}}} \\right)}& \\Rightarrow \\\\ {{\\sigma _v}}&{ = \\frac{1}{m}\\sqrt {\\frac{{{F_o}}}{{1 - {e^{ - 2\\lambda {T_s}/m}}}}} }&{\\,\\,\\,} \\end{array}$$ The standard deviation changes, something we should expect from the filtering associated with the Langevin equation and our experience with Laboratory Exercise 6.1 in Chapter 6 . It is instructive to compare this discrete-time result to the continuous time result. We offer\u2014without proof\u2014that the various equations to describe the filtering of random processes and the calculation of various statistical descriptions are the same in continuous time as in discrete time. You are, of course, welcome to derive these results using the same methods we have used in the previous chapters. See Problem 7.3 . Starting from Equation 7.1 and Equation 7.3 we have the results summarized in Table 1 . Description Continuous-time Discrete-time ${h_v}$ $\\frac{1}{m}{e^{ - \\lambda t/m}}u(t)$ $\\frac{1}{m}{\\rho ^n}u[n]$ ${H_v}$ $\\frac{1}{{ms + \\lambda }}$ $\\frac{1}{m}\\left( {\\frac{1}{{1 - \\rho {z^{ - 1}}}}} \\right)$ ${\\varphi _{hh}}$ $\\left( {\\frac{1}{{2m\\lambda }}} \\right){e^{ - \\lambda \\lvert \\tau \\rvert/m}}$ ${\\left( {\\frac{1}{m}} \\right)^2}\\left( {\\frac{1}{{1 - {\\rho ^2}}}} \\right){\\rho ^{\\lvert k \\rvert}}$ ${\\varphi _{vv}}$ ${F_o}{\\varphi _{hh}}(\\tau )$ ${F_o}{\\varphi _{hh}}[k]$ ${S_{vv}}$ ${\\left( {\\frac{1}{m}} \\right)^2}\\frac{{{F_o}}}{{{\\omega ^2} + {{\\left( {\\lambda /m} \\right)}^2}}}$ ${\\left( {\\frac{1}{m}} \\right)^2}\\left( {\\frac{{{F_o}}}{{1 + {\\rho ^2} - 2\\rho \\cos \\Omega }}} \\right)$ ${\\lvert {{m_v}} \\rvert^2} = \\mathop {\\lim }\\limits_{\\tau ,\\,k \\to \\infty } \\left\\{ {{\\varphi _{vv}}} \\right\\}$ 0 0 $\\begin{aligned}\\sigma_v^2 &= \\left( \\varphi_{vv} - \\lvert m_v \\rvert^2 \\right) \\rvert_{\\tau ,k = 0}\\\\ &= \\langle v^2 \\rangle \\end{aligned}$ $\\frac{{{F_o}}}{{2m\\lambda }}$ ${\\left( {\\frac{1}{m}} \\right)^2}\\left( {\\frac{{{F_o}}}{{1 - {\\rho ^2}}}} \\right)$ Table 7.1: Comparison of continuous-time and discrete-time descriptions of the Langevin velocity process. The parameter \\(\\rho = {e^{ - (\\lambda {T_s}/m)}}.\\) The result for the average value of the velocity is the same; the mean value of the velocity is zero. The result for the continuous-time standard deviation (or variance \\(\\sigma _{v,a}^2\\) ) differs from the discrete-time standard deviation (or variance \\(\\sigma _{v,d}^2\\) ) where \u201c \\(a\\) \u201d stands for analog (continuous-time) and \u201c \\(d\\) \u201d for digital (discrete-time). (7.18) $$\\begin{array}{*{20}{l}} {\\sigma _{v,a}^2}&{ = \\frac{{{F_o}}}{{2m\\lambda }}}\\\\ {\\sigma _{v,d}^2}&{ = \\frac{1}{{{m^2}}}\\left( {\\frac{{{F_o}}}{{1 - {\\rho ^2}}}} \\right) = \\frac{1}{{{m^2}}}\\left( {\\frac{{{F_o}}}{{1 - {e^{ - 2\\lambda {T_s}/m}}}}} \\right)} \\end{array}$$ We pay a price for using discrete-time techniques, the perhaps unexpected term \\(1 - {\\rho ^2}\\) in the denominator of Equation 7.18 . This term can, however, asymptotically resemble the term in Table 7.1 . As the sampling rate increases, as \\({T_s} \\to 0,\\) we have: (7.19) $$\\begin{array}{*{20}{l}} {\\mathop {\\lim }\\limits_{{T_s} \\to 0} \\left\\{ {\\sigma _{v,d}^2} \\right\\}}&{ = \\mathop {\\lim }\\limits_{{T_s} \\to 0} \\left\\{ {\\frac{1}{{{m^2}}}\\left( {\\frac{{{F_o}}}{{1 - {e^{ - 2\\lambda {T_s}/m}}}}} \\right)} \\right\\}}\\\\ {\\,\\,\\,}&{ \\approx \\frac{{{F_o}}}{{{m^2}}}\\left( {\\frac{1}{{1 - (1 - 2\\lambda {T_s}/m)}}} \\right)}\\\\ {\\,\\,\\,}&{ \\approx \\frac{{{F_o}}}{{2m\\lambda {T_s}}} = \\frac{1}{{{T_s}}}\\sigma _{v,a}^2} \\end{array}$$ Note that we have used the Taylor series linearization of \\({\\rho ^2}\\) as \\({T_s} \\to 0.\\) This suggests using a sampling interval such that \\({T_s} < < m/2\\lambda = \\theta /2.\\) We have met this condition with our earlier choice of \\({T_s} = 2\\pi /{\\omega _s} = \\pi m/100\\lambda.\\) We can then calculate the variance of the physical (analog) velocity process from our (digital) data, \\(\\sigma _{v,a}^2 = {T_s}\\,\\sigma _{v,d}^2.\\) Before proceeding with the Langevin position equation, one more observation is in order. The variance of the continuous-time velocity is the mean-square velocity of the particle with mass \\(m\\) in the water bath at temperature \\(\\Psi.\\) The battering of the particle by water molecules is caused by the thermal motion of the molecules. Even though the particle is in thermal equilibrium with its surroundings, the battering continues. From the Equipartition Theorem of thermal physics we know that each degree-of-freedom of motion has as an average kinetic energy of \\({k_B}\\Psi /2\\) due to thermal effects\u2014see Feynman 3 \u2014where \\({k_B} = 1.380658 \\times {10^{ - 23}}\\) J/K is the Boltzmann constant. With \\(K{E_x}\\) denoting the average kinetic energy of translational motion in the \\(x\\) direction, this means: (7.20) $$\\begin{array}{*{20}{l}} {\\frac{{{F_o}}}{{2m\\lambda }}}&{ = \\sigma _{v,a}^2 = \\left\\langle {v_x^2} \\right\\rangle = \\frac{{2\\,K{E_x}}}{m} = \\frac{{{k_B}\\Psi }}{m}\\,\\,\\,\\, \\Rightarrow }\\\\ {{F_o}}&{ = 2\\lambda {k_B}\\Psi } \\end{array}$$ The second line in Equation 7.20 is important. Based upon the dynamic viscosity, the equilibrium temperature, and the Boltzmann constant, we can assign a specific physical value to \\({{F_o}},\\) a term that has, until now, been a simple scale factor.","title":"Descriptive statistics \u2013 mean and standard deviation"},{"location":"Chap_7.html#the-langevin-position-equation","text":"At first glance one might expect that analyzing the Langevin position equation might simply be \u201cmore of the same\u201d. As we shall see, however, this equation offers some important insights into phenomena such as Brownian motion. We start with the causal, stable position equation in continuous time: (7.21) $$\\begin{array}{l} m\\frac{{{d^2}x(t)}}{{d{t^2}}} = f(t) - \\lambda \\frac{{dx(t)}}{{dt}}\\\\ {H_x}(s) = \\frac{1}{{m{s^2} + \\lambda s}} \\end{array}$$ The impulse response \\({h_x}(t)\\) follows from: (7.22) $$\\begin{array}{l} {H_x}(s) = \\frac{1}{{m{s^2} + \\lambda s}} = \\frac{1}{\\lambda }\\left( {\\frac{1}{s} - \\frac{1}{{s + \\lambda /m}}} \\right)\\,\\,\\,\\,\\, \\Rightarrow \\\\ {h_x}(t) = \\frac{1}{\\lambda }u(t) - \\frac{1}{\\lambda }{e^{ - \\lambda t/m}}u(t) \\end{array}$$ Using the impulse-invariant technique yields: (7.23) $$\\begin{array}{*{20}{l}} {{h_x}[n]}&{ = \\frac{1}{\\lambda }u[n] - \\frac{1}{\\lambda }{{\\left( {{e^{ - \\lambda {T_s}/m}}} \\right)}^n}u[n]}&{}\\\\ {\\,\\,\\,}&{ = \\frac{1}{\\lambda }u[n] - \\frac{1}{\\lambda }{\\rho ^n}u[n]}& \\Rightarrow \\\\ {{H_x}(z)}&{ = \\frac{{1{\\rm{/}}\\lambda }}{{1 - {z^{ - 1}}}} - \\frac{{1{\\rm{/}}\\lambda }}{{1 - \\rho {z^{ - 1}}}}}&{}\\\\ {\\,\\,\\,}&{ = \\frac{1}{\\lambda }\\left( {\\frac{{{z^{ - 1}}(1 - \\rho )}}{{1 - {z^{ - 1}}(1 + \\rho ) + \\rho {z^{ - 2}}}}} \\right)}&{} \\end{array}$$ Again we have used \\(\\rho = {e^{ - (\\lambda {T_s}/m)}}.\\) The difference equation relating driving force \\(f[n]\\) to position \\(x[n]\\) is thus given by: (7.24) $$\\begin{array}{l} x[n] - (1 + \\rho )x[n - 1] + \\rho x[n - 2]\\\\ \\,\\,\\,\\,\\,\\,\\,\\, = \\left( {\\frac{{1 - \\rho }}{\\lambda }} \\right)f[n - 1] \\end{array}$$","title":"The Langevin position equation"},{"location":"Chap_7.html#expected-value","text":"The average value of the position \\({m_x},\\) using the property that \\(\\Omega = 0\\) corresponds to \\(z = {\\left. {{e^{j\\Omega }}} \\right|_{\\Omega = 0}} = 1,\\) is straightforward to calculate: (7.25) $$\\begin{array}{*{20}{l}} {{m_x}}&{ = {m_f}\\,{H_x}(\\Omega = 0) = {m_f}\\,{H_x}(z = 1)}\\\\ {\\,\\,\\,}&{ = 0\\left( {\\frac{{1 - \\rho }}{\\lambda }} \\right)\\left( {\\frac{1}{0}} \\right) = indeterminate} \\end{array}$$ What is happening here? First, this is not a consequence of the transformation from continuous time to discrete time. The value of \\({H_x}(\\omega )\\) is also indeterminate for \\(\\omega = 0.\\) We can better understand this result if we look at the impulse response of the difference equation, Equation 7.23 . (7.26) $${h_x}[n] = \\left( {\\frac{1}{\\lambda }} \\right)u[n] - \\left( {\\frac{1}{\\lambda }} \\right){\\rho ^n}u[n]$$ The form of this impulse response brings us back to the discussion in Chapter 5 . The first term is dependent on \\(u[n]\\) whose Fourier transform\u2014as we saw in Equation 5.21 \u2014has singularities at \\(\\Omega = 0.\\) It is these singularities that cause our problem. Nevertheless, our intuition suggests that the mean \\({m_x}\\) should be zero. The random process associated with \\(f[n]\\) has a zero mean, \\({m_f} = \\left\\langle {f[n]} \\right\\rangle = 0,\\) so the positive values should be \u201ccancelled\u201d by the negative values. As we have assumed that \\(f[n]\\) has a Gaussian probability density function \\(N\\left( {\\mu = 0,\\sigma = \\sqrt {{F_o}} } \\right),\\) we can show that this is an example of a filtered Gaussian random walk . The first term in \\({h_x}[n]\\) in Equation 7.26 , \\({h_1}[n] = \\left( {1/\\lambda } \\right)u[n]\\) implies that the position after \\(n\\) steps involves the sum of that number of independent steps: (7.27) $$\\begin{array}{*{20}{l}} {{x_1}[n]}&{ = \\left( {\\frac{1}{\\lambda }} \\right)u[n] \\otimes f[n] = \\left( {\\frac{1}{\\lambda }} \\right)\\sum\\limits_{k = - \\infty }^{ + \\infty } {f[k]u[n - k]} }\\\\ {\\,\\,\\,}&{ = \\left( {\\frac{1}{\\lambda }} \\right)\\sum\\limits_{k = 0}^n {f[k]} } \\end{array}$$ We assume here that the particle with mass \\(m\\) starts at position zero at time zero, \\(x[0] = 0,\\) and that the random driving force starts at time zero, \\(f[n] = 0\\) for \\(n < 0.\\) The term \\(\\sum\\nolimits_k {f[k]}\\) represents the sum of \\(n\\) independent, identically-distributed, Gaussian random variables: a Gaussian random walk. Random walks have been studied extensively and a lucid discussion can be found in Cox 4 . For a random walk where each step has an average value of zero, the expected value of the particle position after \\(n\\) steps is likewise zero. The second term in \\({h_x}[n]\\) in Equation 7.26 is easier; the output of this component of the Langevin filter has a mean of zero. This can be seen through application of Equation 6.9 with \\({m_f} = 0.\\) By identifying the first term in \\({h_x}[n]\\) ( Equation 7.26 ) as a Gaussian random walk problem, we have demonstrated that the mean value of the position in the Langevin position equation is zero, \\({m_x} = \\left\\langle {x[n]} \\right\\rangle = 0.\\)","title":"Expected value"},{"location":"Chap_7.html#autocorrelation-function_1","text":"We are now in a position to work with the autocorrelation function. Again we refer to the methodology developed in Chapter 5 for a deterministic signal, specifically Equation 5.14 , and to the impulse response of the Langevin position equation, Equation 7.26 . For the deterministic signal we had: (7.28) $$x[n] = u[n] - {\\left( {\\frac{1}{2}} \\right)^n}u[n]$$ and for the Langevin position equation: (7.29) $${h_x}[n] = \\left( {\\frac{1}{\\lambda }} \\right)u[n] - \\left( {\\frac{1}{\\lambda }} \\right){\\rho ^n}u[n]$$ The similarity of the two equations should be clear. This means that, referring to Equation 5.19 and using the windowing function \\(w[n]\\) and Equation 7.14 , we can write the autocorrelation function as: (7.30) $${\\varphi _{xx}}[k] = \\frac{{{F_o}}}{{{\\lambda ^2}}}\\left( {\\mathop {\\lim }\\limits_{N \\to \\infty } N - \\left| k \\right| - \\left( {\\frac{{\\rho + {\\rho ^2} + {\\rho ^{\\left| k \\right| + 1}}}}{{1 - {\\rho ^2}}}} \\right)} \\right)$$ In order to show that \\({\\varphi _{xx}}[k]\\) grows linearly with \\(N\\) we do not replace it by its limit. The autocorrelation is displayed in Figure 7.3 . It is important to realize that while it may look quite similar to Figure 5.2 , it differs in an important way. The example that was developed in Chapter 5 was the autocorrelation function of a deterministic signal \\(x[n].\\) The result in Equation 7.30 is the autocorrelation function of the stochastic signal \\(x[n]\\) found through the Langevin equation. Figure 7.3: Autocorrelation function of \\(x[n\\rbrack\\) in Equation 7.30 plotted for \\(\\left| k \\right| < 10.\\) The parameter \\(\\rho = 1/2\\) and the value of \\({\\varphi _{xx}}[k = 0\\rbrack = \\left( {{F_o}/{\\lambda ^2}} \\right)\\left( {N - 5/3)} \\right).\\) \\(N\\) describes the width of window \\(w[n\\rbrack\\) and in this calculation \\(N = 20,000.\\) We have determined the mean value of the random process \\({m_x} = \\left\\langle {x[n]} \\right\\rangle = 0\\) and we now have the autocorrelation function of that random process in the form of Equation 7.30 .","title":"Autocorrelation function"},{"location":"Chap_7.html#power-spectral-density_1","text":"Starting from Equation 6.21 and Equation 7.29 we can compute the power spectral density \\({S_{xx}}(\\Omega ).\\) See Problem 7.6 . (7.31) $$\\begin{array}{*{20}{l}} {{S_{xx}}(\\Omega )}&{ = {{\\left| {{H_x}(\\Omega )} \\right|}^2}{S_{ff}}(\\Omega )\\; = {{\\left| {{H_x}(\\Omega )} \\right|}^2}{F_o}}\\\\ {\\,\\,\\,}&{ = \\frac{{{F_o}{{(1 - \\rho )}^2}{{\\csc }^2}(\\Omega /2)}}{{{{(2\\lambda )}^2}(1 + {\\rho ^2} - 2\\rho \\cos \\Omega )}}} \\end{array}$$ This result including its behavior at \\(\\Omega = 0\\) is shown in Figure 7.4 . Figure 7.4: Power spectral density \\({S_{xx}}(\\Omega )\\) of \\(x[n\\rbrack\\) in Equation 7.31 plotted for the baseband \\(- \\pi \\lt \\Omega \\le + \\pi.\\) The parameter \\(\\rho = 1/2\\) and the parameters \\({F_0}\\) and \\(\\lambda\\) each equal one. The width of \\(w[n\\rbrack\\) in this calculation \\(N = 20,000.\\) Using Equation 7.10 we can determine the variance\u2014the mean-square dispersion \\(\\left\\langle {{x^2}} \\right\\rangle\\) \u2014of the random process. (7.32) $$\\begin{array}{*{20}{l}} {\\sigma _x^2}&{ = {\\gamma _{xx}}[0] = {\\varphi _{xx}}[0] - {{\\left| {{m_x}} \\right|}^2} = {\\varphi _{xx}}[0] - {0^2}}\\\\ {\\,\\,\\,}&{ = \\frac{{{F_o}}}{{{\\lambda ^2}}}\\left( {\\mathop {\\lim }\\limits_{N \\to \\infty } N - \\left( {\\frac{{2\\rho + {\\rho ^2}}}{{1 - {\\rho ^2}}}} \\right)} \\right) = \\left\\langle {{x^2}} \\right\\rangle } \\end{array}$$ The size of the window and the number of independent steps that are added together in Equation 7.27 are the same, \\(N.\\) This means that for large values of \\(N,\\) the variance grows as \\(N\\) and the standard deviation grows as \\(\\sqrt N.\\) This coincides with our knowledge of the Gaussian random walk and Brownian motion, an average displacement of zero and a standard deviation that grows as \\(\\sqrt N\\) and is, therefore, unbounded. To repeat what we mentioned in Chapter 5 , the mathematics may indicate that we are dealing with an \u201cill-behaved\u201d mathematical problem but this problem can, in fact, be a description of a real physical system and amenable to analysis and interpretation. As we saw in Equation 7.19 , examining what happens as the sampling rate increases, as \\({T_s} \\to 0,\\) can provide additional insight into the relation between the analog world and the digital world. Using the same linearization procedure yields: (7.33) $$\\sigma _x^2 = \\frac{{{F_o}}}{{{\\lambda ^2}}}\\left( {\\mathop {\\lim }\\limits_{N \\to \\infty } N - \\left( {\\frac{{3m}}{{2\\lambda {T_s}}} - 2} \\right)} \\right)$$ In Figure 7.1 , we demonstrated that a sufficiently small value of the sampling interval is given by \\({T_s} = \\pi m/100\\lambda.\\) The approximation that we are in a region where the \\(\\sqrt N\\) behavior dominates is thus given by: (7.34) $$N > > \\frac{3}{2}\\left( {\\frac{m}{{\\lambda {T_s}}}} \\right) = \\frac{{150}}{\\pi }$$ The total amount of time, \\({T^*},\\) that passes before we are in this region is characterized by: (7.35) $${T^*} > > \\frac{3}{2}\\left( {\\frac{m}{{\\lambda {T_s}}}} \\right){T_s} = \\frac{3}{2}\\left( {\\frac{m}{\\lambda }} \\right) = \\frac{3}{2}\\theta$$ For the numerical example presented earlier where \\(\\theta = 428\\mu\\) s, this implies that starting at time zero where \\(x[0] = 0,\\) Brownian motion with its \\(\\sqrt N\\) behavior will dominate the digital data when \\({T^*} > > 642\\mu\\) s. As we saw with Table 7.1 , it can be instructive to compare our discrete-time results to their continuous-time counterparts. These are summarized in Table 7.2 . Description Continuous-time Discrete-time ${h_x}$ $\\frac{1}{\\lambda }u(t) - \\frac{1}{\\lambda }{e^{ - \\lambda t/m}}u(t)$ $\\frac{1}{\\lambda }u[n] - \\frac{1}{\\lambda }{\\left( {{e^{ - \\lambda {T_s}/m}}} \\right)^n}u[n]$ ${H_x}$ $\\frac{1}{{m{s^2} + \\lambda s}}$ $\\frac{1}{\\lambda }\\left( {\\frac{{{z^{ - 1}}(1 - \\rho )}}{{1 - {z^{ - 1}}(1 + \\rho ) + \\rho {z^{ - 2}}}}} \\right)$ ${\\varphi _{hh}}$ $\\frac{1}{{{\\lambda ^2}}}(\\mathop {\\lim }\\limits_{T \\to \\infty } T - \\lvert \\tau \\rvert$ $ - \\frac{m}{\\lambda }(2 + {e^{ - \\lambda \\lvert \\tau \\rvert/m}}))$ $\\frac{1}{{{\\lambda ^2}}}(\\mathop {\\lim }\\limits_{N \\to \\infty } N - \\lvert k \\rvert$ $ - (\\frac{{\\rho + {\\rho ^2} + {\\rho ^{\\lvert k \\rvert + 1}}}}{{1 - {\\rho ^2}}}))$ ${\\varphi _{xx}}$ ${F_o}{\\varphi _{hh}}(\\tau )$ ${F_o}{\\varphi _{hh}}[k]$ ${S_{xx}}$ $\\left( {\\frac{1}{{{m^2}}}} \\right)\\left( {\\frac{1}{{{\\omega ^2}}}} \\right)\\frac{{{F_o}}}{{{\\omega ^2} + {{\\left( {\\lambda /m} \\right)}^2}}}$ $\\frac{{{{(1 - \\rho )}^2}{{\\csc }^2}(\\Omega /2)}}{{{{(2\\lambda )}^2}(1 + {\\rho ^2} - 2\\rho \\cos \\Omega )}}$ ${\\lvert {{m_x}} \\rvert^2} = \\mathop {\\lim }\\limits_{\\tau ,\\,k \\to \\infty } \\left\\{ {{\\varphi _{xx}}} \\right\\}$ 0 0 $\\begin{aligned}\\sigma_x^2 &= \\left( \\varphi_{xx} - \\lvert m_x \\rvert^2 \\right) \\rvert_{\\tau ,k = 0}\\\\ &= \\langle x^2 \\rangle \\end{aligned}$ $\\frac{{{F_o}}}{{{\\lambda ^2}}}\\left( {\\mathop {\\lim }\\limits_{T \\to \\infty } T - \\left( {\\frac{{3m}}{\\lambda }} \\right)} \\right)$ $\\frac{{{F_o}}}{{{\\lambda ^2}}}\\left( {\\mathop {\\lim }\\limits_{N \\to \\infty } N - \\left( {\\frac{{2\\rho + {\\rho ^2}}}{{1 - {\\rho ^2}}}} \\right)} \\right)$ Table 7.2: Comparison of continuous-time and discrete-time descriptions of the Langevin position process. The parameter \\(\\rho = {e^{ - (\\lambda {T_s}/m)}}.\\) To compare the variance estimates as we did in Equation 7.19 , we look at the situation where \\({T_s} \\to 0.\\) (7.36) $$\\begin{array}{*{20}{l}} {\\sigma _{x,a}^2}&{ = \\frac{{{F_o}}}{{{\\lambda ^2}}}\\left( {\\mathop {\\lim }\\limits_{T \\to \\infty } T - \\left( {\\frac{{3m}}{\\lambda }} \\right)} \\right)}\\\\ {\\sigma _{x,d}^2}&{ = \\frac{{{F_o}}}{{{\\lambda ^2}}}\\left( {\\mathop {\\lim }\\limits_{N \\to \\infty } N - \\left( {\\frac{{3m}}{{2\\lambda {T_s}}} - 2} \\right)} \\right)} \\end{array}$$ The results are similar to what we saw before. The \\(\\sqrt T\\) or \\(\\sqrt N\\) behavior of the standard deviation dominates after a sufficient observation time. Further, the relative behavior of the two variances can be described by \\(\\sigma _{x,a}^2 \\propto {T_s}\\sigma _{x,d}^2.\\) This is the second time that we have seen this relation between the continuous-time and the discrete-time and it will appear in the next section as well. This may surprise you as it appears that the units of the stochastic variable are not compatible. If, on the left side, the variance has the unit \\({\\left( {m/s} \\right)^2}\\) as in the velocity equation Equation 7.19 , then it should have that same unit for the variance on the right side as well. And the same holds for position. If on the left side, the variance has the unit \\({m^2}\\) as in the position equation Equation 7.36 then it should also be \\({m^2}\\) for the variance on the right side. So how does the \\({T_s}\\) fit in? We will explore this issue in Problem 7.8 .","title":"Power spectral density"},{"location":"Chap_7.html#tethered-particle-motion","text":"While the Langevin equation was described more than 100 years ago, the concepts introduced are still used in modern studies. To further our appreciation for how the processing of stochastic signals can yield insights into, for example, the biophysical properties of DNA, let us look at how a variant of the Langevin equation is used. The motion of a gold particle in a fluid provides a mechanism to study the dynamic behavior of polymers such as double-stranded DNA (dsDNA). In dynamic studies one can see how DNA is affected by ionic concentrations (e.g. \\({\\rm{M}}{{\\rm{g}}^{ + + }}\\) ) or by repair and maintenance proteins such as RecA. In the original model embodied in the Langevin equation, Equation 7.1 , the particle is free to move in the fluid. If, however, the particle is attached to one end of a polymer \u2014a macromolecule that is composed of a chain of essentially identical subunits\u2014and the other end of the polymer is attached to a substrate, then the motion of the particle will no longer be free. This is referred to as tethered particle motion (TPM) and is illustrated in Figure 7.5 . See Lindner 5 . Figure 7.5: Tethered particle ( gold ) attached to one end of a macromolecule (DNA) which, in turn, is attached to a substrate ( red ). Courtesy of Garini, Lindner et al, Bar Ilan University. The tether constrains the particle from free motion through two mechanisms. First, the particle cannot move further away from the attachment point of the molecule than the total molecule length \\(L.\\) If the molecule has a length of \\(L = 1660\\) nm then the three-dimensional envelope of possible positions is a hemisphere of radius 1660 nm. (There is a small correction necessary because the particle cannot penetrate the substrate but we shall ignore this volume exclusion effect.) Second, within this hemisphere small displacements of the particle in the fluid due to thermal collisions with the water molecules are restrained by a spring-like (Hookean) force, \\({f_{mol}} = - kx\\) exerted by the macromolecule. This leads to the modification of the Langevin model presented in Equation 7.1 : (7.37) $$m\\frac{{{d^2}x(t)}}{{d{t^2}}} = f(t)\\,\\,\\,\\underbrace { - \\lambda \\frac{{dx(t)}}{{dt}}}_{frictional\\,force}\\,\\,\\,\\underbrace { - kx}_{Hookean\\,force}$$ where \\(k\\) is the spring constant associated with the macromolecule. The three parameters \\(\\left( {m,\\lambda ,k} \\right)\\) are all positive. Further, the first two deal with the particle and the fluid while the third one, \\(k,\\) is a direct property of the macromolecular tether and thus experiments with the tethered particle can reveal properties of the macromolecule. A simulation of the three-dimensional motion involved is shown in Movie 7.1 . See Lindner 5 . Movie 7.1: Simulation of the motion of a tethered sphere. In the first part of this simulation the DNA is unencumbered and moves through a large domain shown in green . In the second part of the simulation, two protein molecules attach themselves to the DNA and change the dynamics of the motion as indicated in blue . (Courtesy of Garini et al, Bar-Ilan University) Real data as recorded from an \\(R = 40\\) nm gold sphere through a darkfield microscope are shown in Movie 7.2 . See Dietrich 6 . Movie 7.2: Darkfield microscope movie recorded with a $50 \\times$ objective lens with an $NA = 0.8.$ It is important to remember that you are viewing an object that is so small that it can be considered as a point source and thus the image is the point spread function, i.e. the optical impulse response. Nevertheless, the position of the gold particle can be determined to a precision of $\\sigma = 3$ nm. It is the Langevin equation extended with a spring force that describes the motion seen in Movie 7.1 and Movie 7.2 . The transfer function of the modified Langevin equation is: (7.38) $${H_x}(s) = \\frac{1}{{m{s^2} + \\lambda s + k}}$$ As in the Langevin position equation, this is a second-order linear differential equation but this time containing the spring constant. This type of second-order system is well-known. See Section 6.5.2 of Oppenheim 7 . There are three types of possible behavior depending upon the value of the discriminant \\({\\left( {\\lambda /2m} \\right)^2} - \\left( {k/m} \\right).\\) These are: (7.39) $$\\begin{array}{*{20}{l}} {{{\\left( {\\lambda /2m} \\right)}^2} - \\left( {k/m} \\right) > 0}& \\Rightarrow &{overdamped\\,system}\\\\ {{{\\left( {\\lambda /2m} \\right)}^2} - \\left( {k/m} \\right) = 0}& \\Rightarrow &{critically\\,damped\\,system}\\\\ {{{\\left( {\\lambda /2m} \\right)}^2} - \\left( {k/m} \\right) < 0}& \\Rightarrow &{underdamped\\,system} \\end{array}$$ If the system is underdamped it will exhibit exponentially-decaying oscillatory behavior, something which is familiar to us in a mass-spring system. To focus our attention on a realistic system at this molecular scale, it is important to know which of the three situations in Equation 7.39 is the relevant one. We need to look at realistic values for \\(\\left( {m,\\lambda ,k} \\right).\\)","title":"Tethered particle motion"},{"location":"Chap_7.html#how-big-is-big-how-small-is-small-redux","text":"Various measurement modalities can be used to observe the motion of the particle. These can be based upon polystyrene beads that contain fluorescent dye and are observed with fluorescence microscopy, magnetic beads that can be manipulated and measured with magnetic fields ( magnetic tweezers ), and gold particles that can be observed with darkfield microscopy Dietrich 6 . To continue our previous numerical example, let us look at gold particles ( \\(R = 40\\) nm) that are attached to DNA of 4882 bp (basepairs) with a total (contour) length of \\(L = 1660\\) nm. This gold particle is significantly smaller than the one used above so several of the basic parameters are affected. The gold particle is \\(285 \\times\\) larger in radius than a water molecule. We can, therefore, continue to think of a big particle being battered by small molecules. The terminal velocity of a free gold particle is now 64 nm/s meaning that the particle will not sink to the bottom of the test chamber during the course of an experiment. The mass of the gold particle is \\(m = 5.18\\) fg. The damping factor \\(\\lambda = 6\\pi \\eta R = 7.55 \\times {10^{ - 10}}\\) kg/s = 755 ng/s. The time constant \\(\\theta = m/\\lambda = 6.86\\) ns. The smaller gold particle means a significantly shorter time constant for the simpler Langevin velocity analysis. Two of the three parameters in Equation 7.38 have now been estimated. The value for \\(k\\) remains to be determined. There is an accepted model for the elasticity of DNA, the \u201cworm-like chain model\u201d (WLC). See Dietrich 6 and Rubinstein 8 . This model says that for small displacements, \\(x < < L\\) the force exerted by the dsDNA on the particle is given by: (7.40) $${f_{mol}} = - kx = - \\left( {\\frac{{3{k_B}\\Psi }}{{2PL}}} \\right)x$$ where \\(P\\) is the persistence length of the dsDNA molecule. The persistence length represents a way of approximating a polymer such as dsDNA as a collection of straight line segments each of length \\(P.\\) Each segment is modeled as stiff and thus does not bend. According to the model, the change in direction of the polymer occurs at the juncture of two segments. A typical value of \\(P\\) is 50 nm. We shall see later, in the experimental data in Figure 7.10 , that the displacement \\(x\\) is on the order of a few nm while \\(L\\) is 1660 nm justifying the use of Equation 7.40 . When measured at \\(\\Psi = 21\\) \u00b0C and with \\(L = 1660\\) nm the spring constant, using Equation 7.40 , is \\(k = 0.073\\) pN/ \\(\\mu\\) m. Using the values we have found for the three parameters yields: (7.41) $$\\begin{array}{l} {\\left( {\\lambda /2m} \\right)^2} - \\left( {k/m} \\right) = 5.32 \\times {10^{15}}\\,\\,{\\left( {{\\rm{rad}}/{\\rm{s}}} \\right)^2} > 0\\\\ \\,\\,\\,\\,\\,\\,\\,\\,\\, \\Rightarrow underdamped\\,system \\end{array}$$ This second-order system has two poles both of which are on the real axis in the \\(s\\) -plane. A Bode (log-log) plot of the frequency response \\(\\left| {{H_x}(\\omega )} \\right|\\) of this biomolecular-mechanical system is shown in Figure 7.6 . Figure 7.6: Normalized Bode plot in black of the frequency response of the second-order system comprised of a gold particle attached to DNA which, in turn, is attached to a substrate. Note the slope change where the Bode curve with poles at \\(\\omega = 100\\) rad/s and \\(\\omega = {10^8}\\) rad/s deviates from a first-order, dark red , dashed, straight-line approximation. This system with two real poles, one at \\(s = - {\\sigma _1} < 0\\) and the other at \\(s = - {\\sigma _2} < 0,\\) has an impulse response given by: (7.42) $$\\begin{array}{*{20}{l}} {{h_x}(t)}&{ = \\frac{1}{{\\sqrt {{\\lambda ^2} - 4km} }}\\left( {{e^{ - {\\sigma _1}t}} - {e^{ - {\\sigma _2}t}}} \\right)u(t)}&{}\\\\ {{\\sigma _1}}&{ = \\left( {\\frac{\\lambda }{{2m}}} \\right) - \\sqrt {{{\\left( {\\frac{\\lambda }{{2m}}} \\right)}^2} - \\left( {\\frac{k}{m}} \\right)} }&{{\\tau _1} = 1/{\\sigma _1}}\\\\ {{\\sigma _2}}&{ = \\left( {\\frac{\\lambda }{{2m}}} \\right) + \\sqrt {{{\\left( {\\frac{\\lambda }{{2m}}} \\right)}^2} - \\left( {\\frac{k}{m}} \\right)} }&{{\\tau _2} = 1/{\\sigma _2}} \\end{array}$$ The time constants associated with each of these poles are as indicated. Note that since \\({\\sigma _1} < {\\sigma _2},\\) this means that \\({\\tau _1} > {\\tau _2}.\\) The numerical values associated with these time constants for the example presented above are \\({\\tau _1} = 10.3\\) ms and \\({\\tau _2} = 6.86\\) ns, an enormous difference.","title":"How big is big? How small is small? \u2013 redux"},{"location":"Chap_7.html#choosing-the-sampling-period_1","text":"We are now in a position to choose the sampling period \\({T_s}.\\) As in Figure 7.1 , we look at the effect of the sampling period on the spectrum of the sampled noise process. This is shown in Figure 7.7 . ( a ) Spectrum $\\left| {{H_x}(\\omega )} \\right|$ of the extended Langevin filter with spring force (harmonic potential) ( b ) ${\\omega _s} = 2\\pi /{T_s} = 20{\\omega _c}$ ( c ) ${\\omega _s} = 2\\pi /{T_s} = 200{\\omega _c}$ Figure 7.7: ( a ) Spectral magnitude of the extended Langevin filter \\(\\left| {{H_x}(\\omega )} \\right|.\\) ( b , c ) Spectrum after sampling at various frequencies \\({\\omega _s} = 2\\pi /{T_s}.\\) The \u201ccutoff\u201d frequency \\({\\omega _c}\\) is defined in the text. Note the change in the scale of the frequency axes between the graphs. Once again we use a definition of the \u201ccutoff\u201d frequency \\({\\omega _c}\\) as the frequency at which the amplitude-squared is down by a factor of two from its value at \\(\\omega = 0.\\) This (ungainly) frequency is given by: (7.43) $${\\omega _c} = \\sqrt {\\frac{k}{m} - \\frac{{{\\lambda ^2}}}{{2{m^2}}} + \\frac{{\\sqrt {8{k^2}{m^2} - 4km{\\lambda ^2} + {\\lambda ^4}} }}{{2{m^2}}}}$$ This is, as before, not the highest frequency; see Figure 7.7 a . As we see in Figure 7.7 b , choosing \\({\\omega _s} = 20{\\omega _c}\\) is not enough to avoid aliasing. As shown in Figure 7.7 c , however, choosing \\({\\omega _s} = 200{\\omega _c}\\) results in a periodic spectrum with negligible aliasing. This, in turn corresponds to a sampling frequency of \\({\\omega _s} = 19409\\) rad/s ( \\(\\,{f_s} = 3089\\) Hz) and a sampling period of \\({T_s} = 324\\) \\(\\mu\\) s. In studying the Langevin velocity equation ( Figure 7.1 ), the sampling frequency\u2014also defined on the basis of a frequency where the spectrum-squared was down by a factor of two from its value at \\(\\omega = 0\\) \u2014was chosen to be \\(200{\\omega _c}.\\) In this extended equation, \\(200{\\omega _c}\\) is also required. This will be discussed in Problem 7.9 . We are now ready to transform the differential equation into a difference equation. Repeating the steps that we used earlier: (7.44) $$\\begin{array}{l} m\\frac{{{d^2}x(t)}}{{d{t^2}}} + \\lambda \\frac{{dx(t)}}{{dt}} + kx(t) = f(t)\\,\\\\ {h_x}(t) = \\frac{1}{{\\sqrt {{\\lambda ^2} - 4km} }}\\left( {{e^{ - {\\sigma _1}t}} - {e^{ - {\\sigma _2}t}}} \\right)u(t)\\\\ {h_x}[n] = {h_x}(n{T_s}) = \\frac{1}{{\\sqrt {{\\lambda ^2} - 4km} }}\\left( {{{\\underbrace {\\left( {{e^{ - {\\sigma _1}{T_s}}}} \\right)}_{{\\rho _1}}}^n} - {{\\underbrace {\\left( {{e^{ - {\\sigma _2}{T_s}}}} \\right)}_{{\\rho _2}}}^n}} \\right)u[n]\\\\ {h_x}[n] = \\frac{1}{{\\sqrt {{\\lambda ^2} - 4km} }}\\left( {\\rho _1^n - \\rho _2^n} \\right)u[n] \\end{array}$$ Note the definitions of \\({\\rho _1}\\) and \\({\\rho _2}\\) both of which meet the condition \\(0 < {\\rho _1},{\\rho _2} < 1.\\) Further, we know from Equation 7.42 that \\({\\rho _1} \\ne {\\rho _2}.\\) Taking the \\(z\\) -transform and then converting to a difference equation: (7.45) $$\\begin{array}{l} {H_x}(z) = \\frac{1}{{\\sqrt {{\\lambda ^2} - 4km} }}\\left( {\\frac{1}{{1 - {\\rho _1}{z^{ - 1}}}} - \\frac{1}{{1 - {\\rho _2}{z^{ - 1}}}}} \\right)\\\\ \\,\\,\\,\\,\\,\\,\\,\\,\\, = \\frac{1}{{\\sqrt {{\\lambda ^2} - 4km} }}\\left( {\\frac{{({\\rho _1} - {\\rho _2}){z^{ - 1}}}}{{1 - ({\\rho _1} + {\\rho _2}){z^{ - 1}} + {\\rho _1}{\\rho _2}{z^{ - 2}}}}} \\right)\\,\\,\\,\\,\\, \\Rightarrow \\\\ \\,\\,\\,\\,\\,\\\\ x[n] - ({\\rho _1} + {\\rho _2})x[n - 1] + {\\rho _1}{\\rho _2}x[n - 2]\\\\ \\,\\,\\,\\,\\,\\,\\,\\,\\, = \\left( {\\frac{{({\\rho _1} - {\\rho _2})}}{{\\sqrt {{\\lambda ^2} - 4km} }}} \\right)f[n - 1] \\end{array}$$","title":"Choosing the sampling period"},{"location":"Chap_7.html#expected-value_1","text":"Using Equation 6.9 we have: (7.46) $$\\begin{array}{*{20}{l}} {{m_x}}&{ = {m_f}{H_x}(\\Omega = 0) = {m_f}{H_x}(z = 1)}\\\\ {\\,\\,\\,}&{ = 0\\left( {\\frac{1}{{\\sqrt {{\\lambda ^2} - 4km} }}} \\right)\\left( {\\frac{{({\\rho _1} - {\\rho _2})}}{{1 - ({\\rho _1} + {\\rho _2}) + {\\rho _1}{\\rho _2}}}} \\right)}\\\\ {\\,\\,\\,}&{ = 0} \\end{array}$$ The mean position of the tethered particle remains zero. This should not be a surprise.","title":"Expected value"},{"location":"Chap_7.html#autocorrelation-function_2","text":"Starting from Equation 7.44 , we can compute the autocorrelation function \\({\\varphi _{xx}}[k]\\) using the same procedures that we used with Equation 7.29 to obtain Equation 7.30 but with the distinction that the computation is easier because the problem is well-behaved, that is, \\(0 < {\\rho _1},{\\rho _2} < 1.\\) (7.47) $$\\begin{array}{l} {\\varphi _{xx}}[k] = {F_o}\\delta [k] \\otimes {\\varphi _{hh}}[k] = {F_o}\\sum\\limits_{n = - \\infty }^{ + \\infty } {{h_x}[n]{h_x}[n + k]} \\\\ \\,\\,\\,\\,\\,\\,\\, = A\\sum\\limits_{n = - \\infty }^{ + \\infty } {\\left( {(\\rho _1^n - \\rho _2^n)(\\rho _1^{n + k} - \\rho _2^{n + k})u[n]u[n + k]} \\right)} \\\\ \\,\\,\\,\\,\\,\\,\\, = A\\frac{{({\\rho _2} - {\\rho _1})\\left( {\\rho _2^{1 + \\left| k \\right|}(1 - \\rho _1^2) - \\rho _1^{1 + \\left| k \\right|}(1 - \\rho _2^2)} \\right)}}{{(1 - \\rho _1^2)(1 - {\\rho _1}{\\rho _2})(1 - \\rho _2^2)}} \\end{array}$$ where \\(A = {F_o}/\\left( {{\\lambda ^2} - 4km} \\right).\\) Equation 7.47 is complicated. Determining this final form of \\({\\varphi _{xx}}[k]\\) is, however, straightforward when we remember to use the property that the autocorrelation function is even. Notice that Equation 7.30 can be considered as a special case of Equation 7.47 when \\({\\rho _1} = 1.\\)","title":"Autocorrelation function"},{"location":"Chap_7.html#power-spectral-density_2","text":"The power spectral density \\({S_{xx}}(\\Omega ) = {\\mathscr{F}}\\left\\{ {{\\varphi _{xx}}[k]} \\right\\}\\) can be computed from Equation 6.21 and Equation 7.45 . (7.48) $${S_{xx}}(\\Omega ) = \\left( {\\frac{{{F_o}{{({\\rho _1} - {\\rho _2})}^2}}}{{({\\lambda ^2} - 4km)}}} \\right)\\left( {\\frac{1}{{(1 + \\rho _1^2 - 2{\\rho _1}\\cos \\Omega )(1 + \\rho _2^2 - 2{\\rho _2}\\cos \\Omega )}}} \\right)$$ The autocorrelation function \\({\\varphi _{xx}}[k]\\) and the power spectral density are shown in Figure 7.8 . ( a ) Autocorrelation ${{\\varphi _{xx}}[k]}$ of the 1-D Langevin position process ( b ) Power spectral density ${{S_{xx}}(\\Omega )}$ of the 1-D Langevin position process Figure 7.8: ( a ) Autocorrelation function \\({\\varphi _{xx}}[k\\rbrack\\) of the TPM position. The amplitude at \\(k = 0\\) has been normalized to one. ( b ) Power spectral density \\({S_{xx}}(\\Omega )\\) of the TPM position plotted for the baseband \\(- \\pi \\lt \\Omega \\le + \\pi.\\) The amplitude at \\(\\Omega = 0\\) has been normalized to one. Both graphs are for the numerical values given in the text. The numerical values that have been used to produce the graphs in Figure 7.8 are, as above, \\(m = 5.18\\) fg, \\(\\lambda = 755\\) ng/s, and \\(k = 0.073\\) pN/ \\(\\mu\\) m. This leads to poles at \\({\\sigma _1} = 97.1\\) rad/s ( \\(\\approx k/\\lambda\\) ) and \\({\\sigma _2} = 1.5 \\times {10^8}\\) rad/s ( \\(\\approx \\lambda /m\\) ). The sampling period was chosen as \\({T_s} = 2\\pi /200{\\omega _c} =\\) \\(\\pi /100{\\sigma _1} = 324\\) \\(\\mu\\) s. See Figure 7.7 . This means a major \u201cimbalance\u201d between \\({\\rho _1}\\) and \\({\\rho _2}\\) with \\({\\rho _1}\\) = 0.97 and \\({\\rho _2} \\approx 0.\\) See Problem 7.10 .","title":"Power spectral density"},{"location":"Chap_7.html#descriptive-statistic-variance","text":"As we saw in our analysis of the Langevin position equation, the mean-square dispersion \\(\\left\\langle {{x^2}} \\right\\rangle\\) can provide useful information about a physical process. Further we have \\({m_x} = 0\\) and from Equation 7.32 : (7.49) $$\\begin{array}{l} \\left\\langle {{x^2}} \\right\\rangle = {\\varphi _{xx}}[k = 0]\\\\ \\,\\,\\,\\,\\,\\,\\, = A\\frac{{({\\rho _2} - {\\rho _1})\\left( {{\\rho _2}(1 - \\rho _1^2) - {\\rho _1}(1 - \\rho _2^2)} \\right)}}{{(1 - \\rho _1^2)(1 - {\\rho _1}{\\rho _2})(1 - \\rho _2^2)}}\\\\ \\,\\,\\,\\,\\,\\,\\, = \\left( {\\frac{{{F_o}}}{{{\\lambda ^2} - 4km}}} \\right)\\frac{{{{({\\rho _2} - {\\rho _1})}^2}\\left( {1 + {\\rho _1}{\\rho _2}} \\right)}}{{(1 - \\rho _1^2)(1 - {\\rho _1}{\\rho _2})(1 - \\rho _2^2)}} \\end{array}$$ From the definitions of \\({\\rho _1}\\) and \\({\\rho _2}\\) given in Equation 7.44 , we see that the mean-square dispersion is a function of the parameters \\(\\left( {m,\\lambda ,k} \\right)\\) and the sampling period \\({T_s}.\\) If we substitute that into Equation 7.49 the expression becomes (too) complex to appreciate its meaning. In Table 7.1 and Table 7.2 we examined this type of expression to see what effect the conversion from continuous-time to discrete-time had on measures as important as \\(\\left\\langle {{v^2}} \\right\\rangle\\) and \\(\\left\\langle {{x^2}} \\right\\rangle\\) Let us repeat that now for TPM. In continuous-time \\({m_x}\\) remains 0 and \\({\\left\\langle {{x^2}} \\right\\rangle _a}\\) can be written as the simple expression: (7.50) $${\\left\\langle {{x^2}} \\right\\rangle _a} = \\frac{{{F_o}}}{{2k\\lambda }}$$ Allowing the sampling interval to become smaller, \\({T_s} \\to 0,\\) in the discrete-time expression Equation 7.49 and using a series expansion, the equivalent expression\u2014see Problem 7.11 \u2014is: (7.51) $${\\left\\langle {{x^2}} \\right\\rangle _d} = \\frac{{{F_o}}}{{2k\\lambda {T_s}}} = \\frac{{{{\\left\\langle {{x^2}} \\right\\rangle }_a}}}{{{T_s}}}$$ The results of Equation 7.19 and Equation 7.36 are repeated for TPM. There is a simple relationship between the \u201canalog\u201d value and the \u201cdigital\u201d value if the sampling interval \\({T_s}\\) is sufficiently small, if the sampling rate is sufficiently high. Again, \\(\\sigma _{x,a}^2 = {T_s}\\sigma _{x,d}^2.\\)","title":"Descriptive statistic \u2013 variance"},{"location":"Chap_7.html#one-step-further","text":"We can substitute the description for \\({F_o}\\) Equation 7.20 that was given earlier. This gives: (7.52) $$\\begin{array}{l} {\\left\\langle {{x^2}} \\right\\rangle _d} = \\frac{{2\\lambda {k_B}\\Psi }}{{2k\\lambda {T_s}}} = \\frac{{{k_B}\\Psi }}{{k{T_s}}}\\,\\,\\,\\,\\, \\Rightarrow \\\\ \\,\\,\\,\\,\\,\\,\\,k = \\left( {\\frac{{{k_B}\\Psi }}{{{T_s}}}} \\right)\\frac{1}{{{{\\left\\langle {{x^2}} \\right\\rangle }_d}}} \\end{array}$$ The terms in Equation 7.52 are either constants or the parameters of an experiment: the Boltzmann constant ( \\({{k_B}}\\) ), the equilibrium temperature \\(\\Psi\\) of the fluid, and the sampling interval \\({T_s}.\\) By measuring the mean-square dispersion from a sequence of images as in Movie 7.2 , we can estimate the spring constant \\(k\\) of the macromolecule DNA. The spring constant can be used to infer a property of the DNA molecule such as the persistence length \\(P\\) ( Equation 7.40 ) or to follow a change in the macromolecule as it is exposed to proteins such as RecA. Figure 7.9 illustrates why a dynamic change in the spring constant might be expected after RecA is injected into a TPM test chamber containing \\(R = 40\\) nm gold particles tethered through DNA molecules to a substrate. Figure 7.9: Model of varying stages in the interaction of RecA with DNA. In Figure 7.10 , we see how the root-mean-square radial dispersion \\(\\sqrt {\\left\\langle {{r^2} = {x^2} + {y^2}} \\right\\rangle }\\) is affected. It should be obvious that while the analysis described at length above was for the lateral \\(x\\) motion, the lateral \\(y\\) motion can be measured and described in exactly the same way leading to a radial \\(r\\) description. Figure 7.10: Dynamic behavior of DNA due to injection of RecA at \\(t = 0.\\) All measurements and estimates were based upon discrete-time imagery (as in Movie 7.2) and with digital images. As indicated in the legend, two different concentrations of RecA were used and each measurement repeated twice for a total of four movies. After injection of RecA at \\(t = 0,\\) the binding of the protein to the DNA causes the rms radius to decrease from a first equilibrium state to a second, smaller equilibrium state. The higher the concentration of the protein, the faster the transition occurs. The time scale is on the order of minutes See Dietrich 9 .","title":"One step further"},{"location":"Chap_7.html#why-this-case-study","text":"A case study offers the opportunity to show how the ideas that have been developed can (and should) be used. There are many areas of application that lend themselves to a case study: speech processing, radar processing, and economic forecasting are but three examples. In the case study of TPM we have chosen for a more \u201cexotic\u201d application, the use of stochastic signal processing to measure physical phenomena at the molecular level and, in the case of tethered particle motion (TPM), analyzing one molecule at a time. We have seen that the description of such phenomena through the use of the descriptive statistics mean and variance ( \\(\\mu\\) and \\({\\sigma ^2}\\) ) and the functional descriptions autocorrelation and power spectral density ( \\(\\varphi [k]\\) and \\(S(\\Omega )\\) ) allows us to properly implement a discrete-time analysis of continuous-time processes and estimate relevant (bio)physical parameters. Although we are finished with our discussion of the Langevin equation and the extended variant represented in TPM, we are not finished developing tools that can be important in the implementation and application of stochastic signal processing. In the remaining chapters we shall develop these tools.","title":"Why this case study"},{"location":"Chap_7.html#problems","text":"","title":"Problems"},{"location":"Chap_7.html#problem-71","text":"The physical situation represented in Equation 7.1 describes a stable, causal situation. Equation 7.5 describes the transformation to a description of that situation but in the discrete-time representation. Is this new description also stable and causal? Justify your answer.","title":"Problem 7.1"},{"location":"Chap_7.html#problem-72","text":"Consider a system described by a Laplace transform: \\[H(s) = \\sum\\limits_{k = 1}^K {\\frac{{{A_k}}}{{s + {s_k}}}}\\] where \\(K\\) is a finite, positive integer. Show that there does not exist a finite sampling interval \\({T_s}\\) for its impulse response h ( t ) that will satisfy the Nyquist sampling theorem. If this system is processing a stochastic (or deterministic) signal x ( t ) to produce an output signal y ( t ), under what circumstances might a finite sampling interval \\({T_s}\\) exist? Carefully explain your reasoning.","title":"Problem 7.2"},{"location":"Chap_7.html#problem-73","text":"Consider a continuous-time, linear, time-invariant system with impulse response \\(h(t)\\) and whose Fourier transform is \\(H(\\omega ).\\) The input to the system is an ergodic signal \\(x(t)\\) with a finite mean and a finite variance. The output of the system is a stochastic signal \\(y(t).\\) Is the output signal stationary? Determine a relation between the mean of the input \\({m_x}\\) and the mean of the output \\({m_y}.\\) Determine an expression for the output autocorrelation function \\({\\varphi _{yy}}(\\tau )\\) in terms of the autocorrelation function of the stochastic input and the autocorrelation function of the deterministic system. Determine an expression for the output power spectral density \\({S_{yy}}(\\omega )\\) in terms of the power spectral density of the stochastic input and \\(H(\\omega ).\\) Determine a relation between the variance of the input signal \\(x(t)\\) and the variance of the output signal \\(y(t).\\)","title":"Problem 7.3"},{"location":"Chap_7.html#problem-74","text":"Starting from Equation 7.11 show that the autocorrelation function for the velocity, \\({\\varphi _{vv}}[k],\\) is given by Equation 7.12 .","title":"Problem 7.4"},{"location":"Chap_7.html#problem-75","text":"Starting from Equation 7.12 show that the power spectral density for the velocity, \\({S_{vv}}(\\Omega ),\\) is given by Equation 7.13 .","title":"Problem 7.5"},{"location":"Chap_7.html#problem-76","text":"Starting from Equation 6.21 and Equation 7.29 show that the power spectral density for the position, \\({S_{xx}}(\\Omega ),\\) is given by Equation 7.31 .","title":"Problem 7.6"},{"location":"Chap_7.html#problem-77","text":"Consider a TPM experiment that has proceeded long enough so that the first term in Equation 7.36 describes the variance, that is, \\[\\sigma _{x,d}^2 = \\frac{{{F_o}}}{{{\\lambda ^2}}}\\left( {\\mathop {\\lim }\\limits_{N \\to \\infty } N} \\right) = \\frac{{{F_o}}}{{{\\lambda ^2}}}N\\] The Stokes-Einstein diffusion equation says that: (7.53) $$D = \\frac{{{k_B}\\Psi }}{{6\\pi \\eta R}}$$ where \\(D\\) is the diffusion coefficient and the other terms are defined in the text. Determine a simple relationship between the mean-square dispersion, \\(D\\) and \\(N.\\)","title":"Problem 7.7"},{"location":"Chap_7.html#problem-78","text":"Physical units\u2014dimensions\u2014are important! They can be seen as the link between the abstraction of our mathematics and the application in our physical world. If the left-hand side of an equation is in units of meters [m] or kilograms [kg] or volts [V] or dollars [$], then the right-hand side must be in the same units for the equation to be valid. If there is a discrepancy, then a mistake has been made. In the discussions concerning Equation 7.19 , Equation 7.36 , and Equation 7.51 , we have seen expressions of the form \\(\\sigma _{x,a}^2 = {T_s}\\sigma _{x,d}^2\\) where \u201c \\(a\\) \u201d denotes analog (continuous time) and \u201c \\(d\\) \u201d denotes digital (discrete time). If the variance of the continuous-time variable has units of, say, temperature [K], what is the unit of the variance of the discrete-time variable? And now the hard question: Where does your answer to part ( a ) originate? Where in the entire discussion in this chapter does the unit of the discrete-time variable get changed from the original unit of the continuous-time variable?","title":"Problem 7.8"},{"location":"Chap_7.html#problem-79","text":"One might expect that a spectrum with a very high frequency term\u2014as in Figure 7.6 \u2014would require a much higher sampling frequency that that of the Langevin velocity equation as shown in Figure 7.1 . At the end of the section t to n , however, we found a sampling period of \\({T_s} = 13.4\\) \\(\\mu\\) s while for TPM the value was \\({T_s} = 324\\) \\(\\mu\\) s, a longer time interval or lower sampling frequency. How much of this change is due to the change in the radius of the gold particle? Be as quantitative as possible. How much of this change is due to the change in the transfer function of the physical model? Be as quantitative as possible.","title":"Problem 7.9"},{"location":"Chap_7.html#problem-710","text":"Consider a TPM system as in Equation 7.37 . In Equation 7.41 we concluded that this was an overdamped system. We also concluded that the associated values, \\({\\rho _1}\\) and \\({\\rho _2},\\) were not \u201cbalanced\u201d; one was much greater than the other. Show that this means that one pole is located at \\(\\approx \\lambda /m\\) and the other at \\(\\approx k/\\lambda.\\) Which of the these two poles has the larger value? Explain your reasoning.","title":"Problem 7.10"},{"location":"Chap_7.html#problem-711","text":"Starting from Equation 7.49 and the definitions of \\({\\rho _1}\\) and \\({\\rho _2}\\) given in Equation 7.44 , show that when \\({T_s} \\to 0\\) the mean-square dispersion \\({\\left\\langle {{x^2}} \\right\\rangle _d}\\) becomes the expression given in Equation 7.51 . Oppenheim, A. V., A. S. Willsky and I. T. Young (1983). Signals and Systems. Englewood Cliffs, New Jersey, Prentice-Hall \u21a9 Reif, F. (1965). Fundamentals of Statistical and Thermal Physics. New York, McGraw-Hill \u21a9 Feynman, R. P., R. B. Leighton and M. Sands (1963). The Feynman Lectures on Physics: Mainly Mechanics, Radiation, and Heat. Reading, Massachusetts, Addison-Wesley \u21a9 Cox, D. R. and H. D. Miller (1965). The Theory of Stochastic Processes. New York, John Wiley & Sons Inc. \u21a9 Lindner, M., G. Nir, H. R. C. Dietrich, I. T. Young, E. Tauber, I. Bronshtein, L. Altman and Y. Garini (2009). \u201cStudies of single molecules in their natural form.\u201d Israel Journal of Chemistry 49(3-4): 283-291 \u21a9 \u21a9 Dietrich, H. R. C., B. Rieger, F. G. M. Wiertz, F. H. de Groote, H. A. Heering, I. T. Young and Y. Garini (2009). \u201cTethered particle motion mediated by scattering from gold nanoparticles and darkfield microscopy.\u201d J. Nanophotonics 3(031795): 1-17 \u21a9 \u21a9 \u21a9 Oppenheim, A. V., A. S. Willsky and S. H. Nawab (1996). Signals and Systems. Upper Saddle River, New Jersey, Prentice-Hall \u21a9 Rubinstein, M. and R. H. Colby (2003). Polymer Physics. Oxford, UK, Oxford University Press \u21a9 Dietrich, H. R. C., B. Vermolen, B. Rieger, I. T. Young and Y. Garini (2007). \u201cA New Optical Method for Characterizing Single Molecule Interactions based on Dark Field Microscopy.\u201d SPIE: Ultrasensitive and Single-Molecule Detection Technologies II 6444: 1-8 \u21a9","title":"Problem 7.11"},{"location":"Chap_8.html","text":"Characterizing Signal-to-Noise Ratios \u00b6 We now know how to characterize stochastic signals and how to determine how that characterization changes as a stochastic signal is passed through an LTI system, a linear filter. We start with an example. Example: Filtering noise \u00b6 Let the input to an LTI system be given by an ergodic process \\(x[n]\\) with power spectrum \\({S_{xx}}(\\Omega ).\\) Then \\({S_{yy}}(\\Omega ) = {\\left| {H( - \\Omega )} \\right|^2}{S_{xx}}(\\Omega ).\\) If \\({\\varphi _{xx}}[k] = {N_o}\\delta [k]\\) (white noise input) and \\(h[n] = {\\alpha ^n}u[n]\\) with \\(\\alpha\\) real and \\(\\left| \\alpha \\right| < 1\\) then: (8.1) $$\\begin{array}{l} H(\\Omega ) = \\frac{1}{{1 - \\alpha {e^{ - j\\Omega }}}}\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,{S_{xx}}(\\Omega ) = {N_0}\\,\\,\\\\ {S_{yy}}(\\Omega ) = {N_0}{\\left| {\\frac{1}{{1 - \\alpha {e^{ - j\\Omega }}}}} \\right|^2} = \\frac{{{N_0}}}{{1 + {\\alpha ^2} - 2\\alpha \\cos \\Omega }} \\end{array}$$ The output random process \\(y[n]\\) is a non-white, random process. In the following sections we will look at several applications of these ideas as well as attempt to understand why the power density spectrum and the correlation functions play such an important role in stochastic signal processing. Further, we will focus our attention on those situations where the model is additive noise that is statistically independent of the signal. We begin by defining a well-known measure of system performance, the signal-to-noise ratio ( SNR ). We make a distinction between two cases 1) where the signal is deterministic or 2) where the signal is stochastic. In either case, of course, the noise is considered to be stochastic. SNR for deterministic signals in the presence of noise \u00b6 For deterministic signals, signals where the signal amplitude is known for every time instant, we define the signal-to noise ratio as: (8.2) $$S\\tilde N{R_d} = \\frac{S}{N} = \\frac{{\\max \\left| {y[n]} \\right|}}{{{\\sigma _{nn}}}}$$ or using the logarithmic (Bode) description: (8.3) $$SN{R_d} = 20\\,{\\log _{10}}\\left( {\\frac{{\\max \\left| {y[n]} \\right|}}{{{\\sigma _{nn}}}}} \\right)$$ SNR for random signals in the presence of noise \u00b6 For random signals (such as speech) which bear information but whose amplitudes cannot be predicted with certainty, we define the signal-to-noise ratio as: (8.4) $$S\\tilde N{R_r} = \\frac{S}{N} = \\frac{{{\\sigma _{ss}}}}{{{\\sigma _{nn}}}}$$ (8.5) $$SN{R_r} = 20\\,{\\log _{10}}\\left( {\\frac{{{\\sigma _{ss}}}}{{{\\sigma _{nn}}}}} \\right)$$ In both cases \\({\\sigma _{nn}}\\) is the standard deviation of the noise. In the case of random, information-bearing signals, \\({\\sigma _{ss}}\\) is the standard deviation of the signal amplitudes. From our earlier result, Equation 5.2 , we know that (8.6) $$\\sigma _{nn}^2 = {\\gamma _{nn}}[0] = {\\varphi _{nn}}[0] - {\\left| {{m_n}} \\right|^2}$$ We begin with the case where \\({m_n} = 0\\) giving \\({\\sigma _{nn}} = \\sqrt {{\\varphi _{nn}}[0]}.\\) Noise with zero mean leads to a formulation for the standard deviation of the noise in terms of the autocorrelation function of the noise evaluated at \\(k = 0.\\) To simplify matters with respect to the case of information-bearing random signals, we will assume that their mean is also zero yielding \\({\\sigma _{ss}} = \\sqrt {{\\varphi _{ss}}[0]}.\\) The justification for this is simple. If the mean is not zero then we can express the random signal \\(y[n]\\) as \\(y[n] = {m_y} + {y_0}[n]\\) where \\({m_y}\\) is the (deterministic) non-zero average and \\({y_0}[n]\\) is a stochastic signal with the same statistics as \\(y[n]\\) except that its average is zero. For our discussion of SNR , we, therefore, focus on the zero-mean stochastic term. We can now rewrite our definition using our zero-mean assumption as: (8.7) $$SN{R_d} = 10\\,{\\log _{10}}\\left( {\\frac{{\\max {{\\left| {y[n]} \\right|}^2}}}{{{\\varphi _{nn}}[0]}}} \\right)$$ (8.8) $$SN{R_r} = 10\\,{\\log _{10}}\\left( {\\frac{{{\\varphi _{ss}}[0]}}{{{\\varphi _{nn}}[0]}}} \\right)$$ Example: Not too noisy \u00b6 To illustrate the concept for a deterministic signal, say that a video signal generated by a known test pattern is confined to the interval 0 to 1 volt and that the noise, \\(N[n],\\) contaminating the video signal is 10 mv RMS. RMS means \u201croot-mean-square\u201d or \\(\\sqrt {E\\left\\{ {{{\\left| {N[n]} \\right|}^2}} \\right\\}}.\\) From our zero mean assumption, 10 mv RMS is equivalent to \\({\\sigma _{nn}} = 10\\) mv. According to our definition: (8.9) $$\\begin{array}{*{20}{l}} {SN{R_d}}&{ = 10\\,{{\\log }_{10}}\\left( {\\frac{{{{\\left( {1\\,{\\rm{V}}} \\right)}^2}}}{{{{\\left( {{{10}^{ - 2}}\\;{\\rm{V}}} \\right)}^2}}}} \\right)}\\\\ {\\,\\,\\,}&{ = 10\\,{{\\log }_{10}}\\left( {{{10}^4}} \\right) = 40\\;{\\rm{dB}}} \\end{array}$$ Example: Cocktail party noise? \u00b6 We can also illustrate the concept for a random signal as follows. Let the discrete-time output of a microphone be described by \\(r[n] = s[n] + N[n]\\) where \\(s[n]\\) is a sampled, real speech signal and \\(N[n]\\) is sampled, real random noise from the electronics. This is shown in Figure 8.1 . Figure 8.1: Model for a random signal speech, \\(s[n\\rbrack,\\) contaminated by additive noise \\(N[n\\rbrack\\) and resulting in \\(r[n\\rbrack.\\) The random speech signal \\(s[n]\\) has power density spectrum \\({S_{ss}}(\\Omega )\\) given by: (8.10) $${S_{ss}}(\\Omega ) = \\frac{{{S_0}}}{{1 + {\\alpha ^2} - 2\\alpha \\cos \\Omega }}$$ and the independent, additive noise \\(N[n]\\) is characterized by: (8.11) $${S_{nn}}(\\Omega ) = \\frac{{{N_0}}}{{1 + {\\beta ^2} - 2\\beta \\cos \\Omega }}$$ The S\u00d1R r will then follow from: (8.12) $$\\begin{array}{*{20}{l}} {{\\varphi _{ss}}[0]}&{ = \\frac{1}{{2\\pi }}\\int\\limits_{ - \\pi }^{ + \\pi } {{S_{ss}}(\\Omega )} d\\Omega }\\\\ {\\,\\,\\,}&{ = \\frac{1}{{2\\pi }}\\int\\limits_{ - \\pi }^{ + \\pi } {\\frac{{{S_0}}}{{1 + {\\alpha ^2} - 2\\alpha \\cos \\Omega }}} d\\Omega }\\\\ {\\,\\,\\,}&{ = \\frac{{{S_0}}}{{1 - {\\alpha ^2}}}} \\end{array}$$ (8.13) $$\\begin{array}{*{20}{l}} {{\\varphi _{nn}}[0]}&{ = \\frac{1}{{2\\pi }}\\int\\limits_{ - \\pi }^{ + \\pi } {\\frac{{{N_0}}}{{1 + {\\beta ^2} - 2\\beta \\cos \\Omega }}} d\\Omega }\\\\ {\\,\\,\\,}&{ = \\frac{{{N_0}}}{{1 - {\\beta ^2}}}} \\end{array}$$ The proof of Equation 8.12 can be found in Problem 8.1 . Using Equation 8.8 : (8.14) $$\\begin{array}{*{20}{l}} {SN{R_r}}&{ = 10\\,{{\\log }_{10}}\\left( {\\frac{{{S_o}/\\left( {1 - {\\alpha ^2}} \\right)}}{{{N_o}/\\left( {1 - {\\beta ^2}} \\right)}}} \\right)}\\\\ {\\,\\,\\,}&{ = 10\\,{{\\log }_{10}}\\left( {\\frac{{{S_0}}}{{{N_0}}}\\,\\left( {\\frac{{1 - {\\beta ^2}}}{{1 - {\\alpha ^2}}}} \\right)} \\right)} \\end{array}$$ The two power density spectra are illustrated in Figure 8.2 . Figure 8.2: Power density spectra of signal \\({S_{ss}}(\\Omega )\\) (in red ) and noise \\({S_{nn}}(\\Omega )\\) (in green ) for the values \\(\\alpha = 4/7\\) and \\(\\beta = - 2/3.\\) For \\({S_0} = 1,\\) \\({N_0} = 1,\\) \\(\\alpha = 4/7,\\) and \\(\\beta = - 2/3,\\) the SNR r = \u20130.84 dB. SNR for signals and systems with Poisson noise \u00b6 One very important class of noise is Poisson noise. In this case, the noise is not Gaussian, not additive, not independent of the signal, and has a mean value that is greater than zero. We would be tempted to ignore it as a mathematical oddity were it not a type of noise that is encountered in a variety of physical systems. A Poisson process is one that describes the probability of \\(n\\) independent discrete events occurring in a fixed amount of time \\(T\\) if the time between occurrences of successive events is described by an exponential-type probability density function with a rate-parameter \\(\\lambda.\\) The units of \\(\\lambda\\) are events/(unit time). The value of \\(T\\) \u2014the length of the observation window or the integration time\u2014is frequently known. An exceptionally lucid derivation of the Poisson distribution can be found in Section 18.13 of Thomas 1 . The emission of fluorescence photons in a labeled biological specimen, the production of photoelectrons in a CCD camera due to thermal vibrations (dark noise or dark current), and the radioactive decay of a population of identical atoms are examples of random processes governed by a Poisson distribution. The probability of \\(n\\) events in \\(T\\) units of time is given by: (8.15) $$p(n|\\lambda T) = \\frac{{{{\\left( {\\lambda T} \\right)}^n}{e^{ - \\lambda T}}}}{{n!}}$$ For Poisson processes the signal is intrinsically noisy and needs no \u201chelp\u201d from external sources. We define the signal-to-noise ratio as: (8.16) $$\\begin{array}{*{20}{l}} {S\\tilde N{R_P} = \\frac{S}{N} = \\frac{\\mu }{\\sigma }}\\\\ {SN{R_P} = 20\\,{{\\log }_{10}}\\left( {\\frac{\\mu }{\\sigma }} \\right)} \\end{array}$$ where \\(\\mu\\) is the expected value of the stochastic signal and \\(\\sigma\\) is its standard deviation. This process\u2014whether one is talking about \\(\\lambda\\) or \\(\\lambda T\\) \u2014is a one-parameter process. This means that both \\(\\mu\\) and \\(\\sigma\\) will be defined by \\(\\lambda\\) (or \\(\\lambda T\\) ). From Problem 3.4c we know that \\(\\mu = \\lambda T\\) and \\(\\sigma = \\sqrt {\\lambda T}.\\) This means that: (8.17) $$\\begin{array}{*{20}{l}} {S\\tilde N{R_P} = \\frac{{\\lambda T}}{{\\sqrt {\\lambda T} }} = \\sqrt {\\lambda T} }\\\\ {SN{R_P} = 20{{\\log }_{10}}\\left( {\\sqrt {\\lambda T} } \\right) = 10\\,{{\\log }_{10}}\\left( {\\lambda T} \\right)} \\end{array}$$ If we wish to increase the signal-to-noise ratio, we either have to increase the rate parameter \\(\\lambda\\) and/or use a longer observation window \\(T.\\) Either approach simply means that we need more data. The implications of these results warrant some discussion. As the strength of a Poisson signal increases\u2014for example by using a source that emits a greater number of photons per second\u2014so does the strength of the fluctuations. The former is measured by \\(\\mu\\) and the latter by \\(\\sigma.\\) This is illustrated in Figure 8.3 . Figure 8.3: (left) The top half of the image is a \u201cclean\u201d image where the intensity in each block increases by 32 brightness levels. The bottom half is Poisson noise where the mean value ( \\(\\mu\\) ) in each block is the same as the corresponding block above it. The red line is one row of the clean image and the blue line is one row of the noisy image. (right) The intensities along the red line and blue line versus the column numbers (with column \\(0\\) being in the middle) are displayed in red and blue , respectively. In the left-hand panel you should observe that the noise increases even as the average intensity increases. The basis for this observation will be discussed in Problem 8.2 . In the right-hand panel we see the fluctuations increase as the average increases. The calculation in Equation 8.17 shows, however, that as the source strength increases (from left to right) the SNR increases as well. There is much more that can be said about Poisson noise; we will address the issue of the estimation of \\(\\lambda\\) (or \\(\\lambda T\\) ) in an example in Chapter 11 . Problems \u00b6 Problem 8.1 \u00b6 The autocorrelation function of a random process is given by: (8.18) $${\\varphi _{xx}}[k] = {a^{\\left| k \\right|}}\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\left| a \\right| < 1$$ Determine the power spectral density \\({S_{xx}}(\\Omega ).\\) Using \\({S_{xx}}(\\Omega )\\) and Fourier properties prove Equation 8.12 . What is \\({m_x}\\) for this process? Problem 8.2 \u00b6 It has been recognized for over 150 years that the perception \\(p\\) of a physical stimulus \\(S\\) is described in many cases by: (8.19) $$\\Delta p = k\\frac{{\\Delta S}}{S}$$ where \\(\\Delta p\\) is the change in perception, \\(k\\) is a proportionality constant, and \\(\\Delta S\\) represents a change in the stimulus. This is know as the Weber-Fechner Law . As we proceed to smaller increments in the stimulus, that is as \\(\\Delta S \\to 0,\\) what is the functional relation between \\(p\\) and \\(S,\\) that is, what is \\(p(S)?\\) For the stimulus shown in Figure 8.3 , how does our observation of the noise relate to SNR p ? More information about the application of the Weber-Fechner Law to visual perception can be found in Hecht 2 . Problem 8.3 \u00b6 The light, that passes through a test tube containing a suspension of particles in liquid, is measured by a photomultiplier and converted to a discrete-time (digital) signal. The output signal \\(s[n]\\) from the photomultiplier shows a stochastic variation due to the sum of two statistically independent sources: 1) the Brownian motion \\(B[n]\\) of the particles in the liquid, and, 2) the noise from the photomultiplier \\(N[n].\\) Thus: (8.20) $$s[n] = B[n] + N[n]$$ The autocorrelation function of the Brownian motion, that is the velocity, is modeled by: (8.21) $${\\varphi _{BB}}[k] = {e^{ - \\left| k \\right|/D}} = {\\left( {{e^{ - 1/D}}} \\right)^{\\left| k \\right|}} = {\\varepsilon ^{\\left| k \\right|}}$$ with \\(0 < \\varepsilon < 1.\\) The autocorrelation function of the photomultiplier noise is modeled by: (8.22) $${\\varphi _{NN}}[k] = \\delta [k]$$ What is the autocorrelation function of the signal \\(s[n]\\) from the photomultiplier, that is, \\({\\varphi _{ss}}[k]?\\) What is the power spectral density \\({S_{ss}}(\\Omega )\\) of the measured signal? Sketch \\({S_{ss}}(\\Omega ).\\) We wish to estimate \\(D,\\) a parameter related to the diffusion of the particles in the liquid. Our estimate of \\(D\\) will, of course, be sensitive to the signal-to-noise ratio S\u00d1R r as defined in Equation 8.4 . Determine the value of S\u00d1R r . To improve the signal-to-noise ratio we first filter the signal \\(s[n]\\) as shown below: Figure 8.4: Standard model of an (LTI) filter applied after a signal has been contaminated by additive noise. where \\(h[n]\\) is an ideal low-pass filter whose Fourier transform is specified in the baseband \\(- \\pi \\lt \\Omega \\le + \\pi\\) as: (8.23) $$H(\\Omega ) = {\\mathscr{F}}\\left\\{ {h[n]} \\right\\} = \\left\\{ {\\begin{array}{*{20}{c}} 1&{\\left| \\Omega \\right| \\le \\pi /2}\\\\ 0&{\\left| \\Omega \\right| > \\pi /2} \\end{array}} \\right.$$ Determine S\u00d1R q from the filtered version of the signal, \\(q[n].\\) Under what conditions will the signal-to-noise ratio improve, that is, increase as we go from \\(s[n]\\) to \\(q[n]?\\) Thomas, G. B. (1960). Calculus and Analytic Geometry. Reading, Massachusetts, Addison-Wesley \u21a9 Hecht, S. (1924). \u201cThe visual discrimination of intensity and the Weber-Fechner law.\u201d Journal of General Physiology 7(2) \u21a9","title":"8. Characterizing Signal-to-Noise Ratios"},{"location":"Chap_8.html#characterizing-signal-to-noise-ratios","text":"We now know how to characterize stochastic signals and how to determine how that characterization changes as a stochastic signal is passed through an LTI system, a linear filter. We start with an example.","title":"Characterizing Signal-to-Noise Ratios"},{"location":"Chap_8.html#example-filtering-noise","text":"Let the input to an LTI system be given by an ergodic process \\(x[n]\\) with power spectrum \\({S_{xx}}(\\Omega ).\\) Then \\({S_{yy}}(\\Omega ) = {\\left| {H( - \\Omega )} \\right|^2}{S_{xx}}(\\Omega ).\\) If \\({\\varphi _{xx}}[k] = {N_o}\\delta [k]\\) (white noise input) and \\(h[n] = {\\alpha ^n}u[n]\\) with \\(\\alpha\\) real and \\(\\left| \\alpha \\right| < 1\\) then: (8.1) $$\\begin{array}{l} H(\\Omega ) = \\frac{1}{{1 - \\alpha {e^{ - j\\Omega }}}}\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,{S_{xx}}(\\Omega ) = {N_0}\\,\\,\\\\ {S_{yy}}(\\Omega ) = {N_0}{\\left| {\\frac{1}{{1 - \\alpha {e^{ - j\\Omega }}}}} \\right|^2} = \\frac{{{N_0}}}{{1 + {\\alpha ^2} - 2\\alpha \\cos \\Omega }} \\end{array}$$ The output random process \\(y[n]\\) is a non-white, random process. In the following sections we will look at several applications of these ideas as well as attempt to understand why the power density spectrum and the correlation functions play such an important role in stochastic signal processing. Further, we will focus our attention on those situations where the model is additive noise that is statistically independent of the signal. We begin by defining a well-known measure of system performance, the signal-to-noise ratio ( SNR ). We make a distinction between two cases 1) where the signal is deterministic or 2) where the signal is stochastic. In either case, of course, the noise is considered to be stochastic.","title":"Example: Filtering noise"},{"location":"Chap_8.html#snr-for-deterministic-signals-in-the-presence-of-noise","text":"For deterministic signals, signals where the signal amplitude is known for every time instant, we define the signal-to noise ratio as: (8.2) $$S\\tilde N{R_d} = \\frac{S}{N} = \\frac{{\\max \\left| {y[n]} \\right|}}{{{\\sigma _{nn}}}}$$ or using the logarithmic (Bode) description: (8.3) $$SN{R_d} = 20\\,{\\log _{10}}\\left( {\\frac{{\\max \\left| {y[n]} \\right|}}{{{\\sigma _{nn}}}}} \\right)$$","title":"SNR for deterministic signals in the presence of noise"},{"location":"Chap_8.html#snr-for-random-signals-in-the-presence-of-noise","text":"For random signals (such as speech) which bear information but whose amplitudes cannot be predicted with certainty, we define the signal-to-noise ratio as: (8.4) $$S\\tilde N{R_r} = \\frac{S}{N} = \\frac{{{\\sigma _{ss}}}}{{{\\sigma _{nn}}}}$$ (8.5) $$SN{R_r} = 20\\,{\\log _{10}}\\left( {\\frac{{{\\sigma _{ss}}}}{{{\\sigma _{nn}}}}} \\right)$$ In both cases \\({\\sigma _{nn}}\\) is the standard deviation of the noise. In the case of random, information-bearing signals, \\({\\sigma _{ss}}\\) is the standard deviation of the signal amplitudes. From our earlier result, Equation 5.2 , we know that (8.6) $$\\sigma _{nn}^2 = {\\gamma _{nn}}[0] = {\\varphi _{nn}}[0] - {\\left| {{m_n}} \\right|^2}$$ We begin with the case where \\({m_n} = 0\\) giving \\({\\sigma _{nn}} = \\sqrt {{\\varphi _{nn}}[0]}.\\) Noise with zero mean leads to a formulation for the standard deviation of the noise in terms of the autocorrelation function of the noise evaluated at \\(k = 0.\\) To simplify matters with respect to the case of information-bearing random signals, we will assume that their mean is also zero yielding \\({\\sigma _{ss}} = \\sqrt {{\\varphi _{ss}}[0]}.\\) The justification for this is simple. If the mean is not zero then we can express the random signal \\(y[n]\\) as \\(y[n] = {m_y} + {y_0}[n]\\) where \\({m_y}\\) is the (deterministic) non-zero average and \\({y_0}[n]\\) is a stochastic signal with the same statistics as \\(y[n]\\) except that its average is zero. For our discussion of SNR , we, therefore, focus on the zero-mean stochastic term. We can now rewrite our definition using our zero-mean assumption as: (8.7) $$SN{R_d} = 10\\,{\\log _{10}}\\left( {\\frac{{\\max {{\\left| {y[n]} \\right|}^2}}}{{{\\varphi _{nn}}[0]}}} \\right)$$ (8.8) $$SN{R_r} = 10\\,{\\log _{10}}\\left( {\\frac{{{\\varphi _{ss}}[0]}}{{{\\varphi _{nn}}[0]}}} \\right)$$","title":"SNR for random signals in the presence of noise"},{"location":"Chap_8.html#example-not-too-noisy","text":"To illustrate the concept for a deterministic signal, say that a video signal generated by a known test pattern is confined to the interval 0 to 1 volt and that the noise, \\(N[n],\\) contaminating the video signal is 10 mv RMS. RMS means \u201croot-mean-square\u201d or \\(\\sqrt {E\\left\\{ {{{\\left| {N[n]} \\right|}^2}} \\right\\}}.\\) From our zero mean assumption, 10 mv RMS is equivalent to \\({\\sigma _{nn}} = 10\\) mv. According to our definition: (8.9) $$\\begin{array}{*{20}{l}} {SN{R_d}}&{ = 10\\,{{\\log }_{10}}\\left( {\\frac{{{{\\left( {1\\,{\\rm{V}}} \\right)}^2}}}{{{{\\left( {{{10}^{ - 2}}\\;{\\rm{V}}} \\right)}^2}}}} \\right)}\\\\ {\\,\\,\\,}&{ = 10\\,{{\\log }_{10}}\\left( {{{10}^4}} \\right) = 40\\;{\\rm{dB}}} \\end{array}$$","title":"Example: Not too noisy"},{"location":"Chap_8.html#example-cocktail-party-noise","text":"We can also illustrate the concept for a random signal as follows. Let the discrete-time output of a microphone be described by \\(r[n] = s[n] + N[n]\\) where \\(s[n]\\) is a sampled, real speech signal and \\(N[n]\\) is sampled, real random noise from the electronics. This is shown in Figure 8.1 . Figure 8.1: Model for a random signal speech, \\(s[n\\rbrack,\\) contaminated by additive noise \\(N[n\\rbrack\\) and resulting in \\(r[n\\rbrack.\\) The random speech signal \\(s[n]\\) has power density spectrum \\({S_{ss}}(\\Omega )\\) given by: (8.10) $${S_{ss}}(\\Omega ) = \\frac{{{S_0}}}{{1 + {\\alpha ^2} - 2\\alpha \\cos \\Omega }}$$ and the independent, additive noise \\(N[n]\\) is characterized by: (8.11) $${S_{nn}}(\\Omega ) = \\frac{{{N_0}}}{{1 + {\\beta ^2} - 2\\beta \\cos \\Omega }}$$ The S\u00d1R r will then follow from: (8.12) $$\\begin{array}{*{20}{l}} {{\\varphi _{ss}}[0]}&{ = \\frac{1}{{2\\pi }}\\int\\limits_{ - \\pi }^{ + \\pi } {{S_{ss}}(\\Omega )} d\\Omega }\\\\ {\\,\\,\\,}&{ = \\frac{1}{{2\\pi }}\\int\\limits_{ - \\pi }^{ + \\pi } {\\frac{{{S_0}}}{{1 + {\\alpha ^2} - 2\\alpha \\cos \\Omega }}} d\\Omega }\\\\ {\\,\\,\\,}&{ = \\frac{{{S_0}}}{{1 - {\\alpha ^2}}}} \\end{array}$$ (8.13) $$\\begin{array}{*{20}{l}} {{\\varphi _{nn}}[0]}&{ = \\frac{1}{{2\\pi }}\\int\\limits_{ - \\pi }^{ + \\pi } {\\frac{{{N_0}}}{{1 + {\\beta ^2} - 2\\beta \\cos \\Omega }}} d\\Omega }\\\\ {\\,\\,\\,}&{ = \\frac{{{N_0}}}{{1 - {\\beta ^2}}}} \\end{array}$$ The proof of Equation 8.12 can be found in Problem 8.1 . Using Equation 8.8 : (8.14) $$\\begin{array}{*{20}{l}} {SN{R_r}}&{ = 10\\,{{\\log }_{10}}\\left( {\\frac{{{S_o}/\\left( {1 - {\\alpha ^2}} \\right)}}{{{N_o}/\\left( {1 - {\\beta ^2}} \\right)}}} \\right)}\\\\ {\\,\\,\\,}&{ = 10\\,{{\\log }_{10}}\\left( {\\frac{{{S_0}}}{{{N_0}}}\\,\\left( {\\frac{{1 - {\\beta ^2}}}{{1 - {\\alpha ^2}}}} \\right)} \\right)} \\end{array}$$ The two power density spectra are illustrated in Figure 8.2 . Figure 8.2: Power density spectra of signal \\({S_{ss}}(\\Omega )\\) (in red ) and noise \\({S_{nn}}(\\Omega )\\) (in green ) for the values \\(\\alpha = 4/7\\) and \\(\\beta = - 2/3.\\) For \\({S_0} = 1,\\) \\({N_0} = 1,\\) \\(\\alpha = 4/7,\\) and \\(\\beta = - 2/3,\\) the SNR r = \u20130.84 dB.","title":"Example: Cocktail party noise?"},{"location":"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise","text":"One very important class of noise is Poisson noise. In this case, the noise is not Gaussian, not additive, not independent of the signal, and has a mean value that is greater than zero. We would be tempted to ignore it as a mathematical oddity were it not a type of noise that is encountered in a variety of physical systems. A Poisson process is one that describes the probability of \\(n\\) independent discrete events occurring in a fixed amount of time \\(T\\) if the time between occurrences of successive events is described by an exponential-type probability density function with a rate-parameter \\(\\lambda.\\) The units of \\(\\lambda\\) are events/(unit time). The value of \\(T\\) \u2014the length of the observation window or the integration time\u2014is frequently known. An exceptionally lucid derivation of the Poisson distribution can be found in Section 18.13 of Thomas 1 . The emission of fluorescence photons in a labeled biological specimen, the production of photoelectrons in a CCD camera due to thermal vibrations (dark noise or dark current), and the radioactive decay of a population of identical atoms are examples of random processes governed by a Poisson distribution. The probability of \\(n\\) events in \\(T\\) units of time is given by: (8.15) $$p(n|\\lambda T) = \\frac{{{{\\left( {\\lambda T} \\right)}^n}{e^{ - \\lambda T}}}}{{n!}}$$ For Poisson processes the signal is intrinsically noisy and needs no \u201chelp\u201d from external sources. We define the signal-to-noise ratio as: (8.16) $$\\begin{array}{*{20}{l}} {S\\tilde N{R_P} = \\frac{S}{N} = \\frac{\\mu }{\\sigma }}\\\\ {SN{R_P} = 20\\,{{\\log }_{10}}\\left( {\\frac{\\mu }{\\sigma }} \\right)} \\end{array}$$ where \\(\\mu\\) is the expected value of the stochastic signal and \\(\\sigma\\) is its standard deviation. This process\u2014whether one is talking about \\(\\lambda\\) or \\(\\lambda T\\) \u2014is a one-parameter process. This means that both \\(\\mu\\) and \\(\\sigma\\) will be defined by \\(\\lambda\\) (or \\(\\lambda T\\) ). From Problem 3.4c we know that \\(\\mu = \\lambda T\\) and \\(\\sigma = \\sqrt {\\lambda T}.\\) This means that: (8.17) $$\\begin{array}{*{20}{l}} {S\\tilde N{R_P} = \\frac{{\\lambda T}}{{\\sqrt {\\lambda T} }} = \\sqrt {\\lambda T} }\\\\ {SN{R_P} = 20{{\\log }_{10}}\\left( {\\sqrt {\\lambda T} } \\right) = 10\\,{{\\log }_{10}}\\left( {\\lambda T} \\right)} \\end{array}$$ If we wish to increase the signal-to-noise ratio, we either have to increase the rate parameter \\(\\lambda\\) and/or use a longer observation window \\(T.\\) Either approach simply means that we need more data. The implications of these results warrant some discussion. As the strength of a Poisson signal increases\u2014for example by using a source that emits a greater number of photons per second\u2014so does the strength of the fluctuations. The former is measured by \\(\\mu\\) and the latter by \\(\\sigma.\\) This is illustrated in Figure 8.3 . Figure 8.3: (left) The top half of the image is a \u201cclean\u201d image where the intensity in each block increases by 32 brightness levels. The bottom half is Poisson noise where the mean value ( \\(\\mu\\) ) in each block is the same as the corresponding block above it. The red line is one row of the clean image and the blue line is one row of the noisy image. (right) The intensities along the red line and blue line versus the column numbers (with column \\(0\\) being in the middle) are displayed in red and blue , respectively. In the left-hand panel you should observe that the noise increases even as the average intensity increases. The basis for this observation will be discussed in Problem 8.2 . In the right-hand panel we see the fluctuations increase as the average increases. The calculation in Equation 8.17 shows, however, that as the source strength increases (from left to right) the SNR increases as well. There is much more that can be said about Poisson noise; we will address the issue of the estimation of \\(\\lambda\\) (or \\(\\lambda T\\) ) in an example in Chapter 11 .","title":"SNR for signals and systems with Poisson noise"},{"location":"Chap_8.html#problems","text":"","title":"Problems"},{"location":"Chap_8.html#problem-81","text":"The autocorrelation function of a random process is given by: (8.18) $${\\varphi _{xx}}[k] = {a^{\\left| k \\right|}}\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\left| a \\right| < 1$$ Determine the power spectral density \\({S_{xx}}(\\Omega ).\\) Using \\({S_{xx}}(\\Omega )\\) and Fourier properties prove Equation 8.12 . What is \\({m_x}\\) for this process?","title":"Problem 8.1"},{"location":"Chap_8.html#problem-82","text":"It has been recognized for over 150 years that the perception \\(p\\) of a physical stimulus \\(S\\) is described in many cases by: (8.19) $$\\Delta p = k\\frac{{\\Delta S}}{S}$$ where \\(\\Delta p\\) is the change in perception, \\(k\\) is a proportionality constant, and \\(\\Delta S\\) represents a change in the stimulus. This is know as the Weber-Fechner Law . As we proceed to smaller increments in the stimulus, that is as \\(\\Delta S \\to 0,\\) what is the functional relation between \\(p\\) and \\(S,\\) that is, what is \\(p(S)?\\) For the stimulus shown in Figure 8.3 , how does our observation of the noise relate to SNR p ? More information about the application of the Weber-Fechner Law to visual perception can be found in Hecht 2 .","title":"Problem 8.2"},{"location":"Chap_8.html#problem-83","text":"The light, that passes through a test tube containing a suspension of particles in liquid, is measured by a photomultiplier and converted to a discrete-time (digital) signal. The output signal \\(s[n]\\) from the photomultiplier shows a stochastic variation due to the sum of two statistically independent sources: 1) the Brownian motion \\(B[n]\\) of the particles in the liquid, and, 2) the noise from the photomultiplier \\(N[n].\\) Thus: (8.20) $$s[n] = B[n] + N[n]$$ The autocorrelation function of the Brownian motion, that is the velocity, is modeled by: (8.21) $${\\varphi _{BB}}[k] = {e^{ - \\left| k \\right|/D}} = {\\left( {{e^{ - 1/D}}} \\right)^{\\left| k \\right|}} = {\\varepsilon ^{\\left| k \\right|}}$$ with \\(0 < \\varepsilon < 1.\\) The autocorrelation function of the photomultiplier noise is modeled by: (8.22) $${\\varphi _{NN}}[k] = \\delta [k]$$ What is the autocorrelation function of the signal \\(s[n]\\) from the photomultiplier, that is, \\({\\varphi _{ss}}[k]?\\) What is the power spectral density \\({S_{ss}}(\\Omega )\\) of the measured signal? Sketch \\({S_{ss}}(\\Omega ).\\) We wish to estimate \\(D,\\) a parameter related to the diffusion of the particles in the liquid. Our estimate of \\(D\\) will, of course, be sensitive to the signal-to-noise ratio S\u00d1R r as defined in Equation 8.4 . Determine the value of S\u00d1R r . To improve the signal-to-noise ratio we first filter the signal \\(s[n]\\) as shown below: Figure 8.4: Standard model of an (LTI) filter applied after a signal has been contaminated by additive noise. where \\(h[n]\\) is an ideal low-pass filter whose Fourier transform is specified in the baseband \\(- \\pi \\lt \\Omega \\le + \\pi\\) as: (8.23) $$H(\\Omega ) = {\\mathscr{F}}\\left\\{ {h[n]} \\right\\} = \\left\\{ {\\begin{array}{*{20}{c}} 1&{\\left| \\Omega \\right| \\le \\pi /2}\\\\ 0&{\\left| \\Omega \\right| > \\pi /2} \\end{array}} \\right.$$ Determine S\u00d1R q from the filtered version of the signal, \\(q[n].\\) Under what conditions will the signal-to-noise ratio improve, that is, increase as we go from \\(s[n]\\) to \\(q[n]?\\) Thomas, G. B. (1960). Calculus and Analytic Geometry. Reading, Massachusetts, Addison-Wesley \u21a9 Hecht, S. (1924). \u201cThe visual discrimination of intensity and the Weber-Fechner law.\u201d Journal of General Physiology 7(2) \u21a9","title":"Problem 8.3"},{"location":"Chap_9.html","text":"The Matched Filter \u00b6 How do you find a \u201cneedle in a haystack\u201d? To start you have to know what a needle looks like. The \u201cimage\u201d of a needle is a template and with one or more templates you then search through the haystack until a match is found. (Of course, other methods might be available like magnetic separation but here we focus on matching templates as opposed to haystack processing.) Let the input to an LTI system be given by \\(x[n] + N[n]\\) where \\(x[n]\\) is a known signal (the \u201cneedle\u201d) and for simplicity \\(x[n]\\) is real . The real, impulse response of the system is \\(h[n]\\) and the output \\(y[n]\\) (the \u201chaystack\u201d) is: (9.1) $$y[n] = \\left( {x[n] + N[n]} \\right) \\otimes h[n] = {y_x}[n] + {y_N}[n]$$ where \\({y_x}[n]\\) is the component of the output generated by the signal \\(x[n]\\) and \\({y_N}[n]\\) is the component of the output generated by the real noise \\(N[n].\\) We wish to determine a filter \\(h[n]\\) such that, at a specified time \\(n = {n_0},\\) the output signal-to-noise ratio ( SNR ) will be maximized. Why the SNR ? In communication theory 1 , one learns that attempting to detect a signal always involves the possibility that an error will be made. Under a broad range of models it can be shown that maximizing the SNR leads to a minimization of the probability of error. We cannot maximize the SNR by simply amplifying \\(y[n]\\) ; both the signal and noise will be amplified and the SNR will remain the same. To search through the haystack \\(y[n]\\) to detect the needle \\(x[n]\\) we need filtering. We need the matched filter. Setting up the problem \u00b6 Assuming a zero-mean noise process and using a variation on Equation 8.2 to define the SNR at time \\(n = {n_0},\\) we have: (9.2) $$S\\tilde N{R_d} = \\frac{S}{N} = \\frac{{\\left| {{y_x}[n = {n_0}]} \\right|}}{{\\sqrt {E\\left\\{ {{{\\left| {{y_N}[n = {n_0}]} \\right|}^2}} \\right\\}} }}$$ But from Equation 6.25 : (9.3) $$\\begin{array}{*{20}{l}} {E\\left\\{ {{{\\left| {{y_n}[{n_0}]} \\right|}^2}} \\right\\}}&{ = \\frac{1}{{2\\pi }}\\int\\limits_{ - \\pi }^{ + \\pi } {{{\\left| {H( - \\Omega )} \\right|}^2}{S_{nn}}(\\Omega )} d\\Omega }\\\\ {\\,\\,\\,}&{ = \\frac{1}{{2\\pi }}\\int\\limits_{ - \\pi }^{ + \\pi } {{{\\left| {H(\\Omega )} \\right|}^2}{S_{nn}}(\\Omega )} d\\Omega } \\end{array}$$ \\(H(\\Omega )\\) is the Fourier domain characterization of the filter to be found and we have used the fact that \\(h[n]\\) is real to move from \\(H( - \\Omega )\\) to \\(H(\\Omega ).\\) Further, the \\(H(\\Omega )\\) that satisfies our requirement that the SNR be maximized will contain the parameter \\({n_0}.\\) Using Equation 9.1 and Equation 9.2 and remembering that in this specific discussion we are assuming that \\(x[n]\\) as well as \\(h[n]\\) is deterministic, we have: (9.4) $${y_x}[{n_0}] = \\frac{1}{{2\\pi }}\\int\\limits_{ - \\pi }^{ + \\pi } {X(\\Omega )H(\\Omega } ){e^{j\\Omega {n_0}}}d\\Omega$$ Using Cauchy-Schwartz \u00b6 We now apply the Cauchy-Schwartz inequality 2 : (9.5) $${\\left| {\\int\\limits_a^b {Z(\\Omega )} W(\\Omega )d\\Omega } \\right|^2} \\le \\left( {\\int\\limits_a^b {{{\\left| {Z(\\Omega )} \\right|}^2}d\\Omega } } \\right)\\left( {\\int\\limits_a^b {{{\\left| {W(\\Omega )} \\right|}^2}d\\Omega } } \\right)$$ with equality if and only if \\(Z(\\Omega ) = C\\,{W^*}(\\Omega )\\) where \\(C\\) is a real constant. We rewrite Equation 9.4 as: (9.6) $${y_x}[{n_0}] = \\frac{1}{{2\\pi }}\\int\\limits_{ - \\pi }^{ + \\pi } {\\frac{{X(\\Omega )}}{{\\sqrt {{S_{nn}}(\\Omega )} }}H(\\Omega } )\\sqrt {{S_{nn}}(\\Omega )} {e^{j\\Omega {n_0}}}d\\Omega$$ Using the inequality in Equation 9.5 , we then have: (9.7) $${\\left| {{y_x}[{n_0}]} \\right|^2} \\le \\frac{1}{{2\\pi }}\\left( {\\int\\limits_{ - \\pi }^{ + \\pi } {\\frac{{{{\\left| {X(\\Omega )} \\right|}^2}}}{{{S_{nn}}(\\Omega )}}} d\\Omega } \\right)\\left( {\\int\\limits_{ - \\pi }^{ + \\pi } {{{\\left| {H(\\Omega )} \\right|}^2}} {S_{nn}}(\\Omega )d\\Omega } \\right)$$ Combining this result with our definition of \\(S\\tilde NR\\) from Equation 9.2 gives: (9.8) $${\\left( {\\frac{S}{N}} \\right)^2} \\le \\int\\limits_{ - \\pi }^{ + \\pi } {\\frac{{{{\\left| {X(\\Omega )} \\right|}^2}}}{{{S_{nn}}(\\Omega )}}} d\\Omega$$ This result is independent of our choice of \\(H(\\Omega )\\) and, further, fixes the largest signal-to-noise ( SNR ) ratio that can be attained. According to the Cauchy-Schwartz inequality, the maximum is reached if and only if: (9.9) $$\\sqrt {{S_{nn}}(\\Omega )} H(\\Omega ) = C\\frac{{{X^*}(\\Omega )}}{{\\sqrt {{S_{nn}}(\\Omega )} }}{e^{ - j\\Omega {n_0}}}$$ This can be rewritten to give the filter \\(H(\\Omega )\\) as: (9.10) $$H(\\Omega ) = C\\frac{{{X^*}(\\Omega )}}{{{S_{nn}}(\\Omega )}}{e^{ - j\\Omega {n_0}}}$$ and an \\({S\\tilde N{R_d}}\\) of: (9.11) $${\\left( {S\\tilde N{R_d}} \\right)^2} = {\\left( {\\frac{S}{N}} \\right)^2} = \\int\\limits_{ - \\pi }^{ + \\pi } {\\frac{{{{\\left| {X(\\Omega )} \\right|}^2}}}{{{S_{nn}}(\\Omega )}}} d\\Omega $$ The classic example \u00b6 As an example, let \\({S_{nn}}(\\Omega ) = {N_o}\\) that is, white noise of power density \\({N_o}.\\) From our solution for the matched filter, Equation 9.10 , we have immediately: (9.12) $$H(\\Omega ) = \\frac{C}{{{N_0}}}{X^*}(\\Omega ){e^{ - j\\Omega {n_0}}}$$ Taking the inverse Fourier transform of both sides yields the impulse response: (9.13) $$h[n] = \\frac{C}{{{N_0}}}x[{n_0} - n]$$ Example: Matching your filter \u00b6 If \\(x[n]\\) is as shown in Figure 9.1 below, then \\(h[n]\\) will have the form that is also shown. Figure 9.1: ( top ) The signal $x\\lbrack n\\rbrack $ and ( bottom ) the matched filter \\(h\\lbrack n\\rbrack = x\\lbrack {n_0} - n\\rbrack .\\) The \\(S\\tilde N{R_d}\\) at time \\({n_0}\\) will be (9.14) $$\\begin{array}{*{20}{l}} {S\\tilde N{R_d}}&{ = \\sqrt {\\int\\limits_{ - \\pi }^{ + \\pi } {\\frac{{{{\\left| {X(\\Omega )} \\right|}^2}}}{{{N_0}}}} d\\Omega } = \\sqrt {\\frac{1}{{{N_0}}}\\int\\limits_{ - \\pi }^{ + \\pi } {{{\\left| {X(\\Omega )} \\right|}^2}} d\\Omega } }\\\\ {\\,\\,\\,}&{ = \\sqrt {\\frac{{2\\pi E}}{{{N_0}}}} } \\end{array}$$ where \\(E\\) is the energy in the signal \\(x[n].\\) To further interpret this result we note that \\(h[n]\\) is just a \u201cflipped\u201d version of \\(x[n]\\) and this is what we call a matched filter . To explore this just a bit further, we note that \\({y_x}[n]\\) will be: (9.15) $${y_x}[n] = x[n] \\otimes h[n] = x[n] \\otimes \\frac{C}{{{N_0}}}x[{n_0} - n]$$ The matched filter as an autocorrelation \u00b6 Formally writing out the convolution gives: (9.16) $${y_x}[n] = \\left( {\\frac{C}{{{N_0}}}} \\right)\\sum\\limits_{m = - \\infty }^{ + \\infty } {x[m]} x[m + n - {n_0}]$$ which, for real signals, is just the autocorrelation function of \\(x[n].\\) That is: (9.17) $${y_x}[n] = \\left( {\\frac{C}{{{N_0}}}} \\right){\\varphi _{xx}}[n - {n_0}]$$ We have shown earlier, Equation 6.32 , that the maximum of \\({\\varphi _{xx}}[k]\\) occurs at \\(k = 0,\\) that is, \\({\\varphi _{xx}}[k] \\leqslant {\\varphi _{xx}}[0].\\) Translating this to the matched filter problem, we have that \\({y_x}[n]\\) is maximized (given the choice \\(h[n] \\propto x[{n_0} - n]\\) ) at \\(n = {n_0}.\\) This cross-correlation between the two signals in Figure 9.1 is illustrated in Movie 9.1 . Movie 9.1: Cross-correlation of two signals. This involves first shifting one signal with respect to the other, then multiplying the signals point-by-point, and finally computing the \u201carea\u201d under their product. It is important to remember that the cross-correlation depicted in Movie 9.1 is actually a convolution as described in Equation 9.15 . Performance in the presence of noise \u00b6 As we saw in Figure 6.4 , cross-correlation allows us to identify a peak, corresponding to a delay, in noisy (real) data. It is instructive to see how well this concept works at varying signal-to-noise ratios. We use the top signal in Figure 9.1 as a matched filter and a noisy version of the bottom signal in Figure 9.1 as the noisy input signal to the matched filter. We vary the SNR from 40 dB down to 0 dB according to the definition in Equation 8.3 . The result is shown in Movie 9.2 . Movie 9.2: Output of the matched filter as the SNR varies from 40 dB down to 0 dB. Note the stability of the location of the peak position. We see from this animation that the matched filter gives a robust method to estimate the peak position even at low values of the SNR . Problems \u00b6 Problem 9.1 \u00b6 The matched filter gives a robust method to find a signal in noise. We have seen this in Movie 9.2 and we will have the opportunity to experiment with this in the laboratory experiments in this chapter. This suggests that we can perhaps use a matched filter to select one specific signal over other specific signals. Consider the four signals shown in Figure 9.2 . Figure 9.2: Four signals \\({s_i}[n\\rbrack,\\) \\(\\left\\{ {i = 1,2,3,4} \\right\\}\\) each of which is zero for \\(n < 0\\) and \\(n > 7.\\) Based upon Equation 9.15 , determine and sketch the matched filter \\({h_i}[n]\\) for each of the four signals: \\({s_i}[n],\\) \\(\\left\\{ {i = 1,2,3,4} \\right\\}.\\) Assume that \\(C = 1\\) and \\({N_o} = 1\\) Watt/Hz. Determine the output \\({y_{ij}}[n]\\) of each of the four matched filters \\(\\left\\{ {i = 1,2,3,4} \\right\\}\\) for each of the four input signals \\(\\left\\{ {j = 1,2,3,4} \\right\\}.\\) Hint : The use of various properties of convolution and correlation will save you a lot of work. If each of the signals in part ( b ) is corrupted by additive, stationary Gaussian noise whose mean is zero and whose standard deviation is \\(\\sigma,\\) determine the mean of the output of each of the matched filters. The matched filters are not corrupted by noise. Problem 9.2 \u00b6 The signals shown in Figure 9.2 are related to one another. Describe, in words, any relationships you observe among the signals \\({s_i}[n],\\) \\(\\left\\{ {i = 1,2,3,4} \\right\\}.\\) We want the four signals to convey information so we assign a meaning to each of the signals. \\({s_1}[n]\\,\\,\\, \\Leftrightarrow \\,\\,\\,{\\rm{The\\,Chicago\\,Cubs\\,will\\,win\\,the\\,World\\,Series}}\\) \\({s_2}[n]\\,\\,\\, \\Leftrightarrow \\,\\,\\,{\\rm{The\\,Chicago\\,Cubs\\,will\\,win\\,the\\,NBA\\, Championship}}\\) \\({s_3}[n]\\,\\,\\, \\Leftrightarrow \\,\\,\\,{\\rm{The\\,Chicago\\,Cubs\\,will\\,win\\,the\\,Super\\, Bowl}}\\) \\({s_4}[n]\\,\\,\\, \\Leftrightarrow \\,\\,\\,{\\rm{The\\,Chicago\\,Cubs\\,will\\,not\\,win\\,the\\,World\\,Series}}\\) We have tried to make the signals in Figure 9.2 as different from one another as possible in order to protect a message in the presence of additive noise. If the signals are different, then presumably it will still be possible to determine which message is being sent even when the signal is corrupted by noise. We measure the \u201cdifference\u201d between two signals \\(x[n]\\) and \\(y[n]\\) as: (9.18) $${d_{xy}} = \\sum\\limits_{n = - \\infty }^{ + \\infty } {{{\\left| {x[n] - y[n]} \\right|}^2}}$$ Determine the difference \\({d_{ij}}\\) between each possible pair of the four signals \\({s_i}[n],\\) \\(\\left\\{ {i = 1,2,3,4} \\right\\}.\\) Hint : Expanding the quadratic term before you start your computation can save you a lot of work. According to our definition of difference, which signal pair is the most different? The design of signals to facilitate communication in the presence of noise is described in communication theory and information theory. An excellent textbook for these topics is Wozencraft and Jacobs 1 , in particular Chapter 4. Laboratory Exercises \u00b6 Laboratory Exercise 9.1 \u00b6 Movie 9.2 illustrated the stability of peak location in the presence of noise. In this exercise you will experiment with this result. Click on the icon to the left to start. Laboratory Exercise 9.2 \u00b6 Finding a face in a crowd is similar to finding a needle in a haystack. You may have noticed this if you have ever tried to find Waldo (or Wally). Can matched filtering lend a hand or, better said, an eye? Click on the icon to the left to start. Laboratory Exercise 9.3 \u00b6 Fourier analysis tells us that signals can be decomposed into weighted sums of sines and cosines. What happens if we use a sinusoid as a matched filter? To find out, click on the icon to the left. Wozencraft, J. M. and I. M. Jacobs (1965). Principles of Communication Engineering. New York, John Wiley & Sons, Inc. \u21a9 \u21a9 An interpretation of the Cauchy-Schwartz inequality that makes it easier to understand is given by considering the inner product of two complex vectors a and b . This is given by the complex, scalar quantity a \u2022 b * = | a || b *|cos \u03b8 = | a || b |cos \u03b8 where \u03b8 is the angle between the two vectors, \u201c*\u201d denotes complex conjugation, and \\(\\cos \\theta = {\\mathop{\\rm Re}\\nolimits} \\{ {\\bf{a}} \\bullet {\\bf{b}}\\} /\\left| {\\bf{a}} \\right|\\left| {\\bf{b}} \\right|\\) with Re the real part operator. The spectra \\(Z(\\Omega )\\) and \\(W(\\Omega )\\) can be considered as infinite-dimensional vectors . Because \\(\\cos \\theta\\) is between \\(- 1\\) and \\(+ 1,\\) we have \\({\\left| {{\\bf{a}} \\bullet {\\bf{b}}} \\right|^2} \\le {\\left| {\\bf{a}} \\right|^2}{\\left| {\\bf{b}} \\right|^2}\\) which is the Cauchy-Schwartz inequality. The maximum value of the inner product is achieved when the two vectors are parallel, when \\(\\theta = 0\\) or \\(\\theta = \\pm \\pi,\\) in other words when \\({\\bf{a}} = C\\,{\\bf{b}}\\) where \\(C\\) is real. \u21a9","title":"9. The Matched Filter"},{"location":"Chap_9.html#the-matched-filter","text":"How do you find a \u201cneedle in a haystack\u201d? To start you have to know what a needle looks like. The \u201cimage\u201d of a needle is a template and with one or more templates you then search through the haystack until a match is found. (Of course, other methods might be available like magnetic separation but here we focus on matching templates as opposed to haystack processing.) Let the input to an LTI system be given by \\(x[n] + N[n]\\) where \\(x[n]\\) is a known signal (the \u201cneedle\u201d) and for simplicity \\(x[n]\\) is real . The real, impulse response of the system is \\(h[n]\\) and the output \\(y[n]\\) (the \u201chaystack\u201d) is: (9.1) $$y[n] = \\left( {x[n] + N[n]} \\right) \\otimes h[n] = {y_x}[n] + {y_N}[n]$$ where \\({y_x}[n]\\) is the component of the output generated by the signal \\(x[n]\\) and \\({y_N}[n]\\) is the component of the output generated by the real noise \\(N[n].\\) We wish to determine a filter \\(h[n]\\) such that, at a specified time \\(n = {n_0},\\) the output signal-to-noise ratio ( SNR ) will be maximized. Why the SNR ? In communication theory 1 , one learns that attempting to detect a signal always involves the possibility that an error will be made. Under a broad range of models it can be shown that maximizing the SNR leads to a minimization of the probability of error. We cannot maximize the SNR by simply amplifying \\(y[n]\\) ; both the signal and noise will be amplified and the SNR will remain the same. To search through the haystack \\(y[n]\\) to detect the needle \\(x[n]\\) we need filtering. We need the matched filter.","title":"The Matched Filter"},{"location":"Chap_9.html#setting-up-the-problem","text":"Assuming a zero-mean noise process and using a variation on Equation 8.2 to define the SNR at time \\(n = {n_0},\\) we have: (9.2) $$S\\tilde N{R_d} = \\frac{S}{N} = \\frac{{\\left| {{y_x}[n = {n_0}]} \\right|}}{{\\sqrt {E\\left\\{ {{{\\left| {{y_N}[n = {n_0}]} \\right|}^2}} \\right\\}} }}$$ But from Equation 6.25 : (9.3) $$\\begin{array}{*{20}{l}} {E\\left\\{ {{{\\left| {{y_n}[{n_0}]} \\right|}^2}} \\right\\}}&{ = \\frac{1}{{2\\pi }}\\int\\limits_{ - \\pi }^{ + \\pi } {{{\\left| {H( - \\Omega )} \\right|}^2}{S_{nn}}(\\Omega )} d\\Omega }\\\\ {\\,\\,\\,}&{ = \\frac{1}{{2\\pi }}\\int\\limits_{ - \\pi }^{ + \\pi } {{{\\left| {H(\\Omega )} \\right|}^2}{S_{nn}}(\\Omega )} d\\Omega } \\end{array}$$ \\(H(\\Omega )\\) is the Fourier domain characterization of the filter to be found and we have used the fact that \\(h[n]\\) is real to move from \\(H( - \\Omega )\\) to \\(H(\\Omega ).\\) Further, the \\(H(\\Omega )\\) that satisfies our requirement that the SNR be maximized will contain the parameter \\({n_0}.\\) Using Equation 9.1 and Equation 9.2 and remembering that in this specific discussion we are assuming that \\(x[n]\\) as well as \\(h[n]\\) is deterministic, we have: (9.4) $${y_x}[{n_0}] = \\frac{1}{{2\\pi }}\\int\\limits_{ - \\pi }^{ + \\pi } {X(\\Omega )H(\\Omega } ){e^{j\\Omega {n_0}}}d\\Omega$$","title":"Setting up the problem"},{"location":"Chap_9.html#using-cauchy-schwartz","text":"We now apply the Cauchy-Schwartz inequality 2 : (9.5) $${\\left| {\\int\\limits_a^b {Z(\\Omega )} W(\\Omega )d\\Omega } \\right|^2} \\le \\left( {\\int\\limits_a^b {{{\\left| {Z(\\Omega )} \\right|}^2}d\\Omega } } \\right)\\left( {\\int\\limits_a^b {{{\\left| {W(\\Omega )} \\right|}^2}d\\Omega } } \\right)$$ with equality if and only if \\(Z(\\Omega ) = C\\,{W^*}(\\Omega )\\) where \\(C\\) is a real constant. We rewrite Equation 9.4 as: (9.6) $${y_x}[{n_0}] = \\frac{1}{{2\\pi }}\\int\\limits_{ - \\pi }^{ + \\pi } {\\frac{{X(\\Omega )}}{{\\sqrt {{S_{nn}}(\\Omega )} }}H(\\Omega } )\\sqrt {{S_{nn}}(\\Omega )} {e^{j\\Omega {n_0}}}d\\Omega$$ Using the inequality in Equation 9.5 , we then have: (9.7) $${\\left| {{y_x}[{n_0}]} \\right|^2} \\le \\frac{1}{{2\\pi }}\\left( {\\int\\limits_{ - \\pi }^{ + \\pi } {\\frac{{{{\\left| {X(\\Omega )} \\right|}^2}}}{{{S_{nn}}(\\Omega )}}} d\\Omega } \\right)\\left( {\\int\\limits_{ - \\pi }^{ + \\pi } {{{\\left| {H(\\Omega )} \\right|}^2}} {S_{nn}}(\\Omega )d\\Omega } \\right)$$ Combining this result with our definition of \\(S\\tilde NR\\) from Equation 9.2 gives: (9.8) $${\\left( {\\frac{S}{N}} \\right)^2} \\le \\int\\limits_{ - \\pi }^{ + \\pi } {\\frac{{{{\\left| {X(\\Omega )} \\right|}^2}}}{{{S_{nn}}(\\Omega )}}} d\\Omega$$ This result is independent of our choice of \\(H(\\Omega )\\) and, further, fixes the largest signal-to-noise ( SNR ) ratio that can be attained. According to the Cauchy-Schwartz inequality, the maximum is reached if and only if: (9.9) $$\\sqrt {{S_{nn}}(\\Omega )} H(\\Omega ) = C\\frac{{{X^*}(\\Omega )}}{{\\sqrt {{S_{nn}}(\\Omega )} }}{e^{ - j\\Omega {n_0}}}$$ This can be rewritten to give the filter \\(H(\\Omega )\\) as: (9.10) $$H(\\Omega ) = C\\frac{{{X^*}(\\Omega )}}{{{S_{nn}}(\\Omega )}}{e^{ - j\\Omega {n_0}}}$$ and an \\({S\\tilde N{R_d}}\\) of: (9.11) $${\\left( {S\\tilde N{R_d}} \\right)^2} = {\\left( {\\frac{S}{N}} \\right)^2} = \\int\\limits_{ - \\pi }^{ + \\pi } {\\frac{{{{\\left| {X(\\Omega )} \\right|}^2}}}{{{S_{nn}}(\\Omega )}}} d\\Omega $$","title":"Using Cauchy-Schwartz"},{"location":"Chap_9.html#the-classic-example","text":"As an example, let \\({S_{nn}}(\\Omega ) = {N_o}\\) that is, white noise of power density \\({N_o}.\\) From our solution for the matched filter, Equation 9.10 , we have immediately: (9.12) $$H(\\Omega ) = \\frac{C}{{{N_0}}}{X^*}(\\Omega ){e^{ - j\\Omega {n_0}}}$$ Taking the inverse Fourier transform of both sides yields the impulse response: (9.13) $$h[n] = \\frac{C}{{{N_0}}}x[{n_0} - n]$$","title":"The classic example"},{"location":"Chap_9.html#example-matching-your-filter","text":"If \\(x[n]\\) is as shown in Figure 9.1 below, then \\(h[n]\\) will have the form that is also shown. Figure 9.1: ( top ) The signal $x\\lbrack n\\rbrack $ and ( bottom ) the matched filter \\(h\\lbrack n\\rbrack = x\\lbrack {n_0} - n\\rbrack .\\) The \\(S\\tilde N{R_d}\\) at time \\({n_0}\\) will be (9.14) $$\\begin{array}{*{20}{l}} {S\\tilde N{R_d}}&{ = \\sqrt {\\int\\limits_{ - \\pi }^{ + \\pi } {\\frac{{{{\\left| {X(\\Omega )} \\right|}^2}}}{{{N_0}}}} d\\Omega } = \\sqrt {\\frac{1}{{{N_0}}}\\int\\limits_{ - \\pi }^{ + \\pi } {{{\\left| {X(\\Omega )} \\right|}^2}} d\\Omega } }\\\\ {\\,\\,\\,}&{ = \\sqrt {\\frac{{2\\pi E}}{{{N_0}}}} } \\end{array}$$ where \\(E\\) is the energy in the signal \\(x[n].\\) To further interpret this result we note that \\(h[n]\\) is just a \u201cflipped\u201d version of \\(x[n]\\) and this is what we call a matched filter . To explore this just a bit further, we note that \\({y_x}[n]\\) will be: (9.15) $${y_x}[n] = x[n] \\otimes h[n] = x[n] \\otimes \\frac{C}{{{N_0}}}x[{n_0} - n]$$","title":"Example: Matching your filter"},{"location":"Chap_9.html#the-matched-filter-as-an-autocorrelation","text":"Formally writing out the convolution gives: (9.16) $${y_x}[n] = \\left( {\\frac{C}{{{N_0}}}} \\right)\\sum\\limits_{m = - \\infty }^{ + \\infty } {x[m]} x[m + n - {n_0}]$$ which, for real signals, is just the autocorrelation function of \\(x[n].\\) That is: (9.17) $${y_x}[n] = \\left( {\\frac{C}{{{N_0}}}} \\right){\\varphi _{xx}}[n - {n_0}]$$ We have shown earlier, Equation 6.32 , that the maximum of \\({\\varphi _{xx}}[k]\\) occurs at \\(k = 0,\\) that is, \\({\\varphi _{xx}}[k] \\leqslant {\\varphi _{xx}}[0].\\) Translating this to the matched filter problem, we have that \\({y_x}[n]\\) is maximized (given the choice \\(h[n] \\propto x[{n_0} - n]\\) ) at \\(n = {n_0}.\\) This cross-correlation between the two signals in Figure 9.1 is illustrated in Movie 9.1 . Movie 9.1: Cross-correlation of two signals. This involves first shifting one signal with respect to the other, then multiplying the signals point-by-point, and finally computing the \u201carea\u201d under their product. It is important to remember that the cross-correlation depicted in Movie 9.1 is actually a convolution as described in Equation 9.15 .","title":"The matched filter as an autocorrelation"},{"location":"Chap_9.html#performance-in-the-presence-of-noise","text":"As we saw in Figure 6.4 , cross-correlation allows us to identify a peak, corresponding to a delay, in noisy (real) data. It is instructive to see how well this concept works at varying signal-to-noise ratios. We use the top signal in Figure 9.1 as a matched filter and a noisy version of the bottom signal in Figure 9.1 as the noisy input signal to the matched filter. We vary the SNR from 40 dB down to 0 dB according to the definition in Equation 8.3 . The result is shown in Movie 9.2 . Movie 9.2: Output of the matched filter as the SNR varies from 40 dB down to 0 dB. Note the stability of the location of the peak position. We see from this animation that the matched filter gives a robust method to estimate the peak position even at low values of the SNR .","title":"Performance in the presence of noise"},{"location":"Chap_9.html#problems","text":"","title":"Problems"},{"location":"Chap_9.html#problem-91","text":"The matched filter gives a robust method to find a signal in noise. We have seen this in Movie 9.2 and we will have the opportunity to experiment with this in the laboratory experiments in this chapter. This suggests that we can perhaps use a matched filter to select one specific signal over other specific signals. Consider the four signals shown in Figure 9.2 . Figure 9.2: Four signals \\({s_i}[n\\rbrack,\\) \\(\\left\\{ {i = 1,2,3,4} \\right\\}\\) each of which is zero for \\(n < 0\\) and \\(n > 7.\\) Based upon Equation 9.15 , determine and sketch the matched filter \\({h_i}[n]\\) for each of the four signals: \\({s_i}[n],\\) \\(\\left\\{ {i = 1,2,3,4} \\right\\}.\\) Assume that \\(C = 1\\) and \\({N_o} = 1\\) Watt/Hz. Determine the output \\({y_{ij}}[n]\\) of each of the four matched filters \\(\\left\\{ {i = 1,2,3,4} \\right\\}\\) for each of the four input signals \\(\\left\\{ {j = 1,2,3,4} \\right\\}.\\) Hint : The use of various properties of convolution and correlation will save you a lot of work. If each of the signals in part ( b ) is corrupted by additive, stationary Gaussian noise whose mean is zero and whose standard deviation is \\(\\sigma,\\) determine the mean of the output of each of the matched filters. The matched filters are not corrupted by noise.","title":"Problem 9.1"},{"location":"Chap_9.html#problem-92","text":"The signals shown in Figure 9.2 are related to one another. Describe, in words, any relationships you observe among the signals \\({s_i}[n],\\) \\(\\left\\{ {i = 1,2,3,4} \\right\\}.\\) We want the four signals to convey information so we assign a meaning to each of the signals. \\({s_1}[n]\\,\\,\\, \\Leftrightarrow \\,\\,\\,{\\rm{The\\,Chicago\\,Cubs\\,will\\,win\\,the\\,World\\,Series}}\\) \\({s_2}[n]\\,\\,\\, \\Leftrightarrow \\,\\,\\,{\\rm{The\\,Chicago\\,Cubs\\,will\\,win\\,the\\,NBA\\, Championship}}\\) \\({s_3}[n]\\,\\,\\, \\Leftrightarrow \\,\\,\\,{\\rm{The\\,Chicago\\,Cubs\\,will\\,win\\,the\\,Super\\, Bowl}}\\) \\({s_4}[n]\\,\\,\\, \\Leftrightarrow \\,\\,\\,{\\rm{The\\,Chicago\\,Cubs\\,will\\,not\\,win\\,the\\,World\\,Series}}\\) We have tried to make the signals in Figure 9.2 as different from one another as possible in order to protect a message in the presence of additive noise. If the signals are different, then presumably it will still be possible to determine which message is being sent even when the signal is corrupted by noise. We measure the \u201cdifference\u201d between two signals \\(x[n]\\) and \\(y[n]\\) as: (9.18) $${d_{xy}} = \\sum\\limits_{n = - \\infty }^{ + \\infty } {{{\\left| {x[n] - y[n]} \\right|}^2}}$$ Determine the difference \\({d_{ij}}\\) between each possible pair of the four signals \\({s_i}[n],\\) \\(\\left\\{ {i = 1,2,3,4} \\right\\}.\\) Hint : Expanding the quadratic term before you start your computation can save you a lot of work. According to our definition of difference, which signal pair is the most different? The design of signals to facilitate communication in the presence of noise is described in communication theory and information theory. An excellent textbook for these topics is Wozencraft and Jacobs 1 , in particular Chapter 4.","title":"Problem 9.2"},{"location":"Chap_9.html#laboratory-exercises","text":"","title":"Laboratory Exercises"},{"location":"Chap_9.html#laboratory-exercise-91","text":"Movie 9.2 illustrated the stability of peak location in the presence of noise. In this exercise you will experiment with this result. Click on the icon to the left to start.","title":"Laboratory Exercise 9.1"},{"location":"Chap_9.html#laboratory-exercise-92","text":"Finding a face in a crowd is similar to finding a needle in a haystack. You may have noticed this if you have ever tried to find Waldo (or Wally). Can matched filtering lend a hand or, better said, an eye? Click on the icon to the left to start.","title":"Laboratory Exercise 9.2"},{"location":"Chap_9.html#laboratory-exercise-93","text":"Fourier analysis tells us that signals can be decomposed into weighted sums of sines and cosines. What happens if we use a sinusoid as a matched filter? To find out, click on the icon to the left. Wozencraft, J. M. and I. M. Jacobs (1965). Principles of Communication Engineering. New York, John Wiley & Sons, Inc. \u21a9 \u21a9 An interpretation of the Cauchy-Schwartz inequality that makes it easier to understand is given by considering the inner product of two complex vectors a and b . This is given by the complex, scalar quantity a \u2022 b * = | a || b *|cos \u03b8 = | a || b |cos \u03b8 where \u03b8 is the angle between the two vectors, \u201c*\u201d denotes complex conjugation, and \\(\\cos \\theta = {\\mathop{\\rm Re}\\nolimits} \\{ {\\bf{a}} \\bullet {\\bf{b}}\\} /\\left| {\\bf{a}} \\right|\\left| {\\bf{b}} \\right|\\) with Re the real part operator. The spectra \\(Z(\\Omega )\\) and \\(W(\\Omega )\\) can be considered as infinite-dimensional vectors . Because \\(\\cos \\theta\\) is between \\(- 1\\) and \\(+ 1,\\) we have \\({\\left| {{\\bf{a}} \\bullet {\\bf{b}}} \\right|^2} \\le {\\left| {\\bf{a}} \\right|^2}{\\left| {\\bf{b}} \\right|^2}\\) which is the Cauchy-Schwartz inequality. The maximum value of the inner product is achieved when the two vectors are parallel, when \\(\\theta = 0\\) or \\(\\theta = \\pm \\pi,\\) in other words when \\({\\bf{a}} = C\\,{\\bf{b}}\\) where \\(C\\) is real. \u21a9","title":"Laboratory Exercise 9.3"},{"location":"info.html","text":"Tips & Short Cuts \u00b6 To completely refresh a page of the textbook or a laboratory exercise, click on the refresh symbol \u201c\u21bb\u201d in the window bar above or type \u201c\u2318-r\u201d (Apple keyboard) or \u201cCTRL-r\u201d or \u201cCTRL-F5\u201d (Windows/Android/Linux keyboard). \u201cClassic\u201d textbooks frequently have an index at the end of the book to help you find the pages that refer to a specific topic. Instead of that we use the \u201c Search \u201d function ( ) located in the upper-right corner of the title bar . After typing your topic in the indicated space, a list of the screens where it appears will be shown and you can choose one. If you are reading a chapter and want to skip directly to the Laboratory Exercises at the end of that chapter, tap the title bar at the top of the screen and then scroll up, as necessary. If you are reading a chapter and want to skip directly to either the previous chapter or the next chapter, tap the title bar at the top of the screen. Now tap either the previous chapter arrow (\u2190) or the next chapter arrow (\u2192). If you are working on a Laboratory Exercise and want to skip directly to the end of that Laboratory Exercise, tap just below the status bar at the top of the screen. If you are at the end (bottom) of a Laboratory Exercise and want to return to the end of the chapter where that exercise was chosen, tap the arrow (\u2190) or the words \"Laboratory Exercises\" on the bottom-left of the screen. The \u201cpinch\u201d gesture can be used to zoom in (or out) to examine Equations, Figures, and text in the Chapters. Our Privacy Policy and other information related to our activities can be found here . An extended version of this iBook with an additional 32 Laboratory Experiments for a total of 58 experiments makes use of the microphone and camera that can be found on tablets and smartphones. The current implementation of this extended version, StochasticS , is free and can be found here . Authors \u00b6 The authors of this book are Ian T. Young and Ronald Ligteringen . Venue \u00b6 This iBook is published by SocraticSoftware.org and our Privacy Policy can be found here . Contact \u00b6 If you have questions or comments for various aspects of the iBook, send an email to: Technical matters: tech@socraticsoftware.org Educational matters: info@socraticsoftware.org Errata: errata@socraticsoftware.org Business matters: contact@socraticsoftware.org Acknowledgments \u00b6 The contributions of a number of people to this iBook need to be acknowledged. First, we thank Professor Lucas van Vliet and Dr. Piet Verbeek for many substantive discussions and collaborations over the years. Many generations of students in the 1980\u2019s and 1990\u2019s used the original lecture notes and thereby provided important feedback on a number of topics. Jos\u00e9 de Bruin typed, retyped, and re-retyped the non-electronic versions of this manuscript. Anjella van Vliet helped turn the paper manuscript into an electronic one. Dr. Qiaole Zhao proofread the manuscript. And our wives provided the most valuable contributions of all, patience and understanding. Technical Details \u00b6 Signal processing and the associated graphical results were developed with Wolfram Mathematica. Movies were produced with Mathematica and QuickTime Player. All signal processing procedures in this app were written in JavaScript. This \u201ciBook\u201d was prepared on Apple iMacs running Mac OS X. The text processing was done in Microsoft Word and Markdown. Equations were set using MathJax and Wiris MathType. Certain figures were produced with Microsoft PowerPoint. Apache Cordova, MkDocs, Material for MkDocs, and Plotly were essential for the production of this app. The technical characteristics of e-publishing place certain restrictions on the fonts that can be used in inline text as contrasted with fonts that can be used in MathType equations. For example, in the Palatino font the Greek letter \u201cphi\u201d has two versions: \u03d5 and \u03c6. Both have been used in this iBook. Copyright \u00b6 The material in this book, unless otherwise indicated, is covered under international copyright laws, \u00a9 1984, 2010\u20132021. Weather Data \u00b6 We gratefully acknowledge the generosity of the Royal Netherlands Meteorological Institute ( KNMI ) for providing the data used in weather examples presented in this iBook. Cover \u00b6 The stochastic time series, associated power spectral density, and the autocorrelation function of the average daily air temperature from 1 January 1901 to 31 December 2009 as measured at the Royal Netherlands Meteorological Institute (KNMI) in De Bilt, The Netherlands. Musical Data \u00b6 The music processed and presented in this iBook is an excerpt from the Paganini Violin Concerto No.1, rondo allegro spirituoso . The musical \u201criff\u201d that \u2014 depending upon your browser \u2014 may be heard at the launch of this iBook, is intended to help you adjust your output audio volume for subsequent experiments. It is from the soundtrack of the film Charly and entitled Love Montage . It was composed by Ravi Shankar. Version \u00b6 Second Edition Version 2.3.0 Registration \u00b6 ISBN 978-90-816432-1-4 Usage \u00b6 This material is the property of the authors and is for the sole and exclusive use of their students. It may not be sold, reproduced by any means, transmitted, or generally distributed without the authors\u2019 expressed written permission.","title":"Information"},{"location":"info.html#tips-short-cuts","text":"To completely refresh a page of the textbook or a laboratory exercise, click on the refresh symbol \u201c\u21bb\u201d in the window bar above or type \u201c\u2318-r\u201d (Apple keyboard) or \u201cCTRL-r\u201d or \u201cCTRL-F5\u201d (Windows/Android/Linux keyboard). \u201cClassic\u201d textbooks frequently have an index at the end of the book to help you find the pages that refer to a specific topic. Instead of that we use the \u201c Search \u201d function ( ) located in the upper-right corner of the title bar . After typing your topic in the indicated space, a list of the screens where it appears will be shown and you can choose one. If you are reading a chapter and want to skip directly to the Laboratory Exercises at the end of that chapter, tap the title bar at the top of the screen and then scroll up, as necessary. If you are reading a chapter and want to skip directly to either the previous chapter or the next chapter, tap the title bar at the top of the screen. Now tap either the previous chapter arrow (\u2190) or the next chapter arrow (\u2192). If you are working on a Laboratory Exercise and want to skip directly to the end of that Laboratory Exercise, tap just below the status bar at the top of the screen. If you are at the end (bottom) of a Laboratory Exercise and want to return to the end of the chapter where that exercise was chosen, tap the arrow (\u2190) or the words \"Laboratory Exercises\" on the bottom-left of the screen. The \u201cpinch\u201d gesture can be used to zoom in (or out) to examine Equations, Figures, and text in the Chapters. Our Privacy Policy and other information related to our activities can be found here . An extended version of this iBook with an additional 32 Laboratory Experiments for a total of 58 experiments makes use of the microphone and camera that can be found on tablets and smartphones. The current implementation of this extended version, StochasticS , is free and can be found here .","title":"Tips &amp; Short Cuts"},{"location":"info.html#authors","text":"The authors of this book are Ian T. Young and Ronald Ligteringen .","title":"Authors"},{"location":"info.html#venue","text":"This iBook is published by SocraticSoftware.org and our Privacy Policy can be found here .","title":"Venue"},{"location":"info.html#contact","text":"If you have questions or comments for various aspects of the iBook, send an email to: Technical matters: tech@socraticsoftware.org Educational matters: info@socraticsoftware.org Errata: errata@socraticsoftware.org Business matters: contact@socraticsoftware.org","title":"Contact"},{"location":"info.html#acknowledgments","text":"The contributions of a number of people to this iBook need to be acknowledged. First, we thank Professor Lucas van Vliet and Dr. Piet Verbeek for many substantive discussions and collaborations over the years. Many generations of students in the 1980\u2019s and 1990\u2019s used the original lecture notes and thereby provided important feedback on a number of topics. Jos\u00e9 de Bruin typed, retyped, and re-retyped the non-electronic versions of this manuscript. Anjella van Vliet helped turn the paper manuscript into an electronic one. Dr. Qiaole Zhao proofread the manuscript. And our wives provided the most valuable contributions of all, patience and understanding.","title":"Acknowledgments"},{"location":"info.html#technical-details","text":"Signal processing and the associated graphical results were developed with Wolfram Mathematica. Movies were produced with Mathematica and QuickTime Player. All signal processing procedures in this app were written in JavaScript. This \u201ciBook\u201d was prepared on Apple iMacs running Mac OS X. The text processing was done in Microsoft Word and Markdown. Equations were set using MathJax and Wiris MathType. Certain figures were produced with Microsoft PowerPoint. Apache Cordova, MkDocs, Material for MkDocs, and Plotly were essential for the production of this app. The technical characteristics of e-publishing place certain restrictions on the fonts that can be used in inline text as contrasted with fonts that can be used in MathType equations. For example, in the Palatino font the Greek letter \u201cphi\u201d has two versions: \u03d5 and \u03c6. Both have been used in this iBook.","title":"Technical Details"},{"location":"info.html#copyright","text":"The material in this book, unless otherwise indicated, is covered under international copyright laws, \u00a9 1984, 2010\u20132021.","title":"Copyright"},{"location":"info.html#weather-data","text":"We gratefully acknowledge the generosity of the Royal Netherlands Meteorological Institute ( KNMI ) for providing the data used in weather examples presented in this iBook.","title":"Weather Data"},{"location":"info.html#cover","text":"The stochastic time series, associated power spectral density, and the autocorrelation function of the average daily air temperature from 1 January 1901 to 31 December 2009 as measured at the Royal Netherlands Meteorological Institute (KNMI) in De Bilt, The Netherlands.","title":"Cover"},{"location":"info.html#musical-data","text":"The music processed and presented in this iBook is an excerpt from the Paganini Violin Concerto No.1, rondo allegro spirituoso . The musical \u201criff\u201d that \u2014 depending upon your browser \u2014 may be heard at the launch of this iBook, is intended to help you adjust your output audio volume for subsequent experiments. It is from the soundtrack of the film Charly and entitled Love Montage . It was composed by Ravi Shankar.","title":"Musical Data"},{"location":"info.html#version","text":"Second Edition Version 2.3.0","title":"Version"},{"location":"info.html#registration","text":"ISBN 978-90-816432-1-4","title":"Registration"},{"location":"info.html#usage","text":"This material is the property of the authors and is for the sole and exclusive use of their students. It may not be sold, reproduced by any means, transmitted, or generally distributed without the authors\u2019 expressed written permission.","title":"Usage"}],"index":{"fieldVectors":[["title/index.html",[0,4.339]],["text/index.html",[]],["title/Chap_1.html",[1,0.925,2,0.667,3,2.041]],["text/Chap_1.html",[1,1.109,2,1.451,3,3.801,4,4.652,5,3.148,6,1.747,7,1.964,8,3.741,9,3.771,10,3.771,11,0.422,12,1.924,13,2.825,14,2.496,15,2.496,16,3.508,17,2.273,18,2.588,19,0.964,20,1.848,21,3.396,22,2.963,23,4.719,24,4.719,25,1.44,26,5.328,27,5.328,28,5.09,29,5.09,30,3.396,31,2.691,32,1.487,33,2.945,34,0.545,35,1.005,36,3.316,37,2.047,38,3.618,39,1.143,40,1.891,41,2.963,42,5.062,43,4.207,44,2.414,45,3.508,46,2.816,47,2.387,48,3.181,49,2.34,50,4.2,51,3.396,52,2.963,53,1.09,54,2.487,55,5.328,56,3.396,57,2.34,58,4.442,59,2.699,60,3.396,61,3.396,62,3.396,63,3.396,64,1.606,65,1.632,66,2.359,67,3.396,68,1.659,69,4.221,70,3.396,71,2.693,72,2.693,73,3.396,74,3.396,75,3.396,76,3.316,77,2.332,78,1.748,79,2.693,80,1.964,81,2.963,82,2.693,83,2.414,84,2.297,85,2.496,86,2.496,87,2.273,88,2.407,89,5.66,90,4.036,91,1.877,92,5.09,93,2.588,94,5.328,95,2.282,96,3.396,97,4.221,98,3.316,99,0.835,100,1.659,101,1.129,102,4.036,103,3.741,104,1.688,105,1.446,106,2.176,107,2.338,108,1.078,109,2.24,110,1.246,111,1.532,112,2.414,113,3.396,114,1.659,115,2.588,116,2.414,117,2.693,118,3.396,119,2.963,120,1.748,121,2.273,122,1.885,123,2.908,124,2.963,125,2.963,126,3.61,127,1.246,128,2.963,129,3.396,130,2.588,131,5.09,132,2.34,133,1.78,134,2.297,135,3.879,136,1.347,137,3.781,138,2.131,139,1.964,140,3.396,141,3.396,142,0.407,143,1.276,144,2.963,145,1.717,146,4.652,147,3.078,148,1.556,149,4.221,150,3.396,151,2.446,152,2.008,153,1.348,154,3.396,155,1.444,156,4.207,157,2.103,158,1.58,159,2.414,160,2.963,161,2.054,162,4.719,163,4.036,164,3.396,165,2.588,166,2.496,167,3.323,168,2.34,169,0.664,170,1.813,171,5.09,172,2.963,173,4.442,174,5.09,175,3.396,176,3.396,177,3.396,178,3.396,179,3.396,180,3.396,181,3.396,182,3.396,183,3.396,184,1.717,185,4.01,186,6.271,187,2.816,188,2.297,189,3.396,190,2.963,191,3.396,192,2.963,193,3.396,194,3.396,195,1.58,196,1.813,197,2.816,198,1.347,199,2.693,200,5.09,201,2.816,202,2.693,203,3.396,204,5.09,205,3.396,206,3.396,207,3.396,208,2.693,209,3.396,210,1.848,211,1.366,212,3.396,213,2.054,214,1.404,215,2.963,216,1.659,217,3.396,218,3.396,219,3.396,220,2.297,221,3.396,222,3.396,223,4.151,224,3.691,225,2.963,226,5.09,227,3.396,228,2.212,229,4.842,230,2.963,231,2.963,232,1.813,233,2.963,234,3.396,235,2.496,236,3.396,237,3.396,238,3.396,239,3.396,240,1.04,241,3.231,242,2.103,243,3.508,244,3.009,245,2.963,246,3.396,247,3.407,248,3.396,249,2.693,250,2.054,251,3.396,252,2.963,253,1.444,254,2.963,255,1.813,256,1.821,257,2.693,258,3.396,259,0.798,260,1.964,261,3.396,262,2.496,263,2.496,264,2.668,265,2.496,266,1.606]],["title/Chap_1.html#how-to-use-this-ibook",[2,0.787,3,2.407]],["text/Chap_1.html#how-to-use-this-ibook",[1,1.313,2,1.432,3,3.636,11,0.265,12,3.414,13,3.346,14,4.429,15,4.429,16,5.214,17,4.035,18,4.593,19,1.142,20,3.28,21,6.027,22,5.26,23,5.588,24,5.588,25,1.705,26,7.216,27,7.216,28,7.565,29,7.565,30,6.027,31,3.281,32,2.639,33,3.487,34,0.968,35,1.784,36,3.926,37,2.424,38,4.284,39,2.028,40,2.24,41,5.26,42,4.998,43,4.154,44,4.284,45,4.154,46,4.998,47,2.717,48,3.797,49,4.154,50,3.732,51,6.027,52,5.26,53,1.934,54,3.697,55,7.216,56,6.027,57,4.154,58,6.602,59,2.24,60,6.027,61,6.027,62,6.027,63,6.027,64,2.85,65,2.897,66,2.329,67,6.027,68,2.945,69,4.998,70,6.027,71,4.78,72,4.78,73,6.027,74,6.027,75,6.027,76,4.928,77,3.467,78,3.102,79,4.78,80,3.487,81,5.26,82,4.78,83,4.284,84,3.414,85,4.429,86,4.429,87,4.035,88,2.85]],["title/Chap_1.html#highlighting",[89,5.659]],["text/Chap_1.html#highlighting",[11,0.429,13,3.672,40,2.458,89,7.428,90,6.354,91,2.385,92,8.012,93,5.041,94,7.522,95,2.9,96,6.615,97,6.644,98,5.219,99,1.096,100,3.233,101,2.2,102,6.354,103,5.889,104,3.288,105,1.411,106,2.766,107,3.088,108,1.279,109,3.162,110,2.427,111,2.985,112,4.702,113,6.615,114,3.233,115,5.041,116,4.702]],["title/Chap_1.html#outside-this-device",[117,3.972,118,5.008]],["text/Chap_1.html#outside-this-device",[3,3.542,6,2.109,11,0.324,42,7.083,43,5.078,45,5.078,50,4.563,66,2.847,88,3.485,99,1.008,105,1.572,119,6.431,120,3.793,121,4.933,122,4.09,123,2.81,124,6.431,125,6.431,126,4.357,127,2.703,128,6.431]],["title/Chap_1.html#getting-around",[129,5.008,130,3.817]],["text/Chap_1.html#getting-around",[3,3.514,6,2.092,11,0.322,43,5.039,47,2.402,69,6.063,123,2.788,131,8.503,132,5.039,133,3.832,134,3.299,135,5.572,136,2.901,137,5.266,138,2.968,139,4.23,140,7.312,141,7.312,142,0.876,143,1.833,144,6.381,145,3.697]],["title/Chap_1.html#sound-of-music",[146,3.817,147,3.029]],["text/Chap_1.html#sound-of-music",[3,4.009,4,6.356,11,0.403,36,4.609,38,5.03,91,1.958,105,1.509,108,1.05,123,3.181,146,6.356,147,4.279,148,3.242,149,5.867,150,7.076,151,3.401,152,4.184,153,1.874,154,7.076,155,3.01,156,5.748,157,4.382,158,3.293,159,5.03,160,6.175,161,4.279,162,6.56,163,5.611,164,7.076,165,5.392,166,5.2]],["title/Chap_1.html#at-the-movies",[167,3.322]],["text/Chap_1.html#at-the-movies",[2,1.382,8,5.099,11,0.387,37,2.79,47,2.279,105,1.48,108,1.03,123,2.645,135,5.287,143,1.739,149,5.753,151,3.335,153,1.837,156,4.781,162,6.432,163,5.502,167,4.487,168,4.781,169,1.358,170,3.704,171,8.244,172,6.054,173,7.195,174,8.244,175,6.938,176,6.938,177,6.938,178,6.938,179,6.938,180,6.938,181,6.938,182,6.938,183,6.938,184,3.508,185,4.102,186,5.502,187,5.753,188,3.13]],["title/Chap_1.html#enhanced-experience",[48,2.193,189,5.008]],["text/Chap_1.html#enhanced-experience",[1,1.223,2,1.476,11,0.372,19,1.063,23,5.202,24,5.202,25,1.588,31,2.226,33,3.246,50,4.477,59,3.139,66,2.168,95,1.888,106,1.801,123,2.14,126,4.274,134,2.532,137,3.475,138,1.958,185,4.729,186,7.097,188,2.532,190,4.897,191,5.611,192,4.897,193,5.611,194,5.611,195,2.612,196,2.996,197,4.653,198,2.226,199,4.45,200,7.229,201,4.653,202,4.45,203,5.611,204,7.229,205,5.611,206,5.611,207,5.611,208,4.45,209,5.611,210,3.054,211,2.257,212,5.611,213,3.394,214,2.32,215,4.897,216,2.742,217,5.611,218,5.611,219,5.611,220,3.262,221,5.611,222,5.611,223,4.871,224,4.597,225,4.897,226,7.229,227,5.611,228,3.655,229,6.342,230,4.897,231,4.897,232,2.996,233,4.897,234,5.611,235,4.124,236,5.611,237,5.611,238,5.611,239,5.611,240,1.719,241,4.589,242,3.475,243,4.982,244,4.274,245,4.897,246,5.611,247,4.84,248,5.611,249,4.45,250,3.394,251,5.611,252,4.897,253,2.387,254,4.897,255,2.996,256,2.586,257,4.45,258,5.611,259,1.318,260,3.246,261,5.611,262,4.124,263,4.124,264,3.789,265,4.124,266,2.654]],["title/Chap_10.html",[267,2.406,268,2.568,269,1.271]],["text/Chap_10.html",[1,1.285,2,1.077,4,2.194,6,1.284,11,0.437,14,0.672,17,1.123,19,1.232,20,0.913,25,1.354,31,0.666,32,0.4,34,1.343,35,2.165,37,0.935,38,2.389,39,0.969,40,1.249,47,1.474,48,0.4,50,0.566,54,0.82,59,1.07,65,0.806,66,1.462,68,0.447,77,1.32,78,1.482,80,0.971,83,2.047,84,0.413,86,0.672,87,0.612,88,0.432,91,1.324,95,1.855,98,1.093,99,1.078,100,0.82,101,1.258,104,3.166,105,1.176,106,1.079,107,1.159,108,1.258,109,0.615,110,1.233,111,0.413,112,0.65,114,0.82,115,0.697,120,0.471,121,0.612,123,1.824,126,0.541,127,1.388,134,1.049,135,0.697,136,1.334,138,1.45,139,0.529,142,0.727,143,1.433,145,1.175,146,0.697,147,2.893,148,0.419,152,1.987,153,1.513,155,1.43,156,2.317,158,1.082,161,0.553,163,2.284,165,2.194,166,2.78,169,0.658,170,0.488,172,0.798,188,0.413,195,0.426,198,0.922,210,0.498,211,0.368,213,0.553,214,0.378,215,0.798,220,1.299,225,0.798,232,1.241,240,1.03,245,0.798,250,0.553,255,1.538,256,0.6,259,0.394,264,0.479,265,0.672,266,0.432,267,1.317,268,4.514,269,2.621,270,1.337,271,1.742,272,0.672,273,1.241,274,1.123,275,0.725,276,0.863,277,1.517,278,0.992,279,1.353,280,0.672,281,1.299,282,1.156,283,1.513,284,1.928,285,2.244,286,1.912,287,1.609,288,0.948,289,1.243,290,3.938,291,0.518,292,2.143,293,0.58,294,3.849,295,0.529,296,1.468,297,0.672,298,1.345,299,0.798,300,2.47,301,0.672,302,2.047,303,1.708,304,0.498,305,1.543,306,3.949,307,4.418,308,0.672,309,1.538,310,1.082,311,1.572,312,3.516,313,1.099,314,1.555,315,1.602,316,1.495,317,2.707,318,2.426,319,1.45,320,2.561,321,0.694,322,0.4,323,0.922,324,2.881,325,1.091,326,0.566,327,2.035,328,0.798,329,1.352,330,1.649,331,3.298,332,1.83,333,0.914,334,0.914,335,2.504,336,1.456,337,1.312,338,0.725,339,0.848,340,1.517,341,1.431,342,1.345,343,0.529,344,0.724,345,1.233,346,2.401,347,3.591,348,1.547,349,0.725,350,0.798,351,1.464,352,1.33,353,1.678,354,1.913,355,1.342,356,1.371,357,0.725,358,0.771,359,0.886,360,0.798,361,0.914,362,0.95,363,0.863,364,1.093,365,0.697,366,1.196,367,0.462,368,0.553,369,1.099,370,1.33,371,1.34,372,1.345,373,1.017,374,2.893,375,1.555,376,1.391,377,1.514,378,1.707,379,0.64,380,4.065,381,0.798,382,0.961,383,1.196,384,1.983,385,1.678,386,0.672,387,2.237,388,0.798,389,0.848,390,1.193,391,1.175,392,0.914,393,1.352,394,0.714,395,0.863,396,0.914,397,0.914,398,1.391,399,1.015,400,3.296,401,0.914,402,2.787,403,0.914,404,0.657,405,0.914,406,2.513,407,1.678,408,0.914,409,1.594,410,2.67,411,0.488,412,0.84,413,1.039,414,1.233,415,0.914,416,2.028,417,0.914,418,0.914,419,0.914,420,1.093,421,0.914,422,1.602,423,0.914,424,0.914,425,1.278,426,0.798,427,0.4,428,1.678,429,1.793,430,0.612,431,0.395,432,1.616,433,0.4,434,2.933,435,0.798,436,1.391,437,2.787,438,3.446,439,3.137,440,1.218,441,0.725,442,0.508,443,0.508,444,0.672,445,0.63,446,0.9,447,0.793,448,1.191,449,0.82,450,1.131,451,1.708,452,0.58,453,0.6,454,0.672,455,0.914,456,0.529,457,0.95,458,2.47,459,0.798,460,0.798,461,0.914,462,0.541,463,0.697,464,2.148,465,0.798,466,0.612,467,0.863,468,1.544,469,0.971,470,0.914,471,0.58,472,1.278,473,0.914,474,0.725,475,0.914,476,0.612,477,0.439,478,0.914,479,0.697,480,0.798,481,0.697,482,0.798,483,0.914,484,0.914,485,0.914,486,0.596,487,2.378,488,1.241,489,1.334,490,0.914,491,2.388,492,3.559,493,0.518,494,2.029,495,0.914,496,0.566,497,0.798,498,2.155,499,0.992,500,0.879,501,2.279,502,3.191,503,1.065,504,0.914,505,0.673,506,0.914,507,0.725,508,2.324,509,2.324,510,2.134,511,0.914,512,0.914,513,0.914,514,0.913,515,0.697,516,0.914,517,2.029,518,0.672,519,1.678,520,0.914,521,0.914,522,0.914,523,0.725,524,0.914,525,0.508,526,2.155,527,0.914,528,1.482,529,0.798,530,0.798,531,1.391,532,1.475,533,0.65,534,0.596,535,1.156,536,0.725,537,0.948,538,0.65,539,0.992,540,2.33,541,1.678,542,1.678,543,1.678,544,0.798,545,0.672,546,0.914,547,1.555,548,0.725,549,0.832,550,0.989,551,0.757,552,0.914,553,1.678,554,0.914,555,1.678,556,4.425,557,2.67,558,1.678,559,0.63,560,0.462,561,2.78,562,1.193,563,2.513,564,1.961,565,1.33,566,0.914,567,0.508,568,2.561,569,0.518,570,1.123,571,0.971,572,1.439,573,1.494,574,2.408,575,2.155,576,0.82,577,0.914,578,0.914,579,0.488,580,1.928,581,0.65,582,0.914,583,2.826,584,0.612,585,0.612,586,1.003,587,1.603,588,0.58,589,0.529,590,0.612,591,0.566,592,0.914,593,0.553,594,3.855,595,0.566,596,1.193,597,0.217,598,2.029,599,0.914,600,0.992,601,2.596,602,1.065,603,0.541,604,0.914,605,0.714,606,2.155,607,0.541,608,1.299,609,0.914,610,0.798,611,1.233,612,3.591,613,0.914,614,2.155,615,4.389,616,0.798,617,0.518,618,0.725,619,0.672,620,0.725,621,1.193,622,0.914,623,0.553,624,0.914,625,2.513,626,0.666,627,0.439,628,1.391,629,0.725,630,1.843,631,1.555,632,1.261,633,1.155,634,1.843,635,0.914,636,1.487,637,2.143,638,1.317,639,1.29,640,1.876,641,0.957,642,1.156,643,0.672,644,0.914,645,2.029,646,1.464,647,0.725,648,0.798,649,0.798,650,0.672,651,0.935,652,0.914,653,1.093,654,0.479,655,0.798,656,0.914,657,0.508,658,1.556,659,2.324,660,0.914,661,0.383,662,2.155,663,0.914,664,1.233,665,0.914,666,1.265,667,1.681,668,0.553,669,0.798,670,0.612,671,0.798,672,0.541,673,0.798,674,0.596,675,1.175,676,0.806,677,1.123,678,0.596,679,1.464,680,0.914,681,0.798,682,1.136,683,0.914,684,0.834,685,0.439,686,0.914,687,0.672,688,0.914,689,0.896,690,0.914,691,0.914,692,0.914,693,0.798,694,0.914,695,0.914,696,0.914,697,0.914,698,0.63,699,1.391,700,0.672,701,0.914,702,3.361,703,1.464,704,3.361,705,2.324,706,0.898,707,0.914,708,0.541,709,0.931,710,0.725,711,0.914,712,1.678,713,1.652,714,0.914,715,0.914,716,0.914,717,0.914,718,0.672,719,0.914,720,0.541,721,0.798,722,0.914,723,0.914,724,0.541,725,0.914,726,0.725,727,0.914,728,0.378,729,0.553,730,1.555,731,1.039,732,0.914,733,0.58,734,0.58,735,0.58,736,0.914,737,0.914,738,1.039,739,0.488,740,0.596,741,2.029,742,1.843,743,0.914,744,1.678,745,0.914,746,0.914,747,0.914,748,0.914,749,0.612,750,0.488,751,0.612,752,0.406,753,2.029,754,1.464,755,2.029,756,2.343,757,1.193,758,0.672,759,0.914,760,0.914,761,0.981,762,0.488,763,0.697,764,0.612,765,0.508,766,0.914,767,0.798,768,0.914,769,0.914,770,0.798,771,1.678,772,0.914,773,0.426,774,0.65,775,0.596,776,0.798,777,0.914,778,0.672,779,0.672,780,0.672,781,0.596,782,0.63,783,0.541,784,0.612,785,0.725,786,0.672,787,1.093,788,0.672,789,0.63,790,0.672,791,0.798,792,0.498,793,0.63,794,0.63,795,0.666,796,0.596,797,0.553,798,0.914,799,0.406,800,0.798,801,0.488,802,0.454,803,0.914,804,0.798,805,0.914,806,0.672,807,0.914,808,0.479]],["title/Chap_10.html#the-wiener-filter",[268,3.029,269,1.5]],["text/Chap_10.html#the-wiener-filter",[2,1.123,108,1.245,138,2.494,142,0.856,153,2.222,169,1.399,213,4.322,255,3.816,269,2.667,270,2.525,271,4.322,272,5.252,273,3.816,274,4.784,275,5.668,276,3.678,277,3.786,278,4.226,279,2.557,280,5.252,281,3.225,282,4.925,283,1.892,284,4.784,285,1.978,286,1.831,287,3.04,288,2.914,289,3.084]],["title/Chap_10.html#the-restoration-case-noise",[95,1.429,285,1.175,290,2.926]],["text/Chap_10.html#the-restoration-case-noise",[2,0.98,11,0.404,35,2.288,78,3.211,80,3.609,107,2.151,108,1.339,139,3.609,153,2.047,169,1.513,198,2.475,269,2.314,277,2.815,283,2.389,284,5.175,285,2.324,286,2.356,290,5.327,291,3.534,292,4.379,293,3.96,294,6.69,295,3.609,296,2.731,297,4.585,298,3.609,299,5.444,300,4.585,301,4.585,302,4.434,303,6.173,304,3.395,305,2.544,306,5.175,307,4.906,308,4.585,309,3.331,310,2.904,311,2.05,312,6.173,313,2.95,314,5.784,315,4.299,316,1.847,317,4.064,318,2.395,319,2.177,320,4.754,321,2.579,322,2.732,323,2.475,324,3.395,325,2.026,326,3.863]],["title/Chap_10.html#using-the-least-mean-square-error-criterion",[2,0.511,19,0.617,324,1.772,327,1.385,328,2.841]],["text/Chap_10.html#using-the-least-mean-square-error-criterion",[1,1.255,6,1.648,11,0.426,19,1.534,25,1.63,34,1.181,65,2.768,84,2.598,91,1.594,99,1.206,100,2.814,107,1.985,108,0.855,109,2.113,120,2.964,134,2.598,136,2.285,142,0.69,148,2.639,152,4.346,170,3.075,240,1.764,259,1.353,266,2.723,269,1.724,283,1.525,286,2.075,294,5.601,307,3.655,311,1.892,312,4.232,317,3.751,318,2.278,319,2.01,320,4.388,324,4.406,327,3.444,329,2.956,330,2.285,331,4.232,332,2.086,333,5.759,334,5.759,335,1.915,336,3.717,337,1.258,338,4.567,339,3.717,340,2.598,341,2.862,342,3.332,343,3.332,344,2.485,345,4.232,346,5.139,347,4.788,348,1.764,349,4.567,350,5.026,351,6.414,352,5.829,353,7.35,354,2.912,355,1.31,356,1.492,357,4.567,358,1.542,359,2.196,360,5.026,361,5.759,362,3.262,363,2.964,364,4.788,365,4.388,366,3.783,367,2.912,368,3.483,369,2.723,370,4.567,371,2.68,372,3.332,373,2.035,374,3.483,375,5.339,376,4.775,377,3.751]],["title/Chap_10.html#expressing-the-mean-square-error",[19,0.698,324,2.006,327,1.568,378,1.663]],["text/Chap_10.html#expressing-the-mean-square-error",[11,0.431,34,1.4,91,1.689,99,1.252,152,3.609,256,2.184,279,2.184,286,2.232,287,2.596,294,4.652,307,5.279,312,4.486,316,1.807,318,2.7,330,3.026,331,4.486,332,3.013,335,2.981,337,1.421,340,2.755,345,4.486,348,1.87,354,4.405,355,1.389,356,1.581,366,3.142,379,2.328,380,5.256,381,5.327,382,2.524,383,3.142,384,3.997,385,7.626,386,4.486,387,3.609,388,5.327,389,3.087,390,4.339,391,3.087,392,6.104,393,2.455,394,1.514,395,3.142,396,6.104,397,6.104,398,5.062,399,3.692,400,4.841,401,6.104,402,5.062,403,6.104]],["title/Chap_10.html#correlation-returns",[126,2.961,404,1.961]],["text/Chap_10.html#correlation-returns",[2,0.947,11,0.431,34,1.435,40,2.24,50,3.732,99,0.825,107,2.078,108,1.123,152,4.473,286,1.544,296,2.673,307,5.787,318,2.825,325,1.957,330,3.002,335,2.97,337,1.416,341,2.995,356,1.561,359,2.298,378,2.72,384,3.965,387,4.473,404,2.36,405,6.027,406,5.26,407,7.565,408,6.027,409,1.759,410,7.666,411,3.218,412,1.529,413,3.732,414,4.429,415,6.027,416,2.189,417,6.027,418,6.027,419,6.027,420,3.926,421,6.027,422,4.154,423,6.027,424,6.027,425,4.593,426,5.26,427,2.639,428,7.565,429,2.601,430,4.035,431,2.601,432,2.897,433,2.639]],["title/Chap_10.html#the-wiener-hopf-equation",[34,0.682,268,2.568,434,3.706]],["text/Chap_10.html#the-wiener-hopf-equation",[2,0.863,11,0.424,31,2.179,34,1.429,59,2.041,66,2.122,88,2.597,91,1.52,95,2.922,105,1.171,108,1.058,136,2.179,158,2.556,169,1.075,172,4.793,245,4.793,268,5.251,269,2.599,276,2.827,282,3.785,283,1.888,286,1.407,288,2.239,294,4.185,307,3.486,317,3.578,318,2.596,319,2.488,320,4.185,325,1.783,340,3.217,341,2.73,355,1.249,371,3.318,378,2.478,383,2.827,389,2.777,393,2.209,409,2.018,410,5.092,413,3.401,414,4.036,416,2.096,432,2.64,434,6.908,435,4.793,436,4.554,437,4.554,438,4.554,439,5.912,440,2.583,441,4.355,442,3.049,443,3.049,444,4.036,445,3.785,446,1.47,447,3.372,448,2.271,449,3.484,450,1.848,451,5.818,452,3.486,453,1.965,454,4.036,455,5.492,456,3.177,457,4.039,458,5.818,459,4.793,460,4.793,461,5.492,462,3.247,463,4.185,464,3.032,465,4.793,466,3.677,467,2.827,468,2.041,469,3.177,470,5.492,471,3.486,472,4.185,473,5.492,474,4.355,475,5.492,476,3.677,477,2.64,478,5.492,479,4.185,480,4.793,481,4.185,482,4.793,483,5.492,484,5.492,485,5.492]],["title/Chap_10.html#as-seen-from-the-fourier-domain",[468,1.578,486,2.766,487,2.11]],["text/Chap_10.html#as-seen-from-the-fourier-domain",[11,0.422,34,1.163,40,2.689,65,3.479,104,4.45,269,2.167,271,4.377,292,4.1,316,2.142,387,4.279,437,6.001,468,2.689,488,3.864,489,2.872,490,7.237,491,6.001,492,6.703,493,1.611,494,6.316,495,7.237]],["title/Chap_10.html#what-is-that-least-mean-square-error",[19,0.804,324,2.311,327,1.806]],["text/Chap_10.html#what-is-that-least-mean-square-error",[2,1.14,6,1.817,11,0.439,19,0.875,34,1.419,66,1.784,80,2.672,99,1.121,104,2.295,127,1.695,134,2.084,142,0.553,198,1.833,220,2.084,240,1.415,264,2.421,269,1.901,270,1.632,286,1.184,292,2.617,294,3.52,298,2.672,307,4.606,312,3.394,316,1.367,317,5.091,318,2.899,319,2.533,320,4.839,324,3.456,327,1.965,330,1.833,331,3.394,332,3.067,335,2.815,337,1.453,341,2.295,346,4.031,347,3.009,348,2.223,354,2.336,356,1.88,362,2.617,369,3.003,373,1.632,377,3.009,378,2.865,380,3.183,384,2.421,402,6.48,409,1.074,412,0.934,416,2.296,420,3.009,429,2.74,436,3.83,437,5.266,438,3.83,440,1.673,491,3.83,496,2.86,497,4.031,498,5.887,499,2.731,500,2.421,501,2.626,502,2.184,503,2.932,504,4.619,505,1.337,506,4.619,507,3.663,508,7.257,509,7.257,510,5.2,511,4.619,512,4.619,513,4.619,514,2.514,515,3.52,516,4.619,517,4.031,518,3.394,519,6.35,520,4.619,521,4.619,522,4.619,523,3.663,524,4.619,525,2.564,526,5.887,527,4.619,528,2.377,529,4.031,530,4.031,531,3.83,532,2.932,533,3.283,534,3.009]],["title/Chap_10.html#classic-example-classic-result",[91,1.02,105,0.786,535,3.727]],["text/Chap_10.html#classic-example-classic-result",[1,0.905,2,0.652,6,1.687,11,0.439,19,1.117,34,1.353,35,2.029,40,1.543,91,1.632,95,2.307,99,0.568,104,3.916,105,1.258,106,1.892,108,1.17,110,1.524,138,1.45,142,0.498,268,4.766,269,2.359,270,1.468,271,2.512,277,1.874,285,2.265,286,1.912,289,1.792,296,1.468,306,5.275,307,3.743,329,1.671,331,4.333,335,2.722,337,1.308,347,2.706,348,1.806,355,1.341,356,1.527,358,1.112,374,4.146,387,2.456,390,2.953,393,1.671,409,1.903,416,2.278,434,3.625,437,3.444,438,5.684,439,3.444,446,1.579,450,1.398,458,3.053,468,1.543,488,2.218,489,1.648,491,3.444,492,3.294,493,0.925,494,3.625,502,4.197,517,3.625,536,3.294,537,2.404,538,2.953,539,2.456,540,2.795,541,5.896,542,5.896,543,5.896,544,3.625,545,3.053,546,4.154,547,3.851,548,3.294,549,2.109,550,2.508,551,1.874,552,4.154,553,5.896,554,4.154,555,5.896,556,6.221,557,5.467,558,5.896,559,2.863,560,2.1,561,3.129,562,4.191,563,6.511,564,2.279,565,4.676,566,4.154,567,2.306,568,3.165,569,2.353,570,2.781,571,2.403,572,2.572,573,2.621,574,2.72,575,5.467,576,2.03,577,4.154,578,4.154,579,2.218,580,2.781,581,2.953,582,4.154,583,3.984,584,2.781,585,2.781,586,2.544,587,1.786,588,2.637,589,2.403,590,2.781,591,2.572,592,4.154,593,2.512]],["title/Chap_10.html#the-more-general-restoration-case-noise-distortion",[95,0.888,110,0.968,281,1.191,285,0.73,290,1.819,594,1.635,809,2.447]],["text/Chap_10.html#the-more-general-restoration-case-noise-distortion",[11,0.397,17,4.167,19,1.462,35,2.285,78,3.204,83,5.487,105,1.328,107,2.146,108,1.364,109,2.284,110,2.284,121,4.167,127,2.284,142,0.746,153,1.648,268,3.765,269,2.626,271,3.765,277,2.809,281,2.809,283,1.648,285,2.496,286,1.978,287,3.283,288,2.538,289,2.686,294,4.743,305,3.148,310,2.897,313,2.944,314,5.771,324,3.388,325,2.021,327,2.648,330,2.47,335,2.567,337,1.199,340,2.809,342,3.601,347,5.028,355,1.416,393,2.504,409,1.447,429,2.686,450,2.095,528,3.204,539,3.68,540,3.148,573,3.431,594,3.855,595,3.855,596,4.425,597,1.478,598,5.432,599,6.225,600,3.68,601,3.601,602,3.951,603,3.68,604,6.225,605,2.648,606,5.771,607,3.68,608,2.809,609,6.225,610,5.432]],["title/Chap_10.html#why-we-avoid-the-inverse-filter",[269,1.271,611,3.121,612,2.766]],["text/Chap_10.html#why-we-avoid-the-inverse-filter",[1,1.727,2,1.121,11,0.434,25,2.02,35,2.113,87,3.684,101,1.83,104,3.548,105,1.174,108,1.244,142,0.949,145,2.782,153,1.457,211,2.213,268,3.328,269,2.713,285,1.975,311,1.808,315,4.92,337,0.855,355,1.624,372,4.13,374,4.317,380,4.92,383,2.832,412,1.112,432,2.645,448,2.275,450,1.852,464,3.036,487,3.548,492,4.364,501,2.951,502,2.602,540,2.244,550,2.34,551,2.483,561,3.516,564,2.373,568,4.193,573,2.446,574,3.144,576,2.689,587,2.162,594,4.421,598,4.802,606,6.618,611,4.044,612,5.462,613,5.503,614,6.618,615,6.953,616,4.802,617,3.117,618,4.364,619,4.044,620,4.364,621,5.074,622,5.503,623,3.328,624,5.503,625,7.317,626,2.183,627,2.645,628,4.563,629,4.364,630,4.364,631,5.102,632,2.41,633,2.735,634,4.364,635,5.503,636,1.969,637,4.044,638,3.117,639,3.055,640,3.584,641,1.1]],["title/Chap_10.html#example-sound-of-distorted-music",[105,0.786,146,2.808,147,2.229,594,2.282]],["text/Chap_10.html#example-sound-of-distorted-music",[1,1.142,2,0.823,4,5.268,11,0.423,17,3.508,19,0.993,20,2.852,35,2.532,37,2.78,38,4.914,48,2.294,54,2.56,66,2.024,77,3.168,95,1.763,98,3.413,104,2.604,105,1.117,106,1.681,108,1.304,115,3.993,123,2.636,136,2.079,147,5.312,153,1.831,156,5.332,158,2.439,163,5.482,165,5.268,166,5.686,188,2.364,214,2.166,220,2.364,225,4.572,256,1.874,269,2.463,279,2.473,281,2.364,285,2.277,286,1.343,290,3.611,305,2.136,307,3.326,309,3.691,310,2.439,311,2.542,312,3.851,323,2.743,329,2.107,331,3.851,347,4.503,358,1.403,379,1.998,380,5.332,472,3.993,487,2.604,493,1.167,502,2.478,540,3.155,564,2.299,568,3.993,572,4.281,574,3.07,594,4.281,598,4.572,600,3.098,602,3.326,608,2.364,612,4.503,614,4.857,615,5.732,632,3.027,634,4.155,641,1.048,642,3.611,643,3.851,644,5.239,645,6.752,646,6.033,647,4.155,648,4.572,649,4.572,650,3.851,651,2.107,652,5.239,653,3.413,654,2.746,655,4.572,656,5.239,657,2.908,658,4.628,659,7.737,660,5.239,661,2.197,662,6.409,663,5.239,664,3.851,665,5.239,666,2.852,667,3.073,668,3.169,669,4.572,670,3.508,671,4.572,672,3.098]],["title/Chap_10.html#example-cleaning-up-our-act",[105,0.786,215,3.216,673,3.216,674,2.401]],["text/Chap_10.html#example-cleaning-up-our-act",[1,1.736,11,0.427,25,2.035,35,2.493,39,1.873,78,2.865,95,1.873,99,0.984,100,2.721,101,1.851,108,1.25,142,0.667,145,2.815,153,1.474,255,2.973,259,1.308,269,2.674,279,2.573,285,2.471,292,4.075,300,5.286,305,2.27,311,2.618,337,1.117,347,3.627,355,1.267,363,2.865,380,3.837,382,2.302,394,1.381,400,5.704,429,2.402,432,2.676,448,2.302,464,3.059,469,3.221,487,3.96,492,5.704,501,2.974,540,3.249,556,3.957,561,2.334,564,2.649,574,3.162,575,5.161,587,2.55,594,3.448,608,2.512,612,5.486,615,5.964,630,4.415,631,5.161,632,2.438,633,2.767,634,4.415,636,2.851,637,4.075,638,3.154,639,3.09,640,3.627,641,1.438,666,3.03,667,2.474,675,4.029,676,3.457,677,3.727,678,3.627,679,6.277,680,5.567,681,4.858,682,2.721,683,5.567,684,2.767,685,2.676,686,5.567,687,4.092,688,5.567]],["title/Chap_10.html#determining-the-wiener-filter",[240,1.301,268,2.568,269,1.271]],["text/Chap_10.html#determining-the-wiener-filter",[1,1.616,2,1.091,4,4.022,6,1.798,11,0.438,19,0.675,25,1.494,31,1.415,34,1.377,35,2.056,37,1.434,38,3.752,40,1.325,47,1.172,59,1.961,66,2.039,77,2.419,86,2.621,98,2.323,99,1.173,101,1.186,104,3.686,105,1.126,108,0.933,110,1.308,123,2.013,135,2.717,138,1.244,143,0.894,145,1.803,147,2.157,153,1.398,156,3.638,158,1.66,163,4.186,165,4.022,166,3.879,198,1.415,210,1.941,220,1.609,255,1.904,265,2.621,268,5.097,269,2.726,273,2.818,278,2.108,283,1.664,285,1.739,290,4.788,302,3.752,306,4.207,307,2.263,309,1.904,313,1.686,321,1.474,335,2.31,336,2.669,337,1.309,347,2.323,348,1.925,355,1.43,356,1.628,358,0.955,359,1.36,371,1.66,374,3.801,380,3.638,387,2.108,399,2.157,400,4.186,406,4.606,409,1.724,412,0.721,416,2.056,422,2.457,429,2.278,432,1.714,438,4.377,439,2.957,448,1.474,453,1.276,458,2.621,464,2.245,467,1.835,468,1.325,487,2.623,488,1.904,489,1.415,491,2.957,492,4.186,494,3.112,501,2.183,502,3.8,514,1.941,517,3.112,528,2.717,537,1.454,547,3.306,556,5.52,557,4.894,561,3.256,564,1.755,568,4.022,570,2.387,571,2.063,574,2.095,580,4.207,583,2.818,587,1.08,594,4.809,605,1.517,608,1.609,612,2.323,615,5.211,628,2.957,630,2.828,633,1.772,636,1.276,637,2.99,638,2.02,639,1.979,640,2.323,641,0.713,666,1.941,667,2.793,689,2.818,690,3.566,691,3.566,692,3.566,693,3.112,694,3.566,695,3.566,696,3.566,697,3.566,698,2.457,699,2.957,700,2.621,701,3.566,702,7.416,703,4.606,704,7.416,705,6.285,706,1.378,707,3.566,708,2.108,709,1.979,710,2.828,711,3.566,712,5.278,713,3.752,714,3.566,715,3.566,716,3.566,717,3.566,718,2.621,719,3.566,720,2.108,721,3.112,722,3.566,723,3.566,724,2.108,725,3.566,726,2.828,727,3.566,728,1.474,729,2.157,730,3.306,731,2.208,732,3.566,733,2.263,734,2.263,735,2.263,736,3.566,737,3.566]],["title/Chap_10.html#problems",[142,0.731]],["text/Chap_10.html#problems",[]],["title/Chap_10.html#problem-101",[142,0.6,312,3.681]],["text/Chap_10.html#problem-101",[34,1.222,195,3.54,270,2.687,316,2.251,346,4.827,370,6.031,398,6.306,738,4.709,739,4.061,740,4.954]],["title/Chap_10.html#problem-102",[142,0.6,331,3.681]],["text/Chap_10.html#problem-102",[2,1.027,11,0.433,34,1.278,40,2.43,91,2.202,106,2.098,107,2.254,108,1.181,110,2.399,111,2.951,114,3.888,136,2.595,270,2.811,298,3.783,318,2.465,384,3.427,422,4.507,425,4.983,446,1.751,468,2.43,489,2.595,498,6.063,499,3.866,500,3.427,501,3.29,503,4.151,526,6.063,531,5.422,532,5.05,586,2.822,706,2.526,741,7.484,742,6.801,743,6.539,744,7.956,745,6.539,746,6.539,747,6.539,748,6.539,749,4.378,750,3.492]],["title/Chap_10.html#problem-103",[142,0.6,347,3.263]],["text/Chap_10.html#problem-103",[11,0.41,19,1.633,59,2.458,78,3.405,91,1.831,106,2.123,108,1.189,153,1.752,240,2.454,285,2.385,286,2.296,287,3.408,296,2.831,300,4.862,305,2.697,306,5.997,307,5.086,355,1.823,378,2.985,393,2.661,412,1.619,416,2.372,439,6.644,505,2.319,540,2.697,549,2.367,564,2.664,587,2.426,636,2.866,699,5.485,713,4.702,751,4.429,752,2.94,753,7.522]],["title/Chap_10.html#problem-104",[142,0.6,380,3.452]],["text/Chap_10.html#problem-104",[2,1.238,11,0.417,25,2.23,35,2.627,38,4.575,39,2.651,47,2.115,68,3.145,101,2.832,108,0.955,127,2.891,136,2.554,138,2.972,143,1.614,147,3.892,166,4.73,220,2.904,267,4.824,325,2.09,373,2.784,380,4.435,400,5.104,406,5.616,440,2.854,464,3.351,501,3.258,561,3.721,583,4.207,640,4.192,641,1.576,664,4.73,738,3.985,754,6.876,755,7.432,756,5.274,757,4.575,758,4.73,759,6.436,760,6.436,761,2.192,762,3.436,763,4.904,764,4.309,765,3.572]],["title/Chap_10.html#laboratory-exercises",[47,1.646,143,1.256]],["text/Chap_10.html#laboratory-exercises",[]],["title/Chap_10.html#laboratory-exercise-101",[47,1.395,143,1.065,312,3.121]],["text/Chap_10.html#laboratory-exercise-101",[99,1.022,108,1.108,123,2.847,143,1.872,155,3.175,161,4.515,268,4.515,269,2.235,285,2.382,290,5.145,300,5.487,316,2.21,329,3.003,626,2.962,662,6.921,684,3.71]],["title/Chap_10.html#laboratory-exercise-102",[47,1.395,143,1.065,331,3.121]],["text/Chap_10.html#laboratory-exercise-102",[99,1.027,123,2.862,143,1.882,155,3.192,250,4.539,274,5.024,284,5.024,285,2.077,290,5.172,316,2.221,601,4.342,677,5.024,709,4.166,766,7.505,767,6.549]],["title/Chap_10.html#laboratory-exercise-103",[47,1.395,143,1.065,347,2.766]],["text/Chap_10.html#laboratory-exercise-103",[19,1.385,99,1.001,108,1.085,123,2.788,143,1.833,155,3.11,268,4.422,269,2.189,285,2.024,290,5.039,316,2.164,324,3.98,327,3.11,342,4.23,395,3.763,446,1.958,450,2.461,594,4.528,596,5.198,601,5.202,642,5.039,768,7.312,769,7.312]],["title/Chap_10.html#laboratory-exercise-104",[47,1.395,143,1.065,380,2.926]],["text/Chap_10.html#laboratory-exercise-104",[66,2.869,83,6.099,99,1.016,123,2.832,143,1.862,155,3.159,255,3.965,290,5.118,302,5.279,316,2.198,594,4.599,601,4.964,651,2.987,770,6.481,771,8.58,772,7.426]],["title/Chap_10.html#laboratory-exercise-105",[47,1.395,143,1.065,400,3.367]],["text/Chap_10.html#laboratory-exercise-105",[2,1.171,11,0.421,14,4.329,19,1.116,20,3.206,32,2.579,39,1.982,54,2.878,99,0.806,105,1.256,108,1.276,112,4.187,123,2.246,127,2.736,134,2.658,138,2.056,142,0.706,143,1.477,153,1.56,155,2.505,169,1.153,232,4.369,268,4.51,269,2.232,285,1.63,289,2.542,316,1.743,344,2.542,375,5.46,376,4.884,377,3.837,382,2.435,391,3.77,394,1.849,409,1.369,468,2.189,489,2.337,574,2.337,583,4.369,601,3.407,641,1.491,651,2.369,653,3.837,658,3.943,682,3.644,706,2.276,730,5.46,731,3.647,756,5.067,757,4.187,761,2.787,773,2.741,774,4.187,775,3.837,776,5.14,777,5.89,778,4.329,779,4.329,780,4.329,781,3.837,782,4.059,783,3.482,784,3.943,785,4.671,786,4.329,787,4.857,788,4.329,789,4.059,790,4.329,791,5.14,792,3.206,793,4.059,794,4.059,795,2.959,796,3.837,797,3.562,798,5.89,799,2.618,800,5.14,801,3.145,802,2.927,803,5.89,804,5.14,805,5.89,806,4.329,807,5.89,808,3.087]],["title/Chap_11.html",[168,2.926,283,1.124,810,3.018]],["text/Chap_11.html",[1,1.503,2,0.862,6,1.277,7,1.119,11,0.435,19,1.388,25,1.952,31,0.293,32,0.323,33,0.427,34,1.205,35,1.573,36,0.481,37,1.307,39,2.087,40,0.274,44,0.525,47,0.797,48,1.062,50,0.852,53,0.621,57,0.509,59,1.063,64,0.915,66,0.285,68,0.945,72,0.586,77,0.631,84,1.291,88,0.915,91,1.163,95,1.093,99,1.197,100,0.361,101,0.245,105,1.003,106,0.918,107,0.986,108,0.36,110,0.71,114,0.945,120,1.248,123,0.737,126,0.437,127,1.049,133,0.721,134,0.333,136,0.293,138,1.641,139,1.119,142,0.845,143,0.982,145,0.373,148,1.111,151,0.662,153,0.642,155,0.823,157,1.501,158,0.641,167,1.557,168,0.949,169,1.136,170,0.394,184,0.978,185,0.437,188,0.621,195,0.344,196,1.033,198,0.767,210,0.749,211,2.062,214,0.569,216,0.361,220,0.621,223,0.402,232,0.735,233,0.644,240,1.199,241,0.469,247,0.922,253,0.586,254,0.644,256,1.023,259,1.457,260,0.796,262,1.012,264,1.271,266,0.651,270,1.811,271,0.833,272,1.421,275,0.586,276,0.709,279,0.692,280,0.543,281,1.466,282,0.949,283,2.388,286,1.768,287,0.823,288,0.301,289,1.046,291,1.374,293,0.469,295,0.427,296,2.05,298,1.88,303,0.543,304,1.053,305,1.166,309,0.394,311,1.182,315,0.509,316,0.718,317,3.576,318,2.25,319,2.378,321,1.183,322,1.955,323,0.767,324,2.287,325,1.055,326,1.771,327,1.787,329,1.69,330,0.767,332,1.522,335,2.062,337,1.365,338,0.586,339,1.643,341,0.684,342,1.119,344,1.234,346,1.815,348,1.199,349,0.586,351,0.644,352,0.586,354,1.446,355,1.694,356,1.328,358,1.318,359,1.239,362,0.78,363,0.709,364,0.481,366,0.709,368,0.833,369,0.915,370,1.923,371,0.344,372,1.119,373,1.383,379,1.091,382,1.945,388,1.201,389,0.978,390,0.525,391,0.978,393,1.575,394,2.031,395,0.995,399,0.833,404,0.757,409,2.125,412,1.359,413,0.457,416,2.115,420,0.481,422,0.509,427,1.252,429,0.319,431,1.553,433,0.847,440,1.304,442,2.332,445,0.509,446,0.87,447,0.915,448,0.305,449,0.945,450,1.502,453,1.683,454,1.012,456,0.427,459,0.644,462,0.437,464,2.181,467,0.709,471,0.469,477,0.662,488,0.394,493,1.324,496,0.852,502,0.651,505,1.636,515,3.202,523,2.577,525,0.764,534,0.481,537,0.561,540,1.918,548,2.268,549,2.022,550,1.531,551,1.094,559,0.509,560,0.373,562,0.525,564,0.458,567,0.41,570,1.295,571,0.427,576,0.673,579,0.394,580,0.922,584,0.494,586,2.439,587,0.734,589,1.119,590,0.922,591,1.198,597,1.342,605,0.586,608,0.333,617,1.841,620,1.092,623,1.965,633,0.367,636,0.692,638,1.096,639,0.41,641,0.893,651,0.297,654,0.721,657,0.41,661,1.642,667,0.86,668,0.447,674,0.897,676,0.662,684,0.961,685,0.355,687,0.543,689,0.394,706,0.937,708,0.437,709,0.41,710,0.586,718,1.421,724,0.814,726,0.586,728,0.305,735,1.228,738,0.457,739,2.244,740,0.481,750,0.394,752,1.74,762,0.394,764,0.494,765,0.41,770,0.644,773,0.9,781,0.897,789,0.509,792,0.402,795,0.293,796,1.26,799,1.078,802,0.367,808,0.721,810,0.525,811,2.293,812,0.644,813,3.28,814,3.28,815,1.434,816,2.577,817,1.73,818,0.979,819,1.014,820,0.586,821,1.26,822,0.586,823,1.142,824,1.276,825,1.276,826,0.922,827,1.142,828,1.971,829,3.54,830,1.82,831,1.604,832,2.496,833,3.432,834,0.738,835,2.372,836,1.377,837,0.738,838,0.738,839,1.142,840,2.011,841,1.377,842,0.738,843,0.402,844,0.738,845,0.833,846,1.466,847,0.738,848,0.494,849,1.377,850,2.577,851,0.738,852,0.457,853,0.738,854,0.644,855,0.738,856,1.201,857,0.631,858,1.35,859,1.377,860,4.825,861,1.198,862,0.833,863,0.749,864,1.276,865,0.525,866,2.268,867,0.738,868,0.612,869,2.011,870,0.738,871,2.248,872,4.932,873,1.998,874,2.984,875,2.836,876,1.276,877,1.377,878,1.142,879,2.984,880,0.469,881,0.543,882,1.421,883,0.814,884,2.268,885,0.644,886,1.421,887,0.509,888,2.298,889,0.586,890,0.644,891,0.457,892,0.494,893,0.418,894,0.979,895,0.387,896,1.474,897,1.375,898,0.738,899,0.796,900,3.599,901,1.276,902,0.738,903,1.934,904,1.934,905,3.249,906,0.586,907,0.447,908,0.644,909,0.738,910,0.738,911,0.738,912,3.337,913,0.644,914,0.738,915,0.738,916,1.377,917,0.525,918,0.387,919,0.721,920,0.833,921,0.738,922,0.738,923,1.377,924,1.276,925,0.738,926,0.738,927,0.692,928,0.979,929,0.543,930,1.143,931,1.228,932,2.062,933,0.525,934,0.738,935,1.049,936,0.543,937,2.621,938,4.183,939,0.738,940,0.644,941,1.421,942,4.097,943,0.738,944,0.509,945,0.543,946,0.543,947,3.41,948,1.276,949,0.738,950,0.738,951,1.377,952,2.431,953,0.525,954,0.738,955,0.738,956,0.612,957,0.738,958,0.586,959,1.768,960,0.644,961,0.586,962,1.375,963,1.69,964,0.738,965,0.509,966,0.684,967,2.033,968,0.874,969,0.796,970,0.437,971,0.543,972,1.623,973,1.377,974,1.377,975,1.377,976,0.644,977,1.848,978,0.738,979,0.738,980,2.86,981,0.979,982,0.509,983,0.328,984,0.738,985,0.494,986,0.738,987,0.738,988,1.377,989,1.092,990,1.092,991,1.142,992,0.738,993,0.738,994,0.644,995,1.793,996,0.738,997,0.738,998,2.836,999,0.738,1000,1.377,1001,1.474,1002,1.377,1003,0.735,1004,0.738,1005,1.228,1006,0.738,1007,0.738,1008,0.738,1009,0.738,1010,0.738,1011,0.738,1012,0.586,1013,0.738,1014,0.394,1015,0.738,1016,2.694,1017,0.543,1018,2.011,1019,0.437,1020,0.644,1021,0.738,1022,0.796,1023,0.644,1024,0.721,1025,1.276,1026,4.066,1027,2.248,1028,2.248,1029,0.897,1030,0.543,1031,1.377,1032,0.738,1033,0.874,1034,0.662,1035,1.276,1036,1.377,1037,3.012,1038,4.407,1039,5.039,1040,0.738,1041,0.469,1042,1.012,1043,0.979,1044,1.092,1045,1.276,1046,5.193,1047,1.276,1048,0.738,1049,1.276,1050,1.604,1051,0.945,1052,0.543,1053,1.276,1054,1.142,1055,0.738,1056,2.082,1057,0.738,1058,0.586,1059,0.543,1060,1.73,1061,0.586,1062,0.873,1063,0.543,1064,0.586,1065,1.703,1066,0.738,1067,3.28,1068,0.525,1069,1.201,1070,0.612,1071,4.066,1072,0.543,1073,5.38,1074,0.738,1075,0.525,1076,1.226,1077,0.738,1078,0.543,1079,0.543,1080,1.793,1081,1.377,1082,1.377,1083,1.934,1084,6.608,1085,0.525,1086,0.525,1087,0.738,1088,1.377,1089,0.427,1090,0.644,1091,1.377,1092,0.543,1093,1.143,1094,0.563,1095,0.979,1096,0.738,1097,4.202,1098,1.377,1099,0.738,1100,1.142,1101,0.543,1102,0.738,1103,0.738,1104,2.652,1105,0.543,1106,0.738,1107,0.738,1108,2.836,1109,0.738,1110,0.738,1111,1.092,1112,1.377,1113,1.377,1114,1.377,1115,0.738,1116,0.738,1117,1.793,1118,0.738,1119,1.377,1120,0.738,1121,1.377,1122,0.738,1123,1.377,1124,0.738,1125,0.738,1126,0.738,1127,0.738,1128,1.377,1129,2.116,1130,0.644,1131,0.738,1132,0.738,1133,0.738,1134,1.403,1135,0.738,1136,0.437,1137,0.738,1138,0.738,1139,0.738,1140,0.457,1141,0.563,1142,0.738,1143,0.738,1144,0.586,1145,0.644,1146,1.377,1147,0.525,1148,0.644,1149,1.142,1150,1.604,1151,1.688,1152,0.738,1153,0.644,1154,0.644,1155,0.543,1156,1.201,1157,0.738,1158,0.738,1159,0.738,1160,0.586,1161,0.738,1162,1.017,1163,0.738,1164,0.612,1165,0.747,1166,0.738,1167,1.934,1168,0.738,1169,0.586,1170,0.644,1171,0.738,1172,0.738,1173,0.738,1174,0.563,1175,1.049,1176,0.525,1177,0.586,1178,0.738,1179,0.738,1180,0.738,1181,0.738,1182,0.494,1183,0.738,1184,0.738,1185,0.738,1186,0.41,1187,1.276,1188,2.86,1189,1.295,1190,0.644,1191,0.481,1192,0.738,1193,1.377,1194,0.738,1195,1.276,1196,0.738,1197,1.375,1198,0.586,1199,0.509,1200,0.543,1201,1.092,1202,0.612,1203,3.249,1204,0.738,1205,0.738,1206,1.377,1207,0.738,1208,0.644,1209,0.738,1210,1.934,1211,0.644,1212,0.644,1213,1.934,1214,1.012,1215,0.563,1216,0.577,1217,0.402,1218,0.738,1219,0.543,1220,0.738,1221,0.457,1222,0.447,1223,0.644,1224,0.738,1225,0.457,1226,1.848,1227,0.738,1228,0.402,1229,0.738,1230,0.394,1231,0.738,1232,0.586,1233,0.738,1234,0.457,1235,0.738,1236,0.738,1237,0.644,1238,0.738,1239,0.738,1240,0.644,1241,0.738,1242,0.427,1243,0.738,1244,1.377,1245,0.525,1246,0.738,1247,0.543,1248,0.644,1249,0.738,1250,0.586,1251,0.738,1252,0.738,1253,0.738,1254,0.525,1255,1.092,1256,0.738,1257,0.586,1258,0.525,1259,0.644,1260,0.738,1261,0.644,1262,0.738,1263,0.897,1264,0.447,1265,0.586,1266,0.644,1267,0.644,1268,0.644,1269,0.949,1270,0.418,1271,1.092,1272,0.494,1273,0.738]],["title/Chap_11.html#aspects-of-estimation",[168,3.452,283,1.326]],["text/Chap_11.html#aspects-of-estimation",[1,1.863,2,1.085,11,0.435,19,1.696,34,0.84,39,1.76,48,2.29,50,3.239,84,3.116,99,0.716,105,1.473,120,2.692,138,1.825,142,0.627,153,1.385,158,2.434,169,1.351,184,2.644,260,3.026,276,2.692,280,3.844,283,2.263,286,2.294,311,1.718,321,2.162,329,3.109,330,2.74,335,2.296,337,1.277,344,3.336,358,2.069,371,2.434,373,1.848,389,2.644,394,1.297,409,1.605,416,1.828,446,1.4,453,1.871,493,1.164,502,2.473,549,2.47,576,2.556,684,2.599,685,2.514,706,2.021,735,3.32,739,2.792,752,2.324,811,2.257,812,4.564,813,3.844,814,3.844,815,4.083,816,4.147,817,3.163,818,3.718,819,2.741,820,4.147,821,3.407,822,4.147,823,4.337,824,4.849,825,4.849,826,3.501,827,4.337,828,3.604,829,5.476,830,3.909,831,5.725,832,4.564,833,5.175,834,5.23,835,4.337,836,6.904,837,5.23,838,5.23,839,4.337,840,4.337,841,6.904,842,5.23,843,2.846,844,5.23,845,4.176,846,3.163,847,5.23,848,3.501,849,6.904,850,4.147,851,5.23,852,3.239,853,5.23,854,4.564,855,5.23,856,6.026,857,2.396]],["title/Chap_11.html#maximum-likelihood-estimation",[283,1.124,739,2.267,850,3.367]],["text/Chap_11.html#maximum-likelihood-estimation",[2,1.182,6,1.71,11,0.42,34,0.96,50,3.701,53,2.415,59,2.221,95,2.011,105,1.275,138,2.086,148,2.738,169,1.169,188,2.697,196,3.191,259,1.404,283,2.409,287,2.542,305,2.437,322,3.786,329,2.404,337,1.279,339,3.805,358,1.6,359,2.279,372,3.458,393,3.027,394,2.043,399,3.615,431,3.554,453,2.138,493,1.676,597,1.419,739,4.018,770,5.215,811,3.554,818,4.248,827,4.956,846,3.615,850,5.968,858,2.594,859,7.525,860,5.784,861,3.701,862,3.615,863,3.253,864,5.541,865,4.248,866,6.532,867,5.976,868,4.956,869,4.956,870,5.976,871,5.541,872,5.215,873,3.317,874,6.24,875,7.188,876,5.541,877,7.525,878,4.956,879,6.24,880,3.793,881,4.392]],["title/Chap_11.html#example-estimating-the-poisson-rate",[105,0.786,283,0.976,764,2.467,882,2.709]],["text/Chap_11.html#example-estimating-the-poisson-rate",[2,0.702,6,1.776,11,0.436,34,0.718,84,2.015,91,1.236,99,1.218,105,1.323,120,2.299,138,1.559,142,0.854,169,0.874,195,2.079,198,1.772,211,1.797,247,2.99,259,1.049,264,3.252,270,2.192,272,5.24,282,3.078,283,1.888,321,1.847,322,2.717,337,1.361,346,2.835,348,1.901,349,3.542,351,3.898,352,3.542,355,1.412,356,1.607,358,1.196,359,2.366,370,4.921,394,2.008,395,3.193,412,0.903,431,1.927,449,2.183,450,1.503,493,0.995,515,6.781,540,1.821,571,2.584,579,2.385,584,2.99,597,1.061,641,0.893,651,1.797,687,3.283,738,2.766,739,3.313,740,2.91,799,1.985,811,1.927,813,3.283,814,3.283,828,3.078,830,2.259,831,3.704,850,3.542,858,1.54,860,5.852,869,3.704,871,6.61,872,8.073,874,5.912,875,5.415,882,4.56,883,2.641,884,3.542,885,3.898,886,4.023,887,3.078,888,3.956,889,3.542,890,3.898,891,2.766,892,2.99,893,2.53,894,3.175,895,2.341,896,3.404,897,3.175,898,4.466,899,2.584,900,8.593,901,4.141,902,4.466,903,7.13,904,7.13,905,8.378,906,3.542,907,2.701,908,3.898,909,4.466,910,4.466,911,4.466,912,7.768,913,3.898,914,4.466,915,4.466,916,6.205,917,3.175,918,2.341,919,2.341,920,2.701,921,4.466,922,4.466,923,6.205,924,4.141,925,4.466,926,4.466,927,1.598]],["title/Chap_11.html#but-is-it-a-good-estimate",[157,3.102,283,1.326]],["text/Chap_11.html#but-is-it-a-good-estimate",[2,0.64,6,1.665,7,3.366,11,0.421,19,1.402,25,1.154,31,1.618,34,0.655,35,2.19,37,2.729,39,2.737,40,1.515,48,1.785,53,1.308,57,2.809,59,2.162,66,1.575,68,1.992,88,1.928,95,1.958,99,0.796,120,2.994,127,2.134,139,2.358,142,0.813,157,2.524,158,1.897,169,0.798,184,2.061,196,3.107,211,3.147,259,1.367,270,2.614,271,2.465,281,2.625,283,2.511,295,2.358,298,3.925,318,1.803,321,2.406,322,2.548,324,4.027,325,1.889,327,2.886,332,1.477,335,1.934,337,1.149,339,2.061,342,2.358,346,3.693,354,2.061,355,1.78,358,1.816,359,1.554,394,2.077,412,0.824,440,1.477,442,3.766,445,2.809,450,1.372,453,2.081,462,2.41,488,2.177,493,0.908,540,3.017,550,2.475,570,4.542,586,3.51,589,2.358,590,2.729,591,2.524,597,1.611,605,1.734,617,2.309,623,4.732,710,3.233,718,4.986,726,3.233,773,3.158,796,4.419,799,2.586,811,2.928,813,4.276,814,4.276,817,3.519,819,2.136,829,3.233,835,3.38,840,3.38,860,3.603,869,3.38,873,3.23,927,1.458,928,4.136,929,2.996,930,2.41,931,3.693,932,3.693,933,2.898,934,4.076,935,4.434,936,2.996,937,4.542,938,5.962,939,4.076,940,3.557,941,2.996,942,5.392,943,4.076,944,2.809,945,2.996,946,2.996,947,3.823,948,3.779,949,4.076,950,4.076,951,5.818,952,3.366,953,2.898,954,4.076,955,4.076,956,3.38,957,4.076,958,3.233,959,3.692,960,3.557,961,3.233,962,4.822,963,1.64,964,4.076,965,2.809,966,2.892,967,2.898,968,2.587,969,2.358,970,2.41,971,2.996,972,2.729,973,5.818,974,5.818,975,5.818,976,3.557,977,5.17,978,4.076,979,4.076,980,7.823,981,2.898,982,2.809,983,1.812,984,4.076,985,2.729,986,4.076,987,4.076,988,5.818,989,4.614,990,4.614,991,3.38,992,4.076,993,4.076,994,3.557]],["title/Chap_11.html#estimating-the-mean",[19,0.949,283,1.326]],["text/Chap_11.html#estimating-the-mean",[1,1.851,6,1.47,11,0.434,19,1.451,34,0.825,35,1.52,37,2.066,39,2.578,105,1.095,106,1.648,110,1.884,127,1.884,136,2.038,167,3.713,169,1.005,211,2.744,240,1.573,256,1.837,259,1.603,283,2.45,286,2.348,289,2.216,296,1.815,311,2.241,318,2.114,326,4.225,329,2.066,335,2.714,337,1.384,355,1.168,358,1.375,366,2.643,372,2.971,373,2.41,379,1.958,391,2.597,393,2.066,394,2.107,442,2.851,453,1.837,493,1.143,537,2.094,540,3.124,551,3.078,586,2.944,597,1.22,724,3.036,752,3.882,811,2.216,813,5.63,828,4.701,832,6.685,833,5.688,932,3.26,937,4.567,942,4.701,947,3.989,952,3.947,959,3.713,963,3.081,967,4.849,972,3.438,995,6.325,996,5.135,997,5.135,998,4.482,999,5.135,1000,6.822,1001,5.199,1002,6.822,1003,2.742,1004,5.135,1005,4.33,1006,5.135,1007,5.135,1008,5.135,1009,5.135,1010,5.135,1011,5.135,1012,4.073]],["title/Chap_11.html#estimating-the-autocorrelation-function",[283,1.124,412,0.858,505,1.229]],["text/Chap_11.html#estimating-the-autocorrelation-function",[1,1.206,2,0.869,11,0.426,19,1.049,34,0.889,35,2.121,36,3.605,37,2.226,39,2.828,64,3.389,72,4.389,77,2.536,91,1.532,99,1.191,107,1.908,108,1.063,133,2.901,142,0.663,145,2.799,167,3.9,169,1.083,210,3.9,211,2.882,214,2.288,260,3.202,266,2.617,279,1.98,281,2.497,282,3.814,283,1.897,286,2.153,289,2.388,309,2.955,311,1.818,315,3.814,316,1.638,325,1.797,329,2.226,335,2.382,337,1.385,393,2.226,394,2.211,395,2.849,404,2.167,409,2.219,412,1.119,416,1.466,440,2.005,447,2.617,453,1.98,505,2.074,548,5.682,549,1.98,562,3.934,597,1.315,633,2.751,750,2.955,802,2.751,811,2.388,814,5.266,815,3.273,816,5.682,817,3.348,833,3.705,894,3.934,927,1.98,968,3.513,995,5.131,1013,5.535,1014,2.955,1015,5.535,1016,7.217,1017,4.068,1018,4.59,1019,3.273,1020,4.83,1021,5.535,1022,3.202,1023,4.83,1024,2.901,1025,5.131,1026,4.389,1027,5.131,1028,5.131,1029,3.605,1030,4.068]],["title/Chap_11.html#how-good-is-our-estimator",[157,3.102,283,1.326]],["text/Chap_11.html#how-good-is-our-estimator",[1,1.458,2,0.897,6,1.137,7,2.299,11,0.435,19,1.082,34,0.918,39,1.337,88,1.879,99,1.23,105,0.848,106,1.275,107,1.97,134,1.793,138,1.994,142,0.476,148,1.821,168,2.739,184,2.009,188,1.793,211,2.298,214,1.643,220,1.793,223,2.163,241,2.522,259,0.934,262,4.199,270,1.404,279,1.422,281,1.793,283,2.252,296,2.85,305,1.62,311,1.306,317,4.764,318,2.724,321,1.643,329,2.298,335,2.224,337,1.409,348,1.75,354,2.009,355,0.904,356,1.48,358,1.064,373,1.404,389,2.009,391,2.009,393,1.598,394,2,404,1.556,409,2.228,412,1.352,416,2.421,420,2.589,442,3.171,446,1.064,450,1.922,453,1.422,493,1.489,505,1.936,525,2.206,537,1.62,540,1.62,548,4.531,549,2.973,550,2.845,559,2.739,580,3.825,586,2.886,605,1.69,608,1.793,617,2.251,641,0.795,661,2.396,684,1.975,706,1.535,735,2.522,739,2.122,765,2.206,808,2.994,810,2.825,817,2.404,819,2.083,821,2.589,833,4.478,873,3.171,884,3.151,919,2.083,932,2.522,937,2.66,942,4.609,947,3.268,952,2.299,959,2.163,967,2.825,998,6.382,1026,6.59,1027,6.201,1028,6.201,1031,5.713,1032,3.974,1033,2.522,1034,1.91,1035,3.684,1036,5.713,1037,6.78,1038,6.688,1039,5.546,1040,3.974,1041,2.522,1042,4.199,1043,2.825,1044,3.151,1045,3.684,1046,6.6,1047,3.684,1048,3.974,1049,3.684,1050,4.737,1051,1.942,1052,2.921,1053,3.684,1054,3.295,1055,3.974,1056,2.299,1057,3.974,1058,3.151,1059,2.921]],["title/Chap_11.html#langevin-redux",[1060,2.407,1061,3.972]],["text/Chap_11.html#langevin-redux",[1,1.628,6,0.749,11,0.436,25,2.513,32,1.146,34,1.2,35,2.13,37,1.053,64,1.238,84,1.181,88,1.238,91,1.634,95,1.401,99,1.235,105,0.558,127,1.527,138,0.914,142,0.499,151,2.001,153,0.693,169,1.156,170,1.398,256,0.937,259,0.615,264,1.372,270,1.471,283,1.372,296,2.277,298,1.515,304,2.266,317,4.865,318,2.385,319,3.118,323,1.039,330,1.039,332,0.948,337,1.272,341,2.069,344,1.13,348,1.275,355,1.976,356,1.864,359,0.998,362,1.483,364,1.705,369,1.969,373,2.087,379,1.587,390,1.861,391,1.324,393,1.053,399,1.583,409,2.23,412,1.555,416,2.319,427,2.822,433,1.823,446,0.701,447,1.238,449,2.034,450,1.987,453,0.937,454,3.06,464,3.484,467,1.347,493,0.583,505,1.5,523,5.443,525,1.453,550,1.114,560,1.324,589,2.408,590,1.753,591,2.578,597,0.622,617,3.346,638,2.936,641,0.523,661,2.476,708,1.548,724,1.548,728,1.082,811,1.13,829,5.111,835,3.452,846,1.583,884,2.076,888,1.279,924,2.427,947,1.279,952,1.515,969,1.515,972,1.753,1018,4.297,1039,6.54,1046,6.242,1049,2.427,1051,1.279,1056,3.729,1060,2.839,1062,2.339,1063,1.924,1064,2.076,1065,3.095,1066,2.618,1067,5.656,1068,1.861,1069,3.633,1070,2.171,1071,5.159,1072,1.924,1073,7.981,1074,2.618,1075,1.861,1076,2.105,1077,2.618,1078,1.924,1079,1.924,1080,3.86,1081,4.163,1082,4.163,1083,5.182,1084,8.478,1085,1.861,1086,1.861,1087,2.618,1088,4.163,1089,1.515,1090,2.285,1091,4.163,1092,1.924,1093,2.462,1094,1.995,1095,2.959,1096,2.618,1097,7.695,1098,4.163,1099,2.618,1100,3.452,1101,1.924,1102,2.618,1103,2.618,1104,5.475,1105,1.924,1106,2.618,1107,2.618,1108,5.99,1109,2.618,1110,2.618,1111,3.301,1112,4.163,1113,4.163,1114,4.163,1115,2.618,1116,2.618,1117,3.86,1118,2.618,1119,4.163,1120,2.618,1121,4.163,1122,2.618,1123,4.163,1124,2.618,1125,2.618,1126,2.618,1127,2.618,1128,4.163,1129,5.154,1130,2.285,1131,2.618,1132,2.618,1133,2.618,1134,1.515,1135,2.618,1136,1.548,1137,2.618,1138,2.618,1139,2.618,1140,1.621,1141,1.995]],["title/Chap_11.html#trouble-in-paradise",[1142,5.008,1143,5.008]],["text/Chap_11.html#trouble-in-paradise",[1,1.447,11,0.419,19,0.934,34,1.387,59,1.832,99,1.277,105,1.052,106,1.582,108,0.732,110,1.809,126,2.915,138,2.317,142,0.591,148,2.259,153,1.306,167,2.684,253,2.097,259,1.159,266,2.332,271,2.982,276,2.538,283,2.453,318,2.326,323,1.957,325,2.156,326,3.053,329,1.983,335,1.639,337,1.37,339,3.357,348,1.51,356,1.277,359,1.88,372,2.853,389,2.493,393,1.983,394,2.225,404,1.93,409,2.169,412,1.517,416,1.758,442,2.737,446,1.32,453,1.764,493,1.098,505,1.921,540,2.707,548,3.91,549,2.685,551,2.996,564,1.639,567,2.737,587,1.493,620,5.265,636,1.764,674,4.325,684,2.451,735,3.13,811,2.128,813,3.624,814,4.879,816,3.91,826,3.301,832,4.303,833,3.301,931,3.13,932,4.214,938,6.387,941,4.879,942,3.398,947,4.095,952,3.841,967,3.505,998,4.303,1016,4.089,1022,2.853,1025,4.571,1026,6.646,1033,3.13,1046,5.72,1047,4.571,1050,4.089,1053,4.571,1054,4.089,1144,3.91,1145,4.303,1146,6.639,1147,3.505,1148,4.303,1149,5.505,1150,6.224,1151,6.55,1152,4.931,1153,4.303,1154,4.303,1155,3.624,1156,5.794,1157,4.931,1158,4.931,1159,4.931,1160,3.91,1161,4.931,1162,2.068,1163,4.931,1164,4.089,1165,1.905,1166,4.931]],["title/Chap_11.html#problems",[142,0.731]],["text/Chap_11.html#problems",[]],["title/Chap_11.html#problem-111",[142,0.6,813,3.681]],["text/Chap_11.html#problem-111",[99,1.011,259,2.01,270,2.61,337,1.147,355,1.681,363,3.802,370,6.784,382,3.84,412,1.493,493,1.645,912,6.849,1029,4.812,1056,4.274,1167,9.029]],["title/Chap_11.html#problem-112",[142,0.6,814,3.681]],["text/Chap_11.html#problem-112",[11,0.391,25,2.007,39,2.387,99,0.971,240,2.173,283,1.878,288,2.892,305,2.892,332,2.57,337,1.379,382,2.933,394,1.759,412,1.434,453,2.538,493,1.86,587,2.148,639,3.937,676,3.409,739,3.787,762,3.787,830,4.224,850,5.625,858,2.445,866,5.625,963,3.571,1168,7.093,1169,5.625,1170,6.19,1171,7.093]],["title/Chap_11.html#problem-113",[142,0.6,816,3.972]],["text/Chap_11.html#problem-113",[11,0.318,44,5.132,48,3.161,169,1.413,185,4.269,211,2.904,240,2.211,283,1.912,291,4.09,319,2.52,394,2.093,641,1.688,654,3.784,858,2.489,861,5.227,862,4.366,863,3.929,864,6.693,874,5.986,883,4.269,899,4.177,1172,7.219,1173,7.219,1174,5.501,1175,6.432,1176,5.132]],["title/Chap_11.html#problem-114",[142,0.6,829,3.972]],["text/Chap_11.html#problem-114",[11,0.407,19,1.289,34,1.093,39,2.29,99,0.931,114,3.325,240,2.085,253,2.894,283,1.802,322,2.98,325,2.21,337,1.355,355,1.548,393,2.737,412,1.375,448,2.814,450,2.743,493,1.815,496,4.214,587,2.061,641,1.63,668,4.116,839,5.643,840,5.643,858,2.346,866,5.397,874,5.643,875,5.939,878,5.643,888,4.518,896,6.211,897,5.793,1177,5.397,1178,6.805,1179,6.805,1180,6.805,1181,6.805,1182,4.556,1183,6.805]],["title/Chap_11.html#problem-115",[142,0.6,835,4.153]],["text/Chap_11.html#problem-115",[11,0.415,19,1.633,99,1.179,105,1.411,106,2.123,169,1.295,259,1.554,270,2.337,283,2.429,303,4.862,324,4.361,326,4.097,327,3.408,332,3.122,335,2.664,337,1.391,342,3.827,354,3.345,355,1.505,362,3.748,363,3.405,493,1.473,586,2.855,597,1.903,938,6.992,942,5.522,981,4.702,1162,2.774,1184,6.615,1185,6.615,1186,3.672,1187,6.133,1188,9.175,1189,4.429]],["title/Chap_11.html#problem-116",[142,0.6,840,4.153]],["text/Chap_11.html#problem-116",[2,0.98,11,0.418,19,1.591,25,1.765,34,1.242,59,2.318,99,1.058,142,0.747,157,3.863,256,2.232,259,1.466,270,2.204,283,2.224,324,3.395,326,3.863,327,2.653,332,2.8,335,2.919,337,1.402,368,4.675,379,2.379,431,2.692,440,2.8,453,2.232,586,2.692,597,1.836,641,1.247,811,2.692,846,3.773,860,6.037,879,7.483,937,4.176,947,3.777,1001,4.754,1024,3.27,1034,2.998,1187,5.784,1189,4.176,1190,5.444,1191,4.064,1192,6.238,1193,7.729,1194,6.238,1195,5.784,1196,6.238,1197,4.434,1198,4.947]],["title/Chap_11.html#problem-117",[142,0.6,869,4.153]],["text/Chap_11.html#problem-117",[1,1.518,2,1.094,6,1.993,11,0.431,19,1.474,25,2.201,34,1.443,39,2.343,77,2.428,84,2.391,99,0.953,106,1.7,110,1.944,114,2.589,142,0.932,169,1.363,240,1.623,256,1.895,259,1.828,283,2.441,287,2.253,291,3.001,298,3.065,311,1.741,323,2.102,324,2.883,327,2.962,332,1.919,338,4.201,339,2.679,346,4.42,354,3.521,355,1.584,369,2.505,379,2.02,382,3.549,394,1.929,409,1.808,431,3.005,440,2.523,442,2.941,586,3.357,597,1.848,676,2.546,706,2.047,709,2.941,799,2.355,828,3.651,829,4.201,830,2.679,872,6.077,920,3.204,937,3.547,942,5.915,947,4.305,948,4.912,963,2.801,1005,3.363,1051,2.589,1093,3.132,1162,2.92,1195,4.912,1199,3.651,1200,3.894,1201,5.522,1202,4.393,1203,8.811,1204,5.298,1205,5.298,1206,6.964,1207,5.298,1208,4.623,1209,5.298,1210,7.779,1211,4.623,1212,4.623,1213,7.779,1214,3.894,1215,4.037,1216,2.221]],["title/Chap_11.html#problem-118",[142,0.6,876,4.643]],["text/Chap_11.html#problem-118",[11,0.427,19,1.505,91,1.806,95,2.195,107,2.249,108,0.968,153,1.728,240,1.999,259,2.013,264,3.419,286,2.411,287,2.775,291,3.696,305,2.66,324,3.551,327,2.775,342,3.774,355,1.949,366,3.358,388,6.934,394,2.267,409,1.517,416,2.104,446,1.747,447,3.085,459,5.694,493,1.453,505,1.888,549,2.334,641,1.305,667,3.808,752,2.9,795,2.589,815,3.858,1076,3.299,1217,3.551,1218,6.524,1219,4.795,1220,6.524,1221,4.04,1222,3.946,1223,5.694]],["title/Chap_11.html#problem-119",[142,0.6,884,3.972]],["text/Chap_11.html#problem-119",[2,0.838,11,0.434,33,3.088,34,1.254,48,2.337,68,2.608,91,1.937,99,0.73,101,1.775,107,1.84,114,2.608,133,2.797,138,2.725,139,4.049,169,1.369,240,2.144,259,1.254,283,1.853,291,3.024,293,3.388,296,2.928,304,2.905,305,2.176,317,5.086,318,2.736,319,1.863,337,1.087,348,1.635,356,1.383,382,2.207,394,1.324,409,2.052,412,1.578,413,3.305,416,2.338,429,2.303,433,2.337,440,1.934,477,2.565,502,2.524,505,2.259,549,2.504,550,2.27,564,1.775,576,2.608,587,1.616,597,1.268,636,1.91,654,2.797,657,2.963,661,2.238,689,2.85,706,2.062,739,2.85,821,3.477,857,2.446,947,3.42,972,3.573,991,4.426,1035,4.949,1037,6.488,1038,7.569,1039,6.872,1045,4.949,1046,5.333,1060,3.364,1065,3.668,1067,3.923,1071,2.963,1076,2.699,1134,4.517,1197,4.974,1224,5.337,1225,3.305,1226,6.315,1227,5.337,1228,2.905,1229,5.337,1230,2.85,1231,5.337,1232,4.233,1233,5.337,1234,3.305]],["title/Chap_11.html#problem-1110",[142,0.6,901,4.643]],["text/Chap_11.html#problem-1110",[2,1.111,11,0.417,25,2.002,34,1.137,99,0.968,142,0.848,270,2.5,296,2.5,298,4.093,319,2.469,355,1.61,409,2.062,416,2.209,464,3.01,661,2.967,884,5.611,1039,6.917,1071,3.928,1073,6.56,1080,6.56,1084,8.493,1104,6.56,1117,6.56,1165,2.734,1189,4.737,1235,7.076]],["title/Chap_11.html#laboratory-exercises",[47,1.646,143,1.256]],["text/Chap_11.html#laboratory-exercises",[]],["title/Chap_11.html#laboratory-exercise-111",[47,1.395,143,1.065,813,3.121]],["text/Chap_11.html#laboratory-exercise-111",[19,1.625,99,1.016,123,2.832,142,0.89,143,1.862,155,3.159,247,4.972,256,2.657,275,5.889,281,3.872,283,1.966,316,2.198,358,2.297,456,4.296,1003,3.965,1236,7.426]],["title/Chap_11.html#laboratory-exercise-112",[47,1.395,143,1.065,814,3.121]],["text/Chap_11.html#laboratory-exercise-112",[99,1.03,123,2.869,143,2.168,155,3.2,279,2.692,316,2.227,623,4.551,873,4.799,930,5.112,977,5.734,1216,3.155]],["title/Chap_11.html#laboratory-exercise-113",[47,1.395,143,1.065,816,3.367]],["text/Chap_11.html#laboratory-exercise-113",[1,1.333,2,0.961,11,0.395,39,2.059,68,2.989,99,0.837,100,2.989,123,2.333,143,1.534,148,2.803,155,2.602,198,3.03,216,2.989,220,2.76,232,4.077,233,5.339,254,5.339,283,2.022,289,3.295,311,2.01,316,1.811,319,2.665,322,2.679,344,2.64,422,4.216,442,3.396,446,1.638,467,3.149,471,3.883,477,2.94,496,3.788,505,1.77,534,3.985,636,2.189,641,1.223,781,4.974,789,4.216,792,3.33,811,2.64,823,5.073,824,5.672,825,5.672,858,2.633,952,3.539,1043,4.349,1044,4.851,1165,2.364,1214,4.496,1237,5.339,1238,6.118,1239,6.118,1240,5.339,1241,6.118,1242,3.539,1243,6.118,1244,7.636,1245,4.349,1246,6.118,1247,4.496,1248,5.339,1249,6.118,1250,4.851,1251,6.118,1252,6.118,1253,6.118,1254,4.349,1255,6.056,1256,6.118,1257,4.851,1258,4.349,1259,5.339,1260,6.118,1261,5.339,1262,6.118,1263,4.974,1264,3.7,1265,4.851,1266,5.339,1267,5.339,1268,5.339,1269,5.263,1270,3.466,1271,6.056,1272,4.096,1273,6.118]],["title/Chap_12.html",[283,1.124,636,1.519,1274,3.521]],["text/Chap_12.html",[1,1.668,2,0.988,6,1.059,11,0.434,13,0.905,16,0.611,18,0.675,19,0.771,25,0.795,31,1.864,32,1.23,33,0.513,34,1.122,35,1.861,37,1.321,39,2.116,40,0.606,47,1.446,53,0.901,59,0.841,64,1.07,65,0.783,66,0.875,68,0.797,71,1.293,76,1.062,77,0.406,78,0.456,84,0.736,87,0.593,88,0.771,90,2.936,91,0.909,95,0.549,99,1.063,101,2.583,105,0.79,106,0.726,107,0.306,108,0.863,110,0.598,111,0.4,117,1.293,120,0.456,121,0.593,122,0.905,123,1.071,127,1.358,130,2.503,133,0.464,134,0.4,136,1.303,138,1.292,139,0.513,142,0.697,143,1.305,145,1.145,146,0.675,147,0.986,148,1.037,151,1.35,153,0.744,155,1.195,157,2.034,167,1.529,168,0.611,169,0.319,188,1.021,195,0.412,196,0.473,198,1.115,210,0.887,211,0.656,213,1.369,214,0.674,216,0.433,220,1.021,223,0.887,229,0.703,232,0.473,235,0.651,240,0.861,241,1.035,242,0.549,244,0.524,250,1.699,252,0.773,253,0.377,255,1.5,256,1.005,259,1.223,260,0.513,262,0.651,269,0.841,270,1.161,271,1.987,273,0.473,274,2.199,276,1.446,279,1.324,280,0.651,283,2.224,285,0.451,286,0.227,288,1.339,296,0.8,298,0.513,303,0.651,304,1.232,305,0.361,309,0.473,310,0.412,311,1.71,316,0.832,318,1.744,319,2.088,321,1.942,322,0.714,323,1.115,325,1.322,326,1.74,329,1.489,330,0.898,332,2.039,335,2.254,337,1.373,338,0.703,339,1.872,341,1.125,342,0.513,343,0.943,344,0.977,345,0.651,346,1.783,348,0.861,354,0.448,355,1.129,356,1.14,358,0.752,359,0.622,362,0.502,363,0.456,366,1.446,367,1.145,368,1.369,369,1.07,371,0.412,372,0.513,373,0.993,374,0.536,378,0.4,379,1.553,383,0.839,384,3.047,387,1.661,389,1.421,391,0.448,393,0.356,394,2.11,395,0.456,399,0.536,404,0.347,409,1.939,412,0.949,416,1.244,420,1.474,427,0.714,429,1.212,432,1.579,433,0.991,436,0.735,440,0.321,442,1.256,443,0.492,445,0.611,446,1.394,447,0.419,448,1.684,449,1.373,450,1.37,452,1.783,453,2.25,456,0.943,457,0.502,458,0.651,460,0.773,462,0.524,464,1.872,465,0.773,467,0.839,468,0.606,469,1.31,471,0.562,477,0.426,486,0.577,487,2.467,493,0.907,496,1.009,499,0.964,500,0.854,501,1.162,502,2.904,505,0.472,518,0.651,528,1.691,537,1.146,540,1.795,545,0.651,549,1.005,550,1.397,551,1.021,559,0.611,560,0.824,561,2.082,564,1.562,567,0.492,572,0.549,574,2.807,576,2.151,579,1.5,583,1.977,585,0.593,586,0.382,587,1.333,588,1.035,589,0.943,591,1.009,594,0.549,596,0.63,597,0.21,600,3.538,601,0.513,605,0.377,607,0.524,616,0.773,617,0.502,619,0.651,621,0.63,626,1.115,633,1.125,636,2.591,637,0.923,638,1.282,639,1.559,641,1.31,650,0.651,651,1.489,654,0.464,657,0.492,661,0.949,666,0.482,668,1.369,671,0.773,674,0.577,675,0.448,676,2.705,677,0.593,678,1.83,685,0.783,689,1.754,706,1.269,709,0.905,728,0.366,729,0.536,731,0.549,754,0.773,755,0.773,756,0.549,758,0.651,761,1.119,762,0.87,773,0.412,775,0.577,776,1.423,784,1.515,792,0.482,795,0.352,799,0.725,801,0.87,802,0.44,808,0.854,817,0.536,819,1.721,821,0.577,826,1.091,827,0.735,828,0.611,833,3.485,843,0.887,845,0.536,848,0.593,852,0.549,856,0.773,857,0.406,858,0.306,863,0.482,873,0.905,881,0.651,886,0.81,892,1.091,894,2.632,895,4.796,906,0.703,907,1.369,917,0.63,918,0.464,919,0.854,927,0.317,932,1.437,935,1.242,936,0.651,937,3.485,938,3.103,941,1.198,942,1.56,944,1.123,947,1.106,952,3.012,958,0.703,959,2.015,962,1.159,963,1.997,966,0.81,967,0.63,968,2.35,970,0.524,971,2.065,972,0.593,977,0.675,981,0.63,982,0.611,983,1.645,985,1.881,989,0.703,1001,2.141,1003,0.473,1014,1.977,1016,0.735,1019,3.209,1020,0.773,1024,1.94,1026,2.605,1033,0.562,1034,0.783,1041,0.562,1043,4.132,1044,1.795,1051,1.106,1056,1.625,1059,1.198,1078,0.651,1089,0.943,1092,0.651,1093,1.338,1101,2.065,1111,2.228,1136,0.964,1144,1.293,1148,0.773,1149,3.376,1150,1.352,1151,1.423,1153,0.773,1155,0.651,1156,1.975,1162,1.846,1164,1.877,1165,1.085,1186,0.905,1189,0.593,1215,2.503,1216,1.377,1219,1.198,1221,0.549,1228,0.482,1232,0.703,1234,1.009,1237,1.423,1242,1.9,1259,0.773,1263,1.062,1264,0.536,1265,0.703,1266,0.773,1267,0.773,1268,0.773,1269,0.611,1272,0.593,1274,0.735,1275,1.293,1276,0.773,1277,0.577,1278,0.773,1279,0.886,1280,1.74,1281,5.53,1282,0.886,1283,1.159,1284,0.773,1285,0.773,1286,4.136,1287,0.886,1288,0.735,1289,0.964,1290,0.886,1291,0.886,1292,4.514,1293,3.437,1294,0.773,1295,2.936,1296,0.886,1297,3.895,1298,1.511,1299,2.821,1300,0.886,1301,0.886,1302,2.33,1303,0.773,1304,0.735,1305,3.231,1306,3.376,1307,1.423,1308,0.886,1309,2.263,1310,0.839,1311,0.886,1312,0.886,1313,4.099,1314,3.045,1315,1.035,1316,0.651,1317,3.354,1318,0.886,1319,0.886,1320,0.886,1321,0.886,1322,1.159,1323,2.452,1324,0.886,1325,2.263,1326,1.293,1327,0.886,1328,1.123,1329,2.724,1330,3.452,1331,0.886,1332,2.809,1333,0.611,1334,2.866,1335,3.285,1336,2.099,1337,4.072,1338,1.209,1339,0.886,1340,0.886,1341,2.141,1342,1.725,1343,1.795,1344,3.047,1345,1.511,1346,4.912,1347,1.515,1348,0.773,1349,2.661,1350,2.866,1351,1.664,1352,1.198,1353,1.091,1354,1.511,1355,1.242,1356,2.452,1357,1.511,1358,0.886,1359,1.511,1360,0.886,1361,0.886,1362,1.293,1363,1.63,1364,0.886,1365,4.43,1366,2.551,1367,2.099,1368,1.352,1369,1.511,1370,0.886,1371,0.886,1372,0.886,1373,0.886,1374,0.502,1375,0.886,1376,0.735,1377,1.198,1378,0.675,1379,0.886,1380,0.886,1381,0.886,1382,0.886,1383,0.886,1384,0.651,1385,0.886,1386,0.886,1387,1.293,1388,0.773,1389,1.725,1390,0.886,1391,0.886,1392,0.886,1393,0.886,1394,1.293,1395,0.886,1396,0.886,1397,1.63,1398,0.886,1399,0.886,1400,0.886,1401,1.63,1402,0.886,1403,0.886,1404,0.886,1405,2.809,1406,2.809,1407,2.809,1408,0.886,1409,0.886,1410,2.809,1411,2.809,1412,0.886,1413,0.886,1414,1.63,1415,1.63,1416,1.63,1417,0.886,1418,1.159,1419,0.773,1420,0.886,1421,0.886,1422,1.123,1423,0.773,1424,0.886,1425,0.773,1426,0.886,1427,0.675,1428,0.773,1429,0.651,1430,2.605,1431,2.452,1432,2.099,1433,2.452,1434,2.452,1435,3.354,1436,0.593,1437,3.988,1438,0.886,1439,1.511,1440,1.511,1441,0.886,1442,0.773,1443,0.651,1444,2.605,1445,0.773,1446,0.886,1447,1.511,1448,1.63,1449,1.63,1450,1.63,1451,1.63,1452,3.235,1453,0.886,1454,0.675,1455,0.773,1456,1.423,1457,0.886,1458,2.263,1459,1.63,1460,0.886,1461,0.886,1462,0.886,1463,1.725,1464,2.263,1465,0.703,1466,0.675,1467,1.975,1468,3.553,1469,1.63,1470,0.923,1471,0.886,1472,1.423,1473,0.886,1474,1.63,1475,0.773,1476,1.293,1477,0.886,1478,0.524,1479,1.352,1480,3.045,1481,0.886,1482,1.159,1483,0.549,1484,1.035,1485,1.63,1486,2.141,1487,1.352,1488,3.648,1489,0.886,1490,0.886,1491,0.886,1492,0.886,1493,0.886,1494,0.886,1495,0.886,1496,0.886,1497,0.886,1498,0.886,1499,0.886,1500,0.886,1501,0.886,1502,0.886,1503,0.886,1504,0.886,1505,0.886,1506,0.886,1507,0.886,1508,0.886,1509,0.886,1510,0.886,1511,0.886,1512,0.886,1513,0.513,1514,0.651,1515,0.964,1516,0.886,1517,0.886,1518,0.886,1519,0.886,1520,0.773,1521,0.675,1522,0.773,1523,0.886,1524,0.63,1525,0.886,1526,0.886,1527,0.886,1528,0.773,1529,0.886,1530,0.886,1531,0.886,1532,0.886,1533,0.735,1534,0.886,1535,2.263,1536,0.923,1537,0.886,1538,0.886,1539,0.886,1540,0.63,1541,1.63,1542,0.886,1543,0.886,1544,1.352,1545,0.703,1546,0.886,1547,2.263,1548,3.702,1549,1.423,1550,1.423,1551,0.886,1552,0.886,1553,0.886,1554,2.263,1555,0.886,1556,0.886,1557,2.228,1558,1.63,1559,1.63,1560,0.886,1561,0.773,1562,0.886,1563,0.773,1564,0.773,1565,0.773,1566,0.773,1567,0.703,1568,0.703,1569,0.886,1570,0.773,1571,1.63,1572,0.886,1573,0.886,1574,0.886,1575,0.886,1576,2.263,1577,0.63,1578,0.773,1579,0.703,1580,0.611,1581,0.773,1582,0.886,1583,0.886,1584,0.886,1585,0.886,1586,0.886,1587,0.703,1588,0.703,1589,0.886,1590,0.886,1591,1.293,1592,0.773]],["title/Chap_12.html#spectral-estimation",[283,1.326,636,1.792]],["text/Chap_12.html#spectral-estimation",[1,1.563,2,1.127,11,0.431,19,1.051,25,1.569,32,2.428,34,1.153,35,1.642,101,2.385,105,1.183,108,1.065,111,2.502,138,2.776,142,0.86,153,1.468,169,1.085,213,3.354,223,3.018,262,4.076,283,2.362,286,1.421,310,2.581,311,1.822,329,2.23,332,2.009,337,1.114,343,3.208,344,2.393,367,2.804,384,2.906,395,2.854,404,2.171,409,1.289,412,1.45,416,1.9,458,4.076,460,4.839,465,4.839,468,2.061,493,1.235,502,3.393,505,2.076,545,4.076,549,1.984,564,2.896,574,2.2,576,3.506,585,3.713,587,2.547,597,1.317,636,3.116,657,3.078,706,2.143,808,2.906,833,3.713,873,3.078,935,4.226,937,3.713,938,6.06,947,2.71,952,3.208,1051,2.71,1089,3.208,1148,4.839,1149,6.595,1186,3.078,1228,3.018,1275,5.69,1276,4.839,1277,3.612,1278,4.839,1279,5.545,1280,3.434,1281,6.973,1282,5.545,1283,5.1,1284,4.839,1285,4.839,1286,4.076,1287,5.545,1288,4.598,1289,3.279,1290,5.545,1291,5.545,1292,4.076,1293,3.279,1294,4.839,1295,4.398,1296,5.545]],["title/Chap_12.html#the-periodogram-unbiased",[11,0.187,942,2.926,1297,3.521]],["text/Chap_12.html#the-periodogram-unbiased",[1,1.955,6,1.125,11,0.435,13,2.182,34,1.331,40,1.46,64,1.859,84,1.773,91,1.088,99,0.996,106,1.261,120,2.023,133,2.06,148,1.801,153,1.041,157,3.51,195,1.829,198,1.559,241,2.495,250,2.377,253,1.672,256,1.406,260,2.274,270,1.389,279,2.028,283,2.322,296,2.349,318,2.49,321,1.625,323,1.559,330,2.637,332,2.911,335,2.872,337,1.406,339,1.987,341,1.953,343,2.274,348,2.036,355,0.894,356,1.722,362,2.226,373,2.002,379,1.499,384,4.653,389,1.987,394,0.975,409,2.188,416,2.193,420,3.692,429,2.446,433,2.482,440,1.424,447,1.859,450,1.907,453,1.406,464,3.095,493,0.875,502,4.009,518,2.888,528,2.917,549,2.378,550,1.672,551,1.773,560,1.987,564,1.307,576,2.769,586,1.696,587,1.19,616,3.43,636,2.028,689,2.098,801,2.098,817,2.377,819,2.97,833,5.87,907,3.428,918,2.06,937,4.45,938,5.544,941,2.888,942,3.906,952,2.274,962,2.794,968,4.896,1024,2.06,1026,6.117,1089,2.274,1149,6.033,1150,3.259,1151,4.946,1153,3.43,1155,2.888,1156,5.801,1216,1.648,1280,2.434,1281,6.663,1293,5.25,1297,5.512,1298,3.644,1299,2.995,1300,3.93,1301,3.93,1302,3.259,1303,3.43,1304,3.259,1305,4.946,1306,6.396,1307,4.946,1308,3.93,1309,6.647,1310,2.023,1311,3.93,1312,3.93,1313,5.801,1314,6.745,1315,2.495,1316,2.888]],["title/Chap_12.html#windowed-observations",[449,2.447,895,2.625]],["text/Chap_12.html#windowed-observations",[1,1.374,2,0.832,6,1.026,11,0.435,13,1.989,25,1.014,31,1.422,34,1.194,35,1.568,40,1.332,66,1.385,76,3.451,90,4.202,99,1.155,101,2.747,105,0.764,106,1.15,136,1.422,145,2.679,151,1.722,153,0.949,167,2.884,169,0.701,235,2.634,242,2.219,270,1.266,271,3.204,283,1.844,318,2.303,323,1.422,325,2.047,335,2.587,337,1.439,344,1.546,356,1.373,369,2.506,372,2.073,378,1.617,383,2.727,384,2.777,387,4.118,389,1.812,394,2.129,399,2.167,409,1.871,412,1.071,420,2.334,432,1.722,446,1.864,449,2.589,453,2.491,462,2.119,468,1.332,487,3.133,493,1.403,499,3.133,502,3.293,528,1.844,537,1.461,561,2.222,564,1.192,574,3.194,576,2.589,583,3.366,587,1.085,596,2.547,600,3.727,605,1.524,617,2.03,619,2.634,626,2.102,633,2.633,636,2.491,638,2.03,641,0.717,651,2.535,706,2.047,729,2.167,762,1.914,773,1.668,895,4.855,935,2.731,937,3.547,944,2.47,958,2.842,959,1.95,985,4.22,1003,1.914,1019,4.6,1024,2.777,1034,1.722,1043,3.766,1056,3.065,1059,3.894,1150,2.972,1162,2.643,1164,4.393,1165,2.047,1242,3.647,1281,5.775,1286,5.118,1293,3.133,1305,3.127,1306,4.393,1313,6.077,1314,3.322,1317,2.731,1318,3.584,1319,3.584,1320,3.584,1321,3.584,1322,2.547,1323,4.624,1324,3.584,1325,6.303,1326,4.202,1327,3.584,1328,3.651,1329,4.393,1330,3.894,1331,3.584,1332,6.964,1333,2.47,1334,4.624,1335,7.431,1336,4.912,1337,8.048,1338,2.829,1339,3.584,1340,3.584,1341,2.731,1342,4.037,1343,2.842,1344,3.304,1345,3.322,1346,7.364,1347,2.399,1348,3.127,1349,2.03,1350,3.127,1351,2.634,1352,2.634,1353,2.399,1354,3.322,1355,2.731,1356,4.624,1357,3.322,1358,3.584,1359,3.322,1360,3.584,1361,3.584,1362,4.202,1363,5.298,1364,3.584,1365,2.731,1366,3.651,1367,4.912,1368,2.972,1369,3.322,1370,3.584]],["title/Chap_12.html#the-periodogram-what-about-convergence",[11,0.187,952,2.457,1297,3.521]],["text/Chap_12.html#the-periodogram-what-about-convergence",[1,1.285,2,0.503,6,0.917,11,0.433,19,0.923,25,1.379,31,1.272,34,0.783,35,2.208,37,1.96,39,2.754,64,2.304,65,1.54,87,2.145,88,1.515,91,0.887,99,0.667,101,2.355,105,1.039,108,0.476,110,1.787,127,1.176,142,0.706,145,1.62,148,1.468,151,1.54,153,0.849,157,3.017,167,2.652,188,1.446,196,1.711,211,1.289,213,1.938,220,2.198,223,1.744,241,2.034,255,1.711,256,2.109,259,1.547,270,1.132,274,2.145,276,1.649,279,1.743,283,2.426,285,0.887,288,1.307,298,1.854,304,2.652,311,2.451,318,1.51,319,3.002,323,1.272,326,3.65,329,1.289,335,2.48,337,1.399,339,3.33,344,1.383,354,1.62,356,1.262,358,1.304,359,1.222,363,1.649,366,2.508,379,2.248,389,1.62,391,1.62,393,1.289,394,2.293,409,2.13,427,2.133,429,1.383,442,1.779,443,1.779,453,2.109,456,2.819,467,1.649,469,2.819,486,2.087,493,0.713,502,2.304,528,1.649,537,1.307,540,2.404,551,2.198,560,1.62,561,1.344,564,1.065,574,2.96,579,3.516,587,0.97,588,3.092,589,2.819,600,4.725,633,1.593,636,2.534,651,1.289,671,2.796,674,2.087,675,1.62,676,1.54,706,1.882,775,2.087,776,4.252,799,1.424,808,1.679,819,3.089,821,2.087,828,2.208,892,3.262,927,1.146,932,3.741,937,4.742,941,2.355,944,2.208,947,2.381,952,4.623,959,3.584,962,2.278,963,2.371,966,1.593,967,2.278,970,1.895,972,2.145,981,2.278,983,2.62,1001,5.018,1016,2.657,1041,2.034,1043,5.512,1044,3.864,1111,5.222,1136,1.895,1164,2.657,1186,1.779,1219,3.581,1242,1.854,1281,6.186,1292,5.483,1295,3.864,1297,5.461,1313,4.252,1349,2.76,1351,3.581,1368,2.657,1371,3.204,1372,3.204,1373,3.204,1374,1.815,1375,3.204,1376,2.657,1377,3.581,1378,2.442,1379,3.204,1380,3.204,1381,3.204,1382,3.204,1383,3.204,1384,2.355,1385,3.204,1386,3.204,1387,3.864,1388,2.796,1389,2.442,1390,3.204,1391,3.204,1392,3.204,1393,3.204,1394,2.541,1395,3.204,1396,3.204,1397,4.872,1398,3.204,1399,3.204,1400,3.204,1401,4.872,1402,3.204,1403,3.204,1404,3.204,1405,6.585,1406,6.585,1407,6.585,1408,3.204,1409,3.204,1410,6.585,1411,6.585,1412,3.204,1413,3.204,1414,4.872,1415,4.872,1416,4.872,1417,3.204,1418,2.278,1419,2.796,1420,3.204,1421,3.204,1422,2.208,1423,2.796,1424,3.204,1425,2.796,1426,3.204]],["title/Chap_12.html#other-windows",[895,3.199]],["text/Chap_12.html#other-windows",[2,1.278,11,0.377,19,1.401,31,3.228,53,2.61,78,2.994,127,2.134,142,0.697,148,2.666,151,2.796,213,3.519,220,2.625,255,3.106,283,1.959,288,3.017,303,4.276,326,3.603,329,2.34,338,4.614,358,1.557,359,2.218,436,4.824,446,2.178,450,1.958,453,2.081,457,3.296,487,2.891,528,2.994,561,2.439,567,3.229,574,3.397,626,2.308,636,2.081,641,1.627,651,2.34,676,2.796,689,3.106,728,2.405,761,1.981,827,4.824,894,4.135,895,5.087,989,4.614,1014,3.106,1024,3.049,1043,4.135,1092,4.276,1136,3.44,1165,2.248,1286,4.276,1292,5.437,1298,5.394,1315,3.693,1322,4.135,1323,5.077,1329,4.824,1330,4.276,1342,4.433,1349,4.191,1350,5.077,1352,4.276,1353,3.895,1354,5.394,1355,4.433,1365,5.638,1394,4.614,1422,4.009,1427,4.433,1428,5.077,1429,4.276,1430,5.394,1431,5.077,1432,5.394,1433,5.077,1434,5.077,1435,4.433,1436,3.895,1437,5.437,1438,5.817,1439,5.394,1440,5.394,1441,5.817,1442,5.077,1443,4.276,1444,6.859,1445,5.077]],["title/Chap_12.html#a-family-of-windows",[895,2.625,1446,5.008]],["text/Chap_12.html#a-family-of-windows",[1,1.728,2,0.751,6,0.895,11,0.432,18,2.383,19,0.592,31,1.897,32,2.094,34,1.045,39,1.609,59,1.162,65,1.503,68,2.337,77,1.433,88,1.479,91,1.323,95,1.609,99,1.185,101,2.804,105,0.667,107,1.078,108,1.04,117,3.792,127,1.754,136,1.241,157,1.936,198,2.304,229,2.48,250,2.892,259,1.364,269,1.738,270,1.69,271,2.892,274,3.201,276,1.609,283,0.828,288,1.275,305,1.275,311,1.571,321,2.897,322,1.369,332,1.133,337,1.31,339,1.581,345,2.298,346,3.685,355,0.711,367,2.418,368,3.512,369,1.479,374,1.891,379,2.214,394,2.276,412,1.416,429,1.349,432,2.298,446,0.837,448,2.689,450,1.052,452,3.685,453,1.711,464,2.766,487,2.377,500,2.506,501,2.689,537,1.275,540,2.368,561,2.005,572,1.936,574,1.241,583,1.67,636,2.077,637,2.709,639,3.223,641,1.711,651,1.258,661,2.435,666,1.702,668,3.512,676,2.298,731,1.936,756,1.936,761,2.215,762,1.67,784,3.201,799,1.39,802,1.554,843,2.603,852,1.936,858,1.078,894,4.622,895,4.83,906,2.48,907,1.891,959,1.702,963,2.335,966,1.554,971,4.267,983,2.125,1014,3.472,1019,3.433,1024,1.639,1043,3.399,1056,2.767,1078,2.298,1093,1.849,1162,2.005,1165,1.208,1216,2.005,1221,1.936,1286,4.779,1289,1.849,1292,4.779,1310,1.609,1317,5.859,1330,3.514,1334,2.729,1336,2.899,1341,4.425,1343,3.792,1344,4.42,1345,2.899,1347,2.093,1349,3.289,1365,6.32,1366,4.001,1418,2.223,1430,5.383,1431,4.173,1432,4.433,1433,4.173,1434,4.173,1435,4.955,1437,5.828,1444,4.433,1447,2.899,1448,4.782,1449,4.782,1450,4.782,1451,4.782,1452,2.298,1453,3.127,1454,2.383,1455,2.729,1456,4.173,1457,3.127,1458,5.806,1459,4.782,1460,3.127,1461,3.127,1462,3.127,1463,4.425,1464,5.806,1465,2.48,1466,2.383,1467,5.067,1468,6.709,1469,4.782,1470,2.709,1471,3.127,1472,4.173,1473,3.127,1474,4.782,1475,2.729,1476,3.792,1477,3.127,1478,1.849,1479,2.593,1480,4.433,1481,3.127,1482,3.399,1483,1.936,1484,3.035,1485,4.782,1486,2.383,1487,2.593,1488,6.095,1489,3.127,1490,3.127,1491,3.127,1492,3.127,1493,3.127,1494,3.127,1495,3.127,1496,3.127,1497,3.127,1498,3.127,1499,3.127,1500,3.127,1501,3.127,1502,3.127,1503,3.127,1504,3.127,1505,3.127,1506,3.127,1507,3.127,1508,3.127,1509,3.127,1510,3.127,1511,3.127,1512,3.127,1513,1.809,1514,2.298,1515,1.849,1516,3.127,1517,3.127]],["title/Chap_12.html#problems",[142,0.731]],["text/Chap_12.html#problems",[]],["title/Chap_12.html#problem-121",[142,0.6,1286,3.681]],["text/Chap_12.html#problem-121",[1,1.339,11,0.384,32,2.69,33,3.555,34,0.987,35,2.266,37,2.471,39,2.068,84,2.772,90,6.615,101,3.046,130,4.682,214,2.54,240,2.345,321,3.166,325,2.486,337,1.395,355,1.742,373,2.171,442,3.411,446,2.05,450,2.068,561,2.576,574,3.465,591,3.805,801,3.281,895,5.025,983,2.731,1019,4.932,1043,5.443,1162,3.211,1237,6.682,1286,4.515,1292,4.515,1299,5.835,1323,5.362,1329,5.095,1330,5.627,1346,7.279,1357,5.696,1359,5.696,1366,4.234,1367,5.696,1431,5.362,1433,5.362,1434,5.362,1437,5.627,1480,7.733,1518,6.144,1519,6.144,1520,5.362,1521,4.682,1522,5.362,1523,6.144]],["title/Chap_12.html#problem-122",[142,0.6,1292,3.681]],["text/Chap_12.html#problem-122",[1,1.463,2,1.22,6,1.643,11,0.426,31,1.588,34,0.922,35,1.988,37,1.61,39,2.469,47,2.206,53,1.284,59,2.134,66,1.546,90,3.174,91,1.107,101,1.909,105,0.854,106,1.284,108,0.997,122,3.187,127,1.468,130,5.591,134,1.806,138,2.343,142,0.479,143,1.684,151,1.923,188,2.591,211,1.61,216,1.956,232,2.137,240,1.226,244,2.366,259,1.724,269,1.198,271,2.42,274,3.844,276,2.06,280,2.941,283,1.06,309,2.137,319,2.004,321,1.655,323,1.588,325,1.299,329,2.701,332,2.814,337,0.892,341,2.854,342,2.315,355,1.839,358,1.071,371,1.863,373,1.414,389,2.024,432,2.76,446,1.071,448,2.776,450,1.932,452,2.54,453,2.054,471,2.54,477,1.923,487,3.646,493,0.891,496,3.556,537,1.632,540,2.341,550,2.856,559,2.758,561,2.408,564,1.331,576,2.806,583,3.066,587,1.212,591,2.478,594,2.478,600,2.366,621,2.845,626,1.588,636,1.432,638,3.253,641,1.148,654,2.097,676,4.095,677,2.679,678,4.779,685,2.76,689,3.066,709,2.221,754,3.492,755,3.492,795,1.588,826,2.679,848,2.679,873,2.221,886,1.989,894,2.845,895,4.882,917,2.845,919,3.009,936,2.941,963,2.951,968,2.54,971,2.941,985,2.679,1014,2.137,1020,3.492,1034,1.923,1051,2.806,1101,5.392,1144,4.553,1162,1.678,1189,2.679,1215,5.591,1216,2.408,1232,3.174,1234,3.556,1274,3.318,1280,2.478,1295,3.174,1299,4.375,1302,5.568,1329,3.318,1330,4.22,1334,5.011,1338,2.137,1346,3.492,1347,2.679,1349,2.267,1350,5.86,1365,3.05,1435,4.375,1439,3.71,1447,3.71,1452,6.12,1479,3.318,1486,5.117,1487,3.318,1515,2.366,1524,2.845,1525,4.002,1526,4.002,1527,4.002,1528,3.492,1529,4.002,1530,4.002,1531,4.002,1532,4.002,1533,3.318,1534,4.002,1535,6.715,1536,3.253,1537,4.002,1538,4.002,1539,4.002,1540,2.845,1541,5.742,1542,4.002,1543,4.002,1544,3.318,1545,3.174,1546,4.002,1547,6.715,1548,8.085,1549,5.011,1550,5.011,1551,4.002,1552,4.002,1553,4.002,1554,6.715,1555,4.002,1556,4.002,1557,5.818,1558,5.742,1559,5.742]],["title/Chap_12.html#problem-123",[142,0.6,1295,3.972]],["text/Chap_12.html#problem-123",[11,0.431,35,2.455,37,2.44,71,6.024,99,1.039,108,1.127,136,3.291,142,0.91,146,4.622,147,4.594,214,2.508,240,1.858,252,5.293,273,3.239,276,3.122,288,2.473,304,3.301,311,2.496,322,2.656,325,1.969,337,0.942,346,3.85,348,1.858,356,1.571,366,3.909,433,2.656,442,3.367,445,4.18,469,3.509,550,2.58,561,2.543,600,4.903,639,3.367,641,1.213,650,4.458,689,3.239,758,4.458,845,3.669,857,2.779,886,3.015,977,4.622,1033,3.85,1093,3.586,1242,3.509,1305,7.237,1369,5.623,1389,5.788,1560,6.065,1561,5.293,1562,6.065,1563,5.293,1564,5.293,1565,5.293,1566,5.293,1567,4.81,1568,4.81,1569,6.065,1570,5.293,1571,7.595,1572,6.065,1573,6.065,1574,6.065,1575,6.065,1576,8.293,1577,4.312,1578,5.293,1579,4.81,1580,4.18]],["title/Chap_12.html#laboratory-exercises",[47,1.646,143,1.256]],["text/Chap_12.html#laboratory-exercises",[]],["title/Chap_12.html#laboratory-exercise-121",[47,1.395,143,1.065,1286,3.121]],["text/Chap_12.html#laboratory-exercise-121",[99,1.038,108,1.126,123,2.892,155,3.226,168,5.227,283,2.008,316,2.245,574,3.01,881,5.574,1280,4.697,1581,6.619]],["title/Chap_12.html#laboratory-exercise-122",[47,1.395,143,1.065,1292,3.121]],["text/Chap_12.html#laboratory-exercise-122",[2,1.157,11,0.324,16,5.078,19,1.396,31,2.924,39,2.48,99,1.008,123,2.81,139,4.263,143,1.848,155,3.134,210,4.011,279,2.636,283,1.951,316,2.181,636,2.636,826,4.933,1093,4.357,1259,6.431,1582,7.369,1583,7.369,1584,7.369]],["title/Chap_12.html#laboratory-exercise-123",[47,1.395,143,1.065,1295,3.367]],["text/Chap_12.html#laboratory-exercise-123",[2,1.16,66,2.854,99,1.011,121,4.946,123,2.817,143,1.852,155,3.142,250,4.468,255,3.945,283,1.956,316,2.187,449,3.61,453,3.06,895,4.732,1024,3.872,1356,6.447,1585,7.388,1586,7.388]],["title/Chap_12.html#laboratory-exercise-124",[47,1.395,143,1.065,1299,3.236]],["text/Chap_12.html#laboratory-exercise-124",[11,0.405,99,0.918,123,2.558,127,2.461,142,0.804,143,1.682,155,2.853,210,3.651,255,3.582,279,2.4,283,2.14,285,1.857,316,1.986,319,2.341,453,2.891,467,3.453,601,3.881,607,3.967,636,3.102,676,3.225,709,3.724,784,4.491,792,3.651,856,5.855,863,3.651,895,4.717,982,4.623,1044,5.32,1215,5.112,1263,5.264,1264,4.058,1265,5.32,1266,5.855,1267,5.855,1268,5.855,1269,4.623,1272,4.491,1356,5.855,1435,5.112,1440,6.22,1544,5.563,1587,5.32,1588,5.32,1589,6.709,1590,6.709,1591,6.408,1592,5.855]],["title/Chap_13.html",[1593,5.659]],["text/Chap_13.html",[1,1.153,2,1.028,3,0.749,4,1.187,6,0.773,8,1.145,11,0.439,12,2.026,16,1.074,19,1.002,25,0.441,31,0.618,32,0.682,34,1.378,36,1.76,39,1.203,40,1.004,43,1.074,52,1.359,54,1.32,57,1.074,91,1.336,95,0.909,99,1.257,100,1.32,101,2.674,105,0.332,106,0.867,107,0.537,108,1.058,110,0.991,111,0.703,114,1.32,117,1.235,126,0.921,127,1.771,133,0.816,134,0.703,136,1.072,137,0.965,153,0.412,158,1.257,169,0.945,188,0.703,196,0.832,198,0.618,211,0.627,214,0.644,230,1.359,232,1.442,241,0.989,244,0.921,253,2.053,256,0.557,259,1.134,260,0.901,266,0.737,269,0.809,270,0.954,271,1.634,277,1.614,279,0.966,283,0.947,286,1.903,289,0.672,291,1.53,292,0.882,296,1.264,297,2.628,303,1.145,305,0.635,311,0.512,316,0.8,318,2.921,323,0.618,324,3.271,325,1.161,326,0.965,327,2.556,330,0.618,332,0.564,335,1.189,336,3.605,337,1.318,341,0.774,342,1.563,343,0.901,344,0.672,345,1.985,346,0.989,348,1.841,349,2.836,350,2.357,352,1.235,354,2.675,355,0.615,356,1.631,358,0.957,359,1.03,364,1.015,366,1.39,367,0.788,368,3.635,369,0.737,372,1.563,373,0.55,376,2.24,377,1.76,379,0.594,381,4.617,382,2.485,384,1.416,390,2.542,391,1.366,394,1.197,395,1.841,398,2.966,402,1.292,409,0.628,412,0.546,427,0.682,429,1.166,430,1.043,433,0.682,440,1.296,446,0.957,447,0.737,448,1.117,449,0.761,450,0.909,452,2.709,453,0.557,464,0.663,467,1.841,468,1.586,469,0.901,471,0.989,488,0.832,489,1.072,493,1.338,499,3.554,500,4.328,501,3.357,514,2.627,518,1.145,525,1.499,531,2.966,539,0.921,540,1.969,550,0.663,561,0.653,564,0.518,567,1.499,574,2.253,576,1.748,579,1.442,586,0.672,593,0.942,595,2.643,597,1.014,607,0.921,608,1.926,639,0.865,641,1.309,648,1.359,650,1.145,682,0.761,687,1.145,706,1.382,750,1.442,761,1.934,765,0.865,773,0.725,783,0.921,784,1.043,785,1.235,786,1.145,787,1.76,788,1.145,789,1.074,790,1.145,791,1.359,792,1.47,793,1.074,794,1.074,795,1.072,801,1.442,808,1.416,843,3.787,858,0.931,886,2.822,894,1.107,899,0.901,918,2.53,919,1.416,920,0.942,927,0.966,940,1.359,941,1.145,961,1.235,970,0.921,971,3.136,981,1.92,1034,0.749,1056,3.061,1062,0.703,1079,1.145,1095,1.107,1136,0.921,1147,1.107,1165,0.602,1186,0.865,1191,1.015,1199,1.074,1200,1.145,1222,1.634,1228,3.965,1254,1.107,1263,1.015,1293,0.921,1315,0.989,1328,1.862,1333,1.074,1342,2.059,1344,3.958,1353,1.043,1365,1.187,1368,1.292,1384,1.145,1425,1.359,1436,1.043,1452,3.548,1467,5.245,1468,5.245,1472,1.359,1475,4.956,1476,5.19,1478,0.921,1484,1.715,1486,1.187,1545,1.235,1591,2.142,1592,1.359,1593,1.444,1594,3.548,1595,1.558,1596,3.121,1597,4.268,1598,1.043,1599,1.558,1600,1.558,1601,1.558,1602,4.827,1603,1.558,1604,1.558,1605,1.558,1606,1.292,1607,0.865,1608,1.558,1609,1.187,1610,2.701,1611,3.384,1612,1.558,1613,1.558,1614,1.558,1615,1.558,1616,1.558,1617,1.359,1618,1.558,1619,1.558,1620,1.39,1621,3.539,1622,1.043,1623,6.957,1624,3.576,1625,2.701,1626,1.558,1627,1.558,1628,1.107,1629,3.316,1630,2.701,1631,3.576,1632,4.827,1633,1.558,1634,1.558,1635,2.701,1636,3.724,1637,1.808,1638,1.558,1639,6.869,1640,1.558,1641,1.187,1642,3.576,1643,2.701,1644,1.558,1645,1.558,1646,2.701,1647,2.357,1648,2.701,1649,1.558,1650,4.268,1651,4.504,1652,1.558,1653,0.989,1654,2.215,1655,6.296,1656,2.701,1657,1.292,1658,1.558,1659,1.558,1660,1.558,1661,1.558,1662,1.558,1663,1.558,1664,1.558,1665,1.235,1666,1.235,1667,6.01,1668,5.837,1669,0.942,1670,2.394,1671,3.539,1672,1.558,1673,2.701,1674,2.701,1675,2.357,1676,2.701,1677,1.558,1678,1.558,1679,1.558,1680,1.558,1681,1.235,1682,1.235,1683,1.558,1684,1.558,1685,5.29,1686,2.701,1687,1.359,1688,1.235,1689,1.558,1690,2.701,1691,2.701,1692,1.359,1693,1.558,1694,2.24,1695,1.187,1696,3.576,1697,1.558,1698,1.235,1699,1.235,1700,1.074,1701,1.558,1702,1.558,1703,3.576,1704,2.357,1705,1.558,1706,1.145,1707,1.558,1708,1.558,1709,1.558,1710,1.558,1711,2.701,1712,1.145,1713,1.558,1714,0.774,1715,1.235,1716,1.558,1717,1.145,1718,1.107,1719,1.145,1720,1.359,1721,1.187,1722,1.187,1723,1.558,1724,1.187,1725,1.558,1726,1.235,1727,1.359,1728,1.359,1729,1.107,1730,1.558,1731,1.558,1732,1.558,1733,1.558,1734,1.558,1735,1.558,1736,1.558,1737,1.558,1738,1.558,1739,1.558,1740,1.558,1741,1.558,1742,1.292,1743,1.558,1744,1.558,1745,1.558,1746,1.558,1747,2.701,1748,1.558,1749,1.558,1750,1.558,1751,1.145]],["title/Chap_13.html#appendices",[1593,5.659]],["text/Chap_13.html#appendices",[]],["title/Chap_13.html#appendix-i-mean-square-error-minimization",[19,0.617,324,1.772,327,1.385,342,1.883,345,2.393]],["text/Chap_13.html#appendix-i-mean-square-error-minimization",[1,1.099,2,0.792,6,1.444,11,0.414,12,2.858,19,1.438,34,1.396,40,1.874,91,1.396,95,1.697,99,1.214,100,3.294,106,2.163,136,2.002,230,4.402,244,2.983,259,1.784,266,2.386,277,3.426,283,2.01,291,2.858,292,2.858,296,1.782,311,1.657,323,2.002,324,4.829,325,1.638,326,3.124,327,3.447,330,2.002,332,1.827,335,2.524,337,1.35,341,2.507,342,2.918,346,3.202,349,6.021,350,5.883,352,4,354,3.409,355,1.148,358,1.35,359,1.924,364,3.286,366,3.47,368,3.051,377,3.286,381,7.583,382,3.728,390,5.397,395,2.596,398,6.296,402,4.183,430,3.377,440,2.442,447,2.386,453,1.805,471,3.202,488,2.693,493,1.123,514,2.745,518,3.707,540,3.096,593,3.051,595,4.702,597,1.803,608,2.276,682,2.465,687,3.707,918,3.979,919,2.644,920,3.051,940,4.402,941,3.707,970,2.983,1436,3.377,1452,4.954,1594,6.207,1595,5.044,1596,6.626,1597,8.104,1598,3.377,1599,5.044,1600,5.044,1601,5.044,1602,8.445,1603,5.044,1604,5.044,1605,5.044,1606,4.183,1607,2.8,1608,5.044,1609,3.844,1610,6.741,1611,6.427,1612,5.044,1613,5.044,1614,5.044,1615,5.044,1616,5.044,1617,4.402,1618,5.044,1619,5.044]],["title/Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle",[345,2.143,452,1.85,641,0.583,761,0.993,971,2.143,1486,2.222]],["text/Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle",[1,1.212,2,1.052,11,0.44,19,0.628,25,0.56,34,1.392,39,1.438,40,0.736,54,0.968,57,1.365,91,1.183,95,0.666,99,1.266,101,2.822,107,0.683,108,0.994,110,1.216,126,1.171,127,2.041,134,0.894,136,0.786,158,1.543,196,1.057,198,0.786,214,0.819,241,1.257,253,2.366,256,0.709,259,0.779,260,1.146,269,0.992,270,1.171,271,1.198,279,1.186,286,2.041,291,1.122,296,1.171,305,0.808,316,0.586,318,2.975,325,1.076,327,1.818,336,3.898,337,1.296,348,2.052,354,2.527,355,0.451,356,1.804,358,0.53,359,0.755,367,1.001,368,3.864,373,0.7,379,0.755,384,1.737,391,1.676,394,1.38,395,1.706,409,0.77,412,0.67,427,0.867,429,1.43,433,0.867,440,0.717,446,1.144,448,1.371,450,0.666,452,2.713,464,0.842,467,1.019,468,1.588,469,1.146,489,1.315,493,1.34,499,3.961,500,4.542,501,3.536,514,2.72,525,1.84,531,3.545,539,1.171,540,1.352,561,0.83,567,1.84,574,2.535,576,2.089,579,1.77,595,1.226,608,1.929,639,1.099,641,1.34,648,1.728,706,1.652,750,1.057,761,1.895,765,1.099,795,1.315,801,1.77,808,1.737,843,4.113,858,1.143,886,3.175,894,1.408,919,1.038,927,1.186,971,3.142,1034,0.952,1056,3.481,1079,1.456,1095,1.408,1136,1.171,1165,0.765,1186,1.099,1191,1.29,1199,1.365,1200,1.456,1222,1.198,1228,4.269,1254,1.408,1293,1.171,1315,1.257,1328,2.284,1333,1.365,1342,2.526,1344,4.232,1365,1.509,1368,1.642,1384,1.456,1425,1.728,1467,5.847,1468,5.847,1472,1.728,1475,5.576,1476,5.701,1478,1.171,1484,2.104,1545,1.571,1620,1.706,1621,4.145,1622,1.326,1623,7.557,1624,4.275,1625,3.315,1626,1.98,1627,1.98,1628,1.408,1629,3.073,1630,3.315,1631,4.275,1632,5.563,1633,1.98,1634,1.98,1635,3.315,1636,4.362,1637,2.219,1638,1.98,1639,7.282,1640,1.98,1641,1.509,1642,4.275,1643,3.315,1644,1.98,1645,1.98,1646,3.315,1647,2.893,1648,3.315,1649,1.98,1650,4.998,1651,5.067,1652,1.98,1653,1.257,1654,1.226,1655,6.963,1656,3.315,1657,1.642,1658,1.98,1659,1.98,1660,1.98,1661,1.98,1662,1.98,1663,1.98,1664,1.98,1665,1.571,1666,1.571,1667,6.7,1668,6.212,1669,1.198,1670,2.862,1671,2.749,1672,1.98,1673,3.315,1674,3.315,1675,2.893,1676,3.315,1677,1.98,1678,1.98,1679,1.98,1680,1.98,1681,1.571,1682,1.571,1683,1.98,1684,1.98,1685,6.017,1686,3.315,1687,1.728,1688,1.571,1689,1.98,1690,3.315,1691,3.315,1692,1.728,1693,1.98,1694,2.749,1695,1.509,1696,4.275,1697,1.98,1698,1.571,1699,1.571,1700,1.365,1701,1.98,1702,1.98,1703,4.275,1704,2.893,1705,1.98,1706,1.456]],["title/Chap_13.html#epilogue",[1707,6.104]],["text/Chap_13.html#epilogue",[2,0.832,3,2.546,4,4.037,6,1.516,8,3.894,11,0.419,12,3.945,16,3.651,31,2.102,32,2.32,36,4.536,43,3.651,52,4.623,54,2.589,91,1.466,99,1.065,105,1.13,108,1.274,111,2.391,114,3.403,117,4.201,133,2.777,137,3.281,153,1.403,169,1.68,188,2.391,211,2.131,232,3.718,271,3.204,289,2.286,297,5.717,303,3.894,316,1.568,337,1.208,343,3.065,344,2.286,358,1.418,369,2.505,372,4.029,376,5.774,377,3.451,449,2.589,450,1.783,467,3.584,468,1.969,493,1.18,550,2.253,564,1.762,586,2.286,597,1.258,607,3.132,641,1.059,650,3.894,750,2.829,761,1.804,773,2.466,783,3.132,784,3.547,785,4.201,786,3.894,787,4.536,788,3.894,789,3.651,790,3.894,791,4.623,792,3.79,793,3.651,794,3.651,899,3.065,918,3.65,961,4.201,981,4.95,1062,2.391,1147,3.766,1222,3.204,1263,3.451,1353,3.547,1452,5.717,1591,5.522,1592,4.623,1629,4.912,1654,4.312,1668,4.912,1671,5.774,1708,5.298,1709,5.298,1710,5.298,1711,6.964,1712,3.894,1713,5.298,1714,2.633,1715,4.201,1716,5.298,1717,3.894,1718,3.766,1719,3.894,1720,4.623,1721,4.037,1722,4.037,1723,5.298,1724,4.037,1725,5.298,1726,4.201,1727,4.623,1728,4.623,1729,3.766,1730,5.298,1731,5.298,1732,5.298,1733,5.298,1734,5.298,1735,5.298,1736,5.298,1737,5.298,1738,5.298,1739,5.298,1740,5.298,1741,5.298,1742,4.393,1743,5.298,1744,5.298,1745,5.298,1746,5.298,1747,6.964,1748,5.298,1749,5.298,1750,5.298,1751,3.894]],["title/Chap_2.html",[25,1.417,1752,4.643]],["text/Chap_2.html",[1,0.932,2,1.094,3,2.894,11,0.411,12,2.424,13,2.375,15,4.425,16,4.15,19,1.32,20,2.329,32,1.874,39,2.026,40,1.59,53,2.426,59,2.589,65,2.056,66,2.326,68,2.091,76,2.787,91,1.184,105,1.284,106,1.373,108,1.34,109,2.209,110,1.57,111,2.717,119,3.734,120,2.202,127,2.556,138,2.101,142,0.835,152,2.53,153,2.002,158,1.991,169,1.798,195,1.991,199,3.393,224,2.329,240,1.311,242,3.729,249,3.393,259,1.415,265,4.425,269,1.803,277,1.931,286,1.543,288,2.455,289,1.846,295,4.031,296,1.512,301,3.144,316,1.266,340,2.717,358,1.145,359,1.632,371,3.243,372,2.475,373,1.512,374,2.588,383,3.586,412,1.408,431,1.846,440,2.739,446,1.145,447,2.023,462,2.53,466,2.864,468,1.59,469,2.475,479,3.26,480,3.734,481,3.26,487,2.992,489,1.698,493,0.953,532,2.716,537,1.745,581,3.041,597,1.43,605,1.82,623,2.588,641,1.861,651,2.422,653,2.787,657,2.375,685,3.349,724,2.53,734,2.716,751,2.864,761,2.815,773,1.991,792,2.329,826,2.864,857,3.972,858,1.475,873,4.197,891,2.65,896,3.26,929,5.12,981,3.041,1003,2.285,1014,2.285,1051,2.091,1065,2.242,1105,3.144,1134,2.475,1136,2.53,1165,1.653,1221,4.314,1240,3.734,1245,3.041,1277,2.787,1338,4.037,1427,3.26,1443,3.144,1580,2.949,1700,2.949,1715,3.393,1720,3.734,1724,3.26,1752,3.967,1753,3.734,1754,4.279,1755,3.393,1756,3.393,1757,4.279,1758,3.734,1759,4.279,1760,4.279,1761,4.279,1762,3.734,1763,4.279,1764,4.279,1765,4.279,1766,4.279,1767,6.021,1768,3.56,1769,3.734,1770,4.279,1771,3.734,1772,4.279,1773,4.279,1774,4.425,1775,3.734,1776,4.279,1777,4.279,1778,4.279,1779,3.734,1780,2.716,1781,4.279,1782,4.279,1783,4.279,1784,4.279,1785,4.279,1786,3.393,1787,4.279,1788,4.279,1789,4.279,1790,4.279,1791,2.949,1792,3.548,1793,4.279,1794,5.582,1795,2.424,1796,6.021,1797,3.393,1798,3.734,1799,4.279,1800,4.279,1801,3.734,1802,4.279,1803,4.279,1804,3.734,1805,4.279,1806,4.279]],["title/Chap_2.html#prologue",[1752,5.659]],["text/Chap_2.html#prologue",[1,1.025,2,1.151,3,3.09,11,0.374,12,2.664,13,2.61,15,4.725,16,4.431,19,1.218,20,2.56,32,2.059,39,2.163,40,1.747,53,2.527,59,2.722,65,2.26,66,1.817,68,2.298,76,3.063,105,1.371,106,1.509,108,1.351,109,2.359,110,1.725,111,2.901,119,4.104,120,2.42,127,2.687,138,2.244,142,0.563,153,1.94,158,2.189,169,1.813,195,2.189,224,2.56,242,3.981,249,3.729,259,1.511,265,4.725,269,1.925,288,1.918,295,4.238,296,1.662,301,3.456,316,1.392,358,1.259,359,1.793,371,3.409,372,2.721,374,2.844,412,1.481,440,2.853,446,1.259,462,2.781,466,3.148,468,1.747,469,2.721,479,3.584,480,4.104,481,3.584,487,3.195,489,1.866,493,1.047,532,2.985,537,1.918,581,3.343,597,1.117,605,2,641,1.876,651,1.891,653,3.063,657,2.61,685,3.521,724,2.781,734,2.985,751,3.148,761,2.899,773,2.189,792,2.56,826,3.148,857,4.065,873,4.371,891,2.912,896,3.584,929,5.384,981,3.343,1003,2.511,1014,2.511,1051,2.298,1065,2.465,1105,3.456,1134,2.721,1136,2.781,1221,3.981,1245,3.343,1277,3.063,1338,2.511,1427,3.584,1443,3.456,1580,3.241,1700,3.241,1715,3.729,1720,4.104,1724,3.584,1753,4.104,1754,4.703,1755,3.729,1756,3.729,1757,4.703,1758,4.104,1759,4.703,1760,4.703,1761,4.703,1762,4.104,1763,4.703,1764,4.703,1765,4.703,1766,4.703,1767,6.429,1768,3.801,1769,4.104,1770,4.703,1771,4.104,1772,4.703,1773,4.703,1774,4.725,1775,4.104,1776,4.703,1777,4.703,1778,4.703,1779,4.104,1780,2.985,1781,4.703,1782,4.703,1783,4.703,1784,4.703,1785,4.703,1786,3.729,1787,4.703,1788,4.703,1789,4.703,1790,4.703,1791,3.241,1792,3.9,1793,4.703,1794,4.36]],["title/Chap_2.html#problems",[142,0.731]],["text/Chap_2.html#problems",[]],["title/Chap_2.html#problem-21",[142,0.6,1794,4.643]],["text/Chap_2.html#problem-21",[11,0.418,19,1.292,66,2.635,91,1.888,108,1.012,152,4.033,153,1.806,169,1.335,199,5.41,240,2.09,277,3.078,286,2.091,288,2.781,289,2.944,340,3.683,373,2.41,383,4.495,431,2.944,447,3.226,597,1.62,623,4.126,641,1.364,651,2.744,858,2.352,1165,2.635,1221,4.224,1240,5.953,1338,4.663,1795,3.864,1796,8.162,1797,5.41,1798,5.953,1799,6.821,1800,6.821,1801,5.953,1802,6.821,1803,6.821,1804,5.953,1805,6.821,1806,6.821]],["title/Chap_3.html",[134,2.26,822,3.972]],["text/Chap_3.html",[1,1.222,2,0.659,3,0.73,6,1.201,7,0.879,11,0.425,12,2.693,14,1.117,19,0.9,25,1.187,31,2.07,34,0.425,35,2.18,37,0.611,39,0.89,40,0.565,43,1.047,45,2.418,47,0.499,48,0.665,53,1.799,57,1.047,59,0.982,64,1.659,65,0.73,66,1.356,68,0.743,80,1.529,84,0.686,91,0.971,95,0.511,97,2.192,99,0.574,100,1.292,101,1.58,103,1.943,104,1.744,105,1.267,106,0.848,107,1.21,108,1.342,109,2.702,110,2.284,111,0.686,112,1.08,114,2.549,120,0.782,127,1.914,134,1.893,135,1.158,136,0.603,137,0.941,138,0.53,139,1.529,142,0.976,143,1.052,145,1.774,147,0.919,148,0.696,151,0.73,152,0.898,153,1.111,158,0.707,161,0.919,169,1.218,184,1.337,185,2.811,188,0.686,195,1.633,196,0.811,198,0.603,210,1.439,211,1.687,213,0.919,216,1.715,220,0.686,223,1.439,224,2.587,228,0.99,232,2.785,235,1.117,240,2.165,253,0.646,256,0.544,259,1.731,260,0.879,264,1.386,266,0.719,267,0.861,269,0.455,270,1.24,273,0.811,277,2.145,279,0.544,281,0.686,282,1.047,283,0.402,285,0.732,286,1.716,288,1.711,289,1.81,292,0.861,293,0.965,296,0.537,304,0.827,305,1.431,308,1.117,310,0.707,311,1.562,313,2.467,318,1.3,319,0.53,321,1.965,325,1.139,327,0.646,329,0.611,330,1.049,332,0.958,337,0.545,339,1.337,340,1.583,343,2.427,344,2.419,355,0.798,358,1.396,359,1.008,362,0.861,363,0.782,371,1.23,373,1.482,377,0.99,378,0.686,379,0.579,382,1.451,383,0.782,384,0.796,389,1.337,393,1.912,394,1.827,409,0.353,412,1.673,429,2.419,431,0.656,432,0.73,433,0.665,440,2.151,444,1.117,445,1.047,446,1.501,447,1.984,448,1.965,450,1.181,464,1.124,468,2.737,477,1.686,487,2.085,488,0.811,489,2.923,493,1.248,501,1.735,528,2.159,535,1.047,537,0.62,539,0.898,540,0.62,550,2.022,551,2.145,561,1.471,562,1.879,569,0.861,573,2.491,574,1.049,583,0.811,587,2.14,593,0.919,595,0.941,597,1.951,605,0.646,608,1.193,610,1.326,612,0.99,623,0.919,626,2.07,627,2.507,632,2.284,637,1.498,639,1.467,641,1.499,650,1.117,651,1.063,653,0.99,654,0.796,658,1.017,661,2.35,667,1.56,668,0.919,672,0.898,676,2.285,682,1.292,684,0.755,685,0.73,689,0.811,706,2.015,708,1.563,713,1.08,720,0.898,728,1.735,731,0.941,738,0.941,740,0.99,751,1.017,758,1.117,761,1.429,762,0.811,773,1.953,774,1.08,775,0.99,778,1.117,781,1.722,782,1.047,783,0.898,787,0.99,793,1.047,794,1.047,795,0.603,796,1.722,797,1.599,799,1.56,801,0.811,802,0.755,808,0.796,811,1.141,822,2.096,830,0.768,843,1.91,846,1.599,852,2.944,857,0.696,858,2.959,868,2.192,883,0.898,886,0.755,891,1.637,892,1.77,893,0.861,918,0.796,919,0.796,927,1.255,928,2.494,930,2.481,931,0.965,958,1.205,963,0.611,965,1.047,966,1.744,969,0.879,970,0.898,982,4.75,983,2.491,985,1.77,1003,0.811,1019,2.075,1029,0.99,1033,0.965,1041,1.678,1051,0.743,1059,1.117,1062,1.583,1076,0.768,1089,0.879,1094,2.674,1147,1.08,1160,3.77,1162,1.471,1165,2.166,1170,1.326,1197,3.708,1199,1.047,1208,1.326,1214,1.117,1216,1.471,1217,0.827,1228,2.283,1234,0.941,1255,1.205,1269,1.047,1270,1.498,1271,2.096,1272,1.017,1275,2.783,1283,4.604,1310,2.685,1322,1.08,1338,1.874,1344,1.839,1443,1.943,1470,0.861,1484,0.965,1487,1.26,1513,0.879,1515,0.898,1536,3.364,1557,1.205,1563,1.326,1564,1.326,1565,1.326,1566,1.326,1567,1.205,1568,1.205,1607,0.843,1620,1.806,1622,1.77,1651,1.205,1653,1.678,1669,0.919,1706,1.117,1714,0.755,1722,1.158,1751,1.943,1791,4.092,1795,1.498,1807,3.479,1808,3.083,1809,3.975,1810,1.52,1811,3.661,1812,1.52,1813,1.205,1814,1.117,1815,3.77,1816,1.52,1817,1.52,1818,1.52,1819,1.52,1820,1.52,1821,1.52,1822,1.52,1823,1.52,1824,1.52,1825,1.52,1826,1.52,1827,1.943,1828,1.52,1829,1.326,1830,1.52,1831,1.52,1832,1.52,1833,1.52,1834,1.52,1835,3.77,1836,1.52,1837,1.52,1838,3.062,1839,3.062,1840,4.75,1841,1.52,1842,1.52,1843,1.52,1844,1.158,1845,1.326,1846,1.52,1847,1.52,1848,4.552,1849,1.52,1850,1.52,1851,2.096,1852,4.148,1853,1.158,1854,4.195,1855,1.52,1856,1.52,1857,1.52,1858,1.52,1859,1.52,1860,4.552,1861,4.195,1862,2.451,1863,1.52,1864,1.52,1865,1.52,1866,2.451,1867,4.407,1868,1.943,1869,1.205,1870,2.644,1871,1.52,1872,1.52,1873,1.52,1874,3.942,1875,1.52,1876,1.326,1877,1.326,1878,2.644,1879,2.644,1880,1.52,1881,1.52,1882,2.644,1883,2.644,1884,2.644,1885,2.644,1886,4.445,1887,1.205,1888,1.117,1889,1.08,1890,2.192,1891,1.52,1892,1.52,1893,1.52,1894,1.52,1895,1.52,1896,1.52,1897,1.52,1898,1.52,1899,1.52,1900,1.52,1901,1.326,1902,1.52,1903,1.52,1904,2.451,1905,3.253,1906,1.52,1907,1.52,1908,1.52,1909,1.52,1910,1.52,1911,1.52,1912,1.52,1913,1.52,1914,1.52,1915,1.52,1916,1.52,1917,1.52,1918,1.52,1919,1.52,1920,1.52,1921,1.52,1922,1.678,1923,1.52,1924,1.52,1925,1.52,1926,1.52,1927,1.52,1928,1.52,1929,1.52,1930,1.52,1931,1.52,1932,1.52,1933,1.52,1934,3.509,1935,2.644,1936,1.52,1937,3.509,1938,2.783,1939,1.52,1940,1.52,1941,3.89,1942,1.52,1943,1.52,1944,1.52,1945,1.52,1946,1.52,1947,1.52,1948,1.52,1949,2.644,1950,1.52,1951,1.52,1952,1.326,1953,1.77,1954,1.52,1955,1.52,1956,1.52,1957,1.52,1958,1.52,1959,1.52,1960,1.52,1961,1.52,1962,1.52,1963,1.52,1964,1.52,1965,1.52,1966,1.52,1967,1.52,1968,1.52,1969,1.52,1970,1.52,1971,1.52,1972,1.52,1973,2.644,1974,2.644,1975,1.52,1976,1.52,1977,1.52,1978,1.26,1979,1.017,1980,1.52,1981,1.52,1982,1.52,1983,1.52,1984,1.52,1985,1.52,1986,1.52,1987,2.644,1988,1.52,1989,2.644,1990,1.52,1991,1.52,1992,1.52,1993,1.52,1994,1.52,1995,1.52,1996,1.52,1997,1.52,1998,1.52,1999,1.52,2000,1.52,2001,2.418,2002,1.52,2003,1.52,2004,1.52,2005,1.52,2006,1.52,2007,1.52,2008,1.52,2009,1.326,2010,3.479,2011,3.509,2012,1.52,2013,1.52,2014,1.52,2015,1.52,2016,1.52,2017,4.76,2018,3.327,2019,3.509,2020,3.509,2021,1.52,2022,2.644,2023,1.943,2024,1.52,2025,3.509,2026,1.326,2027,2.644,2028,1.326,2029,1.52,2030,1.52,2031,2.644,2032,2.644,2033,1.52,2034,1.52,2035,1.52,2036,1.52,2037,1.52,2038,1.52,2039,1.52,2040,1.52,2041,1.52,2042,1.52,2043,0.919,2044,1.047,2045,1.205,2046,1.205,2047,1.047,2048,1.117,2049,1.52]],["title/Chap_3.html#introduction",[822,4.841]],["text/Chap_3.html#introduction",[1,1.381,11,0.425,34,1.018,59,2.9,66,3.015,84,2.859,91,1.753,108,1.37,109,3.238,161,3.832,169,1.24,195,2.949,198,2.514,235,4.656,259,1.489,277,3.521,286,2,288,3.182,305,2.583,313,2.996,318,2.418,329,2.548,340,3.521,344,2.734,382,2.62,383,3.261,384,3.32,409,1.473,412,1.281,487,3.878,561,2.657,573,2.816,605,2.695,610,5.529,626,2.514,627,3.045,632,2.774,641,1.765,667,2.816,731,3.923,802,3.149,822,5.024,919,3.32,1062,3.521,1338,3.383,1795,3.589,1807,6.471,1808,4.656,1809,5.947,1810,6.335,1811,5.529,1812,6.335]],["title/Chap_3.html#the-basics",[343,3.532]],["text/Chap_3.html#the-basics",[1,1.406,11,0.401,12,4.47,25,1.825,45,4.445,64,3.05,66,2.492,97,5.349,101,2.145,103,4.741,108,0.957,109,2.366,134,2.911,142,1.064,143,1.617,152,3.814,253,2.744,260,3.732,264,3.381,277,2.911,282,4.445,344,3.405,394,1.957,444,4.741,450,2.171,468,3.3,487,3.921,489,3.524,561,2.705,612,4.202,641,1.29,708,3.814,728,2.667,858,2.224,1165,2.492,1197,6.06,1310,3.32,1338,3.444,1487,5.349,1809,4.915,1813,5.115,1814,4.741,1815,6.257,1816,6.45,1817,6.45,1818,6.45,1819,6.45,1820,6.45,1821,6.45,1822,6.45,1823,6.45,1824,6.45,1825,6.45,1826,6.45,1827,4.741,1828,6.45,1829,5.629]],["title/Chap_3.html#what-is-a-random-signal",[108,0.743,597,1.19]],["text/Chap_3.html#what-is-a-random-signal",[2,0.916,3,2.802,11,0.358,25,1.65,40,2.166,45,5.105,53,2.377,105,1.243,108,1.426,109,2.718,110,2.718,120,3,134,2.63,137,3.61,142,0.888,143,1.462,147,3.526,151,2.802,153,2.156,169,1.141,195,2.713,210,3.173,224,3.173,259,1.37,269,1.745,270,2.06,273,3.113,277,2.63,283,1.544,285,2.05,288,2.377,289,2.516,293,3.7,305,2.377,310,2.713,313,2.757,325,1.893,339,2.948,343,4.286,344,2.516,371,3.448,440,2.112,445,4.017,446,1.561,450,1.962,468,2.166,477,2.802,535,4.017,569,3.302,573,3.292,583,3.113,597,2.208,632,2.553,641,1.166,672,3.447,684,2.897,708,3.447,728,3.063,751,3.903,773,3.448,808,3.055,858,2.554,927,2.913,931,3.7,969,3.373,983,2.591,1033,3.7,1147,4.144,1165,2.252,1197,5.266,1199,4.017,1217,3.173,1270,3.302,1808,5.444,1827,4.284,1830,5.829,1831,5.829,1832,5.829,1833,5.829,1834,5.829,1835,4.623,1836,5.829,1837,5.829,1838,5.087,1839,5.087]],["title/Chap_3.html#example-dont-bet-on-it",[105,0.906,1838,3.706,1839,3.706]],["text/Chap_3.html#example-dont-bet-on-it",[1,1.466,2,0.79,6,1.925,7,1.932,11,0.427,12,3.424,14,2.455,19,0.633,25,1.422,31,1.325,35,2.57,37,1.343,39,1.692,47,1.097,48,1.463,53,1.072,65,1.605,80,2.908,91,0.924,97,2.769,99,0.457,103,2.455,105,1.434,106,1.072,107,1.151,108,1.201,110,2.781,112,2.374,127,2.467,134,2.268,135,2.545,142,0.806,143,0.837,145,3.057,148,1.53,169,1.483,184,2.542,185,3.977,188,1.507,195,1.554,210,1.818,211,2.431,256,1.195,259,1.42,264,1.75,266,1.579,270,1.18,286,0.856,288,1.362,289,2.169,305,1.362,308,2.455,311,1.986,318,1.558,319,1.166,325,1.632,332,1.21,339,1.689,343,1.932,344,2.169,355,1.375,358,1.801,373,1.18,379,1.274,382,1.381,389,1.689,393,2.705,394,1.247,412,1.792,429,2.169,431,1.441,432,1.605,440,1.21,446,1.801,450,1.124,488,1.783,493,1.119,528,2.587,537,1.362,539,1.975,540,1.362,550,3.068,551,3.255,587,2.507,593,2.02,595,2.068,597,2.062,608,2.268,637,2.848,639,2.79,641,1.515,651,2.022,654,1.75,661,1.4,676,3.467,685,1.605,689,1.783,706,1.942,720,1.975,761,1.138,762,1.783,773,2.34,774,2.374,783,1.975,796,3.275,801,1.783,846,3.04,858,3.145,868,2.769,886,1.66,891,3.113,892,3.365,918,1.75,958,2.649,970,1.975,982,5.905,983,2.234,1003,1.783,1059,2.455,1062,1.507,1089,1.932,1160,5.72,1162,1.4,1170,2.915,1197,2.374,1208,2.915,1216,2.108,1283,3.573,1322,2.374,1443,3.694,1470,1.892,1484,2.12,1513,1.932,1536,4.585,1557,2.649,1620,1.719,1622,3.365,1669,2.02,1722,2.545,1751,3.694,1791,5.577,1807,4.168,1809,3.831,1811,4.387,1815,3.986,1835,4.794,1840,5.983,1841,3.34,1842,3.34,1843,3.34,1844,2.545,1845,2.915,1846,3.34,1847,3.34,1848,5.869,1849,3.34,1850,3.34,1851,3.986,1852,6.295,1853,2.545,1854,6.725,1855,3.34,1856,3.34,1857,3.34,1858,3.34,1859,3.34,1860,5.869,1861,6.725,1862,3.096,1863,3.34,1864,3.34,1865,3.34,1866,3.096,1867,5.604,1868,3.694,1869,2.649,1870,5.027,1871,3.34,1872,3.34,1873,3.34,1874,4.168,1875,3.34,1876,2.915,1877,2.915,1878,5.027,1879,5.027,1880,3.34,1881,3.34,1882,5.027,1883,5.027,1884,5.027,1885,5.027,1886,2.649,1887,2.649,1888,2.455,1889,2.374,1890,4.168,1891,3.34,1892,3.34,1893,3.34,1894,3.34,1895,3.34,1896,3.34,1897,3.34,1898,3.34,1899,3.34,1900,3.34,1901,2.915]],["title/Chap_3.html#problems",[142,0.731]],["text/Chap_3.html#problems",[]],["title/Chap_3.html#problem-31",[142,0.6,1809,3.817]],["text/Chap_3.html#problem-31",[64,3.423,108,1.074,267,4.1,373,2.557,394,1.795,468,2.689,489,2.872,1228,3.939,1338,3.864,1902,7.237,1903,7.237,1904,6.71,1905,7.836,1906,7.237,1907,7.237,1908,7.237,1909,7.237,1910,7.237,1911,7.237,1912,7.237,1913,7.237,1914,7.237,1915,7.237,1916,7.237,1917,7.237,1918,7.237,1919,7.237,1920,7.237]],["title/Chap_3.html#problem-32",[142,0.6,1811,4.371]],["text/Chap_3.html#problem-32",[11,0.42,53,2.661,64,3.313,101,2.757,108,1.04,136,2.78,143,1.757,286,1.795,373,2.475,448,2.897,464,2.98,468,3.081,489,3.505,501,3.429,641,1.401,761,2.386,1228,3.813,1310,3.606,1344,3.672,1620,3.606,1653,4.447,1921,7.006,1922,4.447,1923,7.006,1924,7.006,1925,7.006,1926,7.006,1927,7.006,1928,7.006,1929,7.006]],["title/Chap_3.html#problem-33",[142,0.6,1815,3.972]],["text/Chap_3.html#problem-33",[1,1.402,104,3.199,105,1.373,108,1.169,109,3.124,240,1.971,286,1.649,313,4.027,340,2.904,394,1.954,447,4.027,468,3.164,489,3.379,493,1.754,573,3.502,626,2.554,627,3.093,632,3.45,667,3.502,983,2.86,1228,3.503,1283,6.054,1310,4.055,1651,5.104,1714,3.199,1904,5.967,1905,5.967,1930,6.436,1931,6.436,1932,6.436,1933,6.436,1934,8.516,1935,7.879,1936,6.436,1937,8.516,1938,6.754,1939,6.436,1940,6.436,1941,7.895,1942,6.436,1943,6.436,1944,6.436,1945,6.436,1946,6.436,1947,6.436,1948,6.436,1949,7.879,1950,6.436,1951,6.436]],["title/Chap_3.html#problem-34",[142,0.6,1835,3.972]],["text/Chap_3.html#problem-34",[19,1.305,57,4.747,127,2.527,240,2.11,259,2.061,382,2.848,394,1.708,412,1.835,440,2.974,493,1.533,587,2.086,761,2.346,799,3.061,830,3.483,858,2.83,963,2.77,966,3.423,983,3.648,1076,3.483,1310,3.545,1952,6.01,1953,4.611,1954,6.887,1955,6.887,1956,6.887,1957,6.887,1958,6.887,1959,6.887,1960,6.887,1961,6.887,1962,6.887,1963,6.887,1964,6.887,1965,6.887,1966,6.887,1967,6.887,1968,6.887,1969,6.887,1970,6.887,1971,6.887,1972,6.887]],["title/Chap_3.html#problem-35",[142,0.6,1848,4.371]],["text/Chap_3.html#problem-35",[11,0.385,19,1.302,34,1.104,99,1.122,240,2.105,321,2.841,337,1.273,412,1.657,440,2.97,448,3.751,562,5.827,587,2.482,597,1.947,797,4.958,799,3.054,858,3.02,966,3.415,1019,4.847,1283,6.59,1344,4.296,1867,7.599,1874,5.697,1973,8.197,1974,8.197,1975,6.871,1976,6.871]],["title/Chap_3.html#problem-36",[142,0.6,1860,4.371]],["text/Chap_3.html#problem-36",[11,0.326,35,2.536,68,3.62,240,2.269,259,1.74,311,2.434,412,1.497,446,1.983,477,3.56,587,2.243,811,3.697,852,4.587,858,2.554,928,6.09,1848,6.464,1860,6.464,1977,7.407]],["title/Chap_3.html#problem-37",[142,0.6,1874,4.153]],["text/Chap_3.html#problem-37",[11,0.368,19,1.347,53,2.282,99,0.973,105,1.517,185,4.205,211,2.86,240,2.723,259,1.966,292,4.028,337,1.104,393,2.86,412,1.437,446,1.904,682,4.088,799,3.161,858,2.884,966,3.534,982,4.901,1838,6.206,1839,6.206,1953,4.761,1978,5.897,1979,4.761,1980,7.111,1981,7.111,1982,7.111,1983,7.111,1984,7.111,1985,7.111]],["title/Chap_3.html#problem-38",[142,0.6,868,4.153]],["text/Chap_3.html#problem-38",[31,2.486,101,2.083,107,2.16,108,1.385,111,2.827,114,4.112,213,3.79,240,1.919,270,2.214,286,2.359,296,2.214,321,3.205,330,2.486,359,2.389,373,2.214,378,2.827,394,2.314,412,1.266,433,2.744,440,2.27,447,2.963,468,2.328,489,2.486,561,2.627,661,3.789,738,3.88,775,4.082,843,4.58,883,3.705,928,4.454,930,4.583,983,2.785,1094,6.413,1162,3.25,1165,3.397,1228,3.41,1515,3.705,1886,6.973,1986,6.266,1987,7.75,1988,6.266,1989,7.75,1990,6.266,1991,6.266,1992,6.266,1993,6.266,1994,6.266,1995,6.266,1996,6.266,1997,6.266,1998,6.266,1999,6.266]],["title/Chap_3.html#problem-39",[142,0.6,2000,5.008]],["text/Chap_3.html#problem-39",[11,0.386,101,2.29,107,2.374,108,1.022,114,4.285,138,2.404,220,3.108,228,4.486,240,2.11,304,3.749,330,2.733,332,2.495,358,1.844,412,1.392,429,2.972,464,2.929,468,2.559,489,2.733,493,1.533,501,3.394,528,3.545,574,3.257,661,2.888,795,2.733,893,3.902,930,4.072,1051,3.366,1165,2.661,1607,3.823,1620,3.545,1653,4.372,1886,6.51,1922,4.372,2001,6.044,2002,6.887,2003,6.887,2004,6.887,2005,6.887,2006,6.887,2007,6.887]],["title/Chap_3.html#problem-310",[142,0.6,2008,5.008]],["text/Chap_3.html#problem-310",[2,0.729,11,0.414,19,0.879,31,3.107,35,1.374,43,3.199,53,1.489,91,1.284,95,1.562,100,3.113,104,3.167,106,1.489,108,1.218,109,3.011,110,1.703,127,1.703,139,3.686,142,0.763,153,1.229,158,2.16,169,0.908,196,2.478,216,3.555,223,3.468,224,4.262,232,4.527,240,2.399,259,1.84,277,2.094,279,1.66,281,2.094,289,2.003,311,1.525,313,2.195,321,2.634,327,1.974,344,2.003,358,1.243,359,1.77,362,2.629,363,2.389,377,3.023,389,2.347,429,3.379,440,1.681,468,2.368,477,2.231,489,2.528,493,1.033,528,2.389,573,2.832,597,1.102,623,2.807,626,3.107,627,3.764,632,2.79,641,1.455,650,3.411,653,3.023,658,3.107,668,2.807,706,3.026,713,3.299,728,1.919,740,3.023,758,3.411,761,1.581,778,3.411,781,4.15,782,3.199,787,3.023,793,3.199,794,3.199,852,4.849,857,2.127,858,2.197,930,2.744,965,3.199,985,4.265,1019,2.744,1029,3.023,1041,4.044,1214,3.411,1216,1.946,1234,2.874,1255,3.681,1269,3.199,1270,2.629,1271,5.053,1272,3.107,1275,5.77,1310,2.389,1563,4.05,1564,4.05,1565,4.05,1566,4.05,1567,3.681,1568,3.681,1706,3.411,1795,2.629,1808,3.411,1862,4.303,1866,4.303,1874,3.849,1941,4.303,2009,4.05,2010,6.494,2011,7.275,2012,4.641,2013,4.641,2014,4.641,2015,4.641,2016,4.641,2017,6.672,2018,6.21,2019,7.275,2020,7.275,2021,4.641,2022,6.371,2023,4.683,2024,4.641,2025,7.275,2026,4.05,2027,6.371,2028,4.05,2029,4.641,2030,4.641,2031,6.371,2032,6.371,2033,4.641,2034,4.641,2035,4.641,2036,4.641,2037,4.641,2038,4.641,2039,4.641,2040,4.641,2041,4.641,2042,4.641,2043,2.807,2044,3.199,2045,3.681,2046,3.681,2047,3.199,2048,3.411,2049,4.641]],["title/Chap_4.html",[108,0.547,188,1.663,597,0.875,1217,2.006]],["text/Chap_4.html",[0,2.114,1,1.563,2,1.046,3,0.971,6,1.449,7,0.835,8,1.06,11,0.435,15,0.571,17,1.353,19,1.297,20,0.423,25,1.145,31,2.009,32,0.885,34,1.036,35,1.103,37,0.312,39,1.362,40,0.939,47,0.83,48,2.217,49,0.994,53,1.476,54,0.705,59,1.385,64,2.176,65,0.373,66,0.557,68,0.705,77,0.356,88,1.406,91,1.12,95,1.134,99,0.949,100,0.988,101,0.48,105,1.296,106,1.082,107,0.871,108,1.029,109,0.529,110,1.857,111,1.342,114,0.38,115,1.1,120,0.4,122,0.431,123,0.55,126,0.853,127,1.367,130,0.592,132,1.393,133,1.324,134,0.912,136,0.802,137,0.481,138,1.177,139,0.449,142,0.712,143,0.845,148,0.926,151,0.971,152,0.853,153,1.072,155,0.614,156,0.535,157,0.894,158,0.941,161,0.47,169,1.499,170,1.349,185,2.564,188,0.35,190,0.678,195,1.735,196,1.079,198,1.606,199,0.616,210,1.1,211,2.594,214,1.394,216,0.705,220,1.14,223,0.423,224,1.1,228,0.506,232,1.079,240,1.24,241,0.916,242,0.894,247,0.52,253,1.075,256,1.732,257,0.616,259,1.63,263,0.571,264,0.756,265,0.571,266,1.594,267,1.431,276,0.4,277,0.651,279,0.723,281,0.912,282,0.535,283,1.072,285,0.933,286,1.975,287,1.845,288,1.213,289,1.283,291,0.817,293,0.916,295,0.835,296,1.051,304,0.785,305,1.03,309,0.77,310,1.176,311,0.474,316,0.748,318,1.884,319,2.39,321,1.045,322,0.34,323,1.479,325,0.82,327,0.614,329,0.813,330,1.825,332,0.732,335,2.579,336,0.73,337,1.356,339,0.73,341,0.386,344,0.335,348,1.551,354,1.022,355,1.152,356,1.458,358,1.506,359,0.55,362,0.817,363,0.743,366,0.743,369,0.682,371,0.361,372,0.449,373,1.43,374,1.222,378,0.651,379,1.754,382,2.568,389,1.278,391,1.022,393,1.499,394,2.059,395,0.743,404,0.989,409,1.592,411,1.349,412,1.102,416,1.789,427,0.885,429,1.09,430,1.991,431,3.028,432,0.694,433,2.015,440,2.571,441,0.616,442,0.431,443,0.431,444,1.485,445,0.535,446,1.695,447,1.406,448,1.045,449,0.38,450,1.001,452,0.916,453,1.333,454,0.571,456,1.169,457,1.431,462,1.195,464,0.33,474,1.144,477,1.429,479,1.1,481,1.1,487,0.386,488,1.588,493,1.253,496,0.481,500,2.411,505,0.976,507,2.004,514,0.423,515,1.1,523,0.616,525,0.431,528,1.301,532,0.493,533,0.552,534,0.506,535,0.535,537,0.824,538,0.552,540,0.317,549,1.064,550,1.434,551,0.35,560,0.73,561,0.326,567,1.651,569,0.44,571,1.169,572,0.481,573,0.345,579,1.349,580,0.52,581,1.026,584,0.52,586,1.283,587,0.612,593,0.873,595,1.251,597,1.943,600,0.853,601,0.449,608,0.651,617,1.145,623,0.47,626,0.573,633,0.386,637,0.44,639,0.431,640,0.94,641,1.616,642,0.535,643,0.571,651,0.813,654,0.407,655,0.678,657,2.81,658,0.966,661,1.06,666,0.423,667,1.322,668,0.47,670,0.966,672,0.853,674,0.94,675,1.278,676,0.373,677,0.52,678,0.506,682,1.453,684,0.386,685,1.429,687,0.571,689,0.77,706,1.149,708,0.459,709,0.431,713,0.552,728,1.541,729,0.873,731,0.894,734,0.493,735,0.493,739,1.588,740,0.506,749,0.966,752,1.799,756,0.481,757,0.552,758,0.571,761,1.724,762,0.415,765,0.801,773,0.941,779,0.571,780,0.571,781,1.316,782,0.994,783,2.204,784,0.52,795,1.18,799,1.322,801,1.079,802,1.004,810,1.796,811,0.335,815,2.393,817,0.873,818,0.552,819,1.324,821,0.506,828,0.994,830,2.046,843,0.423,845,0.47,846,1.799,852,0.481,857,1.158,858,2.584,861,4.124,862,3.062,863,2.866,865,2.649,866,0.616,880,1.283,881,1.485,882,0.571,883,0.459,886,1.852,891,0.894,893,1.431,897,1.437,899,1.462,907,0.873,919,0.756,920,1.222,927,2.97,928,0.552,929,0.571,931,0.916,932,0.916,936,0.571,944,0.994,946,0.571,947,2.119,953,0.552,959,0.423,963,2.193,965,0.535,966,1.256,968,0.493,969,0.449,970,0.459,972,0.52,982,0.994,983,1.498,985,1.692,990,0.616,1001,0.592,1003,1.588,1005,2.14,1014,1.349,1017,0.571,1022,0.835,1024,1.559,1029,0.94,1033,0.493,1034,0.971,1038,0.644,1041,0.493,1042,0.571,1051,1.453,1062,0.35,1076,0.73,1085,0.552,1089,1.169,1093,1.494,1130,0.678,1134,1.169,1162,1.697,1165,1.676,1175,4.012,1176,2.396,1189,0.52,1190,0.678,1191,0.94,1198,2.004,1199,0.994,1200,1.06,1201,3.439,1202,1.196,1214,1.06,1216,1.414,1217,0.785,1221,1.251,1222,0.47,1225,1.565,1230,2.912,1234,0.481,1242,0.449,1247,1.857,1255,0.616,1258,0.552,1261,0.678,1263,0.506,1269,0.535,1270,1.431,1271,1.144,1272,0.52,1277,0.506,1280,0.894,1294,0.678,1299,1.1,1302,0.644,1303,0.678,1315,0.916,1344,0.407,1353,0.52,1366,0.535,1374,1.145,1377,0.571,1387,0.616,1418,1.437,1419,1.259,1427,1.1,1428,0.678,1429,0.571,1436,0.966,1445,0.678,1463,0.592,1478,1.494,1482,1.796,1483,0.481,1484,0.493,1533,1.196,1536,0.44,1557,1.144,1567,0.616,1568,0.616,1577,1.026,1578,1.764,1594,0.571,1598,0.52,1607,0.801,1609,1.926,1611,0.616,1622,0.966,1637,1.353,1641,0.592,1654,1.565,1657,1.196,1666,0.616,1669,0.873,1670,0.966,1671,0.644,1688,0.616,1706,0.571,1714,1.256,1717,0.571,1718,0.552,1719,0.571,1729,1.026,1751,1.857,1756,0.616,1774,0.571,1780,0.916,1791,1.741,1795,0.44,1814,0.571,1840,2.789,1845,0.678,1853,2.569,1876,0.678,1877,1.259,1886,1.144,1887,0.616,1888,0.571,1889,2.114,1890,1.196,1938,1.144,1952,0.678,1953,3.389,1978,1.196,1979,0.52,2009,0.678,2023,0.571,2043,0.873,2044,0.535,2047,0.535,2048,0.571,2050,0.777,2051,0.777,2052,0.777,2053,1.1,2054,1.338,2055,2.021,2056,4.198,2057,0.777,2058,2.343,2059,2.185,2060,0.777,2061,0.777,2062,0.777,2063,0.777,2064,0.777,2065,1.443,2066,2.205,2067,0.777,2068,1.443,2069,0.678,2070,3.252,2071,1.443,2072,2.466,2073,0.777,2074,0.777,2075,0.777,2076,0.994,2077,0.678,2078,0.777,2079,0.777,2080,3.209,2081,1.764,2082,0.777,2083,1.443,2084,2.021,2085,0.571,2086,0.873,2087,2.595,2088,0.616,2089,0.678,2090,0.777,2091,0.777,2092,0.777,2093,2.004,2094,0.777,2095,0.777,2096,0.777,2097,1.676,2098,0.777,2099,1.603,2100,0.777,2101,0.777,2102,3.09,2103,1.926,2104,0.777,2105,0.777,2106,1.144,2107,2.021,2108,1.353,2109,2.595,2110,0.966,2111,0.777,2112,2.877,2113,0.644,2114,0.678,2115,0.678,2116,1.283,2117,0.777,2118,0.777,2119,1.338,2120,0.777,2121,0.777,2122,3.785,2123,0.777,2124,0.777,2125,0.535,2126,1.338,2127,0.777,2128,0.777,2129,1.764,2130,1.338,2131,0.777,2132,1.764,2133,1.437,2134,0.777,2135,2.343,2136,0.777,2137,1.338,2138,1.338,2139,0.777,2140,0.777,2141,0.777,2142,0.777,2143,0.777,2144,0.777,2145,0.777,2146,0.777,2147,2.205,2148,1.443,2149,1.338,2150,0.777,2151,0.777,2152,0.777,2153,0.777,2154,0.777,2155,0.777,2156,0.777,2157,0.777,2158,0.616,2159,0.678,2160,0.777,2161,0.678,2162,0.777,2163,0.777,2164,0.777,2165,2.205,2166,1.443,2167,1.338,2168,0.777,2169,0.777,2170,0.777,2171,0.777,2172,0.777,2173,1.443,2174,1.443,2175,1.443,2176,0.777,2177,0.777,2178,0.777,2179,0.777,2180,0.777,2181,0.777,2182,1.338,2183,0.777,2184,0.777,2185,0.777,2186,0.506,2187,0.777,2188,1.196,2189,3.532,2190,0.777,2191,0.592,2192,1.764,2193,1.026,2194,3.371,2195,2.527,2196,0.678,2197,0.592,2198,0.592,2199,0.678,2200,0.777,2201,0.616,2202,0.777,2203,1.259,2204,1.443,2205,0.777,2206,0.777,2207,0.678,2208,1.443,2209,1.443,2210,1.443,2211,0.777,2212,0.777,2213,0.592,2214,0.777,2215,2.021,2216,2.021,2217,1.338,2218,0.777,2219,0.678,2220,0.777,2221,0.592,2222,0.644,2223,0.678,2224,0.777,2225,0.777,2226,0.777,2227,0.777,2228,0.678,2229,0.571,2230,0.777,2231,0.777,2232,0.777,2233,0.552,2234,0.678,2235,0.777,2236,0.678,2237,0.777,2238,0.678,2239,0.571,2240,0.678,2241,1.06,2242,1.796,2243,1.338,2244,1.888,2245,0.777,2246,0.777,2247,0.777,2248,0.678,2249,3.455,2250,0.777,2251,1.485,2252,1.874,2253,0.777,2254,0.777,2255,0.777,2256,0.777,2257,1.857,2258,0.777,2259,0.777,2260,0.777,2261,0.678,2262,0.777,2263,0.777,2264,1.196,2265,1.874,2266,0.777,2267,0.777,2268,0.777,2269,1.443,2270,0.777,2271,0.777,2272,0.777,2273,0.777,2274,0.777,2275,0.777,2276,1.443,2277,0.552,2278,1.764,2279,0.678,2280,0.777,2281,1.06,2282,0.678,2283,1.144,2284,0.777,2285,0.873,2286,0.873,2287,0.966,2288,1.926,2289,0.678,2290,0.678,2291,0.777,2292,0.777,2293,0.777,2294,0.777,2295,1.338,2296,1.338,2297,0.777,2298,0.777,2299,1.443,2300,0.777,2301,1.259,2302,0.678,2303,0.777,2304,0.777,2305,0.777,2306,0.777,2307,2.527,2308,0.644,2309,2.021,2310,0.777,2311,1.764,2312,2.527,2313,1.144,2314,1.443,2315,0.777,2316,1.144,2317,0.777,2318,0.777,2319,0.777,2320,1.144,2321,2.021,2322,0.777,2323,1.764,2324,0.44,2325,0.777,2326,0.777,2327,2.021,2328,0.777,2329,0.777,2330,0.777,2331,0.777,2332,0.777,2333,0.777,2334,0.777,2335,0.777,2336,0.777,2337,0.678,2338,0.678,2339,0.52,2340,1.443,2341,0.777,2342,0.777,2343,0.777,2344,0.777,2345,0.777,2346,0.777,2347,2.974,2348,1.443,2349,0.777,2350,0.777,2351,0.678,2352,0.777,2353,1.443,2354,1.443,2355,0.777,2356,0.777,2357,0.535,2358,0.644,2359,0.592,2360,0.678,2361,0.777,2362,0.777,2363,1.443,2364,0.678,2365,0.777,2366,0.644,2367,1.443,2368,0.678,2369,0.777,2370,0.678,2371,0.678,2372,0.678,2373,0.616,2374,0.678,2375,0.678,2376,0.678,2377,0.571,2378,0.616,2379,0.616,2380,0.777,2381,0.777,2382,0.678,2383,0.678,2384,0.678,2385,0.678,2386,0.678,2387,0.777,2388,0.777]],["title/Chap_4.html#characterization-of-random-signals",[108,0.63,597,1.009,1217,2.311]],["text/Chap_4.html#characterization-of-random-signals",[2,1.092,11,0.306,15,5.111,59,2.584,105,1.483,106,2.649,108,1.307,157,4.307,196,3.713,198,2.76,211,3.321,224,3.785,228,4.53,253,2.958,256,2.488,358,1.862,374,4.206,379,2.652,394,1.725,447,3.289,597,1.652,773,3.237,818,4.944,846,4.206,861,4.307,862,4.206,886,3.456,927,2.954,931,4.414,1162,2.916,1165,3.19,1714,3.456,1719,5.111,1780,4.414,1888,5.111,2050,6.955,2051,6.955,2052,6.955,2053,5.3]],["title/Chap_4.html#example-fair-chance",[105,0.906,185,2.511,2054,3.937]],["text/Chap_4.html#example-fair-chance",[1,2.049,11,0.435,19,0.942,25,1.407,31,2.65,35,1.472,39,1.674,47,1.634,48,2.178,53,1.596,59,1.848,64,3.565,95,2.247,99,0.914,105,1.061,108,0.738,134,2.244,143,1.247,153,1.317,158,2.315,185,3.948,211,2.686,256,1.779,259,1.771,266,2.352,283,1.317,286,2.218,296,1.757,310,2.315,330,2.65,337,1.171,355,1.132,358,1.788,359,1.897,371,2.315,379,1.897,389,2.515,394,2.282,429,2.146,431,2.882,432,2.391,433,2.178,440,2.419,446,1.332,528,2.56,579,3.566,580,3.33,597,1.181,641,0.995,685,3.21,709,2.761,731,3.08,828,3.428,843,2.707,852,3.08,858,2.778,861,5.359,862,4.56,927,2.883,932,4.239,1003,2.656,1162,2.8,1175,6.595,1270,3.783,1280,3.08,1366,3.428,1482,3.536,1688,3.944,1791,3.428,1840,3.428,1853,5.745,1889,3.536,2055,7.539,2056,7.176,2057,4.974,2058,6.191,2059,3.655,2060,4.974,2061,4.974,2062,4.974,2063,4.974,2064,4.974,2065,6.678,2066,4.341,2067,4.974,2068,6.678,2069,4.341,2070,5.828,2071,6.678,2072,5.537,2073,4.974,2074,4.974,2075,4.974]],["title/Chap_4.html#describing-the-ensemble-average",[53,1.363,927,1.519,1889,3.018]],["text/Chap_4.html#describing-the-ensemble-average",[0,2.59,1,0.794,2,1.175,6,2.009,7,2.108,11,0.424,19,1.482,25,1.031,31,2.785,32,1.595,34,0.585,35,2.078,37,1.465,48,2.787,59,1.354,64,2.536,68,1.78,88,2.536,91,1.008,95,1.226,99,0.499,105,1.497,107,1.256,108,0.541,110,1.968,111,1.644,120,1.875,126,2.154,127,2.335,130,2.776,134,1.644,142,0.643,148,2.457,158,1.696,169,1.245,170,1.945,188,1.644,198,1.446,211,3.514,214,2.631,220,2.42,224,1.983,240,1.95,241,3.404,256,1.919,259,1.991,264,2.811,265,2.678,266,3.01,283,0.965,286,1.374,305,1.486,309,1.945,310,1.696,311,1.762,318,2.175,319,1.272,321,1.506,332,1.32,337,0.566,355,0.829,362,2.064,363,1.875,372,2.108,374,2.204,379,1.389,382,2.217,389,1.842,393,2.157,394,1.856,409,1.247,412,1.084,429,1.572,431,3.966,432,1.751,433,3.074,440,2.543,441,2.889,447,3.32,452,2.313,453,1.303,456,3.103,457,2.064,477,2.578,487,1.811,488,2.864,493,1.194,500,1.909,534,2.373,535,2.511,550,1.55,567,2.977,571,2.108,587,1.103,595,2.256,597,2.047,608,1.644,641,1.694,643,2.678,654,1.909,661,2.249,672,2.154,682,1.78,685,1.751,687,2.678,689,2.864,735,2.313,749,2.439,752,2.384,761,2.548,802,1.811,817,3.244,846,3.849,857,1.669,858,2.922,863,3.821,882,2.678,907,2.204,927,3.126,936,2.678,985,4.7,1003,2.864,1017,2.678,1022,2.108,1029,2.373,1034,1.751,1051,1.78,1162,1.528,1214,2.678,1216,2.249,1217,1.983,1230,1.945,1234,2.256,1247,2.678,1374,2.064,1478,2.154,1536,2.064,1577,2.59,1607,2.022,1611,2.889,1654,3.941,1666,2.889,1671,3.021,1714,1.811,1780,2.313,1795,2.064,1840,2.511,1853,2.776,1886,4.253,1887,2.889,1889,2.59,1953,5.918,2076,2.511,2077,3.179,2078,3.643,2079,3.643,2080,5.567,2081,5.554,2082,3.643,2083,5.363,2084,6.364,2085,2.678,2086,2.204,2087,5.554,2088,2.889,2089,3.179,2090,3.643,2091,3.643,2092,3.643,2093,4.253,2094,3.643,2095,3.643,2096,3.643,2097,3.021,2098,3.643,2099,2.889,2100,3.643,2101,3.643,2102,5.278,2103,2.776,2104,3.643,2105,3.643,2106,2.889,2107,6.364,2108,2.439,2109,5.554,2110,2.439,2111,3.643,2112,3.163,2113,3.021,2114,3.179,2115,3.179,2116,2.313,2117,3.643,2118,3.643]],["title/Chap_4.html#example-average-experience",[48,1.859,105,0.906,927,1.519]],["text/Chap_4.html#example-average-experience",[0,4.992,2,1.103,11,0.428,31,2.787,48,3.075,77,3.218,211,2.825,256,2.513,335,2.335,337,1.419,379,2.678,382,2.904,433,3.075,515,5.352,523,5.57,752,3.122,927,2.513,1198,5.57,1840,4.84,1890,5.824,2109,6.129,2119,6.511,2120,7.023,2121,7.023,2122,7.717,2123,7.023,2124,7.023]],["title/Chap_4.html#other-averages",[927,2.184]],["text/Chap_4.html#other-averages",[11,0.436,105,1.37,110,2.356,169,1.257,259,1.509,286,1.645,318,2.934,335,2.948,337,1.413,356,1.663,382,2.655,394,1.593,395,3.305,427,2.812,440,2.326,500,4.648,507,5.092,597,1.525,713,4.564,761,2.187,773,2.989,883,3.797,927,2.815,982,4.425,1840,4.425,2112,3.191,2125,4.425,2126,5.953,2127,6.421,2128,6.421,2129,5.604,2130,5.953,2131,6.421,2132,5.604,2133,4.564,2134,6.421,2135,5.953,2136,6.421]],["title/Chap_4.html#example-dice-money",[105,0.786,809,3.417,1978,3.056,2137,3.417]],["text/Chap_4.html#example-dice-money",[0,3.267,2,1.137,6,1.811,7,2.659,11,0.435,31,2.872,35,1.873,39,2.13,40,1.708,48,3.17,65,2.209,66,1.776,95,1.547,99,0.866,105,1.544,106,1.475,108,1.157,110,2.322,111,2.074,115,3.503,142,0.551,169,0.899,185,3.742,190,4.011,256,2.264,259,1.701,276,2.366,281,2.074,286,1.998,305,1.874,310,2.139,321,1.9,335,2.593,337,1.421,348,1.408,355,1.046,356,1.191,358,1.694,366,2.366,379,2.413,382,2.617,393,1.849,394,1.795,409,1.683,412,1.463,440,3.062,446,2.19,488,3.379,493,1.023,500,4.087,514,2.502,597,2.008,608,2.074,617,2.604,641,1.635,667,2.813,670,3.077,728,1.9,761,1.565,765,2.551,802,2.284,821,2.994,858,2.182,861,3.919,862,3.828,865,3.267,880,2.917,891,2.846,927,2.79,969,2.659,982,3.168,1051,3.093,1085,3.267,1162,1.927,1198,5.019,1202,3.811,1247,4.651,1263,2.994,1418,3.267,1478,3.742,1567,3.645,1568,3.645,1637,3.077,1791,4.362,1840,4.362,1978,3.811,2054,4.261,2066,5.523,2080,3.645,2103,3.503,2106,3.645,2109,4.011,2112,3.145,2122,7.137,2130,4.261,2133,3.267,2135,6.711,2137,4.261,2138,4.261,2139,4.596,2140,4.596,2141,4.596,2142,4.596,2143,4.596,2144,4.596,2145,4.596,2146,4.596,2147,5.523,2148,6.329,2149,4.261,2150,4.596,2151,4.596,2152,4.596,2153,4.596,2154,4.596,2155,4.596,2156,4.596,2157,4.596,2158,3.645,2159,4.011,2160,4.596,2161,4.011,2162,4.596]],["title/Chap_4.html#properties-of-averaging",[927,1.792,1165,1.935]],["text/Chap_4.html#properties-of-averaging",[2,0.721,3,2.206,6,1.313,11,0.433,19,1.37,34,1.357,59,2.349,88,2.17,99,0.99,108,0.681,110,1.684,133,3.313,136,1.821,137,2.842,138,1.602,142,0.55,152,3.738,169,0.898,195,2.136,210,2.498,211,1.846,214,1.897,256,1.642,277,2.853,285,1.27,286,2.321,288,1.871,293,2.913,296,1.621,316,1.358,318,2.415,327,2.689,329,1.846,335,3.067,337,1.478,348,1.937,354,3.657,356,1.638,358,1.692,379,1.75,382,2.614,430,4.842,433,2.768,440,2.29,444,3.373,446,1.229,450,1.544,454,3.373,462,2.713,493,1.022,500,2.405,507,5.013,525,2.547,538,3.262,560,2.32,569,2.6,597,1.718,651,1.846,666,2.498,667,2.81,684,2.281,706,1.773,708,2.713,728,2.99,734,2.913,752,2.04,795,1.821,799,2.81,819,2.405,857,2.103,893,4.097,907,2.775,927,3.023,944,3.163,947,3.534,963,3.135,965,3.163,966,3.142,983,3.214,1001,3.497,1003,2.45,1005,2.913,1076,2.32,1165,2.794,1190,4.005,1216,1.924,1225,3.915,1230,3.376,1436,4.232,1484,2.913,1533,3.805,1609,5.511,1669,2.775,1756,3.639,2080,3.639,2087,4.005,2102,5.242,2112,2.281,2163,4.589,2164,4.589,2165,5.517,2166,6.322,2167,4.254,2168,4.589,2169,4.589,2170,4.589,2171,4.589,2172,4.589,2173,6.322,2174,6.322,2175,6.322,2176,4.589,2177,4.589,2178,4.589,2179,4.589,2180,4.589,2181,4.589,2182,4.254,2183,4.589]],["title/Chap_4.html#correlation-the-workhorse",[11,0.187,404,1.663,2184,4.246]],["text/Chap_4.html#correlation-the-workhorse",[2,1.079,31,2.726,53,2.63,108,1.02,110,2.521,153,1.819,169,1.714,195,4.223,279,2.933,281,3.1,358,1.839,446,1.839,505,1.988,560,3.474,597,1.947,617,4.644,641,1.814,661,2.881,672,4.062,731,4.255,819,3.601,865,4.884,927,2.933,931,4.361,959,3.739,972,4.6,1003,3.669,1034,3.302,1176,4.884,1221,5.076,1280,4.255,1577,4.884,2112,3.415,2185,6.871,2186,4.476,2187,6.871]],["title/Chap_4.html#autocorrelation",[505,1.767]],["text/Chap_4.html#autocorrelation",[11,0.415,198,2.773,259,1.642,319,2.89,330,2.773,335,2.753,337,1.286,348,2.141,356,1.81,394,1.733,409,1.625,416,2.193,440,3,488,3.732,505,2.023,597,1.967,641,1.764,761,2.38,858,2.409,865,4.968,929,5.136,970,4.132,1014,3.732,1089,4.043,1162,2.931,2188,5.795,2189,6.099,2190,6.989,2191,5.326,2192,6.099]],["title/Chap_4.html#the-mechanics-of-correlations",[404,1.961,2193,3.56]],["text/Chap_4.html#the-mechanics-of-correlations",[2,1.08,6,1.196,11,0.41,19,0.791,25,1.182,34,0.671,48,1.83,49,2.879,53,1.341,64,2.8,88,1.976,91,1.156,95,1.406,99,0.81,105,0.891,106,1.341,107,1.44,108,0.879,111,2.672,122,2.319,132,4.08,133,3.103,134,1.885,138,1.458,148,1.914,153,1.568,169,0.818,170,3.672,195,1.945,210,3.223,211,1.68,214,1.728,247,2.797,256,1.495,257,3.313,259,1.758,267,2.367,281,1.885,282,2.879,283,1.821,289,1.803,291,2.367,295,2.417,310,1.945,316,1.237,319,2.611,322,1.83,323,2.968,325,1.357,329,1.68,330,2.729,337,1.068,339,2.113,358,1.585,369,2.8,374,2.527,379,1.593,389,2.113,391,2.113,393,1.68,394,1.855,409,1.739,429,1.803,431,3.228,444,3.071,446,2.307,448,1.728,453,2.825,456,2.417,474,4.695,479,3.184,481,3.184,528,2.15,533,2.97,537,2.414,567,2.319,571,3.425,597,0.992,600,2.47,640,3.857,641,1.375,642,2.879,651,1.68,655,3.646,657,5.038,676,2.008,678,2.722,739,4.217,765,2.319,810,2.97,819,2.19,846,2.527,857,1.914,858,2.828,865,5.318,866,3.313,899,3.425,919,2.19,920,3.581,927,1.495,946,3.071,983,1.857,1014,2.231,1033,2.652,1034,2.008,1051,2.042,1062,1.885,1089,2.417,1093,2.47,1134,3.425,1176,5.614,1216,2.483,1221,2.587,1222,2.527,1230,4.68,1258,2.97,1277,2.722,1299,4.512,1302,3.465,1315,2.652,1374,2.367,1377,3.071,1387,3.313,1427,3.184,1463,3.184,1578,6.001,1714,2.076,1718,2.97,1729,4.209,1814,3.071,2009,3.646,2023,3.071,2093,3.313,2097,4.91,2103,3.184,2112,2.076,2116,3.758,2188,3.465,2194,8.201,2195,7.481,2196,3.646,2197,3.184,2198,3.184,2199,3.646,2200,4.178,2201,3.313,2202,4.178,2203,5.167,2204,5.921,2205,4.178,2206,4.178,2207,3.646,2208,5.921,2209,5.921,2210,5.921,2211,4.178,2212,4.178,2213,3.184,2214,4.178,2215,6.877,2216,6.877,2217,3.874,2218,4.178,2219,3.646,2220,4.178,2221,3.184,2222,3.465,2223,3.646,2224,4.178,2225,4.178,2226,4.178,2227,4.178,2228,3.646,2229,3.071,2230,4.178,2231,4.178,2232,4.178,2233,2.97,2234,3.646,2235,4.178,2236,3.646,2237,4.178,2238,3.646,2239,3.071,2240,3.646]],["title/Chap_4.html#auto-covariance",[2241,3.681,2242,3.56]],["text/Chap_4.html#auto-covariance",[6,2.005,11,0.423,99,0.959,142,0.839,286,1.795,319,2.894,321,2.897,335,2.329,337,1.288,348,2.146,356,1.815,416,2.196,450,2.358,550,2.98,801,4.428,919,3.672,1533,5.809,1641,5.339,1657,5.809,2102,5.809,2129,6.114,2189,7.237,2192,6.114,2241,5.149,2242,4.98,2243,6.495,2244,4.447,2245,7.006,2246,7.006,2247,7.006]],["title/Chap_4.html#cross-correlation",[404,1.961,411,2.674]],["text/Chap_4.html#cross-correlation",[11,0.424,34,1.142,106,2.282,108,1.055,286,1.822,319,2.92,335,2.782,337,1.299,348,2.178,356,1.842,373,2.513,404,2.784,411,3.797,416,2.215,446,1.904,462,4.946,1353,4.761,2147,6.206,2149,6.593,2248,6.206,2249,6.593,2250,7.111,2251,5.226,2252,6.593]],["title/Chap_4.html#cross-covariance",[411,2.674,2242,3.56]],["text/Chap_4.html#cross-covariance",[0,3.889,1,1.192,11,0.433,25,1.548,54,2.673,99,1.145,108,0.812,110,2.007,111,2.469,153,1.449,169,1.071,198,2.171,259,1.285,286,2.025,319,3.265,323,2.171,325,1.776,335,2.955,336,3.596,337,1.425,348,1.676,356,2.047,359,2.086,373,1.933,389,2.766,394,2.245,409,1.837,411,2.921,412,1.106,416,2.51,427,3.114,440,1.982,446,1.465,449,2.673,450,1.841,550,2.327,551,2.469,623,3.309,641,1.094,677,3.663,728,2.262,729,3.309,815,3.235,963,2.2,1038,4.537,1657,4.537,1706,4.021,2102,4.537,2112,2.719,2147,4.774,2189,7.568,2192,4.774,2242,3.889,2244,5.31,2249,8.241,2251,5.227,2252,6.593,2253,5.471,2254,5.471,2255,5.471,2256,5.471,2257,4.021,2258,5.471,2259,5.471,2260,5.471,2261,4.774,2262,5.471,2263,5.471]],["title/Chap_4.html#example-is-that-coin-fair",[105,0.906,185,2.511,861,2.63]],["text/Chap_4.html#example-is-that-coin-fair",[1,1.93,2,0.734,3,2.245,6,1.337,11,0.432,19,0.885,34,0.751,48,2.046,95,1.572,99,0.876,105,0.996,107,1.611,108,1.221,110,1.714,126,2.762,127,1.714,136,1.854,142,0.56,151,3.509,153,1.237,169,1.252,185,2.762,198,1.854,211,1.879,214,1.932,220,2.108,240,1.431,242,2.893,259,1.098,279,1.671,285,2.173,286,1.64,289,2.762,296,2.261,304,2.543,305,1.905,321,1.932,323,1.854,335,2.735,337,1.351,348,1.96,355,1.661,356,1.658,366,2.405,373,2.261,391,3.236,393,2.936,409,1.975,412,1.294,416,2.079,429,2.016,431,2.016,493,1.04,505,1.352,507,3.705,528,2.405,540,1.905,549,2.612,567,2.593,572,2.893,579,3.417,593,2.826,597,1.734,626,1.854,633,2.322,641,1.57,668,2.826,675,3.691,706,2.473,729,2.826,752,2.845,761,1.591,801,2.495,815,2.762,858,2.206,861,4.863,862,3.871,863,4.734,880,2.965,893,2.647,899,2.703,927,2.612,963,2.574,1005,4.062,1014,3.417,1022,2.703,1134,2.703,1162,1.959,1175,5.563,1315,2.965,1428,4.077,1482,4.549,1669,2.826,1714,2.322,1791,3.22,2043,2.826,2056,6.054,2070,5.585,2072,3.874,2103,3.56,2110,3.128,2112,2.322,2132,4.077,2133,3.321,2182,4.331,2257,3.433,2264,3.874,2265,4.331,2266,4.672,2267,4.672,2268,4.672,2269,6.4,2270,4.672,2271,4.672,2272,4.672,2273,4.672,2274,4.672,2275,4.672,2276,6.4,2277,3.321,2278,6.371,2279,4.077,2280,4.672,2281,3.433,2282,4.077,2283,3.705]],["title/Chap_4.html#describing-the-time-average",[53,1.363,641,0.849,927,1.519]],["text/Chap_4.html#describing-the-time-average",[2,0.892,11,0.437,31,2.253,32,2.487,40,2.11,59,2.11,64,3.445,108,0.843,169,1.717,253,2.415,286,2.174,287,2.415,288,2.315,291,3.217,318,2.257,325,1.844,335,2.422,337,1.131,348,1.739,356,1.471,373,2.006,394,2.264,409,1.972,416,1.504,443,3.152,446,1.52,448,2.348,496,3.516,505,1.643,549,2.031,581,4.036,584,3.801,593,3.434,597,2.015,641,1.697,752,2.524,761,1.934,815,5.017,927,3.308,928,4.036,944,3.913,1216,2.381,1429,4.173,1483,3.516,1557,5.777,1889,5.178,2059,5.354,2284,5.678,2285,4.406,2286,4.406,2287,4.877,2288,5.551,2289,4.955,2290,4.955,2291,5.678,2292,5.678,2293,5.678,2294,5.678,2295,5.264,2296,5.264]],["title/Chap_4.html#the-ergodic-process",[169,0.98,287,2.13]],["text/Chap_4.html#the-ergodic-process",[1,1.19,2,1.116,11,0.432,19,1.034,34,1.392,49,3.763,54,2.668,64,2.582,91,1.966,108,0.81,115,4.161,136,2.167,138,2.918,157,3.381,169,1.739,198,2.167,242,3.381,266,3.359,283,2.09,286,2.023,287,3.686,288,2.227,289,2.356,341,2.714,348,1.673,356,1.415,358,2.238,362,3.093,373,1.929,394,2.203,409,1.651,412,1.436,416,1.446,433,2.391,448,2.258,450,1.837,453,1.954,457,3.093,493,1.581,505,1.58,528,2.81,537,2.227,549,1.954,567,3.031,597,1.297,600,3.229,641,1.578,661,2.29,670,3.656,728,2.258,752,2.427,795,2.167,810,3.882,815,4.2,819,2.862,858,1.883,861,4.398,862,3.303,927,2.824,968,3.466,1024,4.137,1042,4.013,1051,2.668,1089,3.159,1093,3.229,1165,2.11,1242,3.159,1445,4.765,1598,3.656,1607,3.031,1876,4.765,1877,6.198,2058,6.585,2059,5.22,2112,3.53,2288,5.413,2295,5.062,2296,5.062,2297,5.46,2298,5.46,2299,7.103,2300,5.46,2301,6.198,2302,4.765]],["title/Chap_4.html#problems",[142,0.731]],["text/Chap_4.html#problems",[]],["title/Chap_4.html#problem-41",[142,0.6,1853,3.817]],["text/Chap_4.html#problem-41",[0,5.067,11,0.391,25,2.017,53,2.288,99,0.976,106,2.288,240,2.566,259,1.969,330,2.829,332,2.583,337,1.107,348,2.184,355,1.906,356,1.847,373,2.519,382,3.464,431,3.076,440,2.583,464,3.032,493,1.587,597,1.693,858,2.458,1162,2.989,1247,5.239,1637,4.772,1845,6.221,2303,7.129,2304,7.129,2305,7.129]],["title/Chap_4.html#problem-42",[142,0.6,2080,3.972]],["text/Chap_4.html#problem-42",[1,1.289,11,0.419,17,5.488,25,1.674,66,2.285,68,2.89,99,1.023,153,1.566,216,3.653,267,4.235,323,2.347,325,1.92,332,2.143,337,1.161,355,1.345,445,4.076,446,1.583,448,2.445,450,1.99,479,4.507,493,1.317,550,3.487,641,1.183,810,5.314,858,2.577,886,4.281,897,5.827,983,2.629,1189,3.959,1230,3.992,1303,5.161,1419,6.524,1751,6.33,1840,4.076,1938,5.929,2072,4.904,2257,5.494,2281,4.347,2306,5.914,2307,8.613,2308,4.904,2309,8.197,2310,5.914,2311,7.154,2312,8.613,2313,5.929,2314,7.476,2315,5.914,2316,5.929,2317,5.914,2318,5.914,2319,5.914,2320,5.929,2321,8.197,2322,5.914,2323,7.154,2324,3.35,2325,5.914,2326,5.914,2327,8.197,2328,5.914,2329,5.914,2330,5.914,2331,5.914,2332,5.914]],["title/Chap_4.html#problem-43",[142,0.6,2087,4.371]],["text/Chap_4.html#problem-43",[11,0.338,34,1.406,430,5.146,1225,4.76,2165,6.708]],["title/Chap_4.html#problem-44",[142,0.6,1198,3.972]],["text/Chap_4.html#problem-44",[11,0.395,19,1.733,32,2.679,34,1.337,40,2.838,91,1.693,105,1.305,142,0.733,196,3.266,240,2.339,253,3.248,296,2.162,304,3.33,329,2.461,355,1.392,382,3.605,395,3.149,412,1.237,430,4.096,440,3.158,493,1.7,586,3.593,587,1.853,597,2.071,637,3.466,728,2.529,783,4.922,802,3.04,811,2.64,830,4.409,845,3.7,858,2.109,880,3.883,927,2.732,947,4.26,953,4.349,963,3.507,1005,4.847,1024,3.206,1076,3.093,1093,3.617,1165,2.364,1191,3.985,1201,6.914,1594,4.496,1609,4.662,2165,5.339,2167,5.672,2333,6.118,2334,6.118,2335,6.118,2336,6.118,2337,5.339,2338,5.339,2339,4.096,2340,7.636,2341,6.118,2342,6.118]],["title/Chap_4.html#problem-45",[142,0.6,2126,4.643]],["text/Chap_4.html#problem-45",[11,0.314,19,1.587,39,2.399,99,0.976,101,2.37,169,1.856,286,1.827,337,1.107,382,2.948,394,1.768,431,3.076,597,1.693,667,3.168,706,2.754,783,5.429,830,3.605,858,2.458,947,4.094,963,2.867,1005,4.525,1201,5.653,1427,5.432,2112,4.164,2343,7.129]],["title/Chap_4.html#problem-46",[142,0.6,2129,4.371]],["text/Chap_4.html#problem-46",[11,0.34,34,1.242,1225,4.786,2243,7.165]],["title/Chap_4.html#problem-47",[142,0.6,2132,4.371]],["text/Chap_4.html#problem-47",[1,1.708,8,5.759,11,0.419,25,1.805,91,2.169,99,0.873,100,3.117,156,4.396,169,1.248,185,3.771,223,3.471,267,3.613,293,4.048,305,2.601,319,2.96,330,3.109,337,0.991,355,1.451,358,1.708,452,4.048,493,1.42,597,1.515,641,1.567,674,5.104,758,4.687,858,2.199,861,4.853,862,3.858,881,6.234,886,3.17,990,5.058,1041,4.048,1175,4.86,1418,5.57,1482,4.534,1637,4.27,2056,5.289,2070,7.402,2072,5.289,2112,3.17,2344,6.378,2345,6.378,2346,6.378,2347,9.081,2348,7.836,2349,6.378,2350,6.378,2351,5.566,2352,6.378,2353,7.836,2354,7.836,2355,6.378,2356,6.378]],["title/Chap_4.html#problem-48",[142,0.6,2138,4.643]],["text/Chap_4.html#problem-48",[2,1.106,11,0.366,39,3.078,101,2.341,109,2.583,127,3.051,139,4.073,169,1.627,285,1.948,287,2.995,373,2.488,493,1.568,532,4.469,561,2.952,573,3.129,597,1.672,641,1.77,675,3.56,761,2.398,762,3.759,795,2.794,1024,3.69,1093,4.163,1191,4.586,1622,5.568,1670,4.713,1774,5.174,2357,4.852,2358,5.838,2359,5.365,2360,6.144]],["title/Chap_4.html#problem-49",[142,0.6,1202,4.153]],["text/Chap_4.html#problem-49",[2,1.266,11,0.395,19,1.526,59,2.481,99,0.914,110,2.956,114,3.263,256,2.389,295,3.863,378,3.013,379,2.546,382,3.332,440,3.256,457,4.565,477,3.209,597,2.134,639,3.707,685,3.209,749,4.47,757,4.747,795,2.65,799,3.846,830,4.376,920,4.039,963,3.241,966,4.005,1199,5.553,1200,5.922,1201,7.127,1670,4.47,2053,5.088,2108,5.394,2361,6.677,2362,6.677,2363,8.058]],["title/Chap_4.html#laboratory-exercises",[47,1.646,143,1.256]],["text/Chap_4.html#laboratory-exercises",[]],["title/Chap_4.html#laboratory-exercise-41",[47,1.395,143,1.065,1853,3.236]],["text/Chap_4.html#laboratory-exercise-41",[1,1.751,6,1.902,11,0.395,48,2.91,53,2.133,91,1.839,99,0.909,100,3.248,108,0.986,110,2.438,123,2.534,143,1.666,153,1.76,155,2.827,158,3.093,185,3.93,211,3.232,256,2.378,263,4.884,288,3.276,316,1.967,330,2.637,355,1.512,379,2.534,394,2.279,597,1.579,641,1.329,651,2.673,685,3.194,756,4.116,858,2.291,861,5.689,862,4.86,863,3.617,886,3.303,891,4.116,1175,6.581,1890,5.511,2056,6.663,2217,6.162,2264,5.511,2265,7.449,2364,5.8,2365,6.646,2366,5.511]],["title/Chap_4.html#laboratory-exercise-42",[47,1.395,143,1.065,2080,3.367]],["text/Chap_4.html#laboratory-exercise-42",[2,0.828,3,2.532,6,1.508,11,0.419,19,1.314,20,2.867,25,1.491,53,2.226,88,2.491,99,0.949,100,2.574,105,1.124,107,1.816,108,1.03,109,1.933,123,2.009,127,1.933,132,3.631,143,1.321,155,2.241,161,3.186,169,1.518,195,2.452,196,2.813,198,2.753,199,4.178,220,2.377,224,2.867,232,4.142,259,1.238,287,2.241,289,2.273,309,2.813,316,1.56,319,1.839,337,0.818,339,2.664,344,2.273,363,2.712,378,2.377,382,2.869,394,1.924,412,1.568,431,2.273,433,2.307,440,1.909,442,2.924,444,3.872,477,3.335,481,4.015,493,1.545,515,4.015,581,3.745,586,2.994,587,1.595,595,4.297,597,1.251,601,3.048,626,2.091,641,1.387,658,4.645,682,4.029,706,2.036,740,3.432,761,1.794,773,2.452,779,3.872,780,3.872,781,5.054,782,4.782,784,3.527,795,2.091,828,3.631,857,2.414,858,2.392,863,2.867,899,3.048,983,2.342,1029,3.432,1130,4.598,1165,2.036,1214,3.872,1255,4.178,1261,4.598,1269,3.631,1270,3.931,1271,5.502,1272,3.527,1294,4.598,1344,2.761,1374,2.985,1478,3.115,1654,3.263,1717,3.872,1840,3.631,1952,4.598,1979,3.527,2043,3.186,2044,3.631,2047,3.631,2048,3.872,2066,4.598,2076,3.631,2086,3.186,2093,4.178,2099,5.502,2119,4.884,2122,4.598,2193,3.745,2283,4.178,2367,6.938,2368,4.598,2369,5.268,2370,4.598,2371,4.598,2372,4.598,2373,4.178,2374,4.598,2375,4.598,2376,4.598,2377,3.872,2378,4.178,2379,4.178,2380,5.268,2381,5.268,2382,4.598,2383,4.598,2384,4.598,2385,4.598,2386,4.598,2387,5.268,2388,5.268]],["title/Chap_5.html",[404,1.663,583,2.267,1051,2.075]],["text/Chap_5.html",[1,1.524,2,1.098,3,0.382,5,0.737,6,1.525,7,0.46,11,0.436,12,0.451,13,0.441,19,0.884,20,0.433,22,0.694,25,0.729,31,0.316,32,0.348,33,0.46,34,1.23,35,1.685,37,0.593,40,1.125,44,0.565,47,0.485,49,0.548,53,1.412,54,0.721,59,0.767,64,1.432,65,0.709,66,0.307,68,0.721,77,0.364,84,0.359,85,0.584,88,0.976,91,1.048,93,1.124,95,0.867,99,1.137,100,0.389,101,2.448,105,1.214,106,1.215,107,1.692,108,1.093,109,0.541,110,0.757,111,1.854,114,1.48,116,1.831,120,0.759,123,0.303,134,0.666,136,1.202,138,1.197,142,0.661,143,0.517,145,0.746,148,0.676,151,0.382,153,1.165,155,0.338,158,0.687,169,1.477,170,0.788,184,1.043,188,0.931,192,1.287,195,0.37,198,0.316,210,0.803,216,0.721,220,1.162,224,0.803,228,0.518,232,1.617,240,0.789,241,0.505,242,0.913,244,0.47,247,0.532,250,1.248,253,1.288,255,0.425,256,1.083,259,1.296,260,0.46,266,1.791,267,0.451,268,0.481,270,1.648,277,0.359,279,1.355,281,0.666,283,0.802,285,1.048,286,1.869,287,2.267,288,0.601,289,0.343,293,0.505,295,0.46,296,1.648,298,1.193,304,1.123,305,0.324,309,1.101,311,0.995,313,0.376,315,0.548,316,1.217,318,2.538,319,1.197,321,0.61,322,0.646,323,0.819,325,0.983,327,0.627,329,0.83,330,0.316,332,1.097,335,1.835,336,1.915,337,1.333,341,0.395,343,0.46,344,0.637,348,1.429,355,1.55,356,1.714,358,1.178,359,0.982,362,0.836,365,1.124,366,0.409,367,1.531,369,0.376,371,0.96,373,1.07,377,0.961,378,0.359,379,0.787,382,2.12,384,1.985,389,0.746,391,1.043,393,0.32,394,1.935,404,2.8,409,2.058,411,2.35,412,1.558,413,2.725,414,3.234,416,2.345,420,0.518,422,0.548,425,0.606,427,2.149,429,0.637,431,1.112,432,0.991,433,1.326,435,0.694,440,0.747,441,0.631,442,0.441,443,0.441,446,1.249,447,0.376,448,1.252,449,0.389,450,1.57,453,1.974,456,0.853,457,1.169,462,0.47,464,1.459,466,0.532,467,1.062,468,2.282,469,0.46,471,1.309,476,1.725,487,1.025,489,2.258,493,1.303,499,1.22,500,1.081,501,2.42,502,2.838,503,0.505,505,2.091,510,2.177,514,0.803,518,0.584,525,0.819,530,1.8,532,0.505,537,0.601,538,1.049,544,0.694,549,2.699,550,1.096,551,0.931,560,0.746,561,1.588,564,2.126,565,0.631,570,0.532,574,2.838,576,2.506,579,0.788,583,2.022,586,0.89,587,1.723,595,0.492,597,1.619,600,0.872,602,0.505,605,1.748,607,0.47,608,0.666,611,0.584,612,0.961,617,1.459,618,0.631,620,1.636,626,0.316,629,1.17,633,0.733,634,0.631,636,1.47,637,0.451,638,0.836,640,0.961,641,1.301,643,0.584,647,0.631,649,0.694,651,1.036,654,0.417,657,2.846,658,1.725,661,2.057,666,0.433,667,1.346,670,0.532,672,0.47,675,2.078,677,0.532,678,0.518,682,1.259,684,1.704,685,1.238,689,0.425,698,0.548,706,0.797,708,1.523,709,0.441,710,0.631,713,0.565,720,0.47,724,0.872,728,0.61,729,0.892,738,0.913,739,0.788,740,1.344,741,0.694,749,1.725,750,0.425,752,1.524,756,0.913,761,1.031,762,1.831,763,1.124,765,0.819,767,1.8,773,0.37,775,0.518,778,0.584,779,0.584,780,0.584,781,1.678,782,1.775,783,1.523,784,0.988,787,0.518,793,0.548,794,0.548,795,1.022,799,0.656,801,0.425,802,1.28,804,1.287,808,0.417,811,0.343,815,1.523,817,0.481,818,0.565,819,1.081,830,0.402,833,0.532,843,2.901,845,1.248,846,0.481,857,0.945,858,1.182,863,0.433,865,1.049,880,0.936,883,0.47,888,0.389,889,0.631,893,0.836,895,0.773,897,0.565,907,0.481,908,0.694,917,1.466,918,1.587,919,0.417,927,1.834,928,0.565,930,0.47,945,0.584,947,0.389,952,1.752,953,1.466,959,0.433,963,1.036,966,0.395,967,0.565,968,0.505,976,0.694,977,0.606,983,0.656,989,1.17,1003,0.425,1005,1.309,1012,0.631,1014,1.101,1017,0.584,1018,2.844,1019,0.47,1024,1.35,1033,0.505,1034,1.238,1050,0.659,1051,0.721,1056,2.191,1061,0.631,1062,0.931,1085,0.565,1089,0.46,1093,0.47,1094,1.572,1101,2.225,1134,0.46,1155,0.584,1162,0.865,1165,1.7,1176,3.128,1186,0.441,1191,1.344,1197,0.565,1200,0.584,1216,0.865,1221,0.492,1222,0.481,1225,0.913,1228,2.539,1230,0.425,1234,0.913,1242,0.853,1245,0.565,1258,0.565,1264,0.481,1270,0.836,1274,0.659,1276,0.694,1277,1.973,1278,1.287,1289,0.47,1293,3.912,1306,1.223,1310,0.759,1315,0.936,1316,0.584,1317,1.572,1322,0.565,1326,0.631,1328,0.548,1333,0.548,1338,0.425,1344,0.773,1347,0.532,1351,0.584,1352,0.584,1366,0.548,1374,1.169,1378,0.606,1422,1.017,1429,0.584,1442,0.694,1465,0.631,1483,1.595,1484,1.309,1488,1.084,1513,0.46,1514,0.584,1515,1.22,1521,0.606,1536,0.451,1577,0.565,1580,0.548,1581,0.694,1587,0.631,1596,1.287,1607,1.145,1620,2.265,1622,0.988,1628,0.565,1637,3.81,1651,0.631,1653,0.936,1654,0.913,1665,0.631,1669,0.892,1670,0.532,1687,2.248,1688,1.17,1692,0.694,1698,1.636,1700,0.548,1714,0.733,1718,0.565,1721,0.606,1729,1.049,1768,1.523,1795,0.451,1808,0.584,1813,0.631,1814,0.584,1827,1.084,1835,0.631,1851,1.17,1889,0.565,1901,0.694,1922,1.635,1979,0.988,2001,2.363,2017,0.584,2043,2.662,2044,1.422,2045,0.631,2046,0.631,2047,1.422,2048,1.516,2059,1.516,2069,1.287,2076,0.548,2085,1.084,2086,1.248,2088,0.631,2110,0.988,2112,0.395,2114,0.694,2115,0.694,2116,2.793,2125,0.548,2161,0.694,2186,0.518,2188,0.659,2191,2.308,2193,0.565,2197,0.606,2198,0.606,2199,0.694,2222,2.136,2223,0.694,2234,0.694,2236,0.694,2238,0.694,2239,1.084,2241,1.516,2242,1.831,2244,2.961,2248,0.694,2251,1.084,2261,1.287,2278,0.694,2282,0.694,2283,1.17,2285,2.291,2286,2.291,2287,0.988,2288,1.572,2289,0.694,2290,0.694,2301,0.694,2313,1.17,2316,0.631,2337,0.694,2339,0.988,2382,0.694,2383,1.287,2384,1.287,2385,1.287,2386,0.694,2389,3.408,2390,4.365,2391,0.694,2392,0.795,2393,0.659,2394,2.087,2395,1.368,2396,2.043,2397,0.795,2398,0.795,2399,2.308,2400,2.784,2401,2.063,2402,1.223,2403,2.043,2404,0.795,2405,0.795,2406,0.694,2407,0.795,2408,0.795,2409,1.084,2410,0.659,2411,0.795,2412,0.659,2413,0.795,2414,1.368,2415,1.466,2416,0.694,2417,1.223,2418,2.136,2419,1.636,2420,0.795,2421,0.795,2422,1.963,2423,4.42,2424,4.942,2425,0.795,2426,2.063,2427,1.475,2428,0.694,2429,0.795,2430,0.795,2431,2.027,2432,0.795,2433,0.795,2434,1.8,2435,0.795,2436,0.795,2437,0.795,2438,0.795,2439,0.795,2440,0.795,2441,0.631,2442,2.043,2443,1.8,2444,2.643,2445,0.631,2446,0.694,2447,0.631,2448,0.631,2449,1.475,2450,3.028,2451,2.063,2452,0.795,2453,0.795,2454,0.795,2455,0.795,2456,0.694,2457,0.795,2458,0.795,2459,0.795,2460,0.795,2461,0.795,2462,0.631,2463,0.795,2464,0.659,2465,0.795,2466,1.223,2467,0.694,2468,0.694,2469,0.659,2470,0.795,2471,0.795,2472,0.694,2473,0.795,2474,0.795,2475,1.17,2476,1.475,2477,0.694,2478,0.795,2479,0.795,2480,0.795,2481,0.795,2482,0.795,2483,0.795,2484,1.049,2485,0.795,2486,1.8,2487,0.795,2488,0.795,2489,1.475,2490,1.287,2491,0.795,2492,0.795,2493,1.912,2494,3.028,2495,0.795,2496,1.368,2497,1.475,2498,1.475,2499,0.795,2500,0.795,2501,0.795,2502,0.795,2503,0.565,2504,0.795,2505,0.795,2506,0.694,2507,0.694,2508,0.795,2509,0.795,2510,1.475,2511,0.795,2512,0.795,2513,0.795,2514,1.475,2515,0.795,2516,0.795,2517,3.141,2518,1.475,2519,0.795,2520,0.795,2521,0.795,2522,0.795,2523,0.795,2524,0.795,2525,0.694,2526,1.475,2527,0.795,2528,0.795,2529,0.694,2530,0.795,2531,0.795,2532,0.795,2533,0.795,2534,0.795,2535,0.795,2536,0.795,2537,0.795,2538,3.49,2539,1.17,2540,0.694,2541,1.287,2542,1.17,2543,0.795,2544,0.795,2545,0.795,2546,0.795,2547,0.606,2548,0.694,2549,0.795,2550,0.631,2551,2.576,2552,2.063,2553,0.795,2554,0.795,2555,0.795,2556,0.795,2557,0.795,2558,0.795,2559,0.795,2560,0.795,2561,1.475,2562,1.711,2563,0.694,2564,0.584,2565,0.584,2566,0.795,2567,2.063,2568,0.795,2569,1.475,2570,0.795,2571,0.795,2572,0.631,2573,0.694,2574,0.795,2575,0.795,2576,1.475,2577,0.795,2578,0.795,2579,0.795,2580,1.8,2581,0.795,2582,2.063,2583,0.795,2584,2.063,2585,0.795,2586,0.795,2587,1.223,2588,0.795,2589,0.795,2590,1.475,2591,0.795,2592,0.694,2593,0.795,2594,0.795,2595,0.795,2596,0.694,2597,0.795,2598,0.795,2599,0.795,2600,0.795,2601,2.063,2602,0.795,2603,0.795,2604,1.475,2605,0.795,2606,0.795,2607,0.631,2608,0.795,2609,0.795,2610,0.795,2611,2.063,2612,0.795,2613,1.124,2614,0.795,2615,0.795,2616,0.795,2617,0.795]],["title/Chap_5.html#correlations-and-spectra",[404,1.961,583,2.674]],["text/Chap_5.html#correlations-and-spectra",[11,0.331,19,1.425,40,2.796,116,5.349,138,2.626,169,1.692,188,3.395,286,1.928,287,3.2,446,2.014,597,1.787,667,3.344,2112,3.74]],["title/Chap_5.html#correlations-simple-and-complex",[111,1.916,404,1.663,684,2.11]],["text/Chap_5.html#correlations-simple-and-complex",[6,1.375,11,0.429,19,0.91,34,1.408,53,1.542,99,1.172,110,1.763,114,3.883,142,0.576,169,1.45,256,1.719,270,1.698,286,1.231,316,1.423,319,1.677,325,1.56,335,2.849,336,2.43,337,1.385,348,1.472,355,1.685,356,2.219,362,2.723,367,2.43,379,1.833,382,3.063,394,1.618,404,2.9,409,2.175,411,3.955,412,1.679,413,4.041,414,5.84,416,2.442,427,3.638,431,2.816,440,2.364,450,2.196,493,1.453,505,1.391,510,4.142,537,1.96,549,2.972,550,2.775,579,2.566,597,1.973,605,2.044,666,2.616,752,2.136,783,3.858,799,2.136,815,2.842,830,2.43,858,2.249,918,2.519,963,2.624,966,2.389,1005,3.05,1056,3.775,1225,2.976,1310,2.474,1484,3.05,1628,3.416,1827,3.532,2188,3.985,2241,4.795,2242,4.638,2244,5.563,2248,4.194,2251,3.532,2389,6.143,2390,6.09,2391,4.194,2392,4.806,2393,3.985,2394,3.312,2395,4.456,2396,3.811,2397,4.806,2398,4.806,2399,3.662,2400,4.795,2401,7.408,2402,3.985,2403,3.811,2404,4.806,2405,4.806,2406,4.194,2407,4.806,2408,4.806]],["title/Chap_5.html#example-delayed-effect",[105,0.906,255,2.267,2409,3.121]],["text/Chap_5.html#example-delayed-effect",[11,0.425,19,1.314,77,3.179,95,2.335,105,1.758,106,2.226,108,1.03,286,2.254,335,2.741,337,1.281,348,2.125,356,1.797,393,2.79,409,1.916,416,2.183,505,2.008,549,2.482,641,1.649,667,3.084,684,3.448,698,4.781,720,4.102,1017,5.099,1162,2.909,1316,5.099,2409,5.099,2410,5.753,2411,6.938,2412,5.753,2413,6.938]],["title/Chap_5.html#correlations-and-memory",[404,1.961,2414,4.643]],["text/Chap_5.html#correlations-and-memory",[2,0.854,5,5.043,6,1.557,11,0.426,91,2.181,95,1.83,99,0.97,105,1.16,106,1.746,108,0.807,116,3.867,142,0.652,148,2.493,169,1.634,253,2.314,256,1.946,259,1.851,270,1.922,279,1.946,281,2.454,283,1.44,286,2.019,295,3.147,296,1.922,298,4.099,318,2.801,325,1.766,335,2.356,337,1.224,355,1.612,356,1.835,358,1.456,359,2.074,367,2.751,394,1.757,404,3.268,409,2.13,411,2.904,416,1.876,427,3.103,443,3.019,446,1.456,456,3.147,471,4.497,544,4.747,549,2.535,597,1.683,618,4.314,641,1.417,651,2.188,672,3.216,684,2.703,685,3.787,706,2.102,709,3.019,724,3.216,728,2.249,752,2.418,815,3.216,1200,3.998,1245,3.867,1277,5.133,1351,3.998,1374,3.082,1483,3.369,1768,3.216,2086,4.285,2114,4.747,2115,4.747,2186,3.543,2222,4.511,2242,3.867,2244,4.497,2285,5.049,2286,5.049,2339,3.642,2390,5.036,2394,3.749,2395,5.043,2414,5.043,2415,3.867,2416,4.747,2417,4.511,2418,6.922,2419,4.314,2420,5.439,2421,5.439]],["title/Chap_5.html#the-mechanics-of-correlations-redux",[404,1.663,1061,3.367,2193,3.018]],["text/Chap_5.html#the-mechanics-of-correlations-redux",[1,1.533,2,1.26,11,0.434,19,1.155,22,3.802,25,1.233,34,1.336,37,1.753,40,1.619,53,1.398,59,1.619,65,2.094,88,2.884,105,0.929,106,1.398,108,1.044,110,1.599,116,3.097,138,1.521,142,0.522,153,1.154,158,2.028,169,1.57,170,2.327,184,3.084,188,1.966,195,2.028,210,2.371,224,2.371,240,1.335,250,3.688,256,1.559,259,1.024,279,2.182,283,1.615,287,3.412,289,1.88,296,1.54,318,1.35,319,2.455,323,1.729,335,1.449,337,0.947,348,1.335,356,1.823,358,1.633,373,1.54,377,2.838,379,1.661,389,3.084,391,3.084,394,2.285,404,2.984,409,1.984,411,2.327,412,1.68,416,2.26,427,2.67,431,2.632,446,1.166,453,2.727,493,0.97,505,2.036,518,3.202,537,1.777,549,2.517,595,2.698,597,1.448,600,2.576,605,1.853,611,3.202,634,3.455,641,1.219,651,1.753,661,1.827,706,1.683,710,3.455,713,3.097,728,1.802,761,1.484,765,2.419,775,2.838,802,3.497,811,1.88,819,2.284,843,3.319,858,2.426,865,4.335,883,2.576,897,3.097,917,4.335,918,3.196,927,2.182,928,3.097,967,3.097,1024,3.196,1034,2.931,1062,1.966,1270,2.468,1310,2.243,1322,3.097,1347,2.917,1366,3.003,1422,3.003,1483,2.698,1513,2.521,1577,3.097,1580,3.003,1622,4.083,1889,3.097,2043,2.635,2059,5.171,2086,2.635,2191,6.113,2236,3.802,2238,3.802,2242,3.097,2261,5.322,2285,2.635,2286,2.635,2287,2.917,2288,5.361,2289,3.802,2301,3.802,2316,3.455,2390,4.335,2403,4.836,2422,3.32,2423,3.613,2424,4.04,2425,4.357,2426,7.036,2427,6.098,2428,3.802,2429,4.357,2430,4.357,2431,2.917,2432,4.357,2433,4.357,2434,3.802,2435,4.357,2436,4.357]],["title/Chap_5.html#fourier-description-of-correlation-functions",[404,1.443,412,0.745,468,1.369,1714,1.832]],["text/Chap_5.html#fourier-description-of-correlation-functions",[1,1.462,6,1.92,7,3.881,11,0.295,111,3.027,169,1.761,170,3.582,220,3.027,279,2.4,286,2.222,287,3.437,293,4.258,304,3.651,329,2.698,365,5.112,412,1.633,416,1.776,441,5.32,457,3.8,468,3.345,489,3.441,505,2.51,549,2.4,564,2.687,574,3.441,587,2.032,597,2.138,670,4.491,1162,2.813,1191,5.264,1216,2.813,1483,4.154,1581,5.855,1654,4.154,1669,4.058,2043,4.058,2437,6.709,2438,6.709,2439,6.709]],["title/Chap_5.html#a-digression",[2440,6.104]],["text/Chap_5.html#a-digression",[1,1.912,2,0.475,6,0.864,11,0.435,19,0.572,25,0.855,31,1.199,34,1.32,35,2.042,40,1.73,44,2.147,49,2.082,53,1.494,54,1.476,59,1.123,65,1.452,68,1.476,91,1.573,95,1.017,99,1.265,101,2.294,105,0.993,106,0.969,108,1.219,134,1.363,138,1.625,142,0.558,148,1.384,151,1.452,153,1.233,169,0.591,224,1.644,228,1.968,241,1.917,244,1.786,259,1.094,260,1.748,266,1.429,267,1.711,286,1.768,288,1.232,296,2.256,309,1.613,311,1.53,315,2.082,316,1.89,318,2.782,321,1.249,332,1.094,337,1.375,348,0.925,355,1.869,356,1.472,359,1.152,362,1.711,365,2.302,367,1.528,369,1.429,373,1.067,394,2.227,409,2.073,412,1.473,413,1.871,416,1.827,425,2.302,427,1.323,433,2.796,446,0.809,450,1.567,462,1.786,464,2.716,468,2.112,476,3.118,487,1.501,489,2.255,493,1.265,501,2.852,505,1.996,514,2.535,525,1.677,538,2.147,549,2.468,551,1.363,561,1.267,574,1.848,576,2.777,605,2.934,607,1.786,608,1.363,617,3.219,620,4.507,638,1.711,640,1.968,641,1.379,651,1.215,661,2.383,678,1.968,684,2.314,729,1.827,750,1.613,761,1.029,765,1.677,795,1.199,802,1.501,815,1.786,817,1.827,818,2.147,819,1.583,833,2.022,843,4.379,845,1.827,857,2.134,889,2.396,893,1.711,895,2.441,907,1.827,908,2.636,952,2.694,953,3.31,959,1.644,968,1.917,1012,2.396,1014,3.034,1019,1.786,1024,1.583,1034,1.452,1051,1.476,1056,3.288,1062,1.363,1094,3.549,1134,1.748,1186,1.677,1228,2.535,1293,4.49,1315,1.917,1317,4.33,1326,2.396,1328,2.082,1333,2.082,1344,1.583,1374,2.638,1378,2.302,1429,2.22,1488,3.422,1515,1.786,1521,2.302,1607,2.585,1620,1.555,1637,5.598,1653,2.956,1665,2.396,1692,2.636,1813,2.396,1901,2.636,1922,2.956,2001,4.754,2043,3.437,2085,3.422,2161,2.636,2285,1.827,2286,1.827,2287,2.022,2389,4.712,2394,3.209,2415,2.147,2441,2.396,2442,2.396,2443,4.959,2444,6.02,2445,2.396,2446,2.636,2447,2.396,2448,2.396,2449,4.657,2450,6.898,2451,5.683,2452,3.021,2453,3.021,2454,3.021,2455,3.021,2456,2.636,2457,3.021,2458,3.021,2459,3.021,2460,3.021,2461,3.021,2462,2.396,2463,3.021,2464,2.505,2465,3.021,2466,2.505,2467,2.636,2468,2.636,2469,2.505,2470,3.021,2471,3.021,2472,2.636,2473,3.021,2474,3.021,2475,3.693,2476,4.657,2477,2.636,2478,3.021,2479,3.021,2480,3.021,2481,3.021,2482,3.021,2483,3.021,2484,3.31,2485,3.021,2486,4.959,2487,3.021,2488,3.021]],["title/Chap_5.html#the-power-density-spectrum-and-its-properties",[564,1.225,574,1.462,587,1.116,1165,1.424]],["text/Chap_5.html#the-power-density-spectrum-and-its-properties",[1,0.639,2,1.18,6,1.303,11,0.438,19,0.556,25,0.83,32,1.285,34,1.248,40,1.09,53,0.941,54,1.434,68,1.434,99,1.115,101,2.76,105,0.626,106,0.941,107,2.346,108,1.069,109,1.076,111,3.071,134,1.324,136,2.214,138,1.024,142,0.352,169,0.891,198,1.164,253,1.248,266,2.638,268,1.774,270,1.609,277,1.324,279,1.05,286,2.044,287,1.936,305,1.196,311,0.964,313,1.387,316,0.868,318,2.407,319,1.589,321,1.213,329,1.18,332,2.278,335,0.975,336,3.179,337,1.367,341,1.458,344,1.266,348,2.085,355,1.269,356,1.763,359,1.119,367,1.483,371,1.365,382,3.298,384,3.295,391,1.483,394,1.129,404,1.149,409,2.062,411,2.431,412,1.128,413,2.819,416,2.419,420,1.911,433,1.285,435,2.56,446,0.785,448,1.213,450,1.532,453,1.05,457,2.579,467,1.51,468,2.964,487,2.263,489,3.165,493,1.242,499,3.299,500,2.924,501,3.211,502,4.039,503,1.862,505,1.317,510,2.89,525,1.628,530,4.868,532,1.862,549,2.688,550,1.248,561,1.23,564,2.395,574,2.701,576,3.672,579,1.566,587,2.061,597,1.081,600,1.735,612,2.966,629,3.61,636,1.05,641,0.91,654,1.538,661,2.339,667,1.304,689,1.566,708,3.717,724,1.735,729,1.774,749,1.964,783,2.692,795,1.164,799,1.304,801,1.566,815,1.735,880,1.862,918,1.538,919,1.538,952,3.227,1024,1.538,1034,1.41,1050,2.433,1056,2.634,1093,1.735,1094,2.236,1165,2.783,1191,1.911,1216,1.23,1228,3.704,1242,1.697,1293,4.907,1306,3.775,1315,1.862,1422,2.022,1484,2.89,1596,3.973,1607,1.628,1620,1.51,1654,1.817,1669,1.774,1670,1.964,1687,5.487,1688,3.61,1700,2.022,1714,1.458,1795,1.662,1814,2.156,2110,1.964,2125,2.022,2239,3.346,2241,2.156,2251,2.156,2290,2.56,2390,3.236,2399,2.236,2400,5.002,2419,3.61,2434,2.56,2489,4.552,2490,3.973,2491,2.934,2492,2.934,2493,4.221,2494,6.806,2495,2.934,2496,2.72,2497,4.552,2498,4.552,2499,2.934,2500,2.934,2501,2.934,2502,2.934,2503,2.085,2504,2.934,2505,2.934,2506,2.56,2507,2.56,2508,2.934,2509,2.934,2510,4.552,2511,2.934,2512,2.934,2513,2.934,2514,4.552,2515,2.934,2516,2.934,2517,5.972,2518,4.552,2519,2.934,2520,2.934,2521,2.934,2522,2.934,2523,2.934,2524,2.934]],["title/Chap_5.html#examples-of-power-spectra",[105,0.906,564,1.412,583,2.267]],["text/Chap_5.html#examples-of-power-spectra",[]],["title/Chap_5.html#example-white-noise",[105,0.906,285,1.175,675,2.147]],["text/Chap_5.html#example-white-noise",[6,2.299,11,0.429,101,2.21,106,2.133,188,2.999,242,4.116,285,1.839,296,2.348,309,3.549,318,2.49,337,1.032,409,2.008,412,1.343,416,1.76,493,1.48,502,3.8,505,1.923,549,2.378,561,3.369,564,2.21,565,5.271,574,3.56,576,3.248,637,3.765,675,4.063,706,2.568,1051,3.248,1101,4.884,1216,2.787,1293,3.93,1344,3.483,1536,3.765,2043,4.02,2110,4.449,2283,5.271,2496,6.162,2525,5.8,2526,8.035,2527,6.646,2528,6.646,2529,5.8]],["title/Chap_5.html#example-pink-noise",[93,3.236,105,0.906,285,1.175]],["text/Chap_5.html#example-pink-noise",[1,1.523,2,0.837,11,0.434,19,1.324,34,0.856,35,2.069,37,2.143,53,1.71,93,4.06,99,1.231,101,2.594,105,1.491,108,0.791,136,2.114,169,1.526,240,1.632,259,1.252,270,1.882,285,2.159,286,1.791,318,2.664,325,1.73,327,2.973,335,2.324,336,3.534,337,1.286,348,1.632,355,1.775,356,1.38,358,1.426,367,2.694,371,2.48,384,4.088,409,2.051,412,1.077,416,2.065,446,1.871,464,2.266,468,1.98,493,1.737,501,2.203,502,2.519,505,1.542,510,3.382,549,2.5,551,2.404,564,1.771,574,3.412,583,4.165,586,2.299,597,1.66,638,3.018,641,1.065,649,4.649,675,3.534,684,2.648,752,3.467,761,1.815,762,2.845,927,1.906,1101,3.915,1165,2.058,1228,3.804,1234,3.299,1293,4.612,1620,3.597,1637,5.544,1922,3.382,2076,3.672,2396,5.543,2417,4.418,2466,4.418,2530,5.328,2531,5.328,2532,5.328,2533,5.328,2534,5.328,2535,5.328,2536,5.328,2537,5.328]],["title/Chap_5.html#predicting-the-natural-climate-a-case-study",[95,1.095,247,2.179,1062,1.469,1221,2.016,2223,2.841]],["text/Chap_5.html#predicting-the-natural-climate-a-case-study",[1,1.064,2,1.287,3,1.545,6,2.03,11,0.42,13,1.785,34,0.785,35,2.368,53,1.032,59,1.195,64,3.355,66,1.242,85,2.363,91,0.89,101,2.778,105,0.686,107,1.109,108,0.877,111,1.451,136,1.276,138,1.122,145,2.47,153,1.879,158,1.497,192,4.263,210,1.75,242,1.991,250,1.945,259,1.667,266,2.793,270,2.087,279,1.747,281,1.451,283,1.293,288,1.311,296,1.136,309,1.717,311,1.605,316,0.952,322,2.139,323,1.276,329,1.293,337,1.272,343,1.86,355,0.731,358,1.766,359,1.226,366,1.655,371,1.497,404,3.132,409,1.135,412,1.656,413,3.025,414,4.341,416,2.248,429,2.108,432,2.348,442,1.785,446,0.861,447,1.521,448,2.728,450,2.22,453,2.931,464,1.368,466,2.153,467,1.655,469,1.86,476,3.27,493,1.088,501,1.329,505,2.418,560,1.626,561,1.348,564,2.581,570,2.153,574,2.618,583,2.608,586,1.388,587,2.351,602,2.041,617,1.821,626,1.276,633,2.428,636,2.777,641,1.181,643,2.363,647,2.55,651,1.293,657,4.779,677,2.153,738,1.991,739,2.608,741,2.806,756,3.025,762,2.608,773,1.497,795,1.276,804,4.263,808,1.685,845,2.954,846,1.945,857,1.473,893,1.821,918,1.685,927,2.862,953,2.286,977,2.45,983,2.171,989,3.874,1003,1.717,1018,6.194,1033,2.041,1085,2.286,1089,1.86,1155,2.363,1162,1.348,1176,5.824,1222,1.945,1230,1.717,1242,1.86,1258,2.286,1264,1.945,1274,2.666,1276,2.806,1277,3.182,1278,4.263,1352,2.363,1442,2.806,1465,2.55,1514,2.363,1515,2.888,1587,2.55,1620,3.651,1698,4.684,1718,2.286,1721,2.45,1729,3.472,1768,3.492,1827,2.363,1835,2.55,1851,3.874,1922,2.041,2069,4.263,2116,5.2,2197,2.45,2198,2.45,2199,2.806,2222,4.898,2234,2.806,2278,2.806,2313,3.874,2337,2.806,2339,2.153,2399,3.722,2415,2.286,2422,4.501,2423,7.139,2424,7.981,2431,4.416,2434,2.806,2442,4.684,2493,2.981,2538,6.497,2539,3.874,2540,2.806,2541,4.263,2542,3.874,2543,3.215,2544,3.215,2545,3.215,2546,3.215,2547,2.45,2548,2.806,2549,3.215,2550,2.55,2551,6.597,2552,5.907,2553,3.215,2554,3.215,2555,3.215,2556,3.215,2557,3.215,2558,3.215,2559,3.215,2560,3.215,2561,4.884,2562,4.898,2563,2.806,2564,2.363,2565,2.363,2566,3.215,2567,5.907,2568,3.215,2569,4.884,2570,3.215,2571,3.215,2572,2.55,2573,2.806,2574,3.215,2575,3.215,2576,4.884,2577,3.215,2578,3.215,2579,3.215,2580,5.155,2581,3.215,2582,5.907,2583,3.215,2584,5.907,2585,3.215,2586,3.215,2587,4.05,2588,3.215,2589,3.215,2590,4.884,2591,3.215,2592,2.806,2593,3.215]],["title/Chap_5.html#problems",[142,0.731]],["text/Chap_5.html#problems",[]],["title/Chap_5.html#problem-51",[142,0.6,2389,4.153]],["text/Chap_5.html#problem-51",[11,0.336,34,1.402,114,3.736,413,4.735,414,5.619,550,3.252,1225,4.735]],["title/Chap_5.html#problem-52",[142,0.6,2394,3.452]],["text/Chap_5.html#problem-52",[11,0.365,33,4.063,53,2.254,105,1.498,108,1.042,116,4.992,169,1.73,256,2.971,259,1.951,298,4.063,318,2.573,330,2.787,355,1.598,379,2.678,394,2.06,409,1.93,456,4.063,471,4.458,538,4.992,549,2.513,597,2.1,641,1.661,685,3.376,880,4.458,1165,2.713,1808,5.162,2244,4.458,2285,4.248,2286,4.248,2594,7.023]],["title/Chap_5.html#problem-53",[142,0.6,2396,3.972]],["text/Chap_5.html#problem-53",[2,1.131,11,0.405,19,1.364,106,2.311,142,0.863,169,1.409,287,3.063,318,2.231,355,1.638,373,2.544,416,2.232,467,3.706,549,3.015,597,1.71,608,3.249,749,5.642,752,3.201,795,2.857,947,3.519,963,3.39,1005,5.349,2595,7.201,2596,6.284]],["title/Chap_5.html#problem-54",[142,0.6,2399,3.817]],["text/Chap_5.html#problem-54",[11,0.326,107,3.204,169,1.449,270,3.027,286,1.898,287,3.15,412,1.497,416,2.268,502,3.503,505,2.144,549,3.065,661,3.79]],["title/Chap_5.html#problem-55",[142,0.6,413,3.102]],["text/Chap_5.html#problem-55",[1,1.393,11,0.435,25,1.809,99,0.875,107,2.204,108,0.949,110,2.345,240,2.404,286,2.011,296,2.259,304,3.479,318,2.744,325,2.076,337,1.219,378,2.884,404,3.072,409,1.974,411,4.19,412,1.292,416,2.481,446,1.711,493,1.423,576,3.124,605,2.719,661,2.68,667,3.488,843,4.271,930,3.78,1228,3.479,1651,5.069,2001,4.405,2017,4.698,2390,6.575,2403,5.069,2517,5.301,2597,6.392,2598,6.392,2599,6.392]],["title/Chap_5.html#problem-56",[142,0.6,414,3.681]],["text/Chap_5.html#problem-56",[1,1.455,11,0.425,12,3.783,84,3.013,99,1.103,101,2.22,169,1.307,184,3.376,253,3.427,287,2.84,304,3.634,318,2.069,337,1.037,356,1.73,373,2.847,412,1.35,416,2.38,427,2.924,446,1.788,501,2.761,505,1.932,510,4.238,549,2.883,564,2.22,574,2.65,587,2.022,749,4.47,762,4.621,763,5.088,945,4.907,1234,4.135,1289,3.948,1483,4.135,2402,5.537,2600,6.677,2601,8.654,2602,6.677,2603,6.677,2604,8.058,2605,6.677,2606,6.677]],["title/Chap_5.html#laboratory-exercises",[47,1.646,143,1.256]],["text/Chap_5.html#laboratory-exercises",[]],["title/Chap_5.html#laboratory-exercise-51",[47,1.395,143,1.065,2389,3.521]],["text/Chap_5.html#laboratory-exercise-51",[2,0.85,11,0.419,20,2.944,53,1.736,88,2.558,99,0.74,100,2.643,108,1.236,109,1.984,120,3.633,123,2.062,143,1.356,153,1.432,155,2.3,169,1.63,216,3.449,220,3.546,232,4.614,253,2.3,285,1.497,296,1.911,316,1.601,323,2.146,325,1.756,344,2.334,358,1.448,377,3.523,404,2.118,422,3.727,432,2.6,440,1.959,449,2.643,551,2.441,560,2.735,561,2.96,574,3.118,586,2.334,597,1.677,640,3.523,641,1.411,658,5.576,675,3.973,682,4.07,738,3.349,740,5.119,761,2.404,763,4.122,767,6.857,778,3.975,779,3.975,780,3.975,781,5.426,782,5.74,784,4.726,787,3.523,793,3.727,794,3.727,819,2.835,858,1.865,863,2.944,888,2.643,917,3.845,927,1.935,976,4.72,1101,5.775,1197,3.845,1270,3.064,1338,2.888,1979,4.726,2043,4.753,2044,5.415,2045,4.289,2046,4.289,2047,5.415,2048,5.775,2088,4.289,2282,4.72,2283,4.289,2382,4.72,2383,6.16,2384,6.16,2385,6.16,2386,4.72,2607,4.289,2608,5.408,2609,5.408,2610,5.408,2611,7.858,2612,5.408,2613,5.379,2614,5.408,2615,5.408,2616,5.408,2617,5.408]],["title/Chap_6.html",[108,0.547,153,0.976,269,1.103,2110,2.467]],["text/Chap_6.html",[1,0.979,2,0.899,6,0.963,11,0.438,13,0.509,19,0.958,25,0.953,31,0.667,32,1.02,34,1.085,35,1.634,37,0.676,39,0.308,40,0.341,47,1.574,53,0.926,54,0.821,59,0.625,65,0.44,66,0.9,77,0.77,78,0.472,80,0.973,91,1.326,95,0.566,98,2.927,99,1.14,100,2.697,101,2.638,102,1.333,104,2.233,105,0.359,106,0.539,107,1.549,108,1.146,109,2.166,110,0.336,111,1.878,114,0.821,122,0.933,123,1.713,126,0.542,127,1.058,132,1.988,133,1.221,134,0.413,136,0.364,142,0.538,143,1.599,145,0.463,151,0.44,152,0.994,153,1.563,155,1.911,158,1.343,161,0.554,169,1.248,184,1.178,195,0.782,198,0.667,208,1.847,211,0.369,214,1.193,224,0.499,235,1.235,240,1.275,243,1.605,253,0.715,255,0.898,256,0.601,259,1.297,262,0.673,264,0.48,269,1.768,270,0.823,274,1.125,276,0.865,277,1.302,279,1.205,281,0.413,283,0.764,285,1.326,286,1.758,287,1.612,288,0.685,292,2.147,296,1.19,301,0.673,305,1.176,310,1.084,311,1.106,313,2.792,316,1.634,317,3.595,318,2.725,319,2.225,320,2.566,322,0.736,323,0.364,325,1.459,326,0.567,330,1.336,335,2.506,336,1.916,337,1.357,340,2.994,343,0.53,344,1.245,348,1.994,355,1.51,356,1.778,358,0.45,359,0.888,363,0.865,365,1.775,366,2.142,367,0.85,369,0.795,371,1.343,373,1.19,378,2.161,379,0.641,383,1.95,384,2.511,387,1.377,391,0.463,393,0.369,394,1.815,395,0.865,399,1.017,404,2.075,409,2.021,411,2.558,412,1.479,413,0.567,416,2.333,420,0.597,427,1.02,429,1.005,430,1.125,431,1.245,432,1.387,433,1.474,440,1.045,442,0.509,443,0.509,446,1.014,448,0.379,449,0.448,450,0.566,451,0.673,453,0.328,457,0.519,463,0.698,464,1.612,468,1.072,471,0.582,472,0.698,476,0.613,477,1.387,488,0.898,489,0.924,493,0.927,499,3.263,500,2.511,501,2.692,502,2.947,503,2.405,505,1.884,510,2.137,514,0.499,525,0.509,528,0.865,529,0.8,533,1.195,534,1.095,536,0.727,537,0.95,538,0.651,539,1.377,545,0.673,549,2.559,551,1.519,560,0.463,561,0.977,564,2.072,567,0.509,568,0.698,571,0.973,572,0.567,573,2.949,574,1.783,576,1.645,586,0.725,587,1.147,588,1.067,589,0.53,590,0.613,593,1.017,597,1.48,605,1.77,607,0.542,608,0.759,623,0.554,626,2.27,627,2.547,628,1.394,632,3.05,633,0.455,636,0.833,637,0.519,641,1.144,647,0.727,651,0.937,653,0.597,654,0.48,661,0.384,666,1.268,667,2.542,672,0.994,675,0.85,678,0.597,682,2.196,684,0.835,685,0.44,693,0.8,698,3.301,700,0.673,703,1.467,706,1.301,709,0.509,724,1.377,728,0.379,731,0.567,739,2.558,742,0.727,749,0.613,752,1.282,761,0.983,773,0.427,775,0.597,792,0.499,795,1.336,796,1.095,797,1.017,799,0.407,801,0.489,808,0.881,811,0.395,815,0.994,821,0.597,843,0.915,848,0.613,858,0.803,861,0.567,862,0.554,863,1.268,873,0.933,878,0.76,879,0.76,880,1.478,883,0.542,887,0.632,891,1.786,892,1.559,893,1.319,899,1.669,907,0.554,918,0.48,919,1.512,920,0.554,927,1.714,929,0.673,930,1.377,945,0.673,946,0.673,959,0.499,960,0.8,962,0.651,969,0.53,983,0.407,985,0.613,994,0.8,1003,0.898,1019,0.542,1022,1.347,1029,0.597,1030,1.235,1052,2.12,1056,1.948,1059,0.673,1062,1.519,1076,1.459,1079,0.673,1085,1.656,1086,1.195,1095,1.195,1134,0.973,1136,0.542,1144,0.727,1165,0.354,1176,4.197,1216,0.977,1217,0.915,1222,0.554,1225,1.041,1230,0.898,1254,0.651,1265,1.333,1289,0.542,1304,1.394,1310,0.865,1315,0.582,1316,0.673,1328,0.632,1333,0.632,1338,2.023,1344,2.511,1348,0.8,1349,0.519,1374,0.519,1377,0.673,1384,0.673,1387,1.333,1389,1.281,1423,1.467,1436,1.559,1483,1.041,1513,0.53,1515,0.542,1524,0.651,1536,0.519,1580,0.632,1598,0.613,1607,0.509,1609,0.698,1620,0.865,1636,0.8,1641,2.887,1654,1.786,1666,0.727,1706,1.235,1712,1.235,1753,2.517,1768,2.657,1795,0.519,1807,0.76,1809,0.698,1815,0.727,1868,1.235,1888,0.673,2018,1.333,2026,0.8,2059,1.712,2076,0.632,2085,0.673,2086,1.017,2097,1.394,2103,0.698,2112,2.634,2116,1.067,2186,1.095,2191,2.198,2196,2.032,2239,0.673,2241,0.673,2251,0.673,2257,0.673,2277,0.651,2279,0.8,2285,1.409,2286,1.409,2287,1.559,2288,1.775,2302,1.467,2339,0.613,2358,1.394,2390,1.656,2391,0.8,2396,0.727,2400,1.712,2403,1.847,2409,3.302,2412,1.394,2419,1.847,2431,0.613,2447,0.727,2448,1.847,2490,1.467,2503,2.051,2506,0.8,2517,1.394,2538,0.727,2539,1.333,2580,0.8,2618,0.727,2619,0.916,2620,2.566,2621,2.792,2622,3.451,2623,1.235,2624,2.887,2625,1.681,2626,0.916,2627,3.122,2628,2.517,2629,0.8,2630,0.916,2631,0.916,2632,3.485,2633,2.392,2634,1.559,2635,1.559,2636,0.916,2637,0.916,2638,1.681,2639,0.727,2640,0.916,2641,1.681,2642,0.916,2643,0.916,2644,0.8,2645,0.916,2646,2.885,2647,0.916,2648,3.367,2649,0.916,2650,0.916,2651,0.916,2652,0.916,2653,2.329,2654,1.681,2655,0.916,2656,0.8,2657,1.681,2658,0.916,2659,0.916,2660,2.159,2661,0.916,2662,0.8,2663,0.916,2664,1.681,2665,0.76,2666,1.656,2667,0.916,2668,0.916,2669,2.329,2670,1.559,2671,1.559,2672,0.916,2673,1.467,2674,0.916,2675,0.916,2676,0.916,2677,0.916,2678,0.916,2679,0.916,2680,0.8,2681,4.162,2682,0.916,2683,0.916,2684,2.885,2685,2.885,2686,1.681,2687,1.681,2688,0.916,2689,0.916,2690,0.916,2691,0.916,2692,0.916,2693,0.916,2694,0.916,2695,0.916,2696,0.8,2697,0.916,2698,0.698,2699,0.916,2700,0.916,2701,0.916,2702,1.681,2703,4.162,2704,1.681,2705,0.916,2706,0.916,2707,0.916,2708,0.8,2709,0.916,2710,1.681,2711,0.916,2712,0.916,2713,0.8,2714,6.078,2715,2.329,2716,2.885,2717,4.162,2718,2.329,2719,3.367,2720,2.329,2721,2.885,2722,0.916,2723,4.493,2724,0.916,2725,2.885,2726,2.329,2727,1.681,2728,5.057,2729,0.916,2730,1.681,2731,0.916,2732,0.916,2733,1.681,2734,1.681,2735,0.8,2736,1.681,2737,0.916,2738,0.916,2739,0.916,2740,0.916,2741,0.8,2742,0.916,2743,1.681,2744,0.916,2745,0.916,2746,0.916,2747,0.916,2748,0.916,2749,0.8,2750,0.916,2751,0.916,2752,1.681,2753,0.916,2754,1.681,2755,0.916,2756,0.916,2757,0.916,2758,0.916,2759,0.916,2760,0.916,2761,0.916,2762,0.916,2763,0.916,2764,1.681,2765,1.681,2766,0.916,2767,0.916,2768,0.76,2769,1.681,2770,0.916,2771,0.916,2772,0.916,2773,0.916,2774,1.681,2775,0.916,2776,0.916,2777,1.467,2778,0.916,2779,0.916,2780,1.681,2781,1.681,2782,0.916,2783,0.916,2784,0.916,2785,0.916,2786,2.198,2787,2.392,2788,0.916]],["title/Chap_6.html#filtering-of-stochastic-signals",[108,0.63,153,1.124,269,1.271]],["text/Chap_6.html#filtering-of-stochastic-signals",[11,0.439,19,1,53,2.229,66,2.684,108,1.332,109,2.549,111,2.382,153,1.839,169,1.52,253,2.245,259,1.24,277,2.382,279,1.888,286,1.99,287,2.245,305,2.152,313,3.285,318,2.406,322,2.311,325,1.714,335,2.582,337,1.206,348,2.379,356,2.221,394,2.183,404,2.066,409,2.046,411,2.818,412,1.404,416,1.839,427,3.042,442,2.93,446,1.86,505,1.527,537,2.152,549,1.888,551,2.382,560,2.669,597,1.844,641,1.389,651,2.123,672,4.107,728,2.182,752,2.346,761,1.798,795,2.094,808,2.766,1217,3.781,1338,2.818,1768,4.107,1795,2.99,2059,5.707,2112,2.623,2191,5.917,2285,4.696,2286,4.696,2287,5.198,2288,5.917,2390,3.752,2403,6.158,2618,4.186,2619,5.278,2620,4.022,2621,4.377,2622,4.377]],["title/Chap_6.html#interpretation-of-the-convolution-result",[91,1.175,1338,2.267,2623,3.121]],["text/Chap_6.html#interpretation-of-the-convolution-result",[6,1.95,11,0.421,19,1.45,34,1.31,35,2.266,77,2.349,80,2.966,99,0.701,108,1.26,109,1.881,153,2.16,235,5.008,243,5.275,253,2.18,259,1.204,269,2.04,277,2.313,279,1.834,286,2.09,292,4.81,305,2.09,310,2.386,311,1.684,313,3.222,318,2.527,325,1.664,337,0.796,340,3.454,343,2.966,344,2.212,378,2.313,383,2.638,384,3.571,394,2.023,395,2.638,409,2.029,412,1.716,416,1.804,430,3.432,433,3.351,440,1.857,450,1.725,457,2.904,493,1.141,505,1.972,533,3.644,539,3.031,549,1.834,551,2.313,573,4.021,597,1.618,605,2.898,626,3.037,627,2.464,632,4.011,661,2.149,667,3.028,698,3.533,706,2.633,752,2.278,773,2.386,858,1.767,873,2.845,893,2.904,899,3.942,994,4.473,1030,5.008,1216,2.149,1310,2.638,1338,3.638,1344,3.571,1436,4.562,1483,3.174,1513,2.966,1609,3.906,1641,3.906,1809,3.906,2112,3.386,2409,5.008,2431,3.432,2447,4.065,2448,6.07,2620,5.192,2624,5.192,2625,6.814,2626,5.126,2627,6.317,2628,5.946,2629,4.473,2630,5.126,2631,5.126,2632,3.533]],["title/Chap_6.html#the-mean",[19,1.156]],["text/Chap_6.html#the-mean",[2,0.992,6,1.311,11,0.439,19,0.868,34,1.161,54,2.239,66,1.77,78,2.358,91,1.268,99,0.864,101,1.523,104,3.138,108,0.68,109,1.681,111,2.067,136,1.818,152,3.734,169,1.236,198,1.818,259,1.698,269,1.891,277,2.067,296,1.619,313,2.986,318,2.948,326,2.837,330,1.818,335,2.808,337,1.369,340,3.905,344,1.977,348,2.214,355,1.644,356,1.872,363,2.358,378,3.261,384,4.426,393,1.843,394,1.136,399,2.771,409,2.08,430,3.067,431,1.977,432,3.035,440,2.288,443,2.543,449,2.239,468,1.702,472,3.491,489,1.818,573,2.807,576,2.239,597,1.94,626,2.506,627,3.035,632,2.006,666,2.494,667,2.036,678,2.984,731,2.837,749,3.067,752,2.036,775,2.984,799,2.036,919,3.31,920,2.771,927,3.021,1076,3.654,1085,4.489,1086,3.257,1315,2.908,1377,3.367,1436,3.067,1641,6.225,1666,3.633,1815,3.633,2085,3.367,2112,3.591,2627,6.699,2632,5.82,2633,3.799,2634,4.248,2635,4.248,2636,4.582,2637,4.582,2638,6.315,2639,3.633,2640,4.582,2641,6.315,2642,4.582,2643,4.582]],["title/Chap_6.html#the-autocorrelation-function",[412,1.012,505,1.449]],["text/Chap_6.html#the-autocorrelation-function",[2,0.63,11,0.44,34,0.924,65,1.929,91,1.111,99,0.92,108,0.854,132,3.965,169,0.785,286,1.474,292,2.273,296,2.033,317,5.554,318,2.995,319,3.03,320,5.926,330,1.592,335,2.442,337,1.324,340,1.811,344,1.732,348,1.229,356,1.49,366,3.461,369,1.898,371,1.868,383,2.066,387,3.402,394,1.822,404,1.571,409,2.073,412,1.636,416,2.479,427,1.757,429,1.732,431,1.732,433,2.519,440,1.454,446,1.074,505,2.342,514,2.184,528,2.066,529,3.502,536,3.183,537,1.636,549,2.982,571,2.322,573,1.784,597,0.953,605,2.447,623,2.427,626,2.669,627,3.232,632,2.519,651,1.614,654,2.103,682,4.166,698,4.635,706,1.551,801,2.143,843,3.131,918,2.103,962,2.853,1165,1.551,1304,3.328,1316,2.949,1338,2.143,1384,2.949,2086,2.427,2112,3.342,2391,3.502,2400,4.228,2419,4.563,2644,3.502,2645,4.013,2646,7.346,2647,4.013,2648,7.776,2649,4.013,2650,4.013,2651,4.013,2652,4.013,2653,6.725,2654,5.753,2655,4.013,2656,3.502,2657,5.753,2658,4.013,2659,4.013,2660,5.334,2661,4.013,2662,3.502,2663,4.013,2664,5.753,2665,3.328,2666,2.853]],["title/Chap_6.html#the-cross-correlation-function",[404,1.663,411,2.267,412,0.858]],["text/Chap_6.html#the-cross-correlation-function",[1,0.832,2,0.757,6,1.092,11,0.438,19,0.723,25,0.665,34,1.05,35,1.427,37,0.945,40,0.873,53,0.754,54,1.148,59,1.418,80,1.36,91,1.536,95,0.791,98,4.259,99,1.227,100,3.887,101,3.03,102,3.027,104,3.033,106,0.754,107,2.104,108,0.824,109,1.4,111,2.504,126,1.389,127,0.862,132,2.631,134,1.06,142,0.282,158,2.583,161,1.421,169,0.46,184,1.93,195,1.094,198,0.932,214,1.993,224,1.279,240,0.72,256,0.841,259,1.536,269,1.957,270,0.83,274,2.555,276,1.21,277,1.06,279,1.366,281,1.06,286,0.602,288,0.958,296,1.349,311,1.254,313,1.111,317,3.615,318,2.224,319,1.937,322,1.029,325,0.763,330,1.515,335,2.386,336,3.086,337,1.386,340,2.175,344,1.014,348,2.199,355,1.567,356,1.859,359,1.455,365,3.673,367,1.93,371,1.094,373,0.83,378,1.722,379,0.896,383,1.965,387,1.389,394,0.947,404,1.494,409,1.813,411,2.574,412,1.233,413,1.455,416,2.437,429,1.647,450,0.791,463,1.791,464,2.596,468,1.418,471,1.492,488,1.255,489,0.932,493,0.523,499,4.704,500,3.888,501,3.545,502,3.978,503,4.15,505,1.606,510,3.874,528,1.21,533,1.67,534,2.486,537,0.958,538,1.67,539,2.257,545,1.727,549,2.894,551,1.722,561,2.021,564,2.645,567,1.304,568,1.791,572,1.455,573,2.142,574,2.594,576,2.712,587,1.156,588,2.423,589,1.36,590,1.573,593,2.309,597,1.145,605,2.05,626,1.913,627,2.317,628,3.165,632,2.43,636,0.841,641,0.47,647,1.864,651,0.945,666,2.077,667,2.466,693,2.051,698,3.322,700,1.727,703,3.331,706,1.475,724,2.85,739,3.258,796,1.531,797,1.421,808,1.232,815,2.257,879,1.949,883,1.389,887,1.62,892,1.573,893,2.162,899,1.36,919,2,927,1.724,929,1.727,945,1.727,946,1.727,985,1.573,1003,1.255,1019,1.389,1022,1.36,1052,1.727,1056,3.531,1062,1.06,1076,1.188,1079,1.727,1085,1.67,1086,1.67,1095,1.67,1144,1.864,1222,1.421,1225,1.455,1254,1.67,1265,3.027,1289,1.389,1304,1.949,1338,1.255,1344,2,1349,1.331,1374,1.331,1483,1.455,1524,1.67,1580,1.62,1598,1.573,1620,1.21,1654,2.985,1706,2.805,1807,1.949,1868,2.805,1888,1.727,2026,2.051,2076,1.62,2103,1.791,2112,1.897,2239,1.727,2251,1.727,2257,1.727,2390,2.713,2396,1.864,2400,1.727,2419,1.864,2490,3.331,2503,3.944,2506,2.051,2517,3.165,2621,3.165,2623,1.727,2633,1.949,2660,2.179,2666,2.713,2667,2.35,2668,2.35,2669,4.82,2670,2.179,2671,2.179,2672,2.35,2673,3.331,2674,2.35,2675,2.35,2676,2.35,2677,2.35,2678,2.35,2679,2.35,2680,2.051,2681,6.888,2682,2.35,2683,2.35,2684,5.549,2685,5.549,2686,3.817,2687,3.817,2688,2.35,2689,2.35,2690,2.35,2691,2.35,2692,2.35,2693,2.35,2694,2.35,2695,2.35,2696,2.051,2697,2.35,2698,1.791,2699,2.35,2700,2.35,2701,2.35,2702,3.817,2703,6.888,2704,3.817,2705,2.35,2706,2.35,2707,2.35,2708,2.051,2709,2.35,2710,3.817,2711,2.35,2712,2.35]],["title/Chap_6.html#example-a-world-of-random-events-a-case-study",[95,0.981,105,0.622,597,0.692,891,1.805,1062,1.315,1712,2.143]],["text/Chap_6.html#example-a-world-of-random-events-a-case-study",[1,1.573,2,1.034,11,0.421,13,2.146,19,0.732,25,2.043,34,1.16,35,2.365,37,1.555,53,1.241,77,1.771,91,1.55,105,0.825,109,2.055,111,1.744,133,3.451,145,1.955,153,1.024,169,0.757,184,1.955,195,1.799,208,5.222,214,1.598,255,2.064,264,2.026,270,1.979,283,1.024,305,2.284,310,2.607,311,1.84,316,1.658,319,2.52,325,2.488,340,1.744,348,1.184,355,1.274,356,1.002,358,1.035,359,1.474,371,1.799,373,1.366,378,1.744,383,2.882,391,1.955,394,1.791,395,1.99,399,2.338,404,3,409,1.781,411,3.855,412,0.781,416,2.182,431,1.668,432,2.692,446,1.499,448,1.598,453,1.383,476,2.588,488,2.064,493,0.861,505,1.119,525,2.146,571,2.237,586,2.417,607,2.286,608,1.744,633,1.921,637,2.19,641,1.598,653,2.518,684,2.783,685,1.858,739,3.855,796,2.518,821,2.518,848,2.588,873,2.146,891,4.078,892,3.749,907,2.338,930,3.311,959,2.104,960,3.374,1022,3.24,1052,4.116,1059,2.841,1176,6.469,1216,1.621,1230,2.99,1344,2.935,1348,3.374,1387,4.441,1389,4.268,1423,4.887,1620,1.99,1712,2.841,1753,6.301,2086,2.338,2097,4.644,2116,3.555,2186,3.648,2196,5.747,2277,2.748,2279,3.374,2302,4.887,2339,2.588,2409,5.872,2538,3.066,2539,4.441,2580,3.374,2622,5.987,2624,4.268,2670,3.584,2671,3.584,2713,3.374,2714,8.254,2715,6.585,2716,7.22,2717,8.242,2718,6.585,2719,7.663,2720,6.585,2721,7.22,2722,3.866,2723,8.441,2724,3.866,2725,7.22,2726,6.585,2727,5.6,2728,8.736,2729,3.866,2730,5.6,2731,3.866,2732,3.866,2733,5.6,2734,5.6,2735,3.374,2736,5.6,2737,3.866,2738,3.866,2739,3.866,2740,3.866,2741,3.374,2742,3.866,2743,5.6,2744,3.866,2745,3.866,2746,3.866,2747,3.866,2748,3.866,2749,3.374,2750,3.866,2751,3.866,2752,5.6,2753,3.866,2754,5.6,2755,3.866,2756,3.866,2757,3.866,2758,3.866,2759,3.866,2760,3.866,2761,3.866]],["title/Chap_6.html#problems",[142,0.731]],["text/Chap_6.html#problems",[]],["title/Chap_6.html#problem-61",[142,0.6,2620,3.817]],["text/Chap_6.html#problem-61",[1,1.325,11,0.43,31,2.412,99,1.136,108,1.232,109,2.79,153,2.014,169,1.189,240,2.33,276,3.128,286,2.229,313,3.597,318,2.357,335,2.529,337,1.289,340,2.743,348,1.862,355,1.73,356,1.575,358,1.627,384,3.186,394,2.059,409,2.022,416,1.61,420,3.96,551,2.743,573,2.702,597,1.444,632,3.33,641,1.521,667,3.38,698,4.189,761,2.07,797,3.676,858,2.622,863,4.518,899,3.517,930,3.594,983,2.702,1344,3.986,1607,3.374,1636,5.305,1654,3.764,2018,6.032,2412,5.04,2632,4.189,2762,6.078,2763,6.078,2764,7.606,2765,7.606,2766,6.078,2767,6.078,2768,5.04,2769,7.606,2770,6.078,2771,6.078]],["title/Chap_6.html#problem-62",[142,0.6,2621,4.153]],["text/Chap_6.html#problem-62",[1,1.472,11,0.417,99,1.111,107,2.329,108,1.291,109,2.977,240,2.486,286,1.731,287,2.874,313,3.838,335,2.892,337,1.433,340,3.049,394,1.676,409,2.022,416,2.149,493,1.504,549,2.417,573,3.003,626,2.681,627,3.247,632,2.959,641,1.351,667,3.607,698,4.656,761,2.301,2191,5.149,2412,5.603,2632,4.656,2772,6.756,2773,6.756,2774,8.115,2775,6.756,2776,6.756]],["title/Chap_6.html#problem-63",[142,0.6,2622,4.153]],["text/Chap_6.html#problem-63",[11,0.372,99,0.993,108,1.077,153,1.921,337,1.392,348,2.223,356,1.88,373,2.564,404,2.841,409,1.968,412,1.711,464,3.086,493,1.616,795,2.879,1134,4.897,1310,3.735,1328,5.001,1333,5.001,2241,5.333,2358,6.017,2777,7.387]],["title/Chap_6.html#problem-64",[142,0.6,2624,3.817]],["text/Chap_6.html#problem-64",[11,0.421,31,2.595,98,5.183,101,3.041,108,1.273,109,2.399,114,3.888,240,2.437,269,2.382,285,2.202,286,1.676,287,2.781,313,3.763,323,2.595,337,1.386,369,3.092,409,1.52,412,1.322,416,1.732,446,1.751,451,4.806,493,1.772,505,1.892,549,2.339,564,2.645,573,2.906,574,2.595,587,2.409,608,2.951,632,3.484,636,2.339,641,1.308,675,3.307,742,5.186,761,2.227,1003,3.492,1216,2.742,1344,3.427,2778,6.539,2779,6.539,2780,7.956,2781,7.956]],["title/Chap_6.html#problem-65",[142,0.6,2628,4.371]],["text/Chap_6.html#problem-65",[11,0.402,19,1.334,104,3.499,109,2.583,169,1.378,286,2.131,287,2.995,288,2.871,313,3.33,335,2.765,337,1.292,340,3.753,355,2.081,373,2.488,468,2.616,489,2.794,573,3.696,626,2.794,627,3.384,632,3.083,667,3.696,752,3.129,795,2.794,880,5.618,2358,5.838,2632,4.852]],["title/Chap_6.html#problem-66",[142,0.6,2633,4.153]],["text/Chap_6.html#problem-66",[2,1.134,11,0.393,34,1.16,99,0.988,106,2.317,107,2.489,108,1.071,259,1.696,286,2.292,287,3.071,330,2.865,335,2.4,336,3.65,337,1.121,355,1.642,363,3.716,373,2.551,378,3.808,409,1.678,878,5.986,1029,4.703,1052,5.306,1095,5.132,1225,4.471,2782,7.219]],["title/Chap_6.html#laboratory-exercises",[47,1.646,143,1.256]],["text/Chap_6.html#laboratory-exercises",[]],["title/Chap_6.html#laboratory-exercise-61",[47,1.395,143,1.065,2620,3.236]],["text/Chap_6.html#laboratory-exercise-61",[99,1.03,123,2.869,143,1.887,155,3.2,169,1.472,279,2.692,285,2.392,316,2.559,675,3.805,795,2.986,1136,4.449,1768,4.449]],["title/Chap_6.html#laboratory-exercise-62",[47,1.395,143,1.065,2621,3.521]],["text/Chap_6.html#laboratory-exercise-62",[99,1.022,110,2.739,123,2.847,127,2.739,143,1.872,155,3.175,169,1.684,285,2.382,316,2.547,792,4.063,795,2.962,861,4.623,862,4.515,2783,7.465]],["title/Chap_6.html#laboratory-exercise-63",[47,1.395,143,1.065,2622,3.521]],["text/Chap_6.html#laboratory-exercise-63",[11,0.368,39,2.393,99,0.973,101,2.364,107,2.452,122,3.947,123,2.712,143,1.783,155,3.025,169,1.392,211,2.86,256,2.544,283,2.354,285,1.968,287,3.025,301,5.226,316,2.105,366,4.722,379,2.712,394,1.764,409,1.653,412,1.437,416,1.883,505,2.058,564,2.364,587,2.153,636,2.544,811,3.069,2784,7.111,2785,7.111]],["title/Chap_6.html#laboratory-exercise-64",[47,1.395,143,1.065,2624,3.236]],["text/Chap_6.html#laboratory-exercise-64",[32,3.304,99,1.032,123,2.877,143,1.892,153,1.998,155,3.209,169,1.476,316,2.233,477,3.626,1062,3.404,1768,4.461,2786,5.749,2787,6.256]],["title/Chap_6.html#laboratory-exercise-65",[47,1.395,143,1.065,2628,3.706]],["text/Chap_6.html#laboratory-exercise-65",[2,1.179,32,3.286,99,1.027,123,2.862,127,2.753,143,1.882,153,1.987,155,3.192,169,1.469,316,2.221,477,3.607,1062,3.386,1768,4.437,2786,5.719,2787,6.223]],["title/Chap_6.html#laboratory-exercise-66",[47,1.395,143,1.065,2633,3.521]],["text/Chap_6.html#laboratory-exercise-66",[2,1.179,32,3.286,99,1.027,123,2.862,127,2.753,143,1.882,153,1.987,155,3.192,169,1.469,316,2.221,477,3.607,1062,3.386,1768,4.437,2786,5.719,2787,6.223]],["title/Chap_6.html#laboratory-exercise-67",[47,1.395,143,1.065,2634,3.937]],["text/Chap_6.html#laboratory-exercise-67",[2,1.149,99,1.001,108,1.085,123,2.788,143,1.833,151,3.514,155,3.11,255,3.904,262,5.374,269,2.189,285,2.353,316,2.164,412,1.478,431,3.155,505,2.116,564,2.431,574,2.901,587,2.214,709,4.059,969,4.23,1536,4.142,1768,4.323,2786,5.572,2787,6.063]],["title/Chap_6.html#laboratory-exercise-68",[47,1.395,143,1.065,2635,3.937]],["text/Chap_6.html#laboratory-exercise-68",[99,1.038,122,4.21,123,2.892,143,1.902,155,3.226,316,2.245,371,3.53,477,3.646,1515,4.485,1768,4.485,2788,7.585]],["title/Chap_7.html",[11,0.128,34,0.468,95,0.981,1060,1.401,1062,1.315,1134,1.687]],["text/Chap_7.html",[1,1.374,2,1.034,6,1.47,7,0.444,11,0.433,12,0.226,13,0.616,15,0.293,16,0.275,19,1.146,20,1.363,25,1.955,31,0.684,32,0.755,33,0.826,34,1.396,35,1.77,36,1.473,37,0.91,39,2.325,40,0.531,43,0.275,44,0.546,46,0.637,47,0.131,48,0.755,49,0.529,50,0.476,53,1.337,54,0.195,59,1.016,64,0.816,65,0.369,66,0.968,68,0.375,76,1.124,77,0.183,78,0.205,80,0.826,84,0.645,86,0.565,87,0.956,88,0.525,91,1.153,93,0.585,94,0.348,95,1.187,98,0.26,99,1.173,100,1.336,101,2.253,103,0.565,104,0.382,105,0.583,106,0.877,107,0.69,108,0.659,109,1.765,111,0.18,112,0.546,114,0.543,116,0.546,120,0.571,121,0.267,122,0.222,124,0.67,125,0.348,127,1.846,132,0.275,133,0.749,134,0.501,136,0.897,137,0.885,138,1.029,142,0.627,143,0.1,148,0.509,151,0.829,153,0.934,158,0.803,159,1.015,161,0.465,167,1.605,169,1.095,170,0.41,184,0.388,188,0.778,195,0.665,197,0.637,198,0.567,202,0.317,211,0.575,213,0.465,214,2.381,216,2.105,220,0.778,223,0.418,224,0.604,229,0.317,232,1.069,240,0.966,243,1.558,244,1.481,247,0.267,250,0.241,253,0.851,255,0.593,256,0.809,257,0.317,259,1.509,260,0.231,263,0.565,266,0.816,267,1.419,269,1.247,270,0.966,275,0.317,276,0.888,277,0.778,279,1.197,281,0.645,283,0.457,285,0.756,286,0.808,287,0.327,288,0.163,289,0.744,292,0.629,295,0.231,296,1.42,298,0.642,299,0.348,304,0.418,305,0.313,308,0.293,309,0.763,310,1.557,311,1.099,313,0.189,315,0.529,316,0.933,318,1.681,319,2.062,321,0.591,322,1.38,323,1.533,325,1.024,327,1.423,328,0.348,329,1.007,330,0.897,332,1.861,336,0.388,337,1.229,339,1.143,340,0.347,341,1.466,342,0.231,343,0.231,344,0.172,347,0.26,348,1.32,354,1.267,355,1.642,356,1.492,357,0.317,358,1.375,359,0.423,362,0.226,363,0.205,364,1.473,366,0.205,367,0.561,368,0.864,369,0.816,371,1.052,373,0.707,378,1.233,379,0.862,382,0.828,383,0.888,384,0.209,386,0.565,387,1.184,391,0.202,393,0.575,394,1.409,395,0.205,409,1.451,412,1.179,416,1.729,422,0.275,426,0.348,427,1.62,429,0.744,431,0.332,433,0.626,440,0.725,443,0.793,446,1.115,447,0.816,448,1.458,449,0.843,450,1.245,451,1.05,453,0.511,454,0.293,456,0.444,457,0.435,462,0.454,463,0.846,464,0.472,466,1.34,467,0.888,468,0.285,469,1.158,472,0.585,474,0.317,476,0.743,477,0.829,482,0.348,486,1.304,487,0.198,488,0.213,489,1.327,493,1.12,496,0.476,497,0.348,501,1.303,502,1.184,505,1.569,510,0.705,514,0.939,525,0.793,528,0.205,532,0.705,533,0.546,534,0.26,537,1.021,539,1.02,540,1.639,549,1.055,550,1.341,551,1.02,559,0.275,560,0.388,561,2.311,562,0.789,564,1.52,565,0.881,567,0.616,570,0.743,571,0.231,572,0.247,573,1.311,574,1.327,576,0.543,579,1.575,580,1.514,584,0.743,586,1.36,587,1.457,588,1.095,589,0.998,590,0.267,591,0.885,593,0.241,594,0.247,597,1.055,600,0.454,601,0.642,602,1.095,603,3.096,605,0.962,607,0.845,608,0.903,611,0.565,617,1.549,618,0.317,619,0.816,621,1.015,623,0.241,626,1.997,627,2.197,629,0.317,632,1.291,633,0.382,636,1.721,637,0.809,638,1.134,639,0.793,641,1.532,642,0.765,651,0.575,653,0.5,654,0.403,657,0.957,658,0.514,661,0.839,664,1.268,666,0.777,668,0.465,669,0.67,672,0.454,675,0.872,676,1.608,677,0.267,679,0.348,682,1.964,684,0.71,685,0.534,689,0.593,700,0.816,706,0.968,708,0.454,709,0.426,724,0.236,728,1.219,729,0.465,731,0.247,733,2.901,734,0.253,735,0.488,738,0.247,740,0.26,750,1.975,751,0.267,752,1.487,756,0.688,757,0.789,761,1.677,762,1.683,763,0.846,764,1.155,765,0.793,773,0.358,774,0.546,778,0.293,779,0.293,780,0.293,781,0.5,782,0.529,783,1.02,787,0.5,788,0.293,789,0.275,790,0.293,792,0.939,793,0.275,794,0.275,795,0.897,796,0.723,797,0.672,799,1.311,801,0.593,802,1.359,806,2.009,808,0.403,811,1.522,812,0.348,817,0.241,819,0.582,820,0.881,821,0.26,826,0.514,830,1.783,831,0.637,839,0.331,843,0.604,845,1.907,846,0.241,848,0.514,852,1.24,854,0.348,857,1.695,858,0.265,860,1.551,863,0.939,873,0.616,880,0.253,881,0.565,883,1.02,886,2.141,888,3.637,893,1.671,895,0.582,899,0.231,906,0.317,907,0.465,918,0.209,919,0.209,927,0.978,930,0.657,931,0.488,932,0.705,933,1.226,935,0.304,936,0.293,945,0.293,947,2.171,952,0.231,953,0.284,959,0.418,963,2.406,965,0.275,966,1.567,968,0.488,969,0.642,970,0.657,972,0.267,983,1.005,991,0.331,1005,0.488,1012,0.317,1019,0.454,1022,0.642,1023,0.348,1024,1.433,1029,0.26,1030,0.293,1033,0.253,1034,0.534,1042,0.293,1051,1.105,1054,0.921,1056,0.231,1058,0.881,1060,3.139,1061,0.317,1062,1.743,1063,1.268,1064,0.881,1065,2.794,1067,1.471,1068,3.42,1069,0.969,1070,2.267,1071,4.613,1072,1.662,1075,3.062,1076,2.178,1078,0.293,1086,0.284,1089,0.642,1092,0.293,1093,0.236,1100,2.267,1105,0.293,1108,0.67,1111,0.317,1129,0.348,1134,0.231,1136,0.845,1140,3.049,1141,1.526,1145,0.348,1155,0.293,1162,1.146,1165,0.773,1169,1.793,1174,1.089,1177,0.609,1182,2.974,1186,0.793,1191,0.5,1211,0.348,1212,0.348,1215,0.304,1216,1.402,1217,0.418,1222,0.241,1223,0.348,1226,1.089,1230,1.575,1232,0.317,1234,0.476,1242,1.449,1245,0.546,1247,0.293,1248,0.348,1250,0.317,1257,0.317,1263,0.5,1264,1.907,1269,0.275,1270,0.435,1272,0.743,1280,0.688,1289,1.02,1310,0.205,1316,0.293,1317,0.304,1341,0.846,1347,1.155,1349,2.188,1351,0.565,1352,1.05,1353,0.267,1362,0.881,1366,0.275,1374,0.629,1376,1.184,1378,0.585,1384,0.565,1388,0.348,1394,0.609,1418,0.546,1422,0.765,1429,0.293,1437,1.841,1443,0.293,1454,1.723,1456,0.348,1463,0.304,1465,0.317,1466,0.846,1470,1.998,1478,1.184,1479,0.331,1482,0.546,1483,0.247,1486,0.304,1488,0.293,1513,0.444,1514,0.293,1515,1.02,1520,0.348,1521,0.585,1522,0.348,1524,0.789,1536,1.134,1540,0.546,1544,0.331,1545,0.609,1549,0.348,1550,0.348,1570,0.348,1577,0.789,1580,0.275,1587,0.317,1588,1.368,1591,0.317,1594,0.816,1598,0.514,1606,0.637,1607,1.637,1620,1.623,1621,0.637,1622,0.743,1628,1.226,1637,0.267,1639,0.67,1647,0.348,1653,0.705,1669,1.043,1670,0.267,1694,1.43,1695,1.526,1698,0.317,1699,0.881,1700,0.984,1704,0.348,1712,0.816,1714,2.141,1717,0.293,1722,0.585,1726,1.133,1742,0.637,1755,0.317,1756,0.317,1758,0.348,1762,0.348,1768,0.845,1769,0.348,1774,1.268,1780,0.488,1791,0.275,1792,0.637,1795,1.281,1797,0.317,1798,0.67,1813,0.317,1827,0.293,1844,0.846,1868,0.293,1869,2.5,1922,0.705,1953,1.155,1979,0.267,2001,1.189,2010,0.637,2023,0.293,2028,0.348,2043,0.864,2044,0.984,2045,0.609,2046,0.317,2047,0.275,2048,0.293,2053,0.304,2076,0.984,2081,0.348,2085,0.293,2086,0.864,2088,0.609,2089,0.348,2099,0.881,2106,0.609,2108,2.361,2110,0.956,2112,0.382,2113,1.43,2116,0.253,2125,0.529,2133,2.629,2158,0.317,2159,0.348,2193,1.015,2201,0.881,2207,0.348,2213,1.314,2219,0.348,2221,0.585,2229,1.471,2233,0.284,2244,0.705,2277,0.546,2281,2.167,2285,2.237,2286,2.43,2287,1.514,2308,0.637,2320,0.317,2324,3.813,2338,0.348,2351,0.348,2357,1.884,2359,3.175,2360,0.348,2364,0.348,2370,0.348,2371,0.348,2372,0.348,2373,0.317,2374,0.348,2375,0.348,2376,0.348,2377,0.293,2378,0.317,2379,0.317,2393,0.637,2394,0.529,2399,0.304,2400,0.565,2402,0.331,2415,0.284,2416,0.348,2417,0.331,2418,0.637,2422,0.304,2428,0.348,2431,1.155,2441,0.317,2442,0.609,2443,0.348,2444,0.348,2445,1.588,2462,0.881,2464,0.637,2467,0.348,2468,0.348,2469,0.637,2475,1.793,2484,1.78,2486,0.348,2503,0.284,2507,0.348,2525,0.348,2542,0.609,2547,0.304,2550,0.881,2563,0.67,2565,0.816,2572,0.317,2587,0.637,2592,0.67,2596,0.348,2607,0.609,2613,2.549,2618,0.317,2620,0.304,2623,0.293,2632,0.275,2639,0.881,2656,0.348,2665,0.637,2666,2.241,2673,1.247,2698,0.585,2713,0.348,2714,0.348,2735,0.348,2749,0.348,2768,0.637,2777,0.67,2789,0.399,2790,0.399,2791,0.399,2792,1.747,2793,2.402,2794,0.399,2795,1.184,2796,0.712,2797,0.399,2798,0.399,2799,0.768,2800,0.399,2801,0.399,2802,0.712,2803,1.184,2804,0.969,2805,0.969,2806,1.133,2807,0.969,2808,0.399,2809,0.399,2810,2.43,2811,1.599,2812,0.399,2813,0.399,2814,0.969,2815,0.399,2816,0.399,2817,0.399,2818,0.399,2819,0.399,2820,0.399,2821,0.399,2822,2.592,2823,0.399,2824,0.399,2825,0.399,2826,4.183,2827,0.348,2828,1.247,2829,2.083,2830,0.712,2831,0.712,2832,1.029,2833,0.399,2834,0.969,2835,1.43,2836,0.712,2837,0.399,2838,0.768,2839,0.399,2840,0.399,2841,0.399,2842,0.768,2843,0.712,2844,0.399,2845,0.712,2846,1.184,2847,0.399,2848,0.399,2849,0.399,2850,1.973,2851,0.399,2852,0.712,2853,0.399,2854,1.089,2855,0.399,2856,0.399,2857,0.399,2858,0.399,2859,0.348,2860,1.247,2861,0.399,2862,0.712,2863,0.399,2864,3.753,2865,1.599,2866,1.793,2867,2.077,2868,0.712,2869,0.67,2870,0.712,2871,0.399,2872,0.712,2873,0.712,2874,0.399,2875,0.399,2876,0.712,2877,0.304,2878,0.969,2879,1.505,2880,0.712,2881,1.747,2882,0.399,2883,0.399,2884,0.399,2885,0.399,2886,0.399,2887,0.399,2888,0.399,2889,0.399,2890,0.399,2891,0.399,2892,0.399,2893,0.399,2894,0.399,2895,0.399,2896,2.077,2897,0.399,2898,0.399,2899,3.636,2900,0.399,2901,1.324,2902,0.768,2903,2.322,2904,0.399,2905,0.768,2906,1.11,2907,0.399,2908,0.768,2909,0.712,2910,0.399,2911,1.505,2912,0.712,2913,0.399,2914,1.66,2915,0.399,2916,0.712,2917,0.399,2918,1.747,2919,0.399,2920,0.399,2921,0.969,2922,0.399,2923,0.348,2924,1.793,2925,1.793,2926,1.247,2927,0.712,2928,1.875,2929,0.399,2930,2.009,2931,1.599,2932,0.768,2933,0.399,2934,2.962,2935,3.158,2936,0.399,2937,0.399,2938,0.399,2939,1.505,2940,1.184,2941,0.399,2942,1.268,2943,1.184,2944,0.399,2945,1.747,2946,0.712,2947,1.505,2948,0.399,2949,1.505,2950,0.399,2951,0.399,2952,0.399,2953,0.712,2954,0.399,2955,0.399,2956,1.725,2957,0.399,2958,0.399,2959,0.399,2960,0.969,2961,0.399,2962,0.399,2963,0.399,2964,1.11,2965,0.399,2966,0.399,2967,0.399,2968,0.399,2969,0.399,2970,0.768,2971,0.399,2972,0.969,2973,0.399,2974,0.399,2975,0.399,2976,0.712,2977,0.399,2978,0.712,2979,0.768,2980,0.712,2981,0.399,2982,0.399,2983,1.324,2984,0.712,2985,0.399,2986,0.399,2987,0.712,2988,0.712,2989,0.712,2990,0.712,2991,1.428,2992,1.725,2993,1.428,2994,0.399,2995,0.768,2996,1.11,2997,0.399,2998,1.66,2999,0.768,3000,0.399,3001,0.399,3002,0.399,3003,0.399,3004,0.399,3005,0.712,3006,1.588,3007,0.399,3008,0.399,3009,0.768,3010,1.029,3011,0.399,3012,0.712,3013,0.399,3014,0.399,3015,0.399,3016,1.029,3017,0.399,3018,1.029,3019,0.399,3020,0.399,3021,1.247,3022,0.348,3023,1.029,3024,0.399,3025,1.029,3026,1.247,3027,1.247,3028,0.399,3029,3.79,3030,0.399,3031,0.399,3032,0.712,3033,2.077,3034,0.399,3035,0.712,3036,0.768,3037,0.712,3038,1.324,3039,0.399,3040,0.637,3041,0.399,3042,0.399,3043,0.399,3044,0.399,3045,0.399,3046,1.66,3047,1.599,3048,0.399,3049,0.768,3050,0.399,3051,0.399,3052,0.399,3053,1.856,3054,0.399,3055,0.399,3056,0.712,3057,0.399,3058,0.768,3059,0.399,3060,0.399,3061,0.712,3062,0.348,3063,0.712,3064,0.399,3065,0.637,3066,0.712,3067,0.399,3068,0.399,3069,1.184,3070,1.856,3071,2.445,3072,2.186,3073,0.712,3074,0.969,3075,0.399,3076,0.399,3077,1.029,3078,0.399,3079,0.399,3080,0.399,3081,0.768,3082,0.768,3083,0.768,3084,0.768,3085,0.399,3086,1.793,3087,0.712,3088,0.399,3089,0.768,3090,0.67,3091,1.247,3092,0.399,3093,0.399,3094,0.399,3095,0.768,3096,0.399,3097,1.11,3098,0.768,3099,0.399,3100,0.399,3101,0.399,3102,0.768,3103,0.399,3104,0.399,3105,0.399,3106,0.399,3107,0.768,3108,0.768,3109,0.768,3110,1.11,3111,0.399,3112,0.399,3113,0.399,3114,0.399,3115,0.399,3116,0.399,3117,0.768,3118,1.43,3119,1.247,3120,1.43,3121,0.348,3122,0.969,3123,0.399,3124,0.399,3125,0.768,3126,0.399,3127,2.402,3128,0.399,3129,3.371,3130,0.712,3131,1.747,3132,0.399,3133,1.324,3134,0.399,3135,0.399,3136,0.399,3137,0.399,3138,1.599,3139,2.096,3140,0.399,3141,0.969,3142,2.534,3143,2.096,3144,0.712,3145,0.399,3146,1.505,3147,0.637,3148,1.324,3149,0.768,3150,1.599,3151,0.768,3152,0.768,3153,0.768,3154,0.399,3155,0.399,3156,1.599,3157,0.399,3158,0.768,3159,0.399,3160,0.348,3161,0.348,3162,0.399,3163,2.445,3164,0.399,3165,0.712,3166,0.712,3167,0.712,3168,0.399,3169,0.712,3170,0.399,3171,0.399,3172,0.399,3173,1.029,3174,0.399,3175,0.399,3176,1.247,3177,0.768,3178,1.875,3179,0.399,3180,0.399,3181,0.399,3182,0.399,3183,0.712,3184,0.712,3185,0.399,3186,0.348,3187,1.599,3188,0.768,3189,0.399,3190,0.399,3191,0.712,3192,0.399,3193,0.399,3194,0.348,3195,0.712,3196,0.399,3197,0.399,3198,0.768,3199,0.399,3200,1.324,3201,0.969,3202,0.712,3203,0.399,3204,0.399,3205,0.399,3206,0.399,3207,0.399,3208,0.399,3209,0.399,3210,0.712,3211,0.712,3212,0.399,3213,0.399,3214,0.712,3215,0.712,3216,0.768,3217,0.768,3218,0.399,3219,0.399,3220,0.399,3221,0.399,3222,0.712,3223,1.324,3224,0.399,3225,0.399,3226,0.399,3227,1.029,3228,0.768,3229,1.11,3230,0.399,3231,0.399,3232,0.399,3233,0.399,3234,0.712,3235,0.712,3236,0.712,3237,0.399,3238,0.399,3239,1.973,3240,0.399,3241,0.969,3242,0.399,3243,0.399,3244,0.399,3245,0.399,3246,0.712,3247,3.577,3248,3.5,3249,0.712,3250,2.402,3251,0.712,3252,0.712,3253,0.712,3254,1.428,3255,1.029,3256,0.768,3257,0.399,3258,0.399,3259,0.768,3260,0.768,3261,0.399,3262,0.399,3263,0.399,3264,0.399,3265,0.399,3266,0.399,3267,0.399,3268,0.399,3269,0.399,3270,0.399,3271,0.969,3272,0.399,3273,0.399,3274,1.184,3275,0.399,3276,0.399,3277,0.399,3278,0.768,3279,0.399,3280,0.399,3281,0.399,3282,0.712,3283,0.399,3284,0.399,3285,0.712,3286,0.348,3287,0.712,3288,0.399,3289,0.768,3290,1.029,3291,0.768,3292,1.875,3293,0.399,3294,0.399,3295,0.399,3296,0.399,3297,0.399,3298,0.399,3299,0.399,3300,1.11,3301,0.399,3302,0.399,3303,0.399,3304,0.399,3305,0.399,3306,0.399,3307,0.399,3308,0.712,3309,0.712,3310,0.399,3311,0.768,3312,0.969,3313,0.399,3314,1.747,3315,1.029,3316,1.029,3317,1.029,3318,0.399,3319,0.399,3320,0.399,3321,0.399,3322,0.399,3323,0.768,3324,0.399,3325,0.399,3326,0.399,3327,0.399,3328,0.712,3329,0.399,3330,0.399,3331,0.399,3332,1.324,3333,0.399,3334,0.399,3335,0.399,3336,0.399,3337,0.399,3338,0.399,3339,0.768,3340,0.399,3341,0.969,3342,1.247,3343,0.399,3344,0.399,3345,0.768,3346,0.399,3347,0.399,3348,0.399,3349,0.399,3350,0.399,3351,0.399,3352,1.11,3353,0.399,3354,0.768,3355,0.399,3356,0.399,3357,0.399,3358,0.399,3359,0.399,3360,0.399,3361,0.399,3362,0.399,3363,0.399,3364,0.348,3365,0.399,3366,0.399,3367,0.399,3368,0.399,3369,0.399,3370,0.399,3371,0.399,3372,0.399,3373,0.399,3374,0.399,3375,0.399,3376,0.399,3377,0.399,3378,0.399,3379,0.67,3380,0.399,3381,0.399,3382,0.399,3383,0.399,3384,0.399,3385,0.399,3386,0.399,3387,0.399,3388,0.399,3389,0.768,3390,0.399,3391,0.399,3392,0.399,3393,0.399,3394,0.399,3395,0.399,3396,0.399,3397,0.399,3398,0.399,3399,0.399,3400,0.399,3401,0.399,3402,0.399,3403,0.768,3404,0.399,3405,0.399,3406,0.399,3407,0.399,3408,0.399,3409,0.399,3410,0.399,3411,0.399,3412,0.399,3413,0.399,3414,0.399,3415,0.399,3416,0.399,3417,0.399,3418,0.348,3419,0.399]],["title/Chap_7.html#the-langevin-equation-a-case-study",[11,0.143,34,0.523,95,1.095,1060,1.565,1062,1.469]],["text/Chap_7.html#the-langevin-equation-a-case-study",[2,0.843,6,1.536,11,0.396,15,3.945,20,2.921,34,1.421,37,2.159,39,1.806,40,1.995,50,3.324,53,2.512,91,1.944,95,1.806,106,1.722,109,2.577,142,0.643,153,1.86,169,1.532,214,2.219,223,2.921,244,3.174,285,1.486,287,2.283,295,3.105,296,1.897,310,2.498,319,2.451,322,2.351,323,2.13,341,2.668,356,1.391,358,1.437,363,2.763,364,5.1,371,3.269,391,2.714,412,1.679,416,1.421,422,3.699,427,2.351,450,2.635,474,4.257,477,2.58,482,4.684,489,2.13,505,1.553,537,2.189,540,2.189,573,2.386,587,1.626,597,1.859,603,4.629,641,1.661,675,2.714,676,3.376,685,3.376,706,2.074,733,4.969,761,1.828,773,2.498,808,2.813,857,2.46,858,1.851,888,4.058,1060,3.376,1062,3.169,1065,4.103,1136,3.174,1140,3.324,1182,3.594,1223,4.684,1349,3.041,1594,3.945,1598,3.594,1607,3.899,1714,2.668,1722,4.09,1768,4.153,1769,4.684,1953,3.594,2044,3.699,2112,2.668,2125,3.699,2281,3.945,2308,4.451,2324,4.435,2357,3.699,2789,5.368,2790,5.368,2791,5.368,2792,4.684,2793,6.738,2794,5.368,2795,4.451,2796,4.977,2797,5.368,2798,5.368,2799,7.024,2800,5.368,2801,5.368,2802,4.977,2803,4.451,2804,4.684,2805,4.684,2806,4.257,2807,4.684,2808,5.368,2809,5.368,2810,3.699,2811,4.977,2812,5.368]],["title/Chap_7.html#from-t-to-n",[394,1.242,886,2.489]],["text/Chap_7.html#from-t-to-n",[1,1.734,2,1.25,6,1.871,11,0.288,12,3.704,25,1.85,34,1.378,39,2.677,59,2.43,95,2.2,127,2.399,134,2.951,220,2.951,224,3.559,229,5.186,256,2.339,277,2.951,286,1.676,313,3.092,323,3.157,358,1.751,364,4.26,378,2.951,379,2.494,426,5.707,469,3.783,489,3.157,533,5.656,560,3.307,573,3.536,608,2.951,626,3.157,632,3.484,641,1.591,708,3.866,734,4.151,761,2.227,795,2.595,806,4.806,845,4.812,970,3.866,1062,2.951,1076,3.307,1136,3.866,1594,4.806,1622,4.378,1795,4.507,2043,3.955,2793,4.983,2807,5.707,2813,6.539,2814,5.707,2815,6.539,2816,6.539,2817,6.539,2818,6.539,2819,6.539]],["title/Chap_7.html#impulse-invariant-sampling",[39,1.429,626,1.685,1795,2.406]],["text/Chap_7.html#impulse-invariant-sampling",[1,1.521,2,1.189,6,1.997,11,0.431,34,1.417,39,2.919,49,2.958,77,1.966,91,1.188,95,1.444,99,1.281,101,2.006,142,0.723,169,0.84,211,1.726,240,1.315,244,2.537,253,1.825,266,2.029,275,3.403,285,1.188,292,2.431,296,1.516,318,2.633,319,1.498,323,2.394,332,2.743,337,1.176,340,1.936,355,0.976,356,1.112,358,1.149,364,2.795,394,1.731,412,0.867,427,1.879,433,1.879,448,1.774,451,3.154,462,2.537,469,4.037,489,2.394,493,1.776,551,1.936,561,2.926,562,3.051,567,2.382,570,2.873,573,1.907,608,2.723,619,3.154,626,3.442,627,4.085,641,1.206,675,2.17,676,2.063,677,2.873,706,1.658,709,2.382,728,1.774,761,1.462,762,2.291,764,4.039,806,3.154,819,2.249,820,3.403,843,3.798,860,2.658,888,4.239,907,2.596,931,2.724,952,2.483,1024,3.657,1042,3.154,1056,2.483,1060,2.9,1065,2.249,1068,5.881,1075,5.881,1076,2.17,1140,4.321,1141,4.598,1162,1.8,1186,2.382,1316,3.154,1454,5.769,1478,3.568,1606,3.559,1620,2.209,1628,4.289,1694,6.278,1700,2.958,1774,3.154,1795,2.431,2010,3.559,2023,3.154,2108,4.672,2359,4.598,2444,3.745,2814,3.745,2820,4.291,2821,4.291,2822,4.434,2823,4.291,2824,4.291,2825,4.291,2826,4.546,2827,3.745,2828,3.745,2829,4.598,2830,3.979,2831,3.979,2832,5.594,2833,4.291,2834,3.745,2835,3.559,2836,3.979,2837,4.291,2838,6.034,2839,4.291,2840,4.291,2841,4.291,2842,6.034,2843,3.979,2844,4.291,2845,3.979,2846,3.559,2847,4.291,2848,4.291,2849,4.291,2850,3.745,2851,4.291,2852,3.979,2853,4.291,2854,3.27,2855,4.291,2856,4.291,2857,4.291,2858,4.291,2859,3.745]],["title/Chap_7.html#how-big-is-big-how-small-is-small",[1349,3.064,1588,4.289]],["text/Chap_7.html#how-big-is-big-how-small-is-small",[6,1.441,11,0.412,13,3.738,19,1.276,25,1.425,31,1.998,32,2.205,34,1.082,36,3.28,95,1.694,106,1.616,112,3.579,153,1.333,159,4.786,184,2.546,188,3.038,211,2.025,216,2.461,220,2.272,243,3.47,259,1.183,267,4.588,310,3.134,319,2.647,321,2.082,322,2.205,325,1.635,358,1.348,359,1.92,382,2.082,393,2.025,395,2.592,431,2.173,433,2.205,448,2.082,466,5.078,493,1.121,501,2.082,525,2.795,532,3.196,550,2.142,603,3.981,633,2.503,641,1.737,654,2.639,657,2.795,661,2.111,666,2.741,676,2.42,682,3.707,733,5.14,738,3.118,811,2.173,826,3.371,830,4.095,860,4.697,888,3.707,927,1.801,932,3.196,933,3.579,935,3.837,968,3.196,1022,2.913,1051,2.461,1058,3.993,1060,2.42,1065,2.639,1076,3.405,1182,4.508,1186,2.795,1226,3.837,1230,2.689,1245,3.579,1280,3.118,1347,3.371,1349,2.853,1513,2.913,1536,2.853,1620,2.592,1669,3.046,1700,4.64,1714,2.503,1780,3.196,2028,4.394,2108,3.371,2213,3.837,2229,3.701,2324,5.024,2357,3.47,2364,4.394,2613,3.837,2792,7.067,2793,3.837,2805,4.394,2829,3.837,2834,4.394,2860,4.394,2861,5.035,2862,4.668,2863,5.035,2864,6.867,2865,7.033,2866,6.016,2867,6.715,2868,4.668,2869,5.876,2870,4.668,2871,5.035,2872,4.668,2873,4.668,2874,5.035,2875,5.035,2876,4.668,2877,3.837,2878,4.394,2879,6.62,2880,4.668,2881,4.394,2882,5.035,2883,5.035,2884,5.035,2885,5.035,2886,5.035,2887,5.035,2888,5.035,2889,5.035,2890,5.035,2891,5.035,2892,5.035,2893,5.035]],["title/Chap_7.html#choosing-the-sampling-period",[39,1.429,339,2.147,1620,2.186]],["text/Chap_7.html#choosing-the-sampling-period",[2,1.046,6,1.128,11,0.431,19,0.747,25,1.884,32,1.726,33,2.28,34,0.633,35,2.286,37,2.678,39,3.093,95,1.326,99,1.057,101,3.091,105,0.841,106,1.265,108,0.843,136,1.564,138,1.375,151,1.894,161,2.384,216,1.926,243,3.914,244,3.358,256,1.41,259,1.948,269,2.482,276,3.426,279,1.41,285,1.572,299,3.439,319,3.1,325,1.28,327,2.415,328,3.439,329,1.585,337,0.882,339,2.871,342,2.28,354,1.993,355,1.292,356,1.021,358,1.52,366,2.028,379,1.503,427,1.726,446,1.055,447,1.864,448,2.753,454,2.896,477,1.894,493,0.877,501,1.629,551,1.778,561,3.764,574,3.191,584,2.638,586,1.701,588,3.604,589,3.285,591,3.517,594,2.44,611,2.896,621,2.801,626,1.564,627,1.894,636,1.41,637,2.233,666,2.145,689,2.104,750,2.104,756,3.517,757,2.801,762,4.123,774,2.801,802,1.959,817,2.384,819,2.065,820,3.125,830,1.993,845,2.384,852,2.44,860,2.44,873,2.188,881,4.173,888,3.56,907,2.384,1024,2.065,1054,5.52,1060,3.711,1062,1.778,1068,4.037,1089,2.28,1140,4.123,1162,1.653,1174,4.327,1216,1.653,1230,3.032,1250,3.125,1341,3.003,1347,2.638,1349,3.217,1352,4.893,1454,3.003,1478,2.33,1524,2.801,1536,3.217,1621,3.268,1647,3.439,1694,3.268,1695,5.551,1699,3.125,1700,2.716,1722,3.003,1774,4.893,1844,3.003,1869,3.125,2201,3.125,2213,3.003,2359,6.466,2431,2.638,2550,3.125,2826,5.527,2829,3.003,2830,3.654,2831,3.654,2832,3.654,2850,6.357,2894,3.941,2895,3.941,2896,3.268,2897,3.941,2898,3.941,2899,7.234,2900,3.941,2901,6.172,2902,5.679,2903,6.172,2904,3.941,2905,5.679,2906,6.657,2907,3.941,2908,5.679,2909,3.654,2910,3.941,2911,3.439,2912,3.654,2913,3.941,2914,3.268,2915,3.941,2916,3.654,2917,3.941,2918,3.439,2919,3.941,2920,3.941,2921,3.439,2922,3.941,2923,3.439]],["title/Chap_7.html#the-langevin-velocity-equation",[34,0.682,1060,2.041,1065,2.226]],["text/Chap_7.html#the-langevin-velocity-equation",[1,1.225,11,0.424,34,1.463,53,2.323,91,1.556,99,1.246,109,2.063,169,1.1,256,2.011,259,1.701,279,2.011,285,1.556,309,3.002,318,1.742,323,2.231,332,2.037,337,1.243,348,1.722,355,1.279,356,2.074,358,1.505,367,3.66,369,2.659,373,1.987,379,2.144,409,1.307,416,2.12,427,3.17,489,2.231,525,3.121,540,2.293,573,2.499,597,1.335,626,2.231,642,3.875,675,2.843,676,2.702,706,2.172,733,5.552,799,2.499,806,4.132,808,2.947,888,3.537,927,2.011,963,2.911,966,2.794,1065,3.794,1068,3.997,1075,3.997,1310,2.894,1418,3.997,1422,3.875,1470,4.1,1515,3.324,1524,5.145,1795,3.185,2244,3.569,2285,3.4,2286,3.4,2324,3.185,2357,5.517,2394,3.875,2399,4.284,2417,4.662,2418,4.662,2793,4.284,2795,4.662,2802,5.212,2807,4.906,2814,4.906,2845,5.212,2846,4.662,2924,4.459,2925,5.74,2926,6.317,2927,5.212,2928,6.638,2929,5.622,2930,5.32,2931,7.422,2932,7.238,2933,5.622,2934,3.997,2935,3.997,2936,5.622,2937,5.622,2938,5.622]],["title/Chap_7.html#autocorrelation-function",[412,1.012,505,1.449]],["text/Chap_7.html#autocorrelation-function",[1,1.289,2,0.929,11,0.428,25,1.674,34,1.384,64,2.797,99,1.261,148,2.71,170,3.158,195,2.753,224,3.219,269,1.771,318,1.833,332,2.143,337,1.273,348,1.812,355,1.701,356,1.532,373,2.896,383,3.044,409,1.738,412,1.511,416,2.402,493,1.317,505,2.493,564,1.966,587,1.791,605,2.516,626,2.966,627,3.593,636,2.116,654,3.1,661,2.48,729,3.577,802,2.939,873,3.283,888,3.653,918,3.1,930,3.497,1060,2.843,1065,3.1,1067,5.494,1068,6.122,1071,4.781,1072,5.494,1075,4.204,1155,4.347,1366,4.076,1454,4.507,2086,3.577,2462,4.69,2464,4.904,2484,4.204,2665,4.904,2666,5.827,2836,5.483,2924,4.69,2926,5.161,2939,5.161,2940,4.904,2941,5.914,2942,4.347,2943,4.904,2944,5.914,2945,5.161]],["title/Chap_7.html#power-spectral-density",[564,1.412,587,1.286,636,1.519]],["text/Chap_7.html#power-spectral-density",[1,1.406,11,0.435,25,2.233,34,1.036,35,1.91,37,1.901,53,1.517,66,1.826,88,2.235,93,4.916,99,1.167,101,2.624,105,1.008,107,2.224,108,0.701,136,1.875,138,1.649,169,1.544,259,1.11,269,1.931,276,2.432,285,2.032,311,2.413,323,1.875,337,1.324,340,2.133,348,1.976,355,1.468,356,1.671,358,1.265,383,3.32,409,1.834,412,0.955,416,2.352,429,2.039,446,1.727,464,2.01,493,1.436,501,2.667,505,1.867,564,2.624,576,3.152,586,2.039,587,2.39,588,3,589,2.734,591,2.927,597,1.123,605,2.01,636,2.823,638,2.677,639,2.623,661,2.705,675,3.262,676,2.272,733,3,735,3,796,4.202,802,2.349,1060,3.53,1064,3.748,1065,4.135,1067,4.741,1068,5.609,1070,5.349,1071,4.843,1072,4.741,1089,2.734,1092,3.473,1129,4.124,1162,1.982,1264,3.902,1289,3.814,1456,4.124,1607,2.623,1628,3.36,1653,3,1669,2.858,1714,2.349,1922,3,2053,3.601,2106,3.748,2357,3.257,2484,4.586,2665,3.919,2666,5.871,2673,6.886,2795,3.919,2822,4.741,2925,3.748,2926,4.124,2927,4.382,2939,6.409,2945,6.886,2946,4.382,2947,5.63,2948,4.726,2949,4.124,2950,4.726,2951,4.726,2952,4.726,2953,4.382]],["title/Chap_7.html#descriptive-statistics-mean-and-standard-deviation",[11,0.128,19,0.552,289,1.258,799,1.296,966,1.449,1714,1.449]],["text/Chap_7.html#descriptive-statistics-mean-and-standard-deviation",[1,1.468,2,1.171,6,0.822,11,0.43,19,1.412,20,2.437,25,2.293,34,1.365,36,1.871,39,1.507,47,0.943,48,1.257,53,0.921,54,1.403,59,1.067,65,1.38,91,1.976,95,0.966,99,1.189,101,1.489,103,2.11,112,2.041,127,2.829,134,1.296,136,1.139,138,1.563,142,0.344,143,0.72,148,1.316,151,2.152,158,2.084,169,1.216,213,1.737,214,1.187,243,1.979,256,1.027,259,1.293,267,1.627,269,1.648,276,1.478,277,1.296,279,1.602,281,1.296,289,1.239,296,2.196,316,0.85,318,1.387,319,1.921,323,1.139,327,1.221,330,1.139,332,2.441,336,1.452,337,1.349,341,1.427,348,2.064,354,1.452,355,1.878,356,1.746,358,0.769,359,1.095,367,1.452,379,1.095,382,1.187,409,1.279,412,0.58,416,1.89,443,1.594,446,0.769,448,1.187,449,1.403,453,1.027,457,1.627,466,1.922,469,1.661,496,1.778,501,1.187,505,0.831,532,1.823,540,1.826,550,1.221,564,0.955,579,2.391,580,2.997,587,0.87,597,1.063,602,1.823,603,3.675,607,1.698,621,2.041,636,1.027,641,1.737,657,2.485,661,1.204,664,3.291,684,1.427,728,1.187,733,1.823,750,2.391,761,2.539,762,1.533,764,1.922,774,2.041,799,2.995,801,1.533,802,2.735,811,1.239,857,2.522,860,1.778,888,3.488,919,1.505,927,2.224,947,3.037,959,1.563,963,3.187,966,3.349,983,1.276,1012,2.277,1034,1.38,1060,2.987,1064,2.277,1065,3.907,1067,2.11,1068,4.79,1069,4.803,1070,6.182,1071,4.398,1072,2.11,1075,5.075,1076,2.264,1140,3.408,1162,1.204,1182,2.997,1211,2.506,1212,2.506,1216,2.308,1226,2.188,1264,1.737,1270,1.627,1289,1.698,1341,2.188,1347,1.922,1418,2.041,1422,1.979,1437,4.044,1454,2.188,1466,2.188,1479,2.381,1514,2.11,1545,3.551,1549,2.506,1580,1.979,1695,3.412,1714,2.735,1792,2.381,1869,4.929,1953,1.922,2085,2.11,2089,2.506,2099,2.277,2108,1.922,2110,1.922,2113,3.713,2221,2.188,2244,1.823,2281,2.11,2285,3.759,2286,3.759,2324,3.521,2351,2.506,2357,1.979,2359,2.188,2418,2.381,2422,2.188,2431,1.922,2484,3.912,2620,2.188,2639,2.277,2666,2.041,2698,2.188,2714,2.506,2735,2.506,2826,4.389,2829,3.412,2835,2.381,2843,2.662,2860,3.907,2867,3.713,2868,2.662,2880,2.662,2903,6.247,2911,2.506,2921,2.506,2928,3.713,2930,2.11,2934,2.041,2935,2.041,2942,2.11,2943,2.381,2945,2.506,2947,2.506,2949,3.907,2954,2.871,2955,2.871,2956,6.738,2957,2.871,2958,2.871,2959,2.871,2960,2.506,2961,2.871,2962,2.871,2963,2.871,2964,5.503,2965,2.871,2966,2.871,2967,2.871,2968,2.871,2969,2.871,2970,4.477,2971,2.871,2972,2.506,2973,2.871,2974,2.871,2975,2.871,2976,2.662,2977,2.871,2978,2.662,2979,4.477,2980,2.662,2981,2.871,2982,2.871,2983,4.151,2984,2.662,2985,2.871,2986,2.871,2987,2.662,2988,2.662,2989,2.662,2990,2.662,2991,6.215,2992,6.738,2993,6.215,2994,2.871,2995,4.477,2996,5.503,2997,2.871,2998,2.381,2999,4.477,3000,2.871,3001,2.871,3002,2.871,3003,2.871,3004,2.871,3005,2.662,3006,4.929,3007,2.871,3008,2.871,3009,4.477,3010,4.151,3011,2.871,3012,2.662,3013,2.871,3014,2.871,3015,2.871,3016,4.151,3017,2.871,3018,4.151,3019,2.871,3020,2.871,3021,2.506,3022,2.506]],["title/Chap_7.html#the-langevin-position-equation",[34,0.682,214,1.756,1060,2.041]],["text/Chap_7.html#the-langevin-position-equation",[1,1.989,2,1.099,6,1.527,11,0.431,25,1.98,34,1.331,59,1.983,99,1.134,127,1.958,197,4.426,214,3.228,216,3.42,244,3.156,253,2.27,281,2.408,286,2.123,316,1.58,319,1.863,323,2.118,330,2.118,332,2.828,337,1.087,348,1.635,356,2.147,358,1.429,369,2.524,373,1.886,427,3.419,429,2.303,450,1.796,451,3.923,469,3.088,476,3.573,493,1.188,551,2.408,571,3.088,579,3.737,603,3.156,626,2.777,627,2.565,641,1.067,728,2.207,733,3.388,806,3.923,888,4.46,906,4.233,1060,2.565,1071,5.124,1075,4.974,1136,3.156,1216,2.238,1742,4.426,1795,3.024,2001,4.823,2108,5.548,2357,3.678,2793,4.067,2803,4.426,2804,4.658,2806,4.233,2828,4.658,2846,4.426,2942,3.923,2972,4.658,3023,4.949,3024,5.337,3025,6.488,3026,6.107,3027,6.107,3028,5.337,3029,7.569,3030,5.337,3031,5.337,3032,4.949,3033,4.426,3034,5.337,3035,4.949,3036,6.998,3037,4.949,3038,6.488,3039,5.337,3040,4.426]],["title/Chap_7.html#expected-value",[259,1.177,330,1.987]],["text/Chap_7.html#expected-value",[1,1.28,2,0.649,11,0.435,19,1.41,34,1.38,49,2.846,66,1.596,68,2.018,84,1.863,88,2.777,91,1.143,99,1.15,101,2.272,105,0.881,127,1.515,138,1.441,142,0.704,169,0.808,188,1.863,211,1.661,214,3.475,259,1.975,269,1.758,270,1.459,286,1.058,296,2.778,305,2.394,316,1.738,318,1.82,319,1.441,323,1.639,329,1.661,330,1.639,337,0.912,348,1.799,355,2.04,356,1.521,383,2.125,393,2.362,394,1.846,409,0.96,412,0.835,431,1.782,433,2.571,440,1.496,447,1.953,450,2.504,456,2.389,467,2.125,468,1.535,486,2.69,489,1.639,514,2.248,540,3.564,550,1.756,559,2.846,560,2.088,567,2.292,587,1.251,597,2.04,621,2.936,626,2.33,627,2.822,632,1.808,641,1.488,653,2.69,668,2.498,669,5.124,672,2.442,676,3.779,706,1.596,733,2.621,752,3.308,761,1.407,795,2.33,802,2.052,806,5.778,830,2.088,858,1.424,888,2.018,927,2.101,983,1.835,991,3.424,1029,2.69,1051,2.018,1060,2.822,1062,1.863,1063,3.035,1071,2.292,1072,3.035,1086,2.936,1093,2.442,1162,1.732,1165,1.596,1186,2.292,1470,2.339,1540,2.936,1606,3.424,1607,4.131,1628,2.936,1953,2.765,2001,2.846,2108,2.765,2221,3.147,2308,3.424,2324,3.326,2357,2.846,2428,3.604,2445,5.419,2486,3.604,2503,2.936,2572,3.275,2639,3.275,2777,5.124,2928,3.424,2931,5.444,2934,4.174,2935,4.174,2942,3.035,2960,3.604,3029,6.52,3032,3.829,3033,6.171,3040,3.424,3041,4.13,3042,4.13,3043,4.13,3044,4.13,3045,4.13,3046,3.424,3047,6.899,3048,4.13,3049,5.872,3050,4.13,3051,4.13,3052,4.13,3053,7.289,3054,4.13,3055,4.13,3056,3.829,3057,4.13,3058,5.872,3059,4.13,3060,4.13,3061,3.829,3062,3.604,3063,3.829,3064,4.13,3065,3.424,3066,3.829]],["title/Chap_7.html#autocorrelation-function_1",[412,1.012,505,1.449]],["text/Chap_7.html#autocorrelation-function_1",[2,0.787,11,0.427,19,1.271,25,2.141,34,1.492,35,2.239,53,1.607,66,1.935,84,2.26,91,1.386,99,1.232,105,1.068,108,1.199,120,3.453,138,2.342,148,2.295,153,1.326,158,2.331,169,1.313,214,3.128,223,2.726,240,1.534,259,1.576,267,2.838,270,1.77,279,2.4,286,2.071,315,3.452,318,1.552,323,1.988,329,2.015,337,1.347,341,2.489,355,1.139,362,2.838,371,3.123,394,2.09,409,1.759,412,1.79,416,2.003,429,2.161,446,1.341,505,2.563,514,2.726,549,2.707,597,1.594,605,3.218,626,1.988,627,2.407,638,2.838,706,1.935,728,2.774,752,2.226,756,3.102,802,2.489,811,2.161,820,3.972,895,3.516,899,2.898,968,3.179,1019,2.962,1051,3.279,1060,3.636,1064,3.972,1071,4.486,1072,3.681,1089,2.898,1317,3.817,1376,4.153,1482,3.561,1521,3.817,1637,3.353,1791,3.452,2001,3.452,2086,4.058,2285,3.029,2286,3.029,2287,3.353,2394,3.452,2443,4.371,2445,3.972,2464,4.153,2467,4.371,2468,4.371,2469,4.153,2768,4.153,2829,5.113,2934,3.561,2935,3.561,2942,3.681,3029,5.563,3033,4.153,3047,4.644,3067,5.009,3068,5.009,3069,4.153,3070,7.492,3071,4.153,3072,4.371,3073,4.644,3074,4.371,3075,5.009,3076,5.009]],["title/Chap_7.html#power-spectral-density_1",[564,1.412,587,1.286,636,1.519]],["text/Chap_7.html#power-spectral-density_1",[1,0.593,2,0.675,6,0.779,11,0.433,19,0.814,20,2.338,25,2.342,32,1.192,34,1.307,35,1.574,39,1.445,53,0.874,64,1.288,78,1.402,80,1.575,91,1.472,99,1.207,101,2.007,103,2.001,105,0.581,107,0.939,109,0.999,127,2.215,133,1.427,138,0.95,142,0.723,153,0.721,169,0.84,211,1.095,214,2.199,216,2.599,220,1.229,224,1.482,240,0.834,250,1.647,253,1.827,259,1.009,260,1.575,277,1.229,283,0.721,311,0.895,315,1.877,316,1.271,318,2.415,319,0.95,325,1.395,327,1.158,329,1.095,332,2.187,336,1.377,337,1.38,348,1.629,354,1.377,355,1.662,356,1.378,358,0.729,368,1.647,369,1.288,387,3.57,393,1.095,394,2.131,409,1.403,416,1.74,440,0.987,443,1.512,446,0.729,448,1.126,449,1.331,453,0.974,464,1.158,476,1.823,477,2.064,486,1.774,493,0.956,501,2.199,502,2.515,510,3.376,514,1.482,537,1.11,539,1.61,540,1.751,550,1.158,551,1.229,562,3.053,564,1.428,565,4.217,567,1.512,572,1.686,587,1.301,593,1.647,597,1.02,603,2.54,607,2.54,617,3.722,636,1.537,638,1.543,641,1.655,651,1.727,664,2.001,666,1.482,672,1.61,676,1.309,679,2.376,700,2.001,709,1.512,731,1.686,735,1.729,752,2.364,761,2.056,764,1.823,792,1.482,799,2.364,802,1.353,811,2.295,819,1.427,852,1.686,857,1.248,860,1.686,883,1.61,886,3.632,888,3.571,893,3.42,895,1.427,927,0.974,932,1.729,947,3.571,959,1.482,963,2.643,966,2.643,970,1.61,983,1.21,1005,2.726,1019,1.61,1051,1.331,1060,1.309,1063,3.908,1065,1.427,1071,4.817,1075,3.053,1140,2.66,1216,2.532,1217,1.482,1280,1.686,1289,2.54,1341,2.075,1347,2.875,1349,1.543,1374,1.543,1376,4.41,1378,2.075,1394,2.16,1422,1.877,1429,2.001,1437,3.908,1443,2.001,1470,3.955,1482,1.936,1483,1.686,1521,2.075,1570,2.376,1587,2.16,1607,1.512,1653,1.729,1704,2.376,1712,3.157,1714,2.643,1742,2.258,1844,3.273,1869,5.536,1922,1.729,2001,1.877,2076,2.96,2086,1.647,2108,2.875,2133,3.78,2213,2.075,2229,2.001,2244,1.729,2281,3.157,2285,4.42,2286,4.714,2287,4.399,2338,2.376,2400,3.157,2442,2.16,2469,2.258,2507,2.376,2623,2.001,2666,1.936,2698,2.075,2768,2.258,2796,2.525,2806,3.406,2822,3.157,2826,4.933,2835,3.561,2911,4.641,2921,2.376,2924,2.16,2930,2.001,2934,3.053,2935,3.053,2947,3.748,2949,3.748,2972,2.376,2976,2.525,2978,2.525,2980,2.525,2983,3.982,2984,2.525,2987,2.525,2988,2.525,2990,2.525,2998,4.41,3026,2.376,3029,5.448,3037,2.525,3038,3.982,3046,3.561,3053,2.525,3056,2.525,3061,2.525,3066,2.525,3069,2.258,3071,5.789,3072,6.092,3073,2.525,3074,2.376,3077,3.982,3078,2.723,3079,2.723,3080,2.723,3081,4.295,3082,4.295,3083,4.295,3084,4.295,3085,2.723,3086,2.16,3087,2.525,3088,2.723,3089,4.295,3090,3.748,3091,2.376,3092,2.723,3093,2.723,3094,2.723,3095,4.295,3096,2.723,3097,5.318,3098,4.295,3099,2.723,3100,2.723,3101,2.723,3102,4.295,3103,2.723,3104,2.723,3105,2.723,3106,2.723,3107,4.295,3108,4.295,3109,4.295,3110,5.318,3111,2.723,3112,2.723,3113,2.723,3114,2.723,3115,2.723,3116,2.723,3117,4.295,3118,3.561,3119,3.748,3120,3.561,3121,2.376,3122,2.376,3123,2.723,3124,2.723,3125,4.295,3126,2.723]],["title/Chap_7.html#tethered-particle-motion",[603,2.511,2324,2.406,3127,3.236]],["text/Chap_7.html#tethered-particle-motion",[2,0.783,6,2.054,7,1.91,11,0.421,16,2.275,31,1.977,32,1.446,34,1.351,35,1.475,36,3.91,37,1.328,44,2.347,48,1.446,53,1.599,59,1.852,66,2.319,68,1.613,76,2.15,80,1.91,87,4.018,99,1.151,105,0.704,106,1.059,107,1.138,108,0.49,109,2.453,114,2.435,120,1.699,121,2.21,125,2.881,132,2.275,133,1.73,134,1.49,137,3.717,153,0.874,167,4.263,169,0.646,170,1.763,195,2.794,214,2.764,216,1.613,220,1.49,240,1.011,244,1.952,255,1.763,256,1.181,259,1.171,263,3.662,277,1.49,281,1.49,288,1.346,308,2.426,309,1.763,310,2.319,311,1.972,329,2.004,337,1.172,341,2.476,348,1.011,354,3.035,355,1.365,356,0.855,358,1.921,364,2.15,368,1.997,369,1.561,409,1.668,412,1.007,446,1.607,450,2.02,453,1.181,456,1.91,462,1.952,463,2.516,466,2.21,472,3.797,476,2.21,486,2.15,487,1.641,537,2.447,539,1.952,550,2.844,551,2.248,579,3.205,589,1.91,590,2.21,591,2.044,600,2.946,601,1.91,602,2.095,603,4.768,608,1.49,617,3.4,618,2.618,619,2.426,623,1.997,626,1.31,627,1.587,629,2.618,641,0.996,642,3.434,651,1.328,653,2.15,668,1.997,682,1.613,728,2.06,733,3.163,750,1.763,773,1.536,797,1.997,811,1.425,845,4.34,888,3.687,932,2.095,963,1.328,969,2.883,1030,2.426,1034,1.587,1051,2.435,1058,2.618,1060,3.765,1062,2.708,1076,2.52,1100,5.544,1105,2.426,1134,1.91,1140,4.444,1141,3.797,1162,1.384,1165,2.319,1182,4.804,1215,2.516,1222,1.997,1242,2.883,1272,3.336,1349,3.4,1362,2.618,1374,1.87,1394,2.618,1465,2.618,1762,2.881,1780,2.095,1792,2.737,1827,2.426,1953,2.21,2043,1.997,2088,3.952,2110,2.21,2116,2.095,2193,3.542,2219,2.881,2320,2.618,2324,4.962,2393,2.737,2402,2.737,2416,2.881,2431,2.21,2441,2.618,2475,3.952,2550,2.618,2565,2.426,2587,2.737,2613,5.095,2618,2.618,2656,2.881,2792,2.881,2803,2.737,2810,2.275,2811,6.199,2822,4.411,2854,2.516,2864,5.095,2865,4.62,2866,2.618,2867,2.737,2881,5.835,3006,2.618,3025,3.06,3026,2.881,3091,2.881,3127,5.75,3128,3.301,3129,6.585,3130,3.06,3131,5.238,3132,3.301,3133,3.06,3134,3.301,3135,3.301,3136,3.301,3137,3.301,3138,4.62,3139,3.06,3140,3.301,3141,5.238,3142,6.996,3143,6.653,3144,3.06,3145,3.301,3146,5.238,3147,2.737,3148,5.565,3149,4.983,3150,4.62,3151,4.983,3152,4.983,3153,4.983,3154,3.301,3155,3.301,3156,4.62,3157,3.301,3158,4.983,3159,3.301,3160,2.881,3161,2.881,3162,3.301,3163,5.951,3164,3.301,3165,3.06,3166,3.06,3167,3.06,3168,3.301,3169,3.06,3170,3.301,3171,3.301,3172,3.301,3173,4.62,3174,3.301,3175,3.301,3176,4.348,3177,4.983,3178,2.737,3179,3.301,3180,3.301,3181,3.301,3182,3.301,3183,3.06,3184,3.06,3185,3.301,3186,2.881,3187,6.199,3188,4.983,3189,3.301,3190,3.301,3191,3.06,3192,3.301,3193,3.301,3194,2.881,3195,3.06]],["title/Chap_7.html#how-big-is-big-how-small-is-small-redux",[11,0.128,1061,2.312,1349,2.566,1588,3.593]],["text/Chap_7.html#how-big-is-big-how-small-is-small-redux",[2,1.133,6,1.438,11,0.427,13,1.854,19,1.145,25,0.945,32,1.463,34,0.971,35,1.789,40,1.241,48,1.463,59,1.241,65,1.605,80,1.932,84,1.507,87,2.236,99,1.172,101,1.671,105,1.072,107,1.733,109,2.467,127,1.844,133,1.75,136,1.995,151,1.605,158,1.554,159,2.374,213,2.02,216,2.954,240,1.023,243,2.302,244,1.975,256,1.195,259,1.58,266,2.377,267,2.848,279,1.798,283,0.884,310,3.357,311,1.097,319,1.754,322,2.647,323,1.325,329,1.343,332,1.821,337,1.177,341,3.343,343,1.932,347,2.176,348,1.023,354,2.542,355,1.375,356,1.302,358,1.346,368,3.04,369,1.579,379,1.274,382,2.078,409,1.168,427,1.463,446,1.801,447,1.579,449,2.954,450,1.124,453,1.195,466,2.236,493,1.119,497,2.915,550,2.138,551,1.507,561,2.108,579,1.783,584,2.236,588,2.12,589,1.932,603,1.975,626,1.325,627,2.905,633,1.66,638,2.848,639,1.854,641,1.573,666,1.818,682,2.456,708,1.975,733,2.12,750,2.684,757,2.374,765,1.854,792,1.818,796,2.176,797,2.02,801,2.684,811,2.608,812,2.915,826,2.236,830,1.689,845,3.04,846,2.02,852,3.113,860,2.068,863,3.29,888,2.954,933,3.573,963,3.255,966,1.66,983,2.687,1022,1.932,1023,2.915,1060,1.605,1065,2.635,1076,3.647,1100,5.981,1145,2.915,1162,2.108,1169,2.649,1177,3.986,1182,4.047,1226,2.545,1230,1.783,1242,3.891,1349,2.848,1351,2.455,1352,2.455,1362,2.649,1388,2.915,1470,2.848,1513,1.932,1520,2.915,1522,2.915,1588,2.649,1669,2.02,1698,2.649,1953,2.236,2110,3.365,2193,2.374,2213,3.831,2229,3.694,2281,5.57,2324,4.918,2462,2.649,2475,5.334,2525,2.915,2550,2.649,2563,4.387,2565,2.455,2587,2.769,2592,4.387,2613,5.776,2805,2.915,2834,2.915,2854,2.545,2860,2.915,2864,6.167,2866,2.649,2867,2.769,2870,3.096,2872,3.096,2873,3.096,2878,2.915,2879,2.915,2914,4.168,2930,2.455,3027,2.915,3046,2.769,3091,4.387,3129,5.275,3131,4.387,3133,5.604,3142,5.604,3144,3.096,3146,2.915,3156,5.604,3163,2.769,3165,3.096,3166,3.096,3167,3.096,3176,2.915,3178,4.168,3184,3.096,3187,3.096,3191,3.096,3196,3.34,3197,3.34,3198,5.027,3199,3.34,3200,4.66,3201,5.275,3202,3.096,3203,3.34,3204,3.34,3205,3.34,3206,3.34,3207,3.34,3208,3.34,3209,3.34,3210,3.096,3211,3.096,3212,3.34,3213,3.34,3214,3.096,3215,3.096,3216,5.027,3217,5.027,3218,3.34,3219,3.34,3220,3.34,3221,3.34,3222,3.096,3223,5.604,3224,3.34,3225,3.34,3226,3.34,3227,4.66,3228,5.027,3229,6.045,3230,3.34,3231,3.34,3232,3.34,3233,3.34,3234,3.096,3235,3.096,3236,3.096,3237,3.34,3238,3.34,3239,5.869,3240,3.34,3241,5.275,3242,3.34,3243,3.34,3244,3.34,3245,3.34,3246,3.096,3247,5.59,3248,5.59,3249,3.096,3250,2.545,3251,3.096,3252,3.096,3253,3.096,3254,6.725,3255,4.66,3256,5.027,3257,3.34,3258,3.34]],["title/Chap_7.html#choosing-the-sampling-period_1",[39,1.429,339,2.147,1620,2.186]],["text/Chap_7.html#choosing-the-sampling-period_1",[1,1.718,2,0.855,6,1.558,11,0.434,25,2.411,33,2.152,34,1.266,35,2.411,39,2.74,40,1.382,76,4.196,91,1.029,99,1.185,101,2.918,136,2.161,142,0.446,151,1.788,169,0.728,188,1.678,198,2.161,214,1.538,216,1.818,243,3.753,255,1.986,257,2.95,259,1.279,269,1.63,279,1.948,285,1.029,286,0.953,311,1.789,321,2.251,323,2.161,325,1.208,327,2.316,329,1.496,332,2.568,337,1.101,339,3.257,355,1.465,356,1.411,364,2.423,427,2.384,429,1.605,443,2.065,446,1.458,457,2.107,488,1.986,489,2.161,493,0.828,528,1.914,537,1.517,561,3.572,574,2.994,579,1.986,586,2.78,607,2.199,611,2.734,636,1.331,637,2.107,689,1.986,733,2.361,750,1.986,762,3.439,795,1.476,830,1.881,839,3.084,880,2.361,883,2.199,888,4.081,963,2.852,1034,1.788,1060,3.096,1062,1.678,1065,1.949,1071,5.117,1078,2.734,1108,4.752,1140,3.372,1169,5.984,1174,4.149,1230,3.439,1470,2.107,1478,2.199,1536,2.107,1540,2.644,1607,2.065,1620,3.649,2108,2.49,2201,2.95,2359,6.008,2360,3.246,2431,2.49,2445,4.318,2484,3.871,2793,2.834,2803,3.084,2804,3.246,2826,4.915,2846,3.084,2850,4.752,2852,3.448,2854,2.834,2896,6.257,2899,7.435,2901,3.448,2909,3.448,2912,3.448,2914,3.084,2916,3.448,2918,6.187,2925,2.95,3027,3.246,3033,4.515,3035,3.448,3046,4.515,3074,3.246,3163,3.084,3247,5.604,3248,4.579,3249,3.448,3250,6.008,3251,3.448,3252,3.448,3253,3.448,3255,3.448,3259,5.445,3260,5.445,3261,3.719,3262,3.719,3263,3.719,3264,3.719,3265,3.719,3266,3.719,3267,3.719,3268,3.719,3269,3.719,3270,3.719,3271,3.246,3272,3.719,3273,3.719,3274,3.084,3275,3.719,3276,3.719,3277,3.719,3278,5.445,3279,3.719,3280,3.719,3281,3.719,3282,3.448,3283,3.719,3284,3.719,3285,3.448,3286,3.246,3287,3.448,3288,3.719,3289,5.445,3290,5.048,3291,5.445,3292,4.515,3293,3.719,3294,3.719,3295,3.719]],["title/Chap_7.html#expected-value_1",[259,1.177,330,1.987]],["text/Chap_7.html#expected-value_1",[1,1.505,2,1.085,11,0.428,19,1.308,25,1.954,34,1.109,214,2.855,337,1.072,348,2.115,355,1.87,356,1.789,514,3.758,540,2.815,752,3.069,765,3.832,888,3.374,1071,5.044,1169,5.475,2324,3.911,2442,5.475,2639,5.475,2960,6.025,3127,5.261,3247,5.844,3248,5.844,3250,5.261,3290,6.401,3292,5.725,3296,6.904,3297,6.904,3298,6.904,3299,6.904]],["title/Chap_7.html#autocorrelation-function_2",[412,1.012,505,1.449]],["text/Chap_7.html#autocorrelation-function_2",[1,1.577,2,1.257,7,3.253,11,0.434,25,1.591,34,1.438,64,3.423,94,4.906,95,1.892,99,1.095,106,1.804,142,0.674,240,1.722,316,1.664,318,2.619,337,1.124,355,1.279,356,1.456,383,2.894,409,2.081,412,1.463,416,2.238,427,2.462,505,2.095,549,2.864,651,2.261,661,2.358,706,2.172,724,3.324,729,3.4,821,3.662,888,2.747,936,4.132,970,3.324,1071,5.309,1165,2.172,1216,2.358,1378,4.284,1628,3.997,2158,4.459,2666,3.997,2795,4.662,3065,4.662,3069,4.662,3070,6.711,3247,3.997,3248,5.145,3250,4.284,3274,4.662,3282,5.212,3285,5.212,3292,4.662,3300,8.005,3301,5.622,3302,5.622,3303,5.622,3304,5.622,3305,5.622,3306,5.622,3307,5.622,3308,5.212,3309,5.212,3310,5.622,3311,7.238,3312,4.906,3313,5.622,3314,6.317,3315,5.212,3316,5.212,3317,5.212,3318,5.622]],["title/Chap_7.html#power-spectral-density_2",[564,1.412,587,1.286,636,1.519]],["text/Chap_7.html#power-spectral-density_2",[1,1.64,2,0.779,6,1.906,11,0.435,19,0.939,25,1.403,33,2.868,34,1.07,35,2.382,39,1.668,40,1.842,64,2.344,99,0.678,101,2.676,142,0.594,169,1.304,214,3.327,216,2.422,259,1.565,266,2.344,292,2.808,311,1.629,319,2.626,325,1.609,337,1.035,355,1.712,358,1.784,409,1.549,412,1.347,416,2.131,464,2.108,493,1.104,501,3.112,502,3.805,505,2.178,514,2.698,549,2.692,564,2.676,576,2.422,580,5.038,586,2.875,587,2.437,608,2.237,636,2.879,637,3.774,638,2.808,639,3.698,641,0.991,700,3.643,762,2.647,830,3.369,852,4.126,888,3.256,963,2.68,1060,3.202,1071,4.903,1264,4.029,1478,2.931,1536,3.774,1620,2.551,1653,3.146,1922,3.146,2462,3.931,2749,4.325,2810,4.591,2826,3.229,2896,4.11,2899,4.325,2914,5.524,2918,4.325,2924,5.968,2930,3.643,2953,4.595,3211,4.595,3214,4.595,3215,4.595,3234,4.595,3235,4.595,3239,4.325,3246,4.595,3247,5.968,3248,5.349,3250,3.777,3271,4.325,3287,4.595,3312,4.325,3314,4.325,3319,4.956,3320,4.956,3321,4.956,3322,4.956,3323,6.662,3324,4.956,3325,4.956,3326,4.956,3327,4.956,3328,4.595,3329,4.956,3330,4.956,3331,4.956]],["title/Chap_7.html#descriptive-statistic-variance",[11,0.162,289,1.59,947,1.801,1714,1.832]],["text/Chap_7.html#descriptive-statistic-variance",[1,1.071,2,1.04,6,1.895,11,0.417,19,1.419,20,2.674,25,1.39,34,1.416,39,2.698,91,1.36,99,0.906,111,2.217,122,2.728,127,2.43,142,0.589,169,0.962,198,1.95,214,2.032,255,2.624,259,1.556,279,1.758,298,3.832,322,2.152,325,1.595,327,2.817,337,0.763,355,1.824,356,1.273,378,3.618,409,1.142,412,0.993,416,1.301,427,2.152,429,2.12,448,2.739,493,1.094,496,3.043,525,2.728,534,3.201,537,2.004,549,1.758,570,3.29,641,1.603,664,3.611,684,3.292,728,2.032,752,2.944,761,2.256,764,3.29,765,2.728,792,2.674,811,2.12,831,5.492,848,3.29,857,2.252,883,3.916,933,3.493,963,1.976,969,2.843,1058,3.897,1060,2.362,1063,3.611,1071,5.264,1140,3.043,1280,3.043,1349,2.784,1374,2.784,1437,4.868,1550,4.288,1620,2.529,2076,4.565,2125,3.386,2133,6.265,2277,3.493,2810,4.565,2822,3.611,2826,5.223,2934,6.265,2935,6.371,2940,4.075,2989,4.556,2998,4.075,3071,4.075,3086,5.253,3087,4.556,3118,4.075,3119,4.288,3120,4.075,3122,4.288,3173,4.556,3247,3.493,3248,5.7,3250,3.744,3274,4.075,3292,6.213,3308,4.556,3309,4.556,3312,4.288,3314,6.538,3315,6.141,3316,6.141,3317,6.141,3332,6.946,3333,4.914,3334,4.914,3335,4.914,3336,4.914,3337,4.914,3338,4.914,3339,6.623,3340,4.914,3341,4.288,3342,4.288,3343,4.914,3344,4.914]],["title/Chap_7.html#one-step-further",[358,1.137,537,1.732,1607,2.357]],["text/Chap_7.html#one-step-further",[2,1.023,6,1.863,11,0.419,19,1.233,20,2.607,34,1.188,35,2.349,36,4.241,37,1.926,39,1.612,46,3.972,48,2.097,53,2.089,59,2.419,66,1.851,80,2.771,99,0.655,116,4.627,133,2.51,158,2.229,159,3.405,167,4.025,256,1.714,266,2.265,283,1.724,296,1.692,310,2.229,322,3.475,323,1.901,327,2.769,330,1.901,341,2.38,355,1.481,356,1.241,357,3.798,359,1.826,373,1.692,379,1.826,382,1.98,409,1.513,427,2.097,443,2.659,446,1.282,448,1.98,450,1.612,463,4.961,493,1.066,525,2.659,550,2.037,579,2.557,601,3.766,602,3.04,603,3.849,608,2.161,617,2.713,621,3.405,641,1.302,657,2.659,682,3.181,750,3.476,761,1.631,783,2.832,792,2.607,797,2.897,811,2.067,863,2.607,883,2.832,886,3.235,933,3.405,953,3.405,965,3.301,972,3.207,983,2.129,1022,2.771,1076,4.196,1165,1.851,1182,4.358,1216,2.008,1226,3.65,1242,3.766,1362,3.798,1463,3.65,1470,2.713,1488,3.52,1669,3.937,1699,3.798,1714,3.235,2113,6.132,2133,5.257,2159,4.18,2207,4.18,2324,2.713,2415,3.405,2431,3.207,2565,3.52,2613,3.65,2810,3.301,2822,4.784,2826,4.817,2864,3.65,2866,3.798,2881,4.18,2925,5.163,2928,3.972,2930,4.784,2934,4.627,2935,5.257,3010,4.441,3012,4.441,3016,4.441,3018,4.441,3021,5.681,3086,5.163,3127,3.65,3129,7.469,3138,6.856,3139,7.935,3143,6.035,3146,4.18,3163,6.132,3178,3.972,3210,4.441,3223,4.441,3227,4.441,3342,5.681,3345,6.51,3346,4.79,3347,4.79,3348,4.79,3349,4.79,3350,4.79,3351,4.79,3352,7.395,3353,4.79,3354,6.51,3355,4.79,3356,4.79,3357,4.79,3358,4.79,3359,4.79,3360,4.79,3361,4.79,3362,4.79,3363,4.79]],["title/Chap_7.html#why-this-case-study",[95,1.685,1062,2.26]],["text/Chap_7.html#why-this-case-study",[2,1.295,11,0.392,19,1.135,25,1.695,34,0.962,44,4.257,59,2.225,66,2.314,76,3.901,86,5.538,95,2.911,105,1.277,108,1.118,124,6.576,127,2.197,138,2.09,153,1.995,161,3.622,169,1.745,197,4.966,244,3.541,270,2.116,281,2.702,283,1.586,289,2.584,322,2.623,358,1.603,371,3.837,409,1.392,412,1.21,416,1.586,447,2.832,467,4.243,486,3.901,505,1.733,564,1.991,587,1.814,603,3.541,636,2.143,641,1.649,685,2.879,728,2.476,751,4.009,761,2.04,765,3.324,792,3.26,795,2.376,811,2.584,830,3.028,845,3.622,854,5.226,857,2.744,947,2.927,963,2.409,1060,2.879,1062,3.72,1136,3.541,1182,4.009,1353,4.009,1478,3.541,1714,4.098,1768,4.455,1797,4.749,1868,4.401,2106,4.749,2277,4.257,2324,3.393,2393,4.966,2810,5.682,3023,6.986,3127,4.564,3130,5.552,3195,5.552,3364,5.226,3365,5.989,3366,5.989,3367,5.989,3368,5.989,3369,5.989,3370,5.989]],["title/Chap_7.html#problems",[142,0.731]],["text/Chap_7.html#problems",[]],["title/Chap_7.html#problem-71",[142,0.6,1140,3.102]],["text/Chap_7.html#problem-71",[34,1.368,53,2.733,232,3.914,447,3.467,451,6.259,489,2.909,539,5.322,641,1.466,757,5.211,761,2.497,857,3.359,930,4.334,1140,4.54,1141,5.586,1714,4.232,1813,5.814,2828,7.432]],["title/Chap_7.html#problem-72",[142,0.6,2822,3.681]],["text/Chap_7.html#problem-72",[11,0.423,39,2.921,53,2.158,100,3.286,106,2.158,108,1.201,109,2.969,153,1.781,169,1.316,184,3.4,214,2.78,270,2.376,292,3.809,304,3.66,382,2.78,384,3.524,409,1.563,448,3.346,489,2.668,532,4.268,605,2.86,626,2.668,627,3.232,632,2.945,783,3.976,886,4.314,945,4.942,1024,4.549,1111,5.333,1191,5.271,1234,4.164,1247,4.942,1670,4.502,1774,4.942,2826,5.271,3371,6.725,3372,6.725,3373,6.725,3374,6.725,3375,6.725]],["title/Chap_7.html#problem-73",[142,0.6,2829,3.817]],["text/Chap_7.html#problem-73",[11,0.388,19,1.602,98,4.127,104,3.878,106,2.033,108,1.345,109,3.238,127,2.324,153,2.239,240,2.704,253,3.319,277,2.859,287,2.695,296,2.757,325,2.534,378,3.521,412,1.709,416,1.678,468,2.354,489,2.514,505,2.447,564,2.595,573,4.029,587,2.363,605,2.695,626,2.514,627,3.045,632,4.042,636,2.792,641,1.56,752,2.816,947,4.133,1024,4.09,1186,3.517,1622,5.224,1639,6.81,1795,3.589,2010,5.253,2112,3.149,2632,4.366,3376,6.335]],["title/Chap_7.html#problem-74",[142,0.6,2835,4.153]],["text/Chap_7.html#problem-74",[11,0.332,34,1.391,270,2.666,316,2.233,412,1.525,416,1.998,493,1.68,505,2.183,1065,3.954,1067,5.545,2940,6.256,2943,6.256]],["title/Chap_7.html#problem-75",[142,0.6,1141,3.817]],["text/Chap_7.html#problem-75",[11,0.38,34,1.389,270,2.659,316,2.227,493,1.675,564,2.502,587,2.279,636,2.692,1065,3.944,2939,6.566,2943,6.239,2946,6.976]],["title/Chap_7.html#problem-76",[142,0.6,2229,3.681]],["text/Chap_7.html#problem-76",[11,0.379,34,1.458,214,3.095,270,2.645,316,2.216,493,1.667,502,3.54,564,2.489,587,2.267,636,2.678,700,5.501,3069,6.207,3077,6.939]],["title/Chap_7.html#problem-77",[142,0.6,2896,4.153]],["text/Chap_7.html#problem-77",[11,0.398,19,1.292,33,3.946,34,1.311,48,2.987,53,2.189,106,2.189,240,2.09,296,2.884,318,2.114,321,2.82,325,2.215,327,2.901,337,1.059,394,2.024,450,2.295,682,3.333,684,3.39,848,4.567,947,3.333,963,2.744,1245,4.849,1264,5.282,1594,5.013,2201,5.41,2285,4.126,2286,4.126,2287,4.567,2810,4.701,2876,6.324,2878,5.953,2879,5.953,3005,6.324,3021,5.953,3071,6.768,3072,5.953,3086,5.41,3118,5.656,3120,5.656,3377,6.821,3378,6.821,3379,7.123,3380,6.821]],["title/Chap_7.html#problem-78",[142,0.6,2924,3.972]],["text/Chap_7.html#problem-78",[11,0.422,20,3.344,34,1.443,43,4.234,50,3.805,99,0.841,114,3.002,127,3.06,138,2.144,279,2.198,309,4.088,319,2.144,325,1.995,337,0.954,378,2.772,386,5.627,387,4.527,409,1.428,440,3.163,467,3.162,477,2.953,486,4.988,641,1.832,657,3.411,664,4.515,706,2.374,728,2.54,750,3.281,761,2.841,795,3.038,857,3.508,873,3.411,893,5.189,930,3.633,947,3.742,963,2.471,1033,3.9,1216,2.576,1264,3.716,1466,5.835,1712,4.515,1755,4.872,1756,4.872,1758,5.362,2044,4.234,2596,5.362,2713,5.362,2998,5.095,3118,5.095,3119,5.362,3120,5.095,3122,5.362,3341,5.362,3381,6.144,3382,6.144,3383,6.144,3384,6.144,3385,6.144,3386,6.144,3387,6.144]],["title/Chap_7.html#problem-79",[142,0.6,2925,3.972]],["text/Chap_7.html#problem-79",[11,0.394,31,3.179,34,1.063,35,2.372,39,2.9,84,2.985,137,4.097,216,3.915,220,2.985,259,1.554,310,3.079,311,2.173,330,2.625,358,1.771,394,1.641,412,1.337,448,2.735,561,3.614,570,4.429,574,2.625,602,5.086,619,4.862,641,1.323,689,3.532,750,4.783,830,4.052,857,3.031,886,3.288,931,4.199,1060,3.18,1065,3.467,1140,4.097,1232,5.246,1515,5.096,1620,3.405,1621,5.485,1699,5.246,2229,4.862,2324,3.748,2810,4.559,2826,5.219,2864,5.041,2866,5.246,3147,5.485,3271,5.773,3388,6.615,3389,8.012]],["title/Chap_7.html#problem-710",[142,0.6,2930,3.681]],["text/Chap_7.html#problem-710",[11,0.311,19,1.34,34,1.34,106,2.27,109,3.06,259,1.96,270,2.5,304,3.851,319,2.469,358,2.233,446,1.894,580,5.584,888,3.458,1071,4.63,1162,2.967,1234,4.382,1351,5.2,1384,6.13,1515,4.184,1598,4.737,2081,6.175,2233,5.03,2810,4.876,3169,6.56,3236,6.56,3239,7.279,3247,5.03,3248,5.03,3328,6.56,3390,7.076]],["title/Chap_7.html#problem-711",[142,0.6,2940,4.153]],["text/Chap_7.html#problem-711",[1,1.415,11,0.416,19,0.904,34,1.186,46,3.958,100,4.35,108,0.964,109,2.383,153,1.264,169,0.934,188,2.154,198,1.894,202,3.786,216,3.607,232,4.425,247,3.196,270,1.687,289,2.06,298,2.762,316,1.413,319,2.765,327,2.03,332,1.729,344,2.06,355,1.086,378,2.154,379,1.82,493,1.446,584,3.196,586,3.419,588,3.03,603,2.823,658,4.348,682,4.275,706,1.844,740,3.11,763,5.626,778,3.508,779,3.508,780,3.508,781,4.231,782,4.476,783,4.365,787,4.231,788,3.508,789,3.29,790,3.508,793,3.29,794,3.29,857,3.383,863,2.598,886,3.938,1062,2.154,1071,3.605,1182,4.942,1217,2.598,1230,3.942,1248,4.166,1257,3.786,1263,4.231,1264,3.928,1269,3.29,1270,2.704,1272,3.196,1486,3.638,1544,3.958,1577,5.248,1591,3.786,1717,3.508,1726,6.284,1798,5.668,1979,3.196,2043,3.928,2044,4.476,2045,5.151,2046,3.786,2047,3.29,2048,3.508,2099,5.151,2133,3.393,2193,3.393,2324,2.704,2370,4.166,2371,4.166,2372,4.166,2373,3.786,2374,4.166,2375,4.166,2376,4.166,2377,3.508,2378,3.786,2379,3.786,2475,3.786,2542,5.151,2547,3.638,2607,5.151,2826,3.11,2862,4.426,2864,3.638,2934,3.393,2935,3.393,3006,3.786,3063,4.426,3086,3.786,3127,3.638,3131,4.166,3148,4.426,3150,6.844,3176,4.166,3178,6.122,3183,4.426,3200,6.022,3202,4.426,3222,4.426,3247,3.393,3248,3.393,3274,3.958,3332,4.426,3341,4.166,3342,4.166,3391,4.774,3392,4.774,3393,4.774,3394,4.774,3395,4.774,3396,4.774,3397,4.774,3398,4.774,3399,4.774,3400,4.774,3401,4.774,3402,4.774,3403,6.495,3404,4.774,3405,4.774,3406,4.774,3407,4.774,3408,4.774,3409,4.774,3410,4.774,3411,4.774,3412,4.774,3413,4.774,3414,4.774,3415,4.774,3416,4.774,3417,4.774,3418,4.166,3419,4.774]],["title/Chap_8.html",[108,0.483,285,0.901,569,1.844,584,2.179,1217,1.772]],["text/Chap_8.html",[1,1.476,2,0.833,6,0.447,11,0.432,13,0.868,17,1.046,19,1.352,20,0.851,25,2.103,34,0.851,35,1.782,37,1.72,39,0.912,40,1.007,42,1.296,53,1.373,54,0.764,59,1.007,65,1.302,66,1.047,77,0.716,78,2.49,79,1.239,82,1.239,83,1.111,84,1.618,85,1.149,91,0.992,95,2.026,98,1.765,99,0.998,100,0.764,101,2.096,102,1.239,104,1.346,105,1.213,106,0.502,107,1.236,108,1.347,109,1.775,110,0.994,121,2.864,122,2.374,138,0.545,142,0.682,145,0.79,153,1.67,156,1.077,159,1.926,161,0.945,169,1.282,170,1.446,184,0.79,198,1.075,211,1.09,216,2.364,220,1.222,228,1.018,240,1.31,250,0.945,253,1.525,259,1.245,266,0.739,267,2.423,269,1.587,270,0.957,273,3.214,277,0.705,279,0.969,280,1.149,281,1.618,283,0.949,284,1.814,285,2.456,286,0.4,287,0.665,288,1.744,289,1.547,291,1.535,295,0.904,296,0.957,297,1.149,301,1.149,302,2.549,305,0.637,306,3.808,307,0.992,310,2.251,311,1.178,313,1.696,316,0.463,321,2.191,322,1.873,325,1.164,327,0.665,329,0.629,330,0.62,332,1.55,335,0.52,336,0.79,337,1.293,340,1.618,348,1.624,354,0.79,355,1.206,356,1.559,358,1.419,359,0.596,363,1.394,367,1.37,369,0.739,372,0.904,373,1.267,374,0.945,378,0.705,386,1.991,391,1.37,393,1.946,394,0.672,395,0.804,399,0.945,404,0.612,409,1.399,412,1.217,416,1.735,427,0.684,431,1.169,432,0.751,433,0.684,443,0.868,446,0.96,447,0.739,448,0.646,449,2.364,450,0.526,453,0.559,457,0.885,464,1.152,467,1.394,468,1.007,477,0.751,489,0.62,493,0.952,499,2.12,500,1.879,501,2.71,502,2.023,503,2.276,505,1.4,534,1.018,536,1.239,537,0.637,539,0.924,540,2.571,549,0.969,551,0.705,556,1.926,560,0.79,563,3.129,564,1.891,569,3.572,571,0.904,572,2.22,573,1.204,574,1.423,576,0.764,583,1.446,585,3.238,586,0.674,587,1.723,588,1.72,589,2.475,590,1.046,591,2.22,595,0.968,596,2.549,597,1.695,601,2.475,602,1.72,603,1.602,605,2.058,608,0.705,625,2.364,630,1.239,632,1.57,633,0.777,636,0.969,641,1.137,651,1.442,654,0.819,661,0.655,666,0.851,667,2.528,668,0.945,670,1.046,673,2.364,675,1.37,676,0.751,681,1.364,682,2.09,684,0.777,685,0.751,699,1.296,708,0.924,718,1.149,720,1.602,728,1.12,742,2.148,750,1.914,751,2.864,752,0.695,753,2.364,756,0.968,761,1.221,764,1.814,773,1.261,775,1.018,785,1.239,795,1.423,797,0.945,799,2.15,801,2.284,802,0.777,808,1.42,810,1.111,811,1.846,818,1.111,819,0.819,830,2.446,857,1.241,858,1.236,863,2.633,882,4.634,885,1.364,886,3.694,887,1.867,888,3.751,889,1.239,890,1.364,891,2.22,892,1.046,893,1.535,895,1.42,896,2.064,897,1.111,913,1.364,919,0.819,920,1.638,927,1.53,931,0.992,933,1.111,959,3.567,961,2.148,962,1.111,963,2.802,965,1.077,966,2.126,969,1.567,983,1.204,1014,0.835,1022,0.904,1034,2.056,1065,0.819,1076,0.79,1078,1.149,1090,1.364,1092,1.149,1105,1.149,1165,0.604,1177,1.239,1186,1.504,1216,1.136,1217,2.328,1219,1.149,1221,0.968,1225,0.968,1242,0.904,1257,1.239,1263,1.018,1264,1.638,1275,1.239,1283,5.074,1284,2.364,1285,1.364,1288,2.973,1289,2.86,1293,1.602,1310,0.804,1326,1.239,1328,1.077,1330,2.635,1333,1.077,1342,1.191,1344,2.535,1353,1.046,1377,1.991,1389,1.191,1452,1.149,1470,3.002,1484,0.992,1488,2.635,1513,0.904,1515,0.924,1528,1.364,1536,2.031,1540,1.111,1579,1.239,1598,1.814,1653,0.992,1654,0.968,1714,0.777,1717,1.149,1755,1.239,1779,1.364,1780,1.72,1801,1.364,1808,1.149,1852,1.364,1887,1.239,1888,1.149,1922,0.992,1938,4.511,2017,1.149,2018,1.239,2053,1.191,2116,0.992,2158,1.239,2186,1.018,2244,0.992,2264,1.296,2311,1.364,2313,2.148,2316,1.239,2320,1.239,2323,1.364,2324,2.031,2339,1.046,2368,1.364,2377,1.149,2378,1.239,2379,1.239,2394,1.077,2441,1.239,2456,1.364,2466,1.296,2472,1.364,2484,1.926,2529,1.364,2564,4.977,2632,1.867,2644,1.364,2662,1.364,2741,2.364,2806,2.148,2859,1.364,2869,1.364,2877,2.732,2923,1.364,2942,1.149,3006,1.239,3040,1.296,3062,1.364,3090,1.364,3147,1.296,3186,1.364,3194,1.364,3241,1.364,3286,1.364,3379,1.364,3420,1.563,3421,4.221,3422,1.563,3423,3.966,3424,1.563,3425,3.144,3426,1.239,3427,2.732,3428,3.324,3429,2.709,3430,4.964,3431,3.686,3432,3.129,3433,2.512,3434,3.585,3435,1.563,3436,3.324,3437,1.563,3438,2.709,3439,2.709,3440,1.563,3441,3.324,3442,2.709,3443,1.563,3444,1.563,3445,4.914,3446,2.512,3447,1.563,3448,2.709,3449,1.563,3450,2.709,3451,1.563,3452,2.512,3453,1.563,3454,1.563,3455,2.709,3456,3.585,3457,1.563,3458,4.221,3459,1.563,3460,1.563,3461,1.563,3462,1.563,3463,1.563,3464,1.563,3465,1.563,3466,5.581,3467,1.563,3468,4.914,3469,3.585,3470,1.563,3471,2.709,3472,3.966,3473,3.324,3474,1.563,3475,1.563,3476,1.563,3477,1.563,3478,1.563,3479,2.709,3480,1.563,3481,1.563,3482,1.563,3483,1.563,3484,1.563,3485,1.563,3486,1.563,3487,1.563,3488,2.512,3489,1.563,3490,1.563,3491,1.563,3492,1.563,3493,1.563,3494,1.563,3495,1.563,3496,1.563,3497,1.563,3498,2.709,3499,2.709,3500,2.709,3501,1.563,3502,1.563,3503,1.563,3504,2.709,3505,1.563,3506,1.563,3507,1.563,3508,1.563,3509,1.563,3510,3.966,3511,2.709,3512,1.563,3513,1.563,3514,1.563,3515,1.563,3516,3.585,3517,4.277,3518,1.563,3519,1.563,3520,1.563,3521,1.563,3522,3.324,3523,3.324,3524,1.563,3525,1.563,3526,2.512,3527,2.512,3528,1.563,3529,1.563,3530,3.585,3531,4.837,3532,2.709,3533,1.563,3534,1.563,3535,1.563,3536,1.563,3537,1.563,3538,2.709,3539,1.563,3540,1.563,3541,1.563,3542,1.563,3543,1.563,3544,1.563,3545,1.563,3546,1.563,3547,1.563]],["title/Chap_8.html#characterizing-signal-to-noise-ratios",[108,0.547,285,1.02,569,2.088,1217,2.006]],["text/Chap_8.html#characterizing-signal-to-noise-ratios",[66,2.877,105,1.588,108,1.275,109,2.732,153,2.275,240,2.281,269,2.229,277,3.36,279,2.664,313,3.521,316,2.204,572,4.611,750,3.976,1034,3.579,1217,4.677]],["title/Chap_8.html#example-filtering-noise",[105,0.906,269,1.271,285,1.175]],["text/Chap_8.html#example-filtering-noise",[1,1.579,11,0.43,25,2.051,54,2.753,59,2.093,65,2.708,78,2.899,95,2.439,98,4.721,99,0.992,100,2.753,101,2.41,102,4.467,104,2.8,106,1.808,107,1.942,108,1.299,109,2.659,153,2.122,156,3.882,169,1.655,220,2.542,273,3.008,285,2.341,286,1.443,287,2.396,288,2.297,289,2.431,297,4.14,310,2.622,313,2.664,321,2.329,322,2.467,325,1.829,329,2.266,332,2.626,337,0.875,340,2.542,356,1.459,363,2.899,367,2.849,373,1.99,374,3.407,393,2.266,404,2.206,409,1.309,412,1.139,416,1.492,427,2.467,446,1.508,467,2.899,493,1.254,502,3.427,537,2.297,539,3.331,549,2.015,560,2.849,564,2.41,569,3.191,573,3.221,574,2.876,587,1.706,597,1.721,605,2.396,632,2.467,651,2.915,654,2.952,667,2.504,675,3.665,708,3.331,720,3.331,728,2.329,808,2.952,1283,6.368,1288,4.671,1289,3.331,1293,4.285,1353,3.771,1780,3.576,2158,4.467,2484,5.152,2942,4.14,3194,4.916,3420,5.633,3421,4.916,3422,5.633,3423,5.223,3424,5.633]],["title/Chap_8.html#snr-for-deterministic-signals-in-the-presence-of-noise",[108,0.483,273,1.738,284,2.179,285,0.901,605,1.385]],["text/Chap_8.html#snr-for-deterministic-signals-in-the-presence-of-noise",[2,1.111,11,0.39,99,1.141,108,1.36,285,1.958,288,2.885,321,2.926,337,1.099,569,4.008,585,4.737,605,3.01,641,1.415,667,3.707,913,6.175,1536,4.008,1714,3.517,1888,5.2,2564,5.2,3241,6.175,3425,5.2,3426,5.611,3427,5.392,3428,7.733,3429,8.341,3430,7.279,3431,5.392,3432,6.175,3433,6.56]],["title/Chap_8.html#snr-for-random-signals-in-the-presence-of-noise",[108,0.483,273,1.738,284,2.179,285,0.901,597,0.773]],["text/Chap_8.html#snr-for-random-signals-in-the-presence-of-noise",[2,0.826,11,0.421,19,1.622,34,0.845,40,1.954,59,1.954,91,1.455,95,2.772,99,0.948,108,1.331,122,4.302,153,1.835,198,2.087,273,2.808,279,1.881,285,2.37,289,2.269,296,2.449,305,2.144,321,2.174,337,1.204,355,1.577,359,2.005,363,2.707,367,2.659,369,2.487,378,2.373,391,2.659,399,3.181,409,1.222,412,1.063,416,2.052,443,2.919,505,1.522,540,3.656,569,2.979,595,3.257,597,1.957,605,2.237,608,2.373,666,2.862,667,3.662,670,3.521,684,2.614,751,3.521,753,6.048,775,3.426,795,2.087,799,3.445,808,2.756,920,3.181,927,2.479,963,3.444,966,3.852,1034,2.528,1186,2.919,1216,2.205,1221,3.257,1470,3.926,1536,3.926,1779,4.589,1780,3.338,2244,3.338,2394,3.624,2456,4.589,2564,5.696,2632,4.776,3425,3.865,3427,4.007,3428,4.875,3430,7.19,3432,4.589,3433,4.875,3434,7.751,3435,5.259,3436,4.875,3437,5.259,3438,6.93,3439,6.93,3440,5.259,3441,6.425,3442,6.93,3443,5.259,3444,5.259,3445,7.938,3446,4.875,3447,5.259,3448,6.93,3449,5.259,3450,6.93,3451,5.259,3452,4.875,3453,5.259,3454,5.259]],["title/Chap_8.html#example-not-too-noisy",[105,1.068,302,3.56]],["text/Chap_8.html#example-not-too-noisy",[1,1.428,11,0.403,19,1.626,37,2.636,99,0.897,108,1.274,110,2.405,159,4.659,198,2.601,267,5.059,285,1.814,288,2.673,306,5.334,327,2.788,335,2.179,336,3.314,337,1.333,348,2.008,354,3.314,355,1.491,356,1.698,391,3.314,448,2.71,534,4.27,540,2.673,596,4.659,605,2.788,773,3.051,887,4.517,963,2.636,965,4.517,1470,3.713,1488,6.309,1513,3.792,1755,5.198,1801,5.72,2564,5.856,2923,5.72,3430,5.72,3432,5.72,3455,7.967,3456,8.584,3457,6.554,3458,6.953,3459,6.554,3460,6.554,3461,6.554,3462,6.554,3463,6.554]],["title/Chap_8.html#example-cocktail-party-noise",[105,0.786,285,1.02,3464,3.685,3465,3.685]],["text/Chap_8.html#example-cocktail-party-noise",[1,1.716,2,0.739,11,0.437,17,3.148,25,2.546,34,1.033,35,2.331,37,2.586,39,2.163,53,1.509,78,3.309,82,3.729,84,2.122,91,1.301,101,2.618,107,2.216,108,1.224,142,0.563,259,1.105,273,2.511,285,2.179,306,4.904,307,2.985,310,2.189,311,1.545,337,1.223,348,2.244,356,1.898,373,2.272,393,1.891,416,1.702,446,1.259,493,1.047,499,4.331,500,3.839,501,3.519,503,4.65,556,4.57,564,2.436,574,1.866,583,3.433,585,4.304,587,2.218,589,2.721,590,3.148,596,3.343,597,1.87,630,3.729,632,2.059,641,0.94,681,4.104,682,3.142,720,2.781,751,4.904,761,1.602,773,2.189,1217,2.56,1283,6.194,1284,5.61,1285,4.104,1288,5.331,1289,4.656,1484,2.985,1579,3.729,1938,6.91,2564,4.725,3040,3.9,3090,4.104,3421,6.393,3423,6.791,3441,4.36,3445,4.36,3446,4.36,3452,4.36,3458,5.61,3466,6.791,3467,4.703,3468,7.3,3469,7.325,3470,4.703,3471,6.429,3472,4.36,3473,5.96,3474,4.703,3475,4.703,3476,4.703,3477,4.703,3478,4.703,3479,6.429,3480,4.703,3481,4.703]],["title/Chap_8.html#snr-for-signals-and-systems-with-poisson-noise",[108,0.483,109,1.194,273,1.738,285,0.901,882,2.393]],["text/Chap_8.html#snr-for-signals-and-systems-with-poisson-noise",[1,0.826,2,0.867,6,1.084,11,0.418,13,2.103,19,1.44,34,0.609,35,1.634,37,1.524,40,1.408,42,3.142,53,1.771,78,1.95,79,3.005,83,2.693,84,1.71,85,2.785,91,1.049,95,1.275,99,0.891,105,1.389,108,1.178,109,1.39,121,4.358,138,1.322,142,0.661,145,1.916,153,1.003,161,2.292,169,1.4,170,2.947,211,2.22,220,1.71,250,2.292,259,1.68,266,1.792,270,1.339,273,2.023,280,2.785,281,2.49,283,1.003,285,2.407,288,1.545,291,2.146,295,2.192,301,2.785,302,3.923,321,2.282,322,1.659,325,1.23,330,1.503,337,1.232,348,1.691,355,0.862,356,1.43,358,2.124,372,2.192,386,4.056,393,2.22,394,1.369,412,0.766,431,2.382,449,3.495,453,1.355,477,1.821,493,0.844,540,1.545,563,5.681,569,3.127,571,2.192,585,2.536,587,1.147,588,3.503,589,3.766,591,4.031,597,0.9,601,4.138,602,2.405,625,4.816,633,1.883,641,1.43,651,1.524,661,1.589,668,2.292,673,4.816,676,1.821,728,1.567,756,2.346,761,1.29,764,3.695,795,2.19,799,1.684,801,3.819,802,1.883,810,2.693,811,2.809,818,2.693,819,1.986,830,3.844,857,1.736,858,2.244,882,6.169,885,3.306,886,4.54,887,2.611,888,4.517,889,3.005,890,3.306,891,4.031,892,2.536,893,3.127,895,2.893,896,4.206,897,2.693,919,1.986,920,2.292,927,1.974,931,2.405,959,4.658,963,3.191,966,1.883,969,3.193,983,2.453,1014,2.023,1022,2.192,1034,1.821,1078,2.785,1090,3.306,1092,2.785,1105,2.785,1177,3.005,1216,1.589,1219,2.785,1242,2.192,1330,4.784,1377,4.056,1389,2.887,1470,3.688,1515,2.24,1528,3.306,1540,2.693,1598,3.695,1654,2.346,1808,2.785,1852,3.306,1887,3.005,2018,3.005,2053,2.887,2186,2.468,2264,3.142,2311,3.306,2313,4.377,2316,3.005,2320,3.005,2323,3.306,2368,3.306,2441,3.005,2472,3.306,2529,3.306,2564,4.784,2644,3.306,2741,4.816,2859,3.306,3006,3.005,3062,3.306,3147,3.142,3425,4.056,3427,2.887,3431,4.206,3458,3.306,3482,3.789,3483,3.789,3484,3.789,3485,3.789,3486,3.789,3487,3.789,3488,3.513,3489,3.789,3490,3.789,3491,3.789,3492,3.789,3493,3.789,3494,3.789,3495,3.789,3496,3.789,3497,3.789,3498,5.519,3499,5.519,3500,5.519,3501,3.789,3502,3.789,3503,3.789,3504,5.519,3505,3.789,3506,3.789,3507,3.789,3508,3.789,3509,3.789,3510,6.036,3511,5.519]],["title/Chap_8.html#problems",[142,0.731]],["text/Chap_8.html#problems",[]],["title/Chap_8.html#problem-81",[142,0.6,3421,4.371]],["text/Chap_8.html#problem-81",[1,1.565,2,1.128,11,0.413,34,1.154,169,1.647,240,2.2,337,1.116,409,1.67,412,1.452,416,1.902,468,2.669,493,1.599,502,3.98,505,2.079,549,2.57,564,2.388,587,2.175,597,1.706,636,2.57,752,3.192,1165,2.775,1225,4.448,3473,6.659,3512,7.183,3513,7.183,3514,7.183]],["title/Chap_8.html#problem-82",[142,0.6,585,3.353]],["text/Chap_8.html#problem-82",[11,0.402,25,1.85,35,1.936,53,2.098,84,2.951,95,2.2,122,3.63,216,4.361,253,3.384,273,3.492,281,2.951,285,1.81,311,2.149,325,2.123,355,1.488,409,1.52,412,1.322,432,3.143,447,3.092,449,3.195,467,3.366,536,5.186,685,3.143,750,4.248,857,2.996,863,4.978,933,4.648,1034,3.143,1076,3.307,1344,4.677,2116,4.151,2662,5.707,2877,6.063,3431,4.983,3515,6.539,3516,8.576,3517,8.923,3518,6.539,3519,6.539,3520,6.539,3521,6.539,3522,7.376,3523,7.376,3524,6.539,3525,6.539,3526,6.063,3527,6.063]],["title/Chap_8.html#problem-83",[142,0.6,3431,3.817]],["text/Chap_8.html#problem-83",[1,1.409,11,0.423,20,2.581,25,2.082,34,0.762,35,1.404,65,2.279,66,1.832,77,2.173,78,2.441,99,1.081,101,2.446,104,2.357,108,1.353,110,1.74,121,3.175,153,1.256,159,3.371,184,2.398,216,2.317,228,3.089,240,1.981,253,2.017,259,1.114,269,2.366,270,1.675,283,1.712,285,2.362,289,2.046,291,2.686,306,4.328,310,3.424,311,1.558,313,2.242,321,1.961,322,2.831,332,2.342,337,1.325,340,2.917,355,1.079,356,1.228,393,1.907,395,2.441,409,1.837,412,1.487,416,1.948,433,2.076,446,1.269,450,1.596,457,2.686,464,2.75,468,1.762,489,1.882,501,3.267,505,2.129,551,2.14,564,1.577,569,4.168,572,4.004,576,2.317,586,2.046,587,1.436,596,3.371,602,3.01,603,3.823,632,2.076,636,1.696,641,0.948,682,3.159,699,3.932,718,3.485,742,5.127,761,1.615,785,3.76,797,2.868,799,2.108,811,2.046,959,2.581,961,5.127,962,3.371,1065,2.485,1186,2.632,1257,3.76,1263,3.089,1264,3.91,1275,3.76,1310,2.441,1326,3.76,1328,3.268,1333,3.268,1342,3.613,1344,2.485,1452,3.485,1653,3.01,1717,3.485,1922,3.01,2017,3.485,2324,4.168,2339,3.175,2377,3.485,2378,3.76,2379,3.76,2466,3.932,2806,5.127,2869,4.138,2877,3.613,3186,4.138,3286,4.138,3379,4.138,3436,5.994,3466,7.666,3468,5.994,3472,6.821,3488,4.396,3510,4.396,3522,4.396,3523,4.396,3526,4.396,3527,4.396,3528,4.742,3529,4.742,3530,7.357,3531,8.269,3532,6.465,3533,4.742,3534,4.742,3535,4.742,3536,4.742,3537,4.742,3538,6.465,3539,4.742,3540,4.742,3541,4.742,3542,4.742,3543,4.742,3544,4.742,3545,4.742,3546,4.742,3547,4.742]],["title/Chap_9.html",[269,1.271,278,2.511,1463,3.236]],["text/Chap_9.html",[1,1.194,2,1.017,6,0.816,7,1.651,8,1.22,11,0.436,12,0.94,13,0.921,19,0.844,25,0.47,31,1.768,34,1.144,35,1.988,37,1.147,40,1.06,47,1.649,48,1.643,50,1.028,53,1.204,54,1.394,59,0.617,64,1.349,65,0.798,66,1.102,68,1.394,77,1.307,78,1.468,84,1.287,88,0.785,91,1.389,99,1.193,100,1.394,101,0.949,104,3.538,105,0.8,106,1.204,107,2.232,108,1.324,109,1.047,110,1.047,111,1.693,114,1.394,122,1.584,123,1.431,136,1.489,138,0.996,139,0.96,142,0.601,143,1.258,145,1.443,148,1.719,149,1.376,151,0.798,152,0.981,155,1.596,165,1.265,167,3.193,169,0.558,170,1.523,184,1.443,188,0.749,195,1.328,196,1.523,198,1.489,202,1.316,210,0.903,214,1.18,223,2.042,228,1.081,232,0.886,240,1.679,242,1.028,253,0.706,256,0.594,259,0.67,260,0.96,264,2.872,269,2.506,272,3.688,273,3.701,274,1.111,276,1.468,278,4.872,279,0.594,281,0.749,283,0.439,284,2.982,285,2.096,286,1.94,288,0.677,291,0.94,293,1.053,296,0.586,297,1.22,300,2.758,302,2.667,305,1.53,306,2.512,310,0.772,311,1.927,313,0.785,316,1.319,318,1.38,319,0.996,321,0.686,322,0.727,323,2.175,324,1.553,325,1.629,329,0.667,332,1.614,335,0.949,336,2.537,337,1.106,340,3.031,341,0.825,342,0.96,344,1.619,348,0.874,355,1.142,356,0.739,357,2.976,358,1.467,359,1.914,366,1.468,367,2.253,368,2.27,369,0.785,379,0.633,383,1.931,386,1.22,387,0.981,390,1.18,393,0.667,394,1.606,395,0.854,399,1.004,404,1.965,409,0.386,411,2.379,412,0.335,416,0.994,425,1.265,432,0.798,433,0.727,443,0.921,446,1.467,449,0.811,450,0.558,452,1.053,453,0.594,458,1.22,464,1.895,468,1.394,486,1.081,487,0.825,488,0.886,489,0.658,493,0.992,499,2.967,500,3.393,501,3.377,503,4.109,505,0.826,510,1.053,514,1.553,535,1.144,537,1.816,540,1.53,545,1.22,549,1.021,556,4.17,559,1.144,560,0.839,564,0.552,569,2.126,571,0.96,573,1.668,583,0.886,585,1.111,586,2.165,587,0.503,593,1.004,601,0.96,605,0.706,607,0.981,608,0.749,612,1.081,626,1.132,627,1.371,632,2.569,633,1.418,640,1.081,641,0.75,642,1.144,651,1.147,654,0.87,661,1.196,667,2.436,672,0.981,674,1.081,675,0.839,676,0.798,678,1.081,689,0.886,706,0.641,709,0.921,718,1.22,720,4.309,721,1.448,724,0.981,726,1.316,728,0.686,729,1.004,734,1.053,738,1.028,739,2.004,765,0.921,773,0.772,774,1.18,786,3.274,787,1.081,788,1.22,789,1.144,790,1.22,792,0.903,795,0.658,797,1.004,799,0.738,811,0.716,817,1.004,843,0.903,848,1.111,858,0.572,860,2.759,862,1.004,887,3.07,899,0.96,917,1.18,918,0.87,920,1.004,946,1.22,956,4.544,963,0.667,966,0.825,983,2.753,1003,1.523,1014,2.004,1017,1.22,1022,0.96,1030,1.22,1034,0.798,1041,1.811,1052,1.22,1063,1.22,1076,0.839,1086,2.028,1095,1.18,1134,0.96,1147,2.028,1154,1.448,1160,1.316,1165,0.641,1174,2.174,1186,1.584,1189,1.91,1216,0.696,1217,0.903,1219,1.22,1228,2.983,1230,2.004,1250,1.316,1254,3.567,1270,2.126,1289,2.634,1293,2.219,1307,1.448,1310,0.854,1322,1.18,1338,2.004,1343,2.976,1355,2.174,1436,1.111,1455,1.448,1466,1.265,1470,3.323,1476,2.262,1513,2.171,1514,1.22,1540,1.18,1561,1.448,1579,3.533,1611,3.533,1617,2.49,1665,1.316,1670,1.111,1675,1.448,1681,3.98,1682,3.98,1695,1.265,1751,1.22,1780,1.053,1797,1.316,1814,2.097,1868,1.22,1979,1.91,2017,1.22,2077,1.448,2086,1.004,2112,0.825,2221,1.265,2228,1.448,2233,2.028,2239,1.22,2257,1.22,2277,1.18,2339,1.111,2366,2.366,2406,2.49,2409,1.22,2410,3.112,2415,4.17,2422,1.265,2446,1.448,2447,2.262,2448,2.976,2477,1.448,2503,2.028,2562,3.694,2565,2.097,2572,1.316,2573,1.448,2607,1.316,2623,2.097,2624,1.265,2629,1.448,2680,1.448,2698,1.265,2708,1.448,2786,1.265,3022,1.448,3065,1.376,3121,1.448,3141,1.448,3201,1.448,3364,1.448,3418,2.49,3425,4.028,3426,3.98,3427,2.86,3431,1.265,3548,5.081,3549,3.752,3550,1.659,3551,5.232,3552,5.136,3553,3.479,3554,1.659,3555,2.853,3556,5.18,3557,1.659,3558,2.645,3559,1.659,3560,2.853,3561,2.645,3562,3.479,3563,2.645,3564,2.853,3565,3.752,3566,4.13,3567,1.659,3568,1.659,3569,1.659,3570,1.659,3571,3.752,3572,1.659,3573,1.659,3574,1.659,3575,2.853,3576,2.645,3577,1.659,3578,1.659,3579,1.659,3580,2.645,3581,1.659,3582,1.659,3583,1.659,3584,1.659,3585,1.659,3586,1.659,3587,3.275,3588,1.659,3589,2.853,3590,1.659,3591,1.659,3592,1.659,3593,1.659,3594,2.645,3595,2.645,3596,1.659,3597,5.081,3598,1.659,3599,3.479,3600,1.659,3601,1.659,3602,2.645,3603,1.659,3604,1.659,3605,4.455,3606,1.659,3607,1.659,3608,1.659,3609,1.659,3610,1.659,3611,1.659,3612,1.659,3613,1.659,3614,1.659,3615,1.659,3616,2.853,3617,1.659,3618,1.659,3619,1.659,3620,1.659,3621,1.659,3622,1.659,3623,1.659,3624,2.645,3625,2.645,3626,1.659,3627,1.659,3628,1.659,3629,1.659,3630,1.659,3631,1.659,3632,1.659,3633,1.659,3634,1.659,3635,5.018,3636,4.455,3637,1.659,3638,1.448,3639,1.659,3640,1.659,3641,1.659]],["title/Chap_9.html#the-matched-filter",[269,1.5,278,2.961]],["text/Chap_9.html#the-matched-filter",[1,1.204,8,4.06,11,0.418,31,2.192,40,2.053,50,3.421,59,2.053,65,2.655,66,2.765,68,2.699,84,2.493,88,2.612,99,0.756,107,2.737,108,1.291,109,2.625,110,2.625,169,1.081,170,3.821,184,2.793,210,3.007,228,3.598,240,1.692,264,2.895,269,2.377,272,5.834,273,4.645,278,4.694,281,2.493,285,2.197,286,2.284,288,2.253,291,3.129,297,4.06,306,5.314,310,2.571,311,1.815,313,2.612,316,1.635,324,3.895,329,2.222,337,0.858,340,3.582,342,3.196,344,2.384,358,1.916,383,2.843,394,1.37,493,1.23,569,3.129,571,3.196,573,2.455,601,3.196,608,2.493,626,2.192,627,2.655,632,3.677,640,3.598,641,1.105,667,3.732,720,3.266,738,3.421,765,3.066,786,4.06,858,1.904,946,4.06,956,7.213,1034,2.655,1086,5.087,1216,2.316,1270,3.129,1355,5.453,1561,4.821,1780,3.506,2422,4.21,3201,4.821,3418,6.245,3548,8.064,3549,7.938,3550,5.524,3551,4.06,3552,5.934,3553,6.635,3554,5.524,3555,7.156]],["title/Chap_9.html#setting-up-the-problem",[142,0.509,674,2.766,918,2.226]],["text/Chap_9.html#setting-up-the-problem",[2,1.269,7,3.318,11,0.436,19,1.087,34,1.368,84,2.588,99,1.165,100,3.583,101,2.438,104,4.374,107,1.977,148,2.628,169,1.122,260,3.318,269,1.717,272,4.215,273,3.915,285,1.587,286,1.47,305,2.99,321,2.371,335,2.438,336,3.707,337,1.139,340,3.308,348,1.757,356,1.486,394,1.422,468,2.131,487,2.851,499,4.778,500,4.235,501,3.722,503,4.654,537,2.339,540,2.339,585,3.84,605,2.44,641,1.147,651,2.307,689,3.062,720,5.035,795,2.276,797,3.469,811,2.475,1217,3.122,1228,3.122,1307,5.005,1670,3.84,2339,3.84,2503,4.077,2680,5.005,3141,5.005,3425,4.215,3426,4.548,3427,4.371,3551,4.215,3552,4.756,3553,5.317,3556,5.211,3557,5.735,3558,5.317,3559,5.735,3560,7.331,3561,5.317,3562,5.317,3563,5.317]],["title/Chap_9.html#using-cauchy-schwartz",[2,0.667,1681,3.367,1682,3.367]],["text/Chap_9.html#using-cauchy-schwartz",[2,0.784,11,0.438,25,1.412,34,1.213,91,1.852,99,1.26,104,4.306,107,1.721,108,0.741,198,1.981,269,1.494,273,2.665,276,2.569,279,1.786,285,1.381,332,2.425,336,2.524,337,1.04,359,2.552,367,3.385,368,4.568,390,3.548,393,2.008,395,2.569,399,3.019,425,3.804,464,3.212,499,3.958,500,4.411,501,3.806,503,5.342,514,3.643,537,2.035,556,6.158,569,2.828,593,3.019,720,3.958,739,2.665,887,5.205,1076,2.524,1219,3.668,1228,4.11,1230,2.665,1254,5.368,1293,3.958,1343,5.308,1470,4.571,1476,5.308,1513,2.888,1665,3.958,1681,5.308,1682,5.308,2228,4.356,2503,3.548,2708,4.356,3425,5.55,3426,5.308,3427,5.101,3556,3.548,3561,4.627,3562,6.206,3563,4.627,3564,6.693,3565,7.552,3566,7.002,3567,4.991,3568,4.991,3569,4.991,3570,4.991,3571,7.552,3572,4.991,3573,4.991,3574,4.991,3575,6.693,3576,4.627,3577,4.991]],["title/Chap_9.html#the-classic-example",[105,1.068,535,3.452]],["text/Chap_9.html#the-classic-example",[11,0.416,34,1.134,40,2.623,104,3.508,105,1.505,269,2.113,278,4.173,285,1.953,332,2.557,340,3.185,369,3.338,387,4.173,394,1.751,458,5.187,468,2.623,488,3.769,489,2.801,556,5.017,564,2.347,587,2.137,612,4.598,626,2.801,627,3.392,675,3.569,720,4.173,721,6.159,1293,4.173,2257,5.187,2410,6.906,3576,6.544,3578,7.058,3579,7.058,3580,6.544]],["title/Chap_9.html#example-matching-your-filter",[105,0.906,269,1.271,278,2.511]],["text/Chap_9.html#example-matching-your-filter",[11,0.435,35,2.248,77,2.779,91,1.679,99,0.83,108,1.127,136,3.014,145,3.067,269,2.274,278,4.491,286,2.293,293,3.85,311,2.496,332,2.197,336,3.067,340,3.742,348,1.858,356,1.571,383,3.909,394,1.504,500,3.179,501,3.594,503,4.821,537,3.097,633,3.015,641,1.213,706,2.343,709,3.367,720,4.491,862,3.669,887,4.18,1228,4.134,1310,3.122,1470,4.698,1695,4.622,2447,6.024,2448,6.576,2623,4.458,2629,5.293,3425,5.582,3426,6.024,3551,5.582,3552,6.298,3580,5.623,3581,6.065,3582,6.065,3583,6.065,3584,6.065,3585,6.065,3586,6.065,3587,5.293]],["title/Chap_9.html#the-matched-filter-as-an-autocorrelation",[269,1.271,278,2.511,505,1.229]],["text/Chap_9.html#the-matched-filter-as-an-autocorrelation",[7,3.45,11,0.424,34,1.207,35,1.765,37,2.399,53,1.914,64,2.82,68,2.914,99,1.028,107,2.056,108,1.322,142,0.715,167,4.479,184,3.016,195,3.498,269,1.786,272,4.383,276,3.069,278,3.526,286,1.528,311,1.959,318,2.329,325,1.936,340,2.691,355,1.357,358,1.597,359,2.274,394,2.041,404,3.222,409,1.386,411,4.394,412,1.205,416,2.179,443,3.31,446,2.012,450,2.007,493,1.328,505,1.726,510,3.785,549,2.689,678,3.885,720,4.866,724,3.526,728,2.466,739,3.184,817,3.607,899,3.45,917,4.239,920,3.607,1014,3.184,1017,4.383,1022,3.45,1041,3.785,1052,4.383,1154,5.205,1338,4.013,1514,4.383,1751,4.383,1868,4.383,2406,6.558,2446,5.205,3121,5.205,3551,6.349,3552,6.824,3587,5.205,3588,5.964,3589,7.515,3590,5.964,3591,5.964,3592,5.964,3593,5.964]],["title/Chap_9.html#performance-in-the-presence-of-noise",[284,2.843,285,1.175,654,2.226]],["text/Chap_9.html#performance-in-the-presence-of-noise",[2,0.984,6,2.218,11,0.387,34,1.007,35,2.491,77,2.871,91,1.734,107,2.16,108,1.305,136,2.486,145,3.168,149,5.196,167,4.218,198,2.486,214,3.205,223,3.41,259,1.472,269,2.632,273,4.493,278,5.199,283,1.659,285,1.734,302,5.982,311,2.059,355,1.763,357,6.674,359,2.389,404,2.453,411,3.346,453,2.242,569,3.55,573,2.785,632,2.744,633,3.114,651,2.52,661,2.627,718,4.605,773,2.916,1063,4.605,1174,5.906,1270,3.55,1513,3.625,1540,4.454,1579,6.973,2233,4.454,2277,4.454,2409,4.605,2562,6.978,2565,5.696,2572,4.969,2624,4.775,2698,4.775,3431,4.775,3551,5.696,3556,5.509,3594,5.809,3595,5.809]],["title/Chap_9.html#problems",[142,0.731]],["text/Chap_9.html#problems",[]],["title/Chap_9.html#problem-91",[142,0.6,3551,3.681]],["text/Chap_9.html#problem-91",[1,1.589,2,1.146,11,0.421,19,1.382,34,0.914,35,2.159,47,1.869,48,3.194,78,2.928,99,1.162,106,1.826,108,1.373,114,2.78,138,1.986,148,3.342,151,2.735,165,4.336,167,3.097,223,3.097,240,2.466,256,2.036,264,2.982,269,2.689,278,5.311,285,2.228,300,5.36,305,2.32,311,1.869,337,1.319,355,1.294,358,1.523,359,2.17,379,2.17,394,1.809,404,2.228,432,2.735,486,3.706,540,2.974,573,2.529,586,2.455,632,3.194,676,2.735,774,4.044,799,2.529,963,2.288,966,2.828,983,3.992,1134,3.292,1165,2.198,1186,4.049,1189,3.809,1230,3.038,1270,3.223,1338,3.038,1797,4.512,1979,3.809,2017,4.182,2112,2.828,2221,4.336,2366,4.718,2410,4.718,2415,6.24,3556,5.723,3587,4.965,3595,5.275,3596,5.69,3597,7.872,3598,5.69,3599,5.275,3600,5.69,3601,5.69,3602,5.275]],["title/Chap_9.html#problem-92",[142,0.6,3556,3.56]],["text/Chap_9.html#problem-92",[1,1.228,11,0.41,12,3.191,13,3.127,19,1.067,31,3.179,35,2.145,53,2.326,54,2.753,64,2.664,78,2.899,99,1.096,108,1.405,122,4.023,138,1.966,139,3.259,188,2.542,196,3.008,198,2.235,223,3.066,240,2.22,242,3.489,253,2.396,284,4.852,285,2.217,286,1.857,296,1.99,300,4.14,311,1.851,316,1.668,318,2.246,322,2.467,323,3.555,325,2.353,336,2.849,337,1.126,341,2.8,344,3.127,358,1.94,446,1.508,449,2.753,607,3.331,661,2.362,667,3.221,726,4.467,734,3.576,786,5.326,843,3.066,848,3.771,983,3.221,1003,3.87,1030,4.14,1147,4.004,1189,3.771,1513,3.259,1814,5.326,2077,4.916,2366,4.671,2415,5.152,2477,4.916,3022,4.916,3556,5.152,3597,6.719,3599,6.719,3602,5.223,3603,5.633,3604,5.633,3605,8.459,3606,5.633,3607,5.633,3608,5.633,3609,5.633,3610,5.633,3611,5.633,3612,5.633,3613,5.633,3614,5.633,3615,5.633,3616,7.247,3617,5.633,3618,5.633,3619,5.633,3620,5.633,3621,5.633,3622,5.633,3623,5.633,3624,5.223,3625,5.223]],["title/Chap_9.html#laboratory-exercises",[47,1.646,143,1.256]],["text/Chap_9.html#laboratory-exercises",[]],["title/Chap_9.html#laboratory-exercise-91",[47,1.395,143,1.065,3551,3.121]],["text/Chap_9.html#laboratory-exercise-91",[37,3.018,48,3.286,91,2.077,99,1.027,123,2.862,143,1.882,155,3.192,167,4.085,284,5.024,285,2.077,316,2.221,2233,5.335,2562,6.223,3556,5.335,3594,6.958]],["title/Chap_9.html#laboratory-exercise-92",[47,1.395,143,1.065,3556,3.018]],["text/Chap_9.html#laboratory-exercise-92",[99,1.008,123,2.81,155,3.134,264,4.727,269,2.206,278,4.357,316,2.181,386,5.416,559,5.078,729,4.457,956,6.11,1147,5.238,1160,5.844,2086,4.457,2786,5.615,3364,6.431,3548,6.832,3626,7.369,3627,7.369,3628,7.369]],["title/Chap_9.html#laboratory-exercise-93",[47,1.395,143,1.065,3558,3.937]],["text/Chap_9.html#laboratory-exercise-93",[1,1.558,2,0.866,11,0.433,54,2.694,99,1.148,106,2.294,107,2.464,108,0.818,111,3.579,114,2.694,123,2.102,152,3.26,155,2.345,196,2.944,202,4.372,232,2.944,259,1.295,264,2.89,269,1.651,274,3.691,278,3.26,319,2.494,325,2.321,337,0.856,355,1.254,366,3.679,367,3.614,433,2.414,446,2.123,452,3.5,464,2.345,468,2.049,493,1.591,501,2.28,545,4.052,560,2.788,583,2.944,586,3.621,642,3.8,672,3.26,739,2.944,786,4.052,787,3.591,788,4.052,789,3.8,790,4.052,792,3.001,860,5.196,1014,3.816,1041,3.5,1095,3.919,1230,2.944,1250,4.372,1254,5.081,1289,4.961,1322,3.919,1343,4.372,1436,3.691,1455,4.811,1466,4.201,1611,6.654,1617,6.237,1675,4.811,1681,5.668,1682,5.668,1979,3.691,2239,4.052,2573,4.811,2607,4.372,2623,4.052,3065,4.572,3566,5.111,3624,5.111,3625,5.111,3629,5.513,3630,5.513,3631,5.513,3632,5.513,3633,5.513,3634,5.513,3635,8.693,3636,8.391,3637,5.513,3638,4.811,3639,5.513,3640,5.513,3641,5.513]],["title/info.html",[122,3.388]],["text/info.html",[0,2.28,1,1.063,2,1.312,3,3.935,11,0.423,12,2.762,14,2.358,17,3.264,18,3.716,19,0.608,26,2.8,27,2.8,32,2.135,33,3.412,34,0.948,35,1.443,38,2.28,40,1.192,41,2.8,45,4.065,47,2.549,48,2.583,54,1.568,55,2.8,57,2.211,58,2.8,69,5.877,71,3.867,72,2.544,76,3.176,77,3.42,78,1.651,79,2.544,80,1.856,81,2.8,82,2.544,83,2.28,84,2.973,85,2.358,86,2.358,87,2.148,88,2.789,91,0.888,99,0.439,105,1.04,108,0.724,110,1.789,120,1.651,122,1.781,123,1.223,126,1.897,128,2.8,133,2.556,136,1.273,137,4.389,138,2.857,139,3.812,143,1.945,144,6.185,145,2.983,147,3.568,148,1.47,151,1.542,153,1.291,160,2.8,166,2.358,167,1.746,168,2.211,169,1.289,170,1.713,173,2.8,184,1.622,186,3.867,187,4.043,188,1.448,196,2.604,201,4.043,208,4.678,211,1.961,213,2.949,223,1.746,231,2.8,249,2.544,253,1.365,256,1.148,263,5.209,264,1.681,266,1.517,279,1.148,292,2.762,295,1.856,308,2.358,309,1.713,311,1.054,322,1.405,332,1.162,337,0.498,339,1.622,358,1.305,360,2.8,363,1.651,371,1.493,378,1.448,382,1.326,389,1.622,412,0.986,431,1.384,432,1.542,446,0.859,450,1.08,453,2.11,456,1.856,496,1.987,505,0.928,535,2.211,550,1.365,560,1.622,564,1.067,581,2.28,587,0.972,632,1.405,633,2.423,636,1.148,641,0.641,643,2.358,645,2.8,646,2.8,657,1.781,670,3.949,674,2.09,682,2.383,685,2.344,728,1.326,734,3.744,735,3.095,795,1.273,800,2.8,823,4.043,873,1.781,886,1.594,895,1.681,918,1.681,927,1.148,944,3.361,969,3.412,970,1.897,990,2.544,1014,1.713,1041,2.036,1042,2.358,1046,2.445,1079,4.335,1162,2.045,1165,1.239,1199,2.211,1222,1.94,1258,3.466,1277,3.176,1280,1.987,1310,1.651,1355,2.445,1374,3.341,1435,2.445,1478,1.897,1524,2.28,1715,2.544,1718,3.466,1719,4.335,1721,3.716,1724,3.716,1726,2.544,1727,2.8,1728,2.8,1729,4.193,1771,2.8,1775,4.255,1786,5.225,1804,2.8,1829,2.8,1844,2.445,1851,2.544,2023,2.358,2047,2.211,2093,2.544,2116,2.036,2125,3.361,2186,3.842,2197,3.716,2198,3.716,2203,2.8,2233,2.28,2240,2.8,2373,2.544,2377,3.584,2423,2.66,2538,2.544,2539,2.544,2540,2.8,2541,2.8,2542,2.544,2547,3.716,2548,2.8,2618,2.544,2696,4.255,2827,2.8,2854,2.445,2877,2.445,3160,2.8,3161,2.8,3638,2.8,3642,3.208,3643,3.208,3644,4.876,3645,4.876,3646,3.208,3647,4.876,3648,3.208,3649,3.208,3650,3.208,3651,5.898,3652,5.898,3653,3.208,3654,3.208,3655,3.208,3656,3.208,3657,3.208,3658,4.521,3659,3.208,3660,3.208,3661,3.208,3662,3.208,3663,3.208,3664,3.208,3665,3.208,3666,5.147,3667,3.208,3668,3.208,3669,3.208,3670,3.208,3671,3.208,3672,3.208,3673,5.147,3674,3.208,3675,3.208,3676,3.208,3677,4.876,3678,3.208,3679,3.208,3680,3.208,3681,3.208,3682,3.208,3683,3.208,3684,3.208,3685,4.876,3686,5.898,3687,3.208,3688,3.208,3689,3.208,3690,3.208,3691,3.208,3692,3.208,3693,3.208,3694,3.208,3695,3.208,3696,4.876,3697,3.208,3698,4.876,3699,3.208,3700,3.208,3701,3.208,3702,3.208,3703,3.208,3704,3.208,3705,4.876,3706,3.208,3707,3.208,3708,3.208,3709,4.876,3710,3.208,3711,3.208,3712,3.208,3713,4.876,3714,3.208,3715,5.898,3716,3.208,3717,3.208,3718,3.208,3719,3.208,3720,3.208,3721,3.208,3722,3.208,3723,3.208,3724,3.208,3725,3.208,3726,3.208,3727,3.208,3728,3.208,3729,3.208,3730,3.208,3731,3.208,3732,3.208,3733,3.208,3734,3.208,3735,3.208,3736,3.208,3737,3.208,3738,3.208,3739,3.208,3740,3.208,3741,3.208,3742,3.208,3743,3.208,3744,3.208,3745,3.208,3746,3.208,3747,3.208,3748,3.208,3749,3.208]],["title/info.html#tips-short-cuts",[643,2.709,809,3.417,3642,3.685,3643,3.685]],["text/info.html#tips-short-cuts",[0,3.711,2,1.213,3,2.509,11,0.416,12,3.907,26,4.555,27,4.555,33,3.02,34,0.839,35,1.545,47,2.94,48,3.02,54,2.551,69,7.083,71,5.469,76,4.492,77,3.16,78,2.687,79,4.14,80,3.02,81,4.555,82,4.14,83,3.711,84,3.485,85,3.836,86,3.836,87,3.495,88,3.261,99,0.714,120,2.687,122,2.898,123,1.991,126,3.087,133,2.736,137,5.29,138,3.208,139,4.753,143,2.244,144,7.454,145,3.905,148,2.392,153,1.382,187,4.329,196,2.787,201,4.329,208,6.124,213,4.171,223,2.841,253,2.22,263,6.278,264,2.736,266,2.469,279,1.868,295,3.02,311,1.715,337,0.811,339,2.64,358,1.398,389,2.64,412,1.055,535,3.598,581,3.711,633,3.427,674,3.4,682,3.37,734,4.377,735,4.377,895,2.736,969,3.99,1041,3.313,1079,5.676,1280,3.233,1310,2.687,1355,3.978,1478,3.087,1719,3.836,1829,4.555,1844,3.978,2047,3.598,2093,4.14,2186,3.4,2233,3.711,2377,5.068,2618,4.14,3644,6.896,3645,6.896,3646,5.22,3647,6.896,3648,5.22,3649,5.22,3650,5.22,3651,7.723,3652,7.723,3653,5.22,3654,5.22,3655,5.22,3656,5.22,3657,5.22,3658,4.84,3659,5.22]],["title/info.html#authors",[1786,4.841]],["text/info.html#authors",[11,0.336,886,3.8,1719,5.619,1726,6.063,1727,6.672,1728,6.672,1786,6.063,3660,7.646]],["title/info.html#venue",[3661,6.104]],["text/info.html#venue",[3,3.675,11,0.336,18,5.826,84,3.45,88,3.616,187,6.34,3658,7.088,3662,7.646]],["title/info.html#contact",[3663,6.104]],["text/info.html#contact",[3,3.579,151,3.579,168,5.131,231,6.498,249,5.905,670,6.064,873,4.133,3664,7.446,3665,7.446,3666,6.498,3667,7.446,3668,7.446,3669,7.446,3670,7.446,3671,7.446,3672,7.446]],["title/info.html#acknowledgments",[3673,5.327]],["text/info.html#acknowledgments",[2,1.037,3,3.172,17,5.356,77,3.024,110,2.421,136,2.619,170,3.524,211,3.218,309,3.524,358,1.767,363,3.397,432,3.172,450,2.221,560,3.337,685,3.846,728,2.729,734,4.189,795,2.619,823,6.635,969,3.818,1374,4.533,1435,5.029,1715,5.234,1724,5.029,1771,5.76,1775,6.982,2116,4.189,2186,4.299,2373,5.234,2547,5.029,2696,6.982,2827,5.76,2854,5.029,3638,5.76,3673,5.76,3674,6.6,3675,6.6,3676,6.6,3677,8.001,3678,6.6,3679,6.6,3680,6.6,3681,6.6,3682,6.6,3683,6.6,3684,6.6,3685,8.001,3686,8.61,3687,6.6,3688,6.6,3689,6.6,3690,6.6,3691,6.6,3692,6.6,3693,6.6,3694,6.6]],["title/info.html#technical-details",[1042,3.681,3666,4.371]],["text/info.html#technical-details",[2,1.39,3,3.766,11,0.345,14,4.687,18,4.86,33,4.533,34,1.259,35,1.888,40,2.37,45,4.396,72,5.058,77,2.923,91,1.765,105,1.36,108,1.163,128,5.566,167,3.471,169,1.66,196,3.406,201,5.289,292,4.439,332,2.311,360,5.566,371,2.969,382,2.637,446,1.708,918,3.343,944,5.4,970,3.771,990,5.058,1014,3.406,1046,4.86,1162,2.674,1222,3.858,1524,4.534,1804,5.566,2125,4.396,3666,5.566,3695,6.378,3696,7.836,3697,6.378,3698,7.836,3699,6.378,3700,6.378,3701,6.378,3702,6.378,3703,6.378,3704,6.378,3705,7.836,3706,6.378,3707,6.378,3708,6.378,3709,7.836,3710,6.378,3711,6.378,3712,6.378,3713,7.836,3714,6.378,3715,8.482,3716,6.378,3717,6.378,3718,6.378,3719,6.378]],["title/info.html#copyright",[186,4.841]],["text/info.html#copyright",[11,0.332,41,6.584,45,5.199,133,3.954,184,3.815,186,5.983,1719,5.545,1721,5.749,2023,5.545,2240,6.584,2877,5.749,3720,7.544,3721,7.544]],["title/info.html#weather-data",[453,1.792,1277,3.263]],["text/info.html#weather-data",[2,1.173,3,3.588,11,0.379,32,3.269,105,1.592,453,2.671,1258,5.307,1277,4.863,1374,4.229,1718,5.307,1729,5.307,2197,5.689,2198,5.689,3673,6.515,3722,7.465,3723,7.465]],["title/info.html#cover",[1721,4.652]],["text/info.html#cover",[1,1.581,153,1.921,322,3.177,412,1.467,496,4.493,505,2.1,564,2.413,587,2.197,636,2.596,641,1.451,657,4.028,927,2.596,1162,3.043,1258,5.158,1718,5.158,1729,6.017,1851,5.754,2197,5.529,2198,5.529,2423,6.017,2538,5.754,2539,5.754,2540,6.332,2541,6.332,2542,5.754,2547,5.529,2548,6.332]],["title/info.html#musical-data",[147,3.029,453,1.792]],["text/info.html#musical-data",[3,3.992,11,0.402,32,3.075,38,4.992,48,3.075,57,4.84,58,6.129,147,5.023,160,6.129,166,5.162,169,1.374,173,6.129,256,2.513,308,5.162,456,4.063,632,3.075,645,6.129,646,6.129,2186,4.575,3160,6.129,3724,7.023,3725,7.023,3726,7.023,3727,7.023,3728,7.023,3729,7.023,3730,7.023,3731,7.023,3732,7.023,3733,7.023,3734,7.023,3735,7.023,3736,7.023,3737,7.023,3738,7.023,3739,7.023]],["title/info.html#version",[77,2.797]],["text/info.html#version",[55,6.745,77,3.541,550,3.287,3740,7.729]],["title/info.html#registration",[3741,6.104]],["text/info.html#registration",[1,1.675,188,3.469,2203,6.708,3742,7.687,3743,7.687,3744,7.687]],["title/info.html#usage",[3745,6.104]],["text/info.html#usage",[2,1.17,19,1.411,45,5.131,110,2.732,378,3.36,431,3.213,800,6.498,1165,2.877,1199,5.131,1724,5.674,1786,6.814,2125,5.131,3161,6.498,3746,7.446,3747,7.446,3748,7.446,3749,7.446]]],"fields":["title","text"],"invertedIndex":[["",{"_index":11,"text":{"Chap_1.html":{},"Chap_1.html#at-the-movies":{},"Chap_1.html#enhanced-experience":{},"Chap_1.html#getting-around":{},"Chap_1.html#highlighting":{},"Chap_1.html#how-to-use-this-ibook":{},"Chap_1.html#outside-this-device":{},"Chap_1.html#sound-of-music":{},"Chap_10.html":{},"Chap_10.html#as-seen-from-the-fourier-domain":{},"Chap_10.html#classic-example-classic-result":{},"Chap_10.html#correlation-returns":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#example-cleaning-up-our-act":{},"Chap_10.html#example-sound-of-distorted-music":{},"Chap_10.html#expressing-the-mean-square-error":{},"Chap_10.html#laboratory-exercise-105":{},"Chap_10.html#problem-102":{},"Chap_10.html#problem-103":{},"Chap_10.html#problem-104":{},"Chap_10.html#the-more-general-restoration-case-noise-distortion":{},"Chap_10.html#the-restoration-case-noise":{},"Chap_10.html#the-wiener-hopf-equation":{},"Chap_10.html#using-the-least-mean-square-error-criterion":{},"Chap_10.html#what-is-that-least-mean-square-error":{},"Chap_10.html#why-we-avoid-the-inverse-filter":{},"Chap_11.html":{},"Chap_11.html#aspects-of-estimation":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_11.html#estimating-the-autocorrelation-function":{},"Chap_11.html#estimating-the-mean":{},"Chap_11.html#example-estimating-the-poisson-rate":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_11.html#laboratory-exercise-113":{},"Chap_11.html#langevin-redux":{},"Chap_11.html#maximum-likelihood-estimation":{},"Chap_11.html#problem-1110":{},"Chap_11.html#problem-112":{},"Chap_11.html#problem-113":{},"Chap_11.html#problem-114":{},"Chap_11.html#problem-115":{},"Chap_11.html#problem-116":{},"Chap_11.html#problem-117":{},"Chap_11.html#problem-118":{},"Chap_11.html#problem-119":{},"Chap_11.html#trouble-in-paradise":{},"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#laboratory-exercise-122":{},"Chap_12.html#laboratory-exercise-124":{},"Chap_12.html#other-windows":{},"Chap_12.html#problem-121":{},"Chap_12.html#problem-122":{},"Chap_12.html#problem-123":{},"Chap_12.html#spectral-estimation":{},"Chap_12.html#the-periodogram-unbiased":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_12.html#windowed-observations":{},"Chap_13.html":{},"Chap_13.html#appendix-i-mean-square-error-minimization":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_13.html#epilogue":{},"Chap_2.html":{},"Chap_2.html#problem-21":{},"Chap_2.html#prologue":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_3.html#introduction":{},"Chap_3.html#problem-310":{},"Chap_3.html#problem-32":{},"Chap_3.html#problem-35":{},"Chap_3.html#problem-36":{},"Chap_3.html#problem-37":{},"Chap_3.html#problem-39":{},"Chap_3.html#the-basics":{},"Chap_3.html#what-is-a-random-signal":{},"Chap_4.html":{},"Chap_4.html#auto-covariance":{},"Chap_4.html#autocorrelation":{},"Chap_4.html#characterization-of-random-signals":{},"Chap_4.html#cross-correlation":{},"Chap_4.html#cross-covariance":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#describing-the-time-average":{},"Chap_4.html#example-average-experience":{},"Chap_4.html#example-dice-money":{},"Chap_4.html#example-fair-chance":{},"Chap_4.html#example-is-that-coin-fair":{},"Chap_4.html#laboratory-exercise-41":{},"Chap_4.html#laboratory-exercise-42":{},"Chap_4.html#other-averages":{},"Chap_4.html#problem-41":{},"Chap_4.html#problem-42":{},"Chap_4.html#problem-43":{},"Chap_4.html#problem-44":{},"Chap_4.html#problem-45":{},"Chap_4.html#problem-46":{},"Chap_4.html#problem-47":{},"Chap_4.html#problem-48":{},"Chap_4.html#problem-49":{},"Chap_4.html#properties-of-averaging":{},"Chap_4.html#the-ergodic-process":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#correlations-and-memory":{},"Chap_5.html#correlations-and-spectra":{},"Chap_5.html#correlations-simple-and-complex":{},"Chap_5.html#example-delayed-effect":{},"Chap_5.html#example-pink-noise":{},"Chap_5.html#example-white-noise":{},"Chap_5.html#fourier-description-of-correlation-functions":{},"Chap_5.html#laboratory-exercise-51":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_5.html#problem-51":{},"Chap_5.html#problem-52":{},"Chap_5.html#problem-53":{},"Chap_5.html#problem-54":{},"Chap_5.html#problem-55":{},"Chap_5.html#problem-56":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{},"Chap_6.html#filtering-of-stochastic-signals":{},"Chap_6.html#interpretation-of-the-convolution-result":{},"Chap_6.html#laboratory-exercise-63":{},"Chap_6.html#problem-61":{},"Chap_6.html#problem-62":{},"Chap_6.html#problem-63":{},"Chap_6.html#problem-64":{},"Chap_6.html#problem-65":{},"Chap_6.html#problem-66":{},"Chap_6.html#the-autocorrelation-function":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_6.html#the-mean":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function":{},"Chap_7.html#autocorrelation-function_1":{},"Chap_7.html#autocorrelation-function_2":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#descriptive-statistic-variance":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#expected-value":{},"Chap_7.html#expected-value_1":{},"Chap_7.html#from-t-to-n":{},"Chap_7.html#how-big-is-big-how-small-is-small":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#impulse-invariant-sampling":{},"Chap_7.html#one-step-further":{},"Chap_7.html#power-spectral-density":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#power-spectral-density_2":{},"Chap_7.html#problem-710":{},"Chap_7.html#problem-711":{},"Chap_7.html#problem-72":{},"Chap_7.html#problem-73":{},"Chap_7.html#problem-74":{},"Chap_7.html#problem-75":{},"Chap_7.html#problem-76":{},"Chap_7.html#problem-77":{},"Chap_7.html#problem-78":{},"Chap_7.html#problem-79":{},"Chap_7.html#tethered-particle-motion":{},"Chap_7.html#the-langevin-equation-a-case-study":{},"Chap_7.html#the-langevin-position-equation":{},"Chap_7.html#the-langevin-velocity-equation":{},"Chap_7.html#why-this-case-study":{},"Chap_8.html":{},"Chap_8.html#example-cocktail-party-noise":{},"Chap_8.html#example-filtering-noise":{},"Chap_8.html#example-not-too-noisy":{},"Chap_8.html#problem-81":{},"Chap_8.html#problem-82":{},"Chap_8.html#problem-83":{},"Chap_8.html#snr-for-deterministic-signals-in-the-presence-of-noise":{},"Chap_8.html#snr-for-random-signals-in-the-presence-of-noise":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{},"Chap_9.html":{},"Chap_9.html#example-matching-your-filter":{},"Chap_9.html#laboratory-exercise-93":{},"Chap_9.html#performance-in-the-presence-of-noise":{},"Chap_9.html#problem-91":{},"Chap_9.html#problem-92":{},"Chap_9.html#setting-up-the-problem":{},"Chap_9.html#the-classic-example":{},"Chap_9.html#the-matched-filter":{},"Chap_9.html#the-matched-filter-as-an-autocorrelation":{},"Chap_9.html#using-cauchy-schwartz":{},"info.html":{},"info.html#authors":{},"info.html#copyright":{},"info.html#musical-data":{},"info.html#technical-details":{},"info.html#tips-short-cuts":{},"info.html#venue":{},"info.html#weather-data":{}},"title":{"Chap_12.html#the-periodogram-unbiased":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_4.html#correlation-the-workhorse":{},"Chap_7.html":{},"Chap_7.html#descriptive-statistic-variance":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#the-langevin-equation-a-case-study":{}}}],["0",{"_index":355,"text":{"Chap_10.html":{},"Chap_10.html#classic-example-classic-result":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#example-cleaning-up-our-act":{},"Chap_10.html#expressing-the-mean-square-error":{},"Chap_10.html#problem-103":{},"Chap_10.html#the-more-general-restoration-case-noise-distortion":{},"Chap_10.html#the-wiener-hopf-equation":{},"Chap_10.html#using-the-least-mean-square-error-criterion":{},"Chap_10.html#why-we-avoid-the-inverse-filter":{},"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_11.html#estimating-the-mean":{},"Chap_11.html#example-estimating-the-poisson-rate":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_11.html#langevin-redux":{},"Chap_11.html#problem-111":{},"Chap_11.html#problem-1110":{},"Chap_11.html#problem-114":{},"Chap_11.html#problem-115":{},"Chap_11.html#problem-117":{},"Chap_11.html#problem-118":{},"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#problem-121":{},"Chap_12.html#problem-122":{},"Chap_12.html#the-periodogram-unbiased":{},"Chap_13.html":{},"Chap_13.html#appendix-i-mean-square-error-minimization":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#example-dice-money":{},"Chap_4.html#example-fair-chance":{},"Chap_4.html#example-is-that-coin-fair":{},"Chap_4.html#laboratory-exercise-41":{},"Chap_4.html#problem-41":{},"Chap_4.html#problem-42":{},"Chap_4.html#problem-44":{},"Chap_4.html#problem-47":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#correlations-and-memory":{},"Chap_5.html#correlations-simple-and-complex":{},"Chap_5.html#example-pink-noise":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_5.html#problem-52":{},"Chap_5.html#problem-53":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{},"Chap_6.html#problem-61":{},"Chap_6.html#problem-65":{},"Chap_6.html#problem-66":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_6.html#the-mean":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function":{},"Chap_7.html#autocorrelation-function_1":{},"Chap_7.html#autocorrelation-function_2":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#descriptive-statistic-variance":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#expected-value":{},"Chap_7.html#expected-value_1":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#impulse-invariant-sampling":{},"Chap_7.html#one-step-further":{},"Chap_7.html#power-spectral-density":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#power-spectral-density_2":{},"Chap_7.html#problem-711":{},"Chap_7.html#tethered-particle-motion":{},"Chap_7.html#the-langevin-velocity-equation":{},"Chap_8.html":{},"Chap_8.html#example-not-too-noisy":{},"Chap_8.html#problem-82":{},"Chap_8.html#problem-83":{},"Chap_8.html#snr-for-random-signals-in-the-presence-of-noise":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{},"Chap_9.html":{},"Chap_9.html#laboratory-exercise-93":{},"Chap_9.html#performance-in-the-presence-of-noise":{},"Chap_9.html#problem-91":{},"Chap_9.html#the-matched-filter-as-an-autocorrelation":{}},"title":{}}],["0&\\lvert",{"_index":2041,"text":{"Chap_3.html":{},"Chap_3.html#problem-310":{}},"title":{}}],["0&{\\left",{"_index":1328,"text":{"Chap_12.html":{},"Chap_12.html#windowed-observations":{},"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_6.html":{},"Chap_6.html#problem-63":{},"Chap_8.html":{},"Chap_8.html#problem-83":{}},"title":{}}],["0&{i",{"_index":2305,"text":{"Chap_4.html":{},"Chap_4.html#problem-41":{}},"title":{}}],["0,\\sigma",{"_index":3052,"text":{"Chap_7.html":{},"Chap_7.html#expected-value":{}},"title":{}}],["0,t",{"_index":1178,"text":{"Chap_11.html":{},"Chap_11.html#problem-114":{}},"title":{}}],["0.002",{"_index":2577,"text":{"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{}},"title":{}}],["0.073",{"_index":3234,"text":{"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#power-spectral-density_2":{}},"title":{}}],["0.1",{"_index":2211,"text":{"Chap_4.html":{},"Chap_4.html#the-mechanics-of-correlations":{}},"title":{}}],["0.14",{"_index":2871,"text":{"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small":{}},"title":{}}],["0.166",{"_index":1490,"text":{"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{}},"title":{}}],["0.177",{"_index":1493,"text":{"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{}},"title":{}}],["0.179",{"_index":1496,"text":{"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{}},"title":{}}],["0.186",{"_index":1499,"text":{"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{}},"title":{}}],["0.197",{"_index":1502,"text":{"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{}},"title":{}}],["0.200",{"_index":1505,"text":{"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{}},"title":{}}],["0.236",{"_index":1508,"text":{"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{}},"title":{}}],["0.382",{"_index":1510,"text":{"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{}},"title":{}}],["0.46\\co",{"_index":1461,"text":{"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{}},"title":{}}],["0.5",{"_index":1456,"text":{"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_7.html":{},"Chap_7.html#power-spectral-density":{}},"title":{}}],["0.510",{"_index":1506,"text":{"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{}},"title":{}}],["0.515",{"_index":1500,"text":{"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{}},"title":{}}],["0.54",{"_index":1460,"text":{"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{}},"title":{}}],["0.558",{"_index":1503,"text":{"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{}},"title":{}}],["0.577",{"_index":1494,"text":{"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{}},"title":{}}],["0.5\\co",{"_index":1457,"text":{"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{}},"title":{}}],["0.611",{"_index":1497,"text":{"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{}},"title":{}}],["0.619",{"_index":1491,"text":{"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{}},"title":{}}],["0.8",{"_index":3181,"text":{"Chap_7.html":{},"Chap_7.html#tethered-particle-motion":{}},"title":{}}],["0.84",{"_index":3481,"text":{"Chap_8.html":{},"Chap_8.html#example-cocktail-party-noise":{}},"title":{}}],["0.85",{"_index":1132,"text":{"Chap_11.html":{},"Chap_11.html#langevin-redux":{}},"title":{}}],["0.875",{"_index":1131,"text":{"Chap_11.html":{},"Chap_11.html#langevin-redux":{}},"title":{}}],["0.9",{"_index":1088,"text":{"Chap_11.html":{},"Chap_11.html#langevin-redux":{}},"title":{}}],["0.97",{"_index":2953,"text":{"Chap_7.html":{},"Chap_7.html#power-spectral-density":{},"Chap_7.html#power-spectral-density_2":{}},"title":{}}],["0\\\\0&x<0\\end{cas",{"_index":1972,"text":{"Chap_3.html":{},"Chap_3.html#problem-34":{}},"title":{}}],["0\\end{cas",{"_index":1903,"text":{"Chap_3.html":{},"Chap_3.html#problem-31":{}},"title":{}}],["0\\left",{"_index":2960,"text":{"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#expected-value":{},"Chap_7.html#expected-value_1":{}},"title":{}}],["0\\rbrack",{"_index":2467,"text":{"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function_1":{}},"title":{}}],["0^2",{"_index":3088,"text":{"Chap_7.html":{},"Chap_7.html#power-spectral-density_1":{}},"title":{}}],["0}^n",{"_index":3060,"text":{"Chap_7.html":{},"Chap_7.html#expected-value":{}},"title":{}}],["0}^{n",{"_index":833,"text":{"Chap_11.html":{},"Chap_11.html#aspects-of-estimation":{},"Chap_11.html#estimating-the-autocorrelation-function":{},"Chap_11.html#estimating-the-mean":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_11.html#trouble-in-paradise":{},"Chap_12.html":{},"Chap_12.html#spectral-estimation":{},"Chap_12.html#the-periodogram-unbiased":{},"Chap_5.html":{},"Chap_5.html#a-digression":{}},"title":{}}],["1",{"_index":1,"text":{"Chap_1.html":{},"Chap_1.html#enhanced-experience":{},"Chap_1.html#how-to-use-this-ibook":{},"Chap_10.html":{},"Chap_10.html#classic-example-classic-result":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#example-cleaning-up-our-act":{},"Chap_10.html#example-sound-of-distorted-music":{},"Chap_10.html#using-the-least-mean-square-error-criterion":{},"Chap_10.html#why-we-avoid-the-inverse-filter":{},"Chap_11.html":{},"Chap_11.html#aspects-of-estimation":{},"Chap_11.html#estimating-the-autocorrelation-function":{},"Chap_11.html#estimating-the-mean":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_11.html#laboratory-exercise-113":{},"Chap_11.html#langevin-redux":{},"Chap_11.html#problem-117":{},"Chap_11.html#trouble-in-paradise":{},"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#problem-121":{},"Chap_12.html#problem-122":{},"Chap_12.html#spectral-estimation":{},"Chap_12.html#the-periodogram-unbiased":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_12.html#windowed-observations":{},"Chap_13.html":{},"Chap_13.html#appendix-i-mean-square-error-minimization":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_2.html":{},"Chap_2.html#prologue":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_3.html#introduction":{},"Chap_3.html#problem-33":{},"Chap_3.html#the-basics":{},"Chap_4.html":{},"Chap_4.html#cross-covariance":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#example-fair-chance":{},"Chap_4.html#example-is-that-coin-fair":{},"Chap_4.html#laboratory-exercise-41":{},"Chap_4.html#problem-42":{},"Chap_4.html#problem-47":{},"Chap_4.html#the-ergodic-process":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#example-pink-noise":{},"Chap_5.html#fourier-description-of-correlation-functions":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_5.html#problem-55":{},"Chap_5.html#problem-56":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{},"Chap_6.html#problem-61":{},"Chap_6.html#problem-62":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function":{},"Chap_7.html#autocorrelation-function_2":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#descriptive-statistic-variance":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#expected-value":{},"Chap_7.html#expected-value_1":{},"Chap_7.html#from-t-to-n":{},"Chap_7.html#impulse-invariant-sampling":{},"Chap_7.html#power-spectral-density":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#power-spectral-density_2":{},"Chap_7.html#problem-711":{},"Chap_7.html#the-langevin-position-equation":{},"Chap_7.html#the-langevin-velocity-equation":{},"Chap_8.html":{},"Chap_8.html#example-cocktail-party-noise":{},"Chap_8.html#example-filtering-noise":{},"Chap_8.html#example-not-too-noisy":{},"Chap_8.html#problem-81":{},"Chap_8.html#problem-83":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{},"Chap_9.html":{},"Chap_9.html#laboratory-exercise-93":{},"Chap_9.html#problem-91":{},"Chap_9.html#problem-92":{},"Chap_9.html#the-matched-filter":{},"info.html":{},"info.html#cover":{},"info.html#registration":{}},"title":{"Chap_1.html":{}}}],["1&{\\left",{"_index":1333,"text":{"Chap_12.html":{},"Chap_12.html#windowed-observations":{},"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_6.html":{},"Chap_6.html#problem-63":{},"Chap_8.html":{},"Chap_8.html#problem-83":{}},"title":{}}],["1)(1",{"_index":2268,"text":{"Chap_4.html":{},"Chap_4.html#example-is-that-coin-fair":{}},"title":{}}],["1)(p",{"_index":2267,"text":{"Chap_4.html":{},"Chap_4.html#example-is-that-coin-fair":{}},"title":{}}],["1)\\,p(y[k",{"_index":2156,"text":{"Chap_4.html":{},"Chap_4.html#example-dice-money":{}},"title":{}}],["1)^2",{"_index":2274,"text":{"Chap_4.html":{},"Chap_4.html#example-is-that-coin-fair":{}},"title":{}}],["1)^2}(1",{"_index":2272,"text":{"Chap_4.html":{},"Chap_4.html#example-is-that-coin-fair":{}},"title":{}}],["1)^2}(p",{"_index":2271,"text":{"Chap_4.html":{},"Chap_4.html#example-is-that-coin-fair":{}},"title":{}}],["1)}}}}{{1",{"_index":1121,"text":{"Chap_11.html":{},"Chap_11.html#langevin-redux":{}},"title":{}}],["1,2,...,16",{"_index":1402,"text":{"Chap_12.html":{},"Chap_12.html#the-periodogram-what-about-convergence":{}},"title":{}}],["1,2,3,4",{"_index":3597,"text":{"Chap_9.html":{},"Chap_9.html#problem-91":{},"Chap_9.html#problem-92":{}},"title":{}}],["1,y[k",{"_index":2155,"text":{"Chap_4.html":{},"Chap_4.html#example-dice-money":{}},"title":{}}],["1.002",{"_index":2883,"text":{"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small":{}},"title":{}}],["1.024",{"_index":1537,"text":{"Chap_12.html":{},"Chap_12.html#problem-122":{}},"title":{}}],["1.0595\\,{\\rm{hz",{"_index":1573,"text":{"Chap_12.html":{},"Chap_12.html#problem-123":{}},"title":{}}],["1.1",{"_index":162,"text":{"Chap_1.html":{},"Chap_1.html#at-the-movies":{},"Chap_1.html#sound-of-music":{}},"title":{}}],["1.380658",{"_index":3013,"text":{"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{}},"title":{}}],["1.5",{"_index":3329,"text":{"Chap_7.html":{},"Chap_7.html#power-spectral-density_2":{}},"title":{}}],["1/2",{"_index":1482,"text":{"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_4.html":{},"Chap_4.html#example-fair-chance":{},"Chap_4.html#example-is-that-coin-fair":{},"Chap_4.html#problem-47":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function_1":{},"Chap_7.html#power-spectral-density_1":{}},"title":{}}],["1/3",{"_index":1464,"text":{"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{}},"title":{}}],["1/4",{"_index":1539,"text":{"Chap_12.html":{},"Chap_12.html#problem-122":{}},"title":{}}],["1/5",{"_index":2062,"text":{"Chap_4.html":{},"Chap_4.html#example-fair-chance":{}},"title":{}}],["1/\\lambda",{"_index":3055,"text":{"Chap_7.html":{},"Chap_7.html#expected-value":{}},"title":{}}],["1/\\left",{"_index":2430,"text":{"Chap_5.html":{},"Chap_5.html#the-mechanics-of-correlations-redux":{}},"title":{}}],["1/d",{"_index":3537,"text":{"Chap_8.html":{},"Chap_8.html#problem-83":{}},"title":{}}],["1/k",{"_index":1417,"text":{"Chap_12.html":{},"Chap_12.html#the-periodogram-what-about-convergence":{}},"title":{}}],["1/n",{"_index":1009,"text":{"Chap_11.html":{},"Chap_11.html#estimating-the-mean":{}},"title":{}}],["1/{\\sigma",{"_index":3256,"text":{"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{}},"title":{}}],["1/{h_o}(\\omega",{"_index":614,"text":{"Chap_10.html":{},"Chap_10.html#example-sound-of-distorted-music":{},"Chap_10.html#why-we-avoid-the-inverse-filter":{}},"title":{}}],["10",{"_index":267,"text":{"Chap_10.html":{},"Chap_10.html#problem-104":{},"Chap_3.html":{},"Chap_3.html#problem-31":{},"Chap_4.html":{},"Chap_4.html#problem-42":{},"Chap_4.html#problem-47":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function_1":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#how-big-is-big-how-small-is-small":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_8.html":{},"Chap_8.html#example-not-too-noisy":{}},"title":{"Chap_10.html":{}}}],["10.1",{"_index":312,"text":{"Chap_10.html":{},"Chap_10.html#example-sound-of-distorted-music":{},"Chap_10.html#expressing-the-mean-square-error":{},"Chap_10.html#the-restoration-case-noise":{},"Chap_10.html#using-the-least-mean-square-error-criterion":{},"Chap_10.html#what-is-that-least-mean-square-error":{}},"title":{"Chap_10.html#laboratory-exercise-101":{},"Chap_10.html#problem-101":{}}}],["10.10",{"_index":490,"text":{"Chap_10.html":{},"Chap_10.html#as-seen-from-the-fourier-domain":{}},"title":{}}],["10.11",{"_index":494,"text":{"Chap_10.html":{},"Chap_10.html#as-seen-from-the-fourier-domain":{},"Chap_10.html#classic-example-classic-result":{},"Chap_10.html#determining-the-wiener-filter":{}},"title":{}}],["10.12",{"_index":498,"text":{"Chap_10.html":{},"Chap_10.html#problem-102":{},"Chap_10.html#what-is-that-least-mean-square-error":{}},"title":{}}],["10.13",{"_index":506,"text":{"Chap_10.html":{},"Chap_10.html#what-is-that-least-mean-square-error":{}},"title":{}}],["10.14",{"_index":513,"text":{"Chap_10.html":{},"Chap_10.html#what-is-that-least-mean-square-error":{}},"title":{}}],["10.15",{"_index":519,"text":{"Chap_10.html":{},"Chap_10.html#what-is-that-least-mean-square-error":{}},"title":{}}],["10.16",{"_index":526,"text":{"Chap_10.html":{},"Chap_10.html#problem-102":{},"Chap_10.html#what-is-that-least-mean-square-error":{}},"title":{}}],["10.17",{"_index":541,"text":{"Chap_10.html":{},"Chap_10.html#classic-example-classic-result":{}},"title":{}}],["10.18",{"_index":546,"text":{"Chap_10.html":{},"Chap_10.html#classic-example-classic-result":{}},"title":{}}],["10.19",{"_index":552,"text":{"Chap_10.html":{},"Chap_10.html#classic-example-classic-result":{}},"title":{}}],["10.2",{"_index":331,"text":{"Chap_10.html":{},"Chap_10.html#classic-example-classic-result":{},"Chap_10.html#example-sound-of-distorted-music":{},"Chap_10.html#expressing-the-mean-square-error":{},"Chap_10.html#using-the-least-mean-square-error-criterion":{},"Chap_10.html#what-is-that-least-mean-square-error":{}},"title":{"Chap_10.html#laboratory-exercise-102":{},"Chap_10.html#problem-102":{}}}],["10.20",{"_index":553,"text":{"Chap_10.html":{},"Chap_10.html#classic-example-classic-result":{}},"title":{}}],["10.21",{"_index":555,"text":{"Chap_10.html":{},"Chap_10.html#classic-example-classic-result":{}},"title":{}}],["10.22",{"_index":557,"text":{"Chap_10.html":{},"Chap_10.html#classic-example-classic-result":{},"Chap_10.html#determining-the-wiener-filter":{}},"title":{}}],["10.23",{"_index":566,"text":{"Chap_10.html":{},"Chap_10.html#classic-example-classic-result":{}},"title":{}}],["10.24",{"_index":578,"text":{"Chap_10.html":{},"Chap_10.html#classic-example-classic-result":{}},"title":{}}],["10.25",{"_index":690,"text":{"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{}},"title":{}}],["10.26",{"_index":694,"text":{"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{}},"title":{}}],["10.27",{"_index":697,"text":{"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{}},"title":{}}],["10.28",{"_index":701,"text":{"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{}},"title":{}}],["10.29",{"_index":704,"text":{"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{}},"title":{}}],["10.3",{"_index":347,"text":{"Chap_10.html":{},"Chap_10.html#classic-example-classic-result":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#example-cleaning-up-our-act":{},"Chap_10.html#example-sound-of-distorted-music":{},"Chap_10.html#the-more-general-restoration-case-noise-distortion":{},"Chap_10.html#using-the-least-mean-square-error-criterion":{},"Chap_10.html#what-is-that-least-mean-square-error":{},"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{}},"title":{"Chap_10.html#laboratory-exercise-103":{},"Chap_10.html#problem-103":{}}}],["10.30",{"_index":711,"text":{"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{}},"title":{}}],["10.31",{"_index":714,"text":{"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{}},"title":{}}],["10.32",{"_index":719,"text":{"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{}},"title":{}}],["10.33",{"_index":722,"text":{"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{}},"title":{}}],["10.34",{"_index":745,"text":{"Chap_10.html":{},"Chap_10.html#problem-102":{}},"title":{}}],["10.4",{"_index":380,"text":{"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#example-cleaning-up-our-act":{},"Chap_10.html#example-sound-of-distorted-music":{},"Chap_10.html#expressing-the-mean-square-error":{},"Chap_10.html#problem-104":{},"Chap_10.html#what-is-that-least-mean-square-error":{},"Chap_10.html#why-we-avoid-the-inverse-filter":{}},"title":{"Chap_10.html#laboratory-exercise-104":{},"Chap_10.html#problem-104":{}}}],["10.5",{"_index":400,"text":{"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#example-cleaning-up-our-act":{},"Chap_10.html#expressing-the-mean-square-error":{},"Chap_10.html#problem-104":{}},"title":{"Chap_10.html#laboratory-exercise-105":{}}}],["10.6",{"_index":406,"text":{"Chap_10.html":{},"Chap_10.html#correlation-returns":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#problem-104":{}},"title":{}}],["10.7",{"_index":415,"text":{"Chap_10.html":{},"Chap_10.html#correlation-returns":{}},"title":{}}],["10.8",{"_index":426,"text":{"Chap_10.html":{},"Chap_10.html#correlation-returns":{},"Chap_7.html":{},"Chap_7.html#from-t-to-n":{}},"title":{}}],["10.9",{"_index":437,"text":{"Chap_10.html":{},"Chap_10.html#as-seen-from-the-fourier-domain":{},"Chap_10.html#classic-example-classic-result":{},"Chap_10.html#the-wiener-hopf-equation":{},"Chap_10.html#what-is-that-least-mean-square-error":{}},"title":{}}],["100",{"_index":2550,"text":{"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#tethered-particle-motion":{}},"title":{}}],["100{\\sigma",{"_index":3330,"text":{"Chap_7.html":{},"Chap_7.html#power-spectral-density_2":{}},"title":{}}],["1024",{"_index":1391,"text":{"Chap_12.html":{},"Chap_12.html#the-periodogram-what-about-convergence":{}},"title":{}}],["106",{"_index":221,"text":{"Chap_1.html":{},"Chap_1.html#enhanced-experience":{}},"title":{}}],["106a",{"_index":222,"text":{"Chap_1.html":{},"Chap_1.html#enhanced-experience":{}},"title":{}}],["107",{"_index":217,"text":{"Chap_1.html":{},"Chap_1.html#enhanced-experience":{}},"title":{}}],["109",{"_index":2558,"text":{"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{}},"title":{}}],["10:00",{"_index":1172,"text":{"Chap_11.html":{},"Chap_11.html#problem-113":{}},"title":{}}],["10\\,{\\log",{"_index":3450,"text":{"Chap_8.html":{},"Chap_8.html#snr-for-random-signals-in-the-presence-of-noise":{}},"title":{}}],["10\\,{{\\log",{"_index":3458,"text":{"Chap_8.html":{},"Chap_8.html#example-cocktail-party-noise":{},"Chap_8.html#example-not-too-noisy":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{}},"title":{}}],["10^8",{"_index":3246,"text":{"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#power-spectral-density_2":{}},"title":{}}],["10^{10",{"_index":2892,"text":{"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small":{}},"title":{}}],["10^{15}}\\,\\,{\\left",{"_index":3237,"text":{"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{}},"title":{}}],["10{\\omega",{"_index":2905,"text":{"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{}},"title":{}}],["10}^4",{"_index":3462,"text":{"Chap_8.html":{},"Chap_8.html#example-not-too-noisy":{}},"title":{}}],["11",{"_index":810,"text":{"Chap_11.html":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_4.html":{},"Chap_4.html#problem-42":{},"Chap_4.html#the-ergodic-process":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{}},"title":{"Chap_11.html":{}}}],["11.1",{"_index":813,"text":{"Chap_11.html":{},"Chap_11.html#aspects-of-estimation":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_11.html#estimating-the-mean":{},"Chap_11.html#example-estimating-the-poisson-rate":{},"Chap_11.html#trouble-in-paradise":{}},"title":{"Chap_11.html#laboratory-exercise-111":{},"Chap_11.html#problem-111":{}}}],["11.10",{"_index":901,"text":{"Chap_11.html":{},"Chap_11.html#example-estimating-the-poisson-rate":{}},"title":{"Chap_11.html#problem-1110":{}}}],["11.11",{"_index":915,"text":{"Chap_11.html":{},"Chap_11.html#example-estimating-the-poisson-rate":{}},"title":{}}],["11.12",{"_index":921,"text":{"Chap_11.html":{},"Chap_11.html#example-estimating-the-poisson-rate":{}},"title":{}}],["11.13",{"_index":925,"text":{"Chap_11.html":{},"Chap_11.html#example-estimating-the-poisson-rate":{}},"title":{}}],["11.14",{"_index":939,"text":{"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{}},"title":{}}],["11.15",{"_index":943,"text":{"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{}},"title":{}}],["11.16",{"_index":995,"text":{"Chap_11.html":{},"Chap_11.html#estimating-the-autocorrelation-function":{},"Chap_11.html#estimating-the-mean":{}},"title":{}}],["11.17",{"_index":996,"text":{"Chap_11.html":{},"Chap_11.html#estimating-the-mean":{}},"title":{}}],["11.18",{"_index":997,"text":{"Chap_11.html":{},"Chap_11.html#estimating-the-mean":{}},"title":{}}],["11.19",{"_index":999,"text":{"Chap_11.html":{},"Chap_11.html#estimating-the-mean":{}},"title":{}}],["11.2",{"_index":814,"text":{"Chap_11.html":{},"Chap_11.html#aspects-of-estimation":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_11.html#estimating-the-autocorrelation-function":{},"Chap_11.html#example-estimating-the-poisson-rate":{},"Chap_11.html#trouble-in-paradise":{}},"title":{"Chap_11.html#laboratory-exercise-112":{},"Chap_11.html#problem-112":{}}}],["11.20",{"_index":1004,"text":{"Chap_11.html":{},"Chap_11.html#estimating-the-mean":{}},"title":{}}],["11.21",{"_index":1013,"text":{"Chap_11.html":{},"Chap_11.html#estimating-the-autocorrelation-function":{}},"title":{}}],["11.22",{"_index":1025,"text":{"Chap_11.html":{},"Chap_11.html#estimating-the-autocorrelation-function":{},"Chap_11.html#trouble-in-paradise":{}},"title":{}}],["11.23",{"_index":1031,"text":{"Chap_11.html":{},"Chap_11.html#how-good-is-our-estimator":{}},"title":{}}],["11.24",{"_index":1032,"text":{"Chap_11.html":{},"Chap_11.html#how-good-is-our-estimator":{}},"title":{}}],["11.25",{"_index":1035,"text":{"Chap_11.html":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_11.html#problem-119":{}},"title":{}}],["11.26",{"_index":1045,"text":{"Chap_11.html":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_11.html#problem-119":{}},"title":{}}],["11.27",{"_index":1047,"text":{"Chap_11.html":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_11.html#trouble-in-paradise":{}},"title":{}}],["11.28",{"_index":1049,"text":{"Chap_11.html":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_11.html#langevin-redux":{}},"title":{}}],["11.29",{"_index":1053,"text":{"Chap_11.html":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_11.html#trouble-in-paradise":{}},"title":{}}],["11.3",{"_index":816,"text":{"Chap_11.html":{},"Chap_11.html#aspects-of-estimation":{},"Chap_11.html#estimating-the-autocorrelation-function":{},"Chap_11.html#trouble-in-paradise":{}},"title":{"Chap_11.html#laboratory-exercise-113":{},"Chap_11.html#problem-113":{}}}],["11.3.2",{"_index":1385,"text":{"Chap_12.html":{},"Chap_12.html#the-periodogram-what-about-convergence":{}},"title":{}}],["11.30",{"_index":1066,"text":{"Chap_11.html":{},"Chap_11.html#langevin-redux":{}},"title":{}}],["11.31",{"_index":1080,"text":{"Chap_11.html":{},"Chap_11.html#langevin-redux":{},"Chap_11.html#problem-1110":{}},"title":{}}],["11.32",{"_index":1096,"text":{"Chap_11.html":{},"Chap_11.html#langevin-redux":{}},"title":{}}],["11.33",{"_index":1102,"text":{"Chap_11.html":{},"Chap_11.html#langevin-redux":{}},"title":{}}],["11.34",{"_index":1107,"text":{"Chap_11.html":{},"Chap_11.html#langevin-redux":{}},"title":{}}],["11.35",{"_index":1114,"text":{"Chap_11.html":{},"Chap_11.html#langevin-redux":{}},"title":{}}],["11.36",{"_index":1116,"text":{"Chap_11.html":{},"Chap_11.html#langevin-redux":{}},"title":{}}],["11.37",{"_index":1122,"text":{"Chap_11.html":{},"Chap_11.html#langevin-redux":{}},"title":{}}],["11.38",{"_index":1126,"text":{"Chap_11.html":{},"Chap_11.html#langevin-redux":{}},"title":{}}],["11.39",{"_index":1148,"text":{"Chap_11.html":{},"Chap_11.html#trouble-in-paradise":{},"Chap_12.html":{},"Chap_12.html#spectral-estimation":{}},"title":{}}],["11.4",{"_index":829,"text":{"Chap_11.html":{},"Chap_11.html#aspects-of-estimation":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_11.html#langevin-redux":{},"Chap_11.html#problem-117":{}},"title":{"Chap_11.html#problem-114":{}}}],["11.40",{"_index":1153,"text":{"Chap_11.html":{},"Chap_11.html#trouble-in-paradise":{},"Chap_12.html":{},"Chap_12.html#the-periodogram-unbiased":{}},"title":{}}],["11.41",{"_index":1157,"text":{"Chap_11.html":{},"Chap_11.html#trouble-in-paradise":{}},"title":{}}],["11.42",{"_index":1187,"text":{"Chap_11.html":{},"Chap_11.html#problem-115":{},"Chap_11.html#problem-116":{}},"title":{}}],["11.43",{"_index":1192,"text":{"Chap_11.html":{},"Chap_11.html#problem-116":{}},"title":{}}],["11.44",{"_index":1195,"text":{"Chap_11.html":{},"Chap_11.html#problem-116":{},"Chap_11.html#problem-117":{}},"title":{}}],["11.45",{"_index":1203,"text":{"Chap_11.html":{},"Chap_11.html#problem-117":{}},"title":{}}],["11.46",{"_index":1207,"text":{"Chap_11.html":{},"Chap_11.html#problem-117":{}},"title":{}}],["11.47",{"_index":1224,"text":{"Chap_11.html":{},"Chap_11.html#problem-119":{}},"title":{}}],["11.48",{"_index":1235,"text":{"Chap_11.html":{},"Chap_11.html#problem-1110":{}},"title":{}}],["11.5",{"_index":835,"text":{"Chap_11.html":{},"Chap_11.html#aspects-of-estimation":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_11.html#langevin-redux":{}},"title":{"Chap_11.html#problem-115":{}}}],["11.6",{"_index":840,"text":{"Chap_11.html":{},"Chap_11.html#aspects-of-estimation":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_11.html#problem-114":{}},"title":{"Chap_11.html#problem-116":{}}}],["11.7",{"_index":869,"text":{"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_11.html#example-estimating-the-poisson-rate":{},"Chap_11.html#maximum-likelihood-estimation":{}},"title":{"Chap_11.html#problem-117":{}}}],["11.8",{"_index":876,"text":{"Chap_11.html":{},"Chap_11.html#maximum-likelihood-estimation":{}},"title":{"Chap_11.html#problem-118":{}}}],["11.9",{"_index":884,"text":{"Chap_11.html":{},"Chap_11.html#example-estimating-the-poisson-rate":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_11.html#langevin-redux":{},"Chap_11.html#problem-1110":{}},"title":{"Chap_11.html#problem-119":{}}}],["12",{"_index":1274,"text":{"Chap_12.html":{},"Chap_12.html#problem-122":{},"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{}},"title":{"Chap_12.html":{}}}],["12.1",{"_index":1286,"text":{"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#other-windows":{},"Chap_12.html#problem-121":{},"Chap_12.html#spectral-estimation":{},"Chap_12.html#windowed-observations":{}},"title":{"Chap_12.html#laboratory-exercise-121":{},"Chap_12.html#problem-121":{}}}],["12.10",{"_index":1318,"text":{"Chap_12.html":{},"Chap_12.html#windowed-observations":{}},"title":{}}],["12.11",{"_index":1320,"text":{"Chap_12.html":{},"Chap_12.html#windowed-observations":{}},"title":{}}],["12.12",{"_index":1324,"text":{"Chap_12.html":{},"Chap_12.html#windowed-observations":{}},"title":{}}],["12.13",{"_index":1331,"text":{"Chap_12.html":{},"Chap_12.html#windowed-observations":{}},"title":{}}],["12.14",{"_index":1334,"text":{"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#problem-122":{},"Chap_12.html#windowed-observations":{}},"title":{}}],["12.15",{"_index":1336,"text":{"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#windowed-observations":{}},"title":{}}],["12.16",{"_index":1339,"text":{"Chap_12.html":{},"Chap_12.html#windowed-observations":{}},"title":{}}],["12.17",{"_index":1367,"text":{"Chap_12.html":{},"Chap_12.html#problem-121":{},"Chap_12.html#windowed-observations":{}},"title":{}}],["12.18",{"_index":1379,"text":{"Chap_12.html":{},"Chap_12.html#the-periodogram-what-about-convergence":{}},"title":{}}],["12.19",{"_index":1404,"text":{"Chap_12.html":{},"Chap_12.html#the-periodogram-what-about-convergence":{}},"title":{}}],["12.2",{"_index":1292,"text":{"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#other-windows":{},"Chap_12.html#problem-121":{},"Chap_12.html#spectral-estimation":{},"Chap_12.html#the-periodogram-what-about-convergence":{}},"title":{"Chap_12.html#laboratory-exercise-122":{},"Chap_12.html#problem-122":{}}}],["12.20",{"_index":1409,"text":{"Chap_12.html":{},"Chap_12.html#the-periodogram-what-about-convergence":{}},"title":{}}],["12.21",{"_index":1414,"text":{"Chap_12.html":{},"Chap_12.html#the-periodogram-what-about-convergence":{}},"title":{}}],["12.22",{"_index":1416,"text":{"Chap_12.html":{},"Chap_12.html#the-periodogram-what-about-convergence":{}},"title":{}}],["12.23",{"_index":1469,"text":{"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{}},"title":{}}],["12.24",{"_index":1474,"text":{"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{}},"title":{}}],["12.3",{"_index":1295,"text":{"Chap_12.html":{},"Chap_12.html#problem-122":{},"Chap_12.html#spectral-estimation":{},"Chap_12.html#the-periodogram-what-about-convergence":{}},"title":{"Chap_12.html#laboratory-exercise-123":{},"Chap_12.html#problem-123":{}}}],["12.4",{"_index":1299,"text":{"Chap_12.html":{},"Chap_12.html#problem-121":{},"Chap_12.html#problem-122":{},"Chap_12.html#the-periodogram-unbiased":{},"Chap_4.html":{},"Chap_4.html#the-mechanics-of-correlations":{}},"title":{"Chap_12.html#laboratory-exercise-124":{}}}],["12.5",{"_index":1302,"text":{"Chap_12.html":{},"Chap_12.html#problem-122":{},"Chap_12.html#the-periodogram-unbiased":{},"Chap_4.html":{},"Chap_4.html#the-mechanics-of-correlations":{}},"title":{}}],["12.6",{"_index":1305,"text":{"Chap_12.html":{},"Chap_12.html#problem-123":{},"Chap_12.html#the-periodogram-unbiased":{},"Chap_12.html#windowed-observations":{}},"title":{}}],["12.7",{"_index":1312,"text":{"Chap_12.html":{},"Chap_12.html#the-periodogram-unbiased":{}},"title":{}}],["12.8",{"_index":1314,"text":{"Chap_12.html":{},"Chap_12.html#the-periodogram-unbiased":{},"Chap_12.html#windowed-observations":{}},"title":{}}],["12.9",{"_index":1309,"text":{"Chap_12.html":{},"Chap_12.html#the-periodogram-unbiased":{}},"title":{}}],["128",{"_index":1400,"text":{"Chap_12.html":{},"Chap_12.html#the-periodogram-what-about-convergence":{}},"title":{}}],["12\\co",{"_index":2779,"text":{"Chap_6.html":{},"Chap_6.html#problem-64":{}},"title":{}}],["13",{"_index":1532,"text":{"Chap_12.html":{},"Chap_12.html#problem-122":{}},"title":{}}],["13.1",{"_index":1595,"text":{"Chap_13.html":{},"Chap_13.html#appendix-i-mean-square-error-minimization":{}},"title":{}}],["13.10",{"_index":1642,"text":{"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{}},"title":{}}],["13.11",{"_index":1648,"text":{"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{}},"title":{}}],["13.12",{"_index":1650,"text":{"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{}},"title":{}}],["13.13",{"_index":1656,"text":{"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{}},"title":{}}],["13.14",{"_index":1673,"text":{"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{}},"title":{}}],["13.15",{"_index":1683,"text":{"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{}},"title":{}}],["13.16",{"_index":1686,"text":{"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{}},"title":{}}],["13.17",{"_index":1690,"text":{"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{}},"title":{}}],["13.18",{"_index":1691,"text":{"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{}},"title":{}}],["13.19",{"_index":1696,"text":{"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{}},"title":{}}],["13.2",{"_index":1601,"text":{"Chap_13.html":{},"Chap_13.html#appendix-i-mean-square-error-minimization":{}},"title":{}}],["13.20",{"_index":1701,"text":{"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{}},"title":{}}],["13.21",{"_index":1703,"text":{"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{}},"title":{}}],["13.3",{"_index":398,"text":{"Chap_10.html":{},"Chap_10.html#expressing-the-mean-square-error":{},"Chap_10.html#problem-101":{},"Chap_13.html":{},"Chap_13.html#appendix-i-mean-square-error-minimization":{}},"title":{}}],["13.4",{"_index":1621,"text":{"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#problem-79":{}},"title":{}}],["13.5",{"_index":1624,"text":{"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{}},"title":{}}],["13.6",{"_index":1625,"text":{"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{}},"title":{}}],["13.7",{"_index":1630,"text":{"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{}},"title":{}}],["13.8",{"_index":1631,"text":{"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{}},"title":{}}],["13.81",{"_index":2315,"text":{"Chap_4.html":{},"Chap_4.html#problem-42":{}},"title":{}}],["13.9",{"_index":1634,"text":{"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{}},"title":{}}],["15.2",{"_index":2100,"text":{"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{}},"title":{}}],["15.5",{"_index":2861,"text":{"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small":{}},"title":{}}],["150",{"_index":3515,"text":{"Chap_8.html":{},"Chap_8.html#problem-82":{}},"title":{}}],["15\\frac{1}{6",{"_index":2143,"text":{"Chap_4.html":{},"Chap_4.html#example-dice-money":{}},"title":{}}],["16",{"_index":1387,"text":{"Chap_12.html":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_4.html":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{}},"title":{}}],["16384",{"_index":1393,"text":{"Chap_12.html":{},"Chap_12.html#the-periodogram-what-about-convergence":{}},"title":{}}],["1660",{"_index":3156,"text":{"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#tethered-particle-motion":{}},"title":{}}],["17",{"_index":3412,"text":{"Chap_7.html":{},"Chap_7.html#problem-711":{}},"title":{}}],["18",{"_index":2097,"text":{"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{}},"title":{}}],["18.1",{"_index":1273,"text":{"Chap_11.html":{},"Chap_11.html#laboratory-exercise-113":{}},"title":{}}],["18.13",{"_index":3487,"text":{"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{}},"title":{}}],["180",{"_index":2187,"text":{"Chap_4.html":{},"Chap_4.html#correlation-the-workhorse":{}},"title":{}}],["188.9",{"_index":2886,"text":{"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small":{}},"title":{}}],["1889",{"_index":1777,"text":{"Chap_2.html":{},"Chap_2.html#prologue":{}},"title":{}}],["1894",{"_index":484,"text":{"Chap_10.html":{},"Chap_10.html#the-wiener-hopf-equation":{}},"title":{}}],["19",{"_index":2098,"text":{"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{}},"title":{}}],["19.29",{"_index":2319,"text":{"Chap_4.html":{},"Chap_4.html#problem-42":{}},"title":{}}],["1901",{"_index":2540,"text":{"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"info.html":{},"info.html#cover":{}},"title":{}}],["1902",{"_index":2544,"text":{"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{}},"title":{}}],["1908",{"_index":2789,"text":{"Chap_7.html":{},"Chap_7.html#the-langevin-equation-a-case-study":{}},"title":{}}],["1924",{"_index":3545,"text":{"Chap_8.html":{},"Chap_8.html#problem-83":{}},"title":{}}],["19409",{"_index":3269,"text":{"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period_1":{}},"title":{}}],["1944",{"_index":176,"text":{"Chap_1.html":{},"Chap_1.html#at-the-movies":{}},"title":{}}],["1946",{"_index":1255,"text":{"Chap_11.html":{},"Chap_11.html#laboratory-exercise-113":{},"Chap_3.html":{},"Chap_3.html#problem-310":{},"Chap_4.html":{},"Chap_4.html#laboratory-exercise-42":{}},"title":{}}],["1956",{"_index":2206,"text":{"Chap_4.html":{},"Chap_4.html#the-mechanics-of-correlations":{}},"title":{}}],["1960",{"_index":785,"text":{"Chap_10.html":{},"Chap_10.html#laboratory-exercise-105":{},"Chap_13.html":{},"Chap_13.html#epilogue":{},"Chap_8.html":{},"Chap_8.html#problem-83":{}},"title":{}}],["1963",{"_index":2372,"text":{"Chap_4.html":{},"Chap_4.html#laboratory-exercise-42":{},"Chap_7.html":{},"Chap_7.html#problem-711":{}},"title":{}}],["1964",{"_index":485,"text":{"Chap_10.html":{},"Chap_10.html#the-wiener-hopf-equation":{}},"title":{}}],["1965",{"_index":2607,"text":{"Chap_5.html":{},"Chap_5.html#laboratory-exercise-51":{},"Chap_7.html":{},"Chap_7.html#problem-711":{},"Chap_9.html":{},"Chap_9.html#laboratory-exercise-93":{}},"title":{}}],["1976",{"_index":1778,"text":{"Chap_2.html":{},"Chap_2.html#prologue":{}},"title":{}}],["1977",{"_index":791,"text":{"Chap_10.html":{},"Chap_10.html#laboratory-exercise-105":{},"Chap_13.html":{},"Chap_13.html#epilogue":{}},"title":{}}],["1980\u2019",{"_index":3681,"text":{"info.html":{},"info.html#acknowledgments":{}},"title":{}}],["1983",{"_index":3391,"text":{"Chap_7.html":{},"Chap_7.html#problem-711":{}},"title":{}}],["1984",{"_index":3720,"text":{"info.html":{},"info.html#copyright":{}},"title":{}}],["1990",{"_index":2728,"text":{"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{}},"title":{}}],["1990\u2019",{"_index":3682,"text":{"info.html":{},"info.html#acknowledgments":{}},"title":{}}],["1992",{"_index":1732,"text":{"Chap_13.html":{},"Chap_13.html#epilogue":{}},"title":{}}],["1994",{"_index":2382,"text":{"Chap_4.html":{},"Chap_4.html#laboratory-exercise-42":{},"Chap_5.html":{},"Chap_5.html#laboratory-exercise-51":{}},"title":{}}],["1996",{"_index":778,"text":{"Chap_10.html":{},"Chap_10.html#laboratory-exercise-105":{},"Chap_3.html":{},"Chap_3.html#problem-310":{},"Chap_5.html":{},"Chap_5.html#laboratory-exercise-51":{},"Chap_7.html":{},"Chap_7.html#problem-711":{}},"title":{}}],["1998",{"_index":1266,"text":{"Chap_11.html":{},"Chap_11.html#laboratory-exercise-113":{},"Chap_12.html":{},"Chap_12.html#laboratory-exercise-124":{}},"title":{}}],["1999",{"_index":2385,"text":{"Chap_4.html":{},"Chap_4.html#laboratory-exercise-42":{},"Chap_5.html":{},"Chap_5.html#laboratory-exercise-51":{}},"title":{}}],["1\\,{\\rm{v",{"_index":3459,"text":{"Chap_8.html":{},"Chap_8.html#example-not-too-noisy":{}},"title":{}}],["1\\left",{"_index":2121,"text":{"Chap_4.html":{},"Chap_4.html#example-average-experience":{}},"title":{}}],["1^2}\\left",{"_index":2139,"text":{"Chap_4.html":{},"Chap_4.html#example-dice-money":{}},"title":{}}],["1pt",{"_index":1877,"text":{"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_4.html":{},"Chap_4.html#the-ergodic-process":{}},"title":{}}],["1}&{x\\;{\\rm{even}}\\;2,\\;4,\\;6",{"_index":2144,"text":{"Chap_4.html":{},"Chap_4.html#example-dice-money":{}},"title":{}}],["1}&{x\\;{\\rm{odd}}\\;1,\\;3,\\;5",{"_index":2145,"text":{"Chap_4.html":{},"Chap_4.html#example-dice-money":{}},"title":{}}],["1}&{{\\mathop{\\rm",{"_index":2764,"text":{"Chap_6.html":{},"Chap_6.html#problem-61":{}},"title":{}}],["1}(\\omega",{"_index":717,"text":{"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{}},"title":{}}],["1}\\left\\{x(\\omega)\\right",{"_index":1825,"text":{"Chap_3.html":{},"Chap_3.html#the-basics":{}},"title":{}}],["1}^6",{"_index":2119,"text":{"Chap_4.html":{},"Chap_4.html#example-average-experience":{},"Chap_4.html#laboratory-exercise-42":{}},"title":{}}],["1}^k",{"_index":1111,"text":{"Chap_11.html":{},"Chap_11.html#langevin-redux":{},"Chap_12.html":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_7.html":{},"Chap_7.html#problem-72":{}},"title":{}}],["1}^n",{"_index":872,"text":{"Chap_11.html":{},"Chap_11.html#example-estimating-the-poisson-rate":{},"Chap_11.html#maximum-likelihood-estimation":{},"Chap_11.html#problem-117":{}},"title":{}}],["1}}(1",{"_index":3038,"text":{"Chap_7.html":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#the-langevin-position-equation":{}},"title":{}}],["1}}\\;{\\kern",{"_index":2300,"text":{"Chap_4.html":{},"Chap_4.html#the-ergodic-process":{}},"title":{}}],["1}}\\left",{"_index":1688,"text":{"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_4.html":{},"Chap_4.html#example-fair-chance":{},"Chap_5.html":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{}},"title":{}}],["1}}\\sum\\limits_{n",{"_index":2288,"text":{"Chap_4.html":{},"Chap_4.html#describing-the-time-average":{},"Chap_4.html#the-ergodic-process":{},"Chap_5.html":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_6.html":{},"Chap_6.html#filtering-of-stochastic-signals":{}},"title":{}}],["1}}u[n",{"_index":2776,"text":{"Chap_6.html":{},"Chap_6.html#problem-62":{}},"title":{}}],["1}}}}{{1",{"_index":3074,"text":{"Chap_7.html":{},"Chap_7.html#autocorrelation-function_1":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#power-spectral-density_1":{}},"title":{}}],["1\u2014at",{"_index":2454,"text":{"Chap_5.html":{},"Chap_5.html#a-digression":{}},"title":{}}],["1\u2019",{"_index":2065,"text":{"Chap_4.html":{},"Chap_4.html#example-fair-chance":{}},"title":{}}],["2",{"_index":25,"text":{"Chap_1.html":{},"Chap_1.html#enhanced-experience":{},"Chap_1.html#how-to-use-this-ibook":{},"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#example-cleaning-up-our-act":{},"Chap_10.html#problem-104":{},"Chap_10.html#using-the-least-mean-square-error-criterion":{},"Chap_10.html#why-we-avoid-the-inverse-filter":{},"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_11.html#langevin-redux":{},"Chap_11.html#problem-1110":{},"Chap_11.html#problem-112":{},"Chap_11.html#problem-116":{},"Chap_11.html#problem-117":{},"Chap_12.html":{},"Chap_12.html#spectral-estimation":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_12.html#windowed-observations":{},"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_3.html#the-basics":{},"Chap_3.html#what-is-a-random-signal":{},"Chap_4.html":{},"Chap_4.html#cross-covariance":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#example-fair-chance":{},"Chap_4.html#laboratory-exercise-42":{},"Chap_4.html#problem-41":{},"Chap_4.html#problem-42":{},"Chap_4.html#problem-47":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#problem-55":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function":{},"Chap_7.html#autocorrelation-function_1":{},"Chap_7.html#autocorrelation-function_2":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#descriptive-statistic-variance":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#expected-value_1":{},"Chap_7.html#from-t-to-n":{},"Chap_7.html#how-big-is-big-how-small-is-small":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#power-spectral-density":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#power-spectral-density_2":{},"Chap_7.html#the-langevin-position-equation":{},"Chap_7.html#why-this-case-study":{},"Chap_8.html":{},"Chap_8.html#example-cocktail-party-noise":{},"Chap_8.html#example-filtering-noise":{},"Chap_8.html#problem-82":{},"Chap_8.html#problem-83":{},"Chap_9.html":{},"Chap_9.html#using-cauchy-schwartz":{}},"title":{"Chap_2.html":{}}}],["2(\\left",{"_index":1125,"text":{"Chap_11.html":{},"Chap_11.html#langevin-redux":{}},"title":{}}],["2(k",{"_index":1120,"text":{"Chap_11.html":{},"Chap_11.html#langevin-redux":{}},"title":{}}],["2)}}{{{{(2\\lambda",{"_index":3083,"text":{"Chap_7.html":{},"Chap_7.html#power-spectral-density_1":{}},"title":{}}],["2.093",{"_index":1511,"text":{"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{}},"title":{}}],["2.1",{"_index":1794,"text":{"Chap_2.html":{},"Chap_2.html#prologue":{}},"title":{"Chap_2.html#problem-21":{}}}],["2.10",{"_index":2386,"text":{"Chap_4.html":{},"Chap_4.html#laboratory-exercise-42":{},"Chap_5.html":{},"Chap_5.html#laboratory-exercise-51":{}},"title":{}}],["2.121",{"_index":1507,"text":{"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{}},"title":{}}],["2.3.0",{"_index":3740,"text":{"info.html":{},"info.html#version":{}},"title":{}}],["2.5",{"_index":2282,"text":{"Chap_4.html":{},"Chap_4.html#example-is-that-coin-fair":{},"Chap_5.html":{},"Chap_5.html#laboratory-exercise-51":{}},"title":{}}],["2.550",{"_index":1504,"text":{"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{}},"title":{}}],["2.764",{"_index":1498,"text":{"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{}},"title":{}}],["2.837",{"_index":1501,"text":{"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{}},"title":{}}],["2.9",{"_index":2609,"text":{"Chap_5.html":{},"Chap_5.html#laboratory-exercise-51":{}},"title":{}}],["2/3",{"_index":3479,"text":{"Chap_8.html":{},"Chap_8.html#example-cocktail-party-noise":{}},"title":{}}],["2/\\pi",{"_index":954,"text":{"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{}},"title":{}}],["20",{"_index":479,"text":{"Chap_10.html":{},"Chap_10.html#the-wiener-hopf-equation":{},"Chap_2.html":{},"Chap_2.html#prologue":{},"Chap_4.html":{},"Chap_4.html#problem-42":{},"Chap_4.html#the-mechanics-of-correlations":{}},"title":{}}],["20,000",{"_index":2469,"text":{"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function_1":{},"Chap_7.html#power-spectral-density_1":{}},"title":{}}],["200/\\theta",{"_index":2858,"text":{"Chap_7.html":{},"Chap_7.html#impulse-invariant-sampling":{}},"title":{}}],["2002",{"_index":1564,"text":{"Chap_12.html":{},"Chap_12.html#problem-123":{},"Chap_3.html":{},"Chap_3.html#problem-310":{}},"title":{}}],["2003",{"_index":1544,"text":{"Chap_12.html":{},"Chap_12.html#laboratory-exercise-124":{},"Chap_12.html#problem-122":{},"Chap_7.html":{},"Chap_7.html#problem-711":{}},"title":{}}],["2007",{"_index":1248,"text":{"Chap_11.html":{},"Chap_11.html#laboratory-exercise-113":{},"Chap_7.html":{},"Chap_7.html#problem-711":{}},"title":{}}],["2009",{"_index":2542,"text":{"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_7.html":{},"Chap_7.html#problem-711":{},"info.html":{},"info.html#cover":{}},"title":{}}],["200\\lambda",{"_index":2908,"text":{"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{}},"title":{}}],["200\\left",{"_index":2857,"text":{"Chap_7.html":{},"Chap_7.html#impulse-invariant-sampling":{}},"title":{}}],["200^2",{"_index":2214,"text":{"Chap_4.html":{},"Chap_4.html#the-mechanics-of-correlations":{}},"title":{}}],["200{\\omega",{"_index":2918,"text":{"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#power-spectral-density_2":{}},"title":{}}],["2010\u20132021",{"_index":3721,"text":{"info.html":{},"info.html#copyright":{}},"title":{}}],["2013",{"_index":2195,"text":{"Chap_4.html":{},"Chap_4.html#the-mechanics-of-correlations":{}},"title":{}}],["2014",{"_index":2009,"text":{"Chap_3.html":{},"Chap_3.html#problem-310":{},"Chap_4.html":{},"Chap_4.html#the-mechanics-of-correlations":{}},"title":{}}],["2020",{"_index":1731,"text":{"Chap_13.html":{},"Chap_13.html#epilogue":{}},"title":{}}],["2048",{"_index":1399,"text":{"Chap_12.html":{},"Chap_12.html#the-periodogram-what-about-convergence":{}},"title":{}}],["20\\,{\\log",{"_index":3433,"text":{"Chap_8.html":{},"Chap_8.html#snr-for-deterministic-signals-in-the-presence-of-noise":{},"Chap_8.html#snr-for-random-signals-in-the-presence-of-noise":{}},"title":{}}],["20\\,{{\\log",{"_index":3501,"text":{"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{}},"title":{}}],["20\\lambda",{"_index":2906,"text":{"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{}},"title":{}}],["20th",{"_index":2387,"text":{"Chap_4.html":{},"Chap_4.html#laboratory-exercise-42":{}},"title":{}}],["20{\\omega",{"_index":3259,"text":{"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period_1":{}},"title":{}}],["20{{\\log",{"_index":3507,"text":{"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{}},"title":{}}],["21",{"_index":2870,"text":{"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{}},"title":{}}],["214",{"_index":2736,"text":{"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{}},"title":{}}],["214th",{"_index":2738,"text":{"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{}},"title":{}}],["23",{"_index":3014,"text":{"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{}},"title":{}}],["2334",{"_index":2913,"text":{"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{}},"title":{}}],["256",{"_index":1390,"text":{"Chap_12.html":{},"Chap_12.html#the-periodogram-what-about-convergence":{}},"title":{}}],["26",{"_index":67,"text":{"Chap_1.html":{},"Chap_1.html#how-to-use-this-ibook":{}},"title":{}}],["26.4",{"_index":2200,"text":{"Chap_4.html":{},"Chap_4.html#the-mechanics-of-correlations":{}},"title":{}}],["283",{"_index":3401,"text":{"Chap_7.html":{},"Chap_7.html#problem-711":{}},"title":{}}],["285",{"_index":3208,"text":{"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{}},"title":{}}],["289",{"_index":2734,"text":{"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{}},"title":{}}],["291",{"_index":3402,"text":{"Chap_7.html":{},"Chap_7.html#problem-711":{}},"title":{}}],["2\\alpha",{"_index":1288,"text":{"Chap_12.html":{},"Chap_12.html#spectral-estimation":{},"Chap_8.html":{},"Chap_8.html#example-cocktail-party-noise":{},"Chap_8.html#example-filtering-noise":{}},"title":{}}],["2\\beta",{"_index":3471,"text":{"Chap_8.html":{},"Chap_8.html#example-cocktail-party-noise":{}},"title":{}}],["2\\int\\limits_0",{"_index":2605,"text":{"Chap_5.html":{},"Chap_5.html#problem-56":{}},"title":{}}],["2\\lambda",{"_index":2903,"text":{"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{}},"title":{}}],["2\\left",{"_index":523,"text":{"Chap_10.html":{},"Chap_10.html#what-is-that-least-mean-square-error":{},"Chap_11.html":{},"Chap_11.html#langevin-redux":{},"Chap_4.html":{},"Chap_4.html#example-average-experience":{}},"title":{}}],["2\\operatorname{r",{"_index":1749,"text":{"Chap_13.html":{},"Chap_13.html#epilogue":{}},"title":{}}],["2\\pi",{"_index":762,"text":{"Chap_10.html":{},"Chap_10.html#problem-104":{},"Chap_11.html":{},"Chap_11.html#problem-112":{},"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#windowed-observations":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_4.html":{},"Chap_4.html#problem-48":{},"Chap_5.html":{},"Chap_5.html#example-pink-noise":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_5.html#problem-56":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#impulse-invariant-sampling":{},"Chap_7.html#power-spectral-density_2":{}},"title":{}}],["2\\rho",{"_index":2947,"text":{"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#power-spectral-density":{},"Chap_7.html#power-spectral-density_1":{}},"title":{}}],["2\\sum\\limits_{k",{"_index":2602,"text":{"Chap_5.html":{},"Chap_5.html#problem-56":{}},"title":{}}],["2\\sum\\limits_{m",{"_index":1055,"text":{"Chap_11.html":{},"Chap_11.html#how-good-is-our-estimator":{}},"title":{}}],["2]\\qquad",{"_index":1932,"text":{"Chap_3.html":{},"Chap_3.html#problem-33":{}},"title":{}}],["2^2}\\left",{"_index":2140,"text":{"Chap_4.html":{},"Chap_4.html#example-dice-money":{}},"title":{}}],["2^{1/12}}\\,\\,{\\rm{hz",{"_index":1572,"text":{"Chap_12.html":{},"Chap_12.html#problem-123":{}},"title":{}}],["2e\\left",{"_index":402,"text":{"Chap_10.html":{},"Chap_10.html#expressing-the-mean-square-error":{},"Chap_10.html#what-is-that-least-mean-square-error":{},"Chap_13.html":{},"Chap_13.html#appendix-i-mean-square-error-minimization":{}},"title":{}}],["2k",{"_index":1104,"text":{"Chap_11.html":{},"Chap_11.html#langevin-redux":{},"Chap_11.html#problem-1110":{}},"title":{}}],["2k\\lambda",{"_index":3347,"text":{"Chap_7.html":{},"Chap_7.html#one-step-further":{}},"title":{}}],["2k}}}_{m",{"_index":1115,"text":{"Chap_11.html":{},"Chap_11.html#langevin-redux":{}},"title":{}}],["2m",{"_index":1100,"text":{"Chap_11.html":{},"Chap_11.html#langevin-redux":{},"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#tethered-particle-motion":{}},"title":{}}],["2n",{"_index":1366,"text":{"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#problem-121":{},"Chap_12.html#windowed-observations":{},"Chap_4.html":{},"Chap_4.html#example-fair-chance":{},"Chap_5.html":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function":{}},"title":{}}],["2p",{"_index":2269,"text":{"Chap_4.html":{},"Chap_4.html#example-is-that-coin-fair":{}},"title":{}}],["2pl",{"_index":3225,"text":{"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{}},"title":{}}],["2{\\left",{"_index":1123,"text":{"Chap_11.html":{},"Chap_11.html#langevin-redux":{}},"title":{}}],["2{\\mathop{\\rm",{"_index":1674,"text":{"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{}},"title":{}}],["2{\\omega",{"_index":2902,"text":{"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{}},"title":{}}],["2{\\rho",{"_index":3323,"text":{"Chap_7.html":{},"Chap_7.html#power-spectral-density_2":{}},"title":{}}],["2{m^2",{"_index":3268,"text":{"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period_1":{}},"title":{}}],["2}(1",{"_index":3084,"text":{"Chap_7.html":{},"Chap_7.html#power-spectral-density_1":{}},"title":{}}],["2}(\\omega",{"_index":3082,"text":{"Chap_7.html":{},"Chap_7.html#power-spectral-density_1":{}},"title":{}}],["2})}^3",{"_index":1083,"text":{"Chap_11.html":{},"Chap_11.html#langevin-redux":{}},"title":{}}],["2})}}{{{{(1",{"_index":1082,"text":{"Chap_11.html":{},"Chap_11.html#langevin-redux":{}},"title":{}}],["2}/2{\\sigma",{"_index":1170,"text":{"Chap_11.html":{},"Chap_11.html#problem-112":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{}},"title":{}}],["2}{{\\csc",{"_index":3081,"text":{"Chap_7.html":{},"Chap_7.html#power-spectral-density_1":{}},"title":{}}],["2}{{\\left",{"_index":1475,"text":{"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{}},"title":{}}],["2}}\\;{\\rm{v",{"_index":3461,"text":{"Chap_8.html":{},"Chap_8.html#example-not-too-noisy":{}},"title":{}}],["2}}}(\\mathop",{"_index":3109,"text":{"Chap_7.html":{},"Chap_7.html#power-spectral-density_1":{}},"title":{}}],["2}}}\\left",{"_index":3072,"text":{"Chap_7.html":{},"Chap_7.html#autocorrelation-function_1":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#problem-77":{}},"title":{}}],["2}}}\\quad",{"_index":1875,"text":{"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{}},"title":{}}],["2}}}n",{"_index":3377,"text":{"Chap_7.html":{},"Chap_7.html#problem-77":{}},"title":{}}],["2}}}{\\rho",{"_index":1074,"text":{"Chap_11.html":{},"Chap_11.html#langevin-redux":{}},"title":{}}],["2}}}{{1",{"_index":3090,"text":{"Chap_7.html":{},"Chap_7.html#power-spectral-density_1":{},"Chap_8.html":{},"Chap_8.html#example-cocktail-party-noise":{}},"title":{}}],["2}}}{{2{m^2",{"_index":3264,"text":{"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period_1":{}},"title":{}}],["3",{"_index":134,"text":{"Chap_1.html":{},"Chap_1.html#enhanced-experience":{},"Chap_1.html#getting-around":{},"Chap_10.html":{},"Chap_10.html#laboratory-exercise-105":{},"Chap_10.html#using-the-least-mean-square-error-criterion":{},"Chap_10.html#what-is-that-least-mean-square-error":{},"Chap_11.html":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_12.html":{},"Chap_12.html#problem-122":{},"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_3.html#the-basics":{},"Chap_3.html#what-is-a-random-signal":{},"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#example-fair-chance":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#from-t-to-n":{},"Chap_7.html#tethered-particle-motion":{}},"title":{"Chap_3.html":{}}}],["3(031795",{"_index":3411,"text":{"Chap_7.html":{},"Chap_7.html#problem-711":{}},"title":{}}],["3.1",{"_index":1809,"text":{"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_3.html#introduction":{},"Chap_3.html#the-basics":{},"Chap_6.html":{},"Chap_6.html#interpretation-of-the-convolution-result":{}},"title":{"Chap_3.html#problem-31":{}}}],["3.10",{"_index":2008,"text":{"Chap_3.html":{}},"title":{"Chap_3.html#problem-310":{}}}],["3.2",{"_index":1811,"text":{"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_3.html#introduction":{}},"title":{"Chap_3.html#problem-32":{}}}],["3.253",{"_index":1492,"text":{"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{}},"title":{}}],["3.3",{"_index":1815,"text":{"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_3.html#the-basics":{},"Chap_6.html":{},"Chap_6.html#the-mean":{}},"title":{"Chap_3.html#problem-33":{}}}],["3.4",{"_index":1835,"text":{"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_3.html#what-is-a-random-signal":{},"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{}},"title":{"Chap_3.html#problem-34":{}}}],["3.401",{"_index":1495,"text":{"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{}},"title":{}}],["3.4c",{"_index":3503,"text":{"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{}},"title":{}}],["3.5",{"_index":1848,"text":{"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_3.html#problem-36":{}},"title":{"Chap_3.html#problem-35":{}}}],["3.6",{"_index":1860,"text":{"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_3.html#problem-36":{}},"title":{"Chap_3.html#problem-36":{}}}],["3.7",{"_index":1874,"text":{"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_3.html#problem-310":{},"Chap_3.html#problem-35":{}},"title":{"Chap_3.html#problem-37":{}}}],["3.739",{"_index":1489,"text":{"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{}},"title":{}}],["3.8",{"_index":868,"text":{"Chap_11.html":{},"Chap_11.html#maximum-likelihood-estimation":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{}},"title":{"Chap_3.html#problem-38":{}}}],["3.9",{"_index":2000,"text":{"Chap_3.html":{}},"title":{"Chap_3.html#problem-39":{}}}],["3/7",{"_index":2064,"text":{"Chap_4.html":{},"Chap_4.html#example-fair-chance":{}},"title":{}}],["30",{"_index":2730,"text":{"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{}},"title":{}}],["3089",{"_index":3270,"text":{"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period_1":{}},"title":{}}],["31",{"_index":1851,"text":{"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"info.html":{},"info.html#cover":{}},"title":{}}],["32",{"_index":79,"text":{"Chap_1.html":{},"Chap_1.html#how-to-use-this-ibook":{},"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{},"info.html":{},"info.html#tips-short-cuts":{}},"title":{}}],["324",{"_index":3271,"text":{"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#power-spectral-density_2":{},"Chap_7.html#problem-79":{}},"title":{}}],["327",{"_index":2608,"text":{"Chap_5.html":{},"Chap_5.html#laboratory-exercise-51":{}},"title":{}}],["327.36",{"_index":2202,"text":{"Chap_4.html":{},"Chap_4.html#the-mechanics-of-correlations":{}},"title":{}}],["365.242",{"_index":2578,"text":{"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{}},"title":{}}],["365.248",{"_index":2561,"text":{"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{}},"title":{}}],["37",{"_index":957,"text":{"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{}},"title":{}}],["371",{"_index":2915,"text":{"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{}},"title":{}}],["39,447",{"_index":2546,"text":{"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{}},"title":{}}],["39,812",{"_index":2543,"text":{"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{}},"title":{}}],["39812/109",{"_index":2560,"text":{"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{}},"title":{}}],["3\\delta",{"_index":2772,"text":{"Chap_6.html":{},"Chap_6.html#problem-62":{}},"title":{}}],["3^2}\\left",{"_index":2141,"text":{"Chap_4.html":{},"Chap_4.html#example-dice-money":{}},"title":{}}],["4",{"_index":188,"text":{"Chap_1.html":{},"Chap_1.html#at-the-movies":{},"Chap_1.html#enhanced-experience":{},"Chap_10.html":{},"Chap_10.html#example-sound-of-distorted-music":{},"Chap_11.html":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_11.html#maximum-likelihood-estimation":{},"Chap_12.html":{},"Chap_12.html#problem-122":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_13.html":{},"Chap_13.html#epilogue":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_5.html":{},"Chap_5.html#correlations-and-spectra":{},"Chap_5.html#example-white-noise":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#expected-value":{},"Chap_7.html#how-big-is-big-how-small-is-small":{},"Chap_7.html#problem-711":{},"Chap_9.html":{},"Chap_9.html#problem-92":{},"info.html":{},"info.html#registration":{}},"title":{"Chap_4.html":{}}}],["4.1",{"_index":1853,"text":{"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#example-fair-chance":{}},"title":{"Chap_4.html#laboratory-exercise-41":{},"Chap_4.html#problem-41":{}}}],["4.10",{"_index":2146,"text":{"Chap_4.html":{},"Chap_4.html#example-dice-money":{}},"title":{}}],["4.11",{"_index":2149,"text":{"Chap_4.html":{},"Chap_4.html#cross-correlation":{},"Chap_4.html#example-dice-money":{}},"title":{}}],["4.12",{"_index":2152,"text":{"Chap_4.html":{},"Chap_4.html#example-dice-money":{}},"title":{}}],["4.13",{"_index":430,"text":{"Chap_10.html":{},"Chap_10.html#correlation-returns":{},"Chap_13.html":{},"Chap_13.html#appendix-i-mean-square-error-minimization":{},"Chap_4.html":{},"Chap_4.html#problem-43":{},"Chap_4.html#problem-44":{},"Chap_4.html#properties-of-averaging":{},"Chap_6.html":{},"Chap_6.html#interpretation-of-the-convolution-result":{},"Chap_6.html#the-mean":{}},"title":{}}],["4.14",{"_index":1609,"text":{"Chap_13.html":{},"Chap_13.html#appendix-i-mean-square-error-minimization":{},"Chap_4.html":{},"Chap_4.html#problem-44":{},"Chap_4.html#properties-of-averaging":{},"Chap_6.html":{},"Chap_6.html#interpretation-of-the-convolution-result":{}},"title":{}}],["4.15",{"_index":2165,"text":{"Chap_4.html":{},"Chap_4.html#problem-43":{},"Chap_4.html#problem-44":{},"Chap_4.html#properties-of-averaging":{}},"title":{}}],["4.16",{"_index":2168,"text":{"Chap_4.html":{},"Chap_4.html#properties-of-averaging":{}},"title":{}}],["4.17",{"_index":2179,"text":{"Chap_4.html":{},"Chap_4.html#properties-of-averaging":{}},"title":{}}],["4.18",{"_index":1190,"text":{"Chap_11.html":{},"Chap_11.html#problem-116":{},"Chap_4.html":{},"Chap_4.html#properties-of-averaging":{}},"title":{}}],["4.19",{"_index":2188,"text":{"Chap_4.html":{},"Chap_4.html#autocorrelation":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_5.html":{},"Chap_5.html#correlations-simple-and-complex":{}},"title":{}}],["4.2",{"_index":2080,"text":{"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#example-dice-money":{},"Chap_4.html#properties-of-averaging":{}},"title":{"Chap_4.html#laboratory-exercise-42":{},"Chap_4.html#problem-42":{}}}],["4.20",{"_index":2243,"text":{"Chap_4.html":{},"Chap_4.html#auto-covariance":{},"Chap_4.html#problem-46":{}},"title":{}}],["4.21",{"_index":2248,"text":{"Chap_4.html":{},"Chap_4.html#cross-correlation":{},"Chap_5.html":{},"Chap_5.html#correlations-simple-and-complex":{}},"title":{}}],["4.22",{"_index":2253,"text":{"Chap_4.html":{},"Chap_4.html#cross-covariance":{}},"title":{}}],["4.23",{"_index":2258,"text":{"Chap_4.html":{},"Chap_4.html#cross-covariance":{}},"title":{}}],["4.24",{"_index":2261,"text":{"Chap_4.html":{},"Chap_4.html#cross-covariance":{},"Chap_5.html":{},"Chap_5.html#the-mechanics-of-correlations-redux":{}},"title":{}}],["4.25",{"_index":2266,"text":{"Chap_4.html":{},"Chap_4.html#example-is-that-coin-fair":{}},"title":{}}],["4.26",{"_index":2270,"text":{"Chap_4.html":{},"Chap_4.html#example-is-that-coin-fair":{}},"title":{}}],["4.27",{"_index":2273,"text":{"Chap_4.html":{},"Chap_4.html#example-is-that-coin-fair":{}},"title":{}}],["4.28",{"_index":2276,"text":{"Chap_4.html":{},"Chap_4.html#example-is-that-coin-fair":{}},"title":{}}],["4.29",{"_index":2284,"text":{"Chap_4.html":{},"Chap_4.html#describing-the-time-average":{}},"title":{}}],["4.3",{"_index":2087,"text":{"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#properties-of-averaging":{}},"title":{"Chap_4.html#problem-43":{}}}],["4.30",{"_index":2289,"text":{"Chap_4.html":{},"Chap_4.html#describing-the-time-average":{},"Chap_5.html":{},"Chap_5.html#the-mechanics-of-correlations-redux":{}},"title":{}}],["4.31",{"_index":2295,"text":{"Chap_4.html":{},"Chap_4.html#describing-the-time-average":{},"Chap_4.html#the-ergodic-process":{}},"title":{}}],["4.32",{"_index":2296,"text":{"Chap_4.html":{},"Chap_4.html#describing-the-time-average":{},"Chap_4.html#the-ergodic-process":{}},"title":{}}],["4.33",{"_index":2299,"text":{"Chap_4.html":{},"Chap_4.html#the-ergodic-process":{}},"title":{}}],["4.34",{"_index":2301,"text":{"Chap_4.html":{},"Chap_4.html#the-ergodic-process":{},"Chap_5.html":{},"Chap_5.html#the-mechanics-of-correlations-redux":{}},"title":{}}],["4.4",{"_index":1198,"text":{"Chap_11.html":{},"Chap_11.html#problem-116":{},"Chap_4.html":{},"Chap_4.html#example-average-experience":{},"Chap_4.html#example-dice-money":{}},"title":{"Chap_4.html#problem-44":{}}}],["4.5",{"_index":2126,"text":{"Chap_4.html":{},"Chap_4.html#other-averages":{}},"title":{"Chap_4.html#problem-45":{}}}],["4.6",{"_index":2129,"text":{"Chap_4.html":{},"Chap_4.html#auto-covariance":{},"Chap_4.html#other-averages":{}},"title":{"Chap_4.html#problem-46":{}}}],["4.7",{"_index":2132,"text":{"Chap_4.html":{},"Chap_4.html#example-is-that-coin-fair":{},"Chap_4.html#other-averages":{}},"title":{"Chap_4.html#problem-47":{}}}],["4.8",{"_index":2138,"text":{"Chap_4.html":{},"Chap_4.html#example-dice-money":{}},"title":{"Chap_4.html#problem-48":{}}}],["4.9",{"_index":1202,"text":{"Chap_11.html":{},"Chap_11.html#problem-117":{},"Chap_4.html":{},"Chap_4.html#example-dice-money":{}},"title":{"Chap_4.html#problem-49":{}}}],["4/7",{"_index":1284,"text":{"Chap_12.html":{},"Chap_12.html#spectral-estimation":{},"Chap_8.html":{},"Chap_8.html#example-cocktail-party-noise":{}},"title":{}}],["40",{"_index":2565,"text":{"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#one-step-further":{},"Chap_7.html#tethered-particle-motion":{},"Chap_9.html":{},"Chap_9.html#performance-in-the-presence-of-noise":{}},"title":{}}],["40,000",{"_index":2215,"text":{"Chap_4.html":{},"Chap_4.html#the-mechanics-of-correlations":{}},"title":{}}],["400",{"_index":2612,"text":{"Chap_5.html":{},"Chap_5.html#laboratory-exercise-51":{}},"title":{}}],["4096",{"_index":1392,"text":{"Chap_12.html":{},"Chap_12.html#the-periodogram-what-about-convergence":{}},"title":{}}],["40\\;{\\rm{db",{"_index":3463,"text":{"Chap_8.html":{},"Chap_8.html#example-not-too-noisy":{}},"title":{}}],["42",{"_index":1517,"text":{"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{}},"title":{}}],["420",{"_index":2224,"text":{"Chap_4.html":{},"Chap_4.html#the-mechanics-of-correlations":{}},"title":{}}],["428",{"_index":2888,"text":{"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small":{}},"title":{}}],["428\\mu",{"_index":3104,"text":{"Chap_7.html":{},"Chap_7.html#power-spectral-density_1":{}},"title":{}}],["44.1",{"_index":754,"text":{"Chap_10.html":{},"Chap_10.html#problem-104":{},"Chap_12.html":{},"Chap_12.html#problem-122":{}},"title":{}}],["440",{"_index":1571,"text":{"Chap_12.html":{},"Chap_12.html#problem-123":{}},"title":{}}],["466.2\\,{\\rm{hz",{"_index":1574,"text":{"Chap_12.html":{},"Chap_12.html#problem-123":{}},"title":{}}],["4882",{"_index":3204,"text":{"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{}},"title":{}}],["49(3",{"_index":3400,"text":{"Chap_7.html":{},"Chap_7.html#problem-711":{}},"title":{}}],["49.4",{"_index":2589,"text":{"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{}},"title":{}}],["4\\co",{"_index":2537,"text":{"Chap_5.html":{},"Chap_5.html#example-pink-noise":{}},"title":{}}],["4\\left",{"_index":1684,"text":{"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{}},"title":{}}],["4km",{"_index":3250,"text":{"Chap_7.html":{},"Chap_7.html#autocorrelation-function_2":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#descriptive-statistic-variance":{},"Chap_7.html#expected-value_1":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#power-spectral-density_2":{}},"title":{}}],["4km{\\lambda",{"_index":3267,"text":{"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period_1":{}},"title":{}}],["4p(1",{"_index":2275,"text":{"Chap_4.html":{},"Chap_4.html#example-is-that-coin-fair":{}},"title":{}}],["4}\\left",{"_index":1380,"text":{"Chap_12.html":{},"Chap_12.html#the-periodogram-what-about-convergence":{}},"title":{}}],["5",{"_index":1051,"text":{"Chap_11.html":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_11.html#langevin-redux":{},"Chap_11.html#problem-117":{},"Chap_12.html":{},"Chap_12.html#problem-122":{},"Chap_12.html#spectral-estimation":{},"Chap_2.html":{},"Chap_2.html#prologue":{},"Chap_3.html":{},"Chap_3.html#problem-39":{},"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#example-dice-money":{},"Chap_4.html#the-ergodic-process":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#example-white-noise":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function_1":{},"Chap_7.html#expected-value":{},"Chap_7.html#how-big-is-big-how-small-is-small":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#tethered-particle-motion":{}},"title":{"Chap_5.html":{}}}],["5.1",{"_index":2389,"text":{"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#correlations-simple-and-complex":{}},"title":{"Chap_5.html#laboratory-exercise-51":{},"Chap_5.html#problem-51":{}}}],["5.1.3",{"_index":2439,"text":{"Chap_5.html":{},"Chap_5.html#fourier-description-of-correlation-functions":{}},"title":{}}],["5.10",{"_index":2421,"text":{"Chap_5.html":{},"Chap_5.html#correlations-and-memory":{}},"title":{}}],["5.11",{"_index":2427,"text":{"Chap_5.html":{},"Chap_5.html#the-mechanics-of-correlations-redux":{}},"title":{}}],["5.12",{"_index":2429,"text":{"Chap_5.html":{},"Chap_5.html#the-mechanics-of-correlations-redux":{}},"title":{}}],["5.13",{"_index":2434,"text":{"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{}},"title":{}}],["5.14",{"_index":2443,"text":{"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function_1":{}},"title":{}}],["5.15",{"_index":2449,"text":{"Chap_5.html":{},"Chap_5.html#a-digression":{}},"title":{}}],["5.16",{"_index":2450,"text":{"Chap_5.html":{},"Chap_5.html#a-digression":{}},"title":{}}],["5.17",{"_index":2459,"text":{"Chap_5.html":{},"Chap_5.html#a-digression":{}},"title":{}}],["5.18",{"_index":2462,"text":{"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#power-spectral-density_2":{}},"title":{}}],["5.19",{"_index":2464,"text":{"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function":{},"Chap_7.html#autocorrelation-function_1":{}},"title":{}}],["5.2",{"_index":2394,"text":{"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#correlations-and-memory":{},"Chap_5.html#correlations-simple-and-complex":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function_1":{},"Chap_7.html#the-langevin-velocity-equation":{},"Chap_8.html":{},"Chap_8.html#snr-for-random-signals-in-the-presence-of-noise":{}},"title":{"Chap_5.html#problem-52":{}}}],["5.20",{"_index":2479,"text":{"Chap_5.html":{},"Chap_5.html#a-digression":{}},"title":{}}],["5.21",{"_index":2486,"text":{"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_7.html":{},"Chap_7.html#expected-value":{}},"title":{}}],["5.22",{"_index":2489,"text":{"Chap_5.html":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{}},"title":{}}],["5.23",{"_index":530,"text":{"Chap_10.html":{},"Chap_10.html#what-is-that-least-mean-square-error":{},"Chap_5.html":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{}},"title":{}}],["5.24",{"_index":2493,"text":{"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{}},"title":{}}],["5.25",{"_index":2505,"text":{"Chap_5.html":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{}},"title":{}}],["5.26",{"_index":2506,"text":{"Chap_5.html":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{}},"title":{}}],["5.27",{"_index":2516,"text":{"Chap_5.html":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{}},"title":{}}],["5.28",{"_index":2519,"text":{"Chap_5.html":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{}},"title":{}}],["5.29",{"_index":2520,"text":{"Chap_5.html":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{}},"title":{}}],["5.3",{"_index":2396,"text":{"Chap_5.html":{},"Chap_5.html#correlations-simple-and-complex":{},"Chap_5.html#example-pink-noise":{},"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{}},"title":{"Chap_5.html#problem-53":{}}}],["5.30",{"_index":2522,"text":{"Chap_5.html":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{}},"title":{}}],["5.31",{"_index":2523,"text":{"Chap_5.html":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{}},"title":{}}],["5.32",{"_index":2525,"text":{"Chap_5.html":{},"Chap_5.html#example-white-noise":{},"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{}},"title":{}}],["5.33",{"_index":2527,"text":{"Chap_5.html":{},"Chap_5.html#example-white-noise":{}},"title":{}}],["5.34",{"_index":2530,"text":{"Chap_5.html":{},"Chap_5.html#example-pink-noise":{}},"title":{}}],["5.35",{"_index":2531,"text":{"Chap_5.html":{},"Chap_5.html#example-pink-noise":{}},"title":{}}],["5.36",{"_index":2595,"text":{"Chap_5.html":{},"Chap_5.html#problem-53":{}},"title":{}}],["5.4",{"_index":2399,"text":{"Chap_5.html":{},"Chap_5.html#correlations-simple-and-complex":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_7.html":{},"Chap_7.html#the-langevin-velocity-equation":{}},"title":{"Chap_5.html#problem-54":{}}}],["5.477",{"_index":1509,"text":{"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{}},"title":{}}],["5.5",{"_index":413,"text":{"Chap_10.html":{},"Chap_10.html#correlation-returns":{},"Chap_10.html#the-wiener-hopf-equation":{},"Chap_11.html":{},"Chap_11.html#problem-119":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#correlations-simple-and-complex":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_5.html#problem-51":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{}},"title":{"Chap_5.html#problem-55":{}}}],["5.6",{"_index":414,"text":{"Chap_10.html":{},"Chap_10.html#correlation-returns":{},"Chap_10.html#the-wiener-hopf-equation":{},"Chap_5.html":{},"Chap_5.html#correlations-simple-and-complex":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_5.html#problem-51":{}},"title":{"Chap_5.html#problem-56":{}}}],["5.6a",{"_index":2699,"text":{"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{}},"title":{}}],["5.6b",{"_index":2588,"text":{"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{}},"title":{}}],["5.7",{"_index":2411,"text":{"Chap_5.html":{},"Chap_5.html#example-delayed-effect":{}},"title":{}}],["5.8",{"_index":2417,"text":{"Chap_5.html":{},"Chap_5.html#correlations-and-memory":{},"Chap_5.html#example-pink-noise":{},"Chap_7.html":{},"Chap_7.html#the-langevin-velocity-equation":{}},"title":{}}],["5.9",{"_index":2420,"text":{"Chap_5.html":{},"Chap_5.html#correlations-and-memory":{}},"title":{}}],["5/3",{"_index":2468,"text":{"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function_1":{}},"title":{}}],["50",{"_index":2587,"text":{"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#tethered-particle-motion":{}},"title":{}}],["51",{"_index":2759,"text":{"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{}},"title":{}}],["56\\co",{"_index":1291,"text":{"Chap_12.html":{},"Chap_12.html#spectral-estimation":{}},"title":{}}],["58",{"_index":81,"text":{"Chap_1.html":{},"Chap_1.html#how-to-use-this-ibook":{},"info.html":{},"info.html#tips-short-cuts":{}},"title":{}}],["6",{"_index":2110,"text":{"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#example-is-that-coin-fair":{},"Chap_5.html":{},"Chap_5.html#example-white-noise":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#tethered-particle-motion":{}},"title":{"Chap_6.html":{}}}],["6.1",{"_index":2620,"text":{"Chap_6.html":{},"Chap_6.html#filtering-of-stochastic-signals":{},"Chap_6.html#interpretation-of-the-convolution-result":{},"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{}},"title":{"Chap_6.html#laboratory-exercise-61":{},"Chap_6.html#problem-61":{}}}],["6.10",{"_index":2645,"text":{"Chap_6.html":{},"Chap_6.html#the-autocorrelation-function":{}},"title":{}}],["6.11",{"_index":2651,"text":{"Chap_6.html":{},"Chap_6.html#the-autocorrelation-function":{}},"title":{}}],["6.12",{"_index":2653,"text":{"Chap_6.html":{},"Chap_6.html#the-autocorrelation-function":{}},"title":{}}],["6.13",{"_index":2658,"text":{"Chap_6.html":{},"Chap_6.html#the-autocorrelation-function":{}},"title":{}}],["6.14",{"_index":2659,"text":{"Chap_6.html":{},"Chap_6.html#the-autocorrelation-function":{}},"title":{}}],["6.15",{"_index":2665,"text":{"Chap_6.html":{},"Chap_6.html#the-autocorrelation-function":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function":{},"Chap_7.html#power-spectral-density":{}},"title":{}}],["6.16",{"_index":2667,"text":{"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{}},"title":{}}],["6.17",{"_index":2670,"text":{"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{},"Chap_6.html#the-cross-correlation-function":{}},"title":{}}],["6.18",{"_index":2672,"text":{"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{}},"title":{}}],["6.19",{"_index":2676,"text":{"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{}},"title":{}}],["6.2",{"_index":2621,"text":{"Chap_6.html":{},"Chap_6.html#filtering-of-stochastic-signals":{},"Chap_6.html#the-cross-correlation-function":{}},"title":{"Chap_6.html#laboratory-exercise-62":{},"Chap_6.html#problem-62":{}}}],["6.20",{"_index":2677,"text":{"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{}},"title":{}}],["6.21",{"_index":700,"text":{"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_7.html":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#power-spectral-density_2":{},"Chap_7.html#problem-76":{}},"title":{}}],["6.22",{"_index":693,"text":{"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{}},"title":{}}],["6.23",{"_index":2678,"text":{"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{}},"title":{}}],["6.24",{"_index":2679,"text":{"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{}},"title":{}}],["6.25",{"_index":2680,"text":{"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_9.html":{},"Chap_9.html#setting-up-the-problem":{}},"title":{}}],["6.26",{"_index":2683,"text":{"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{}},"title":{}}],["6.27",{"_index":2687,"text":{"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{}},"title":{}}],["6.28",{"_index":2690,"text":{"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{}},"title":{}}],["6.29",{"_index":2693,"text":{"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{}},"title":{}}],["6.3",{"_index":2622,"text":{"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{},"Chap_6.html#filtering-of-stochastic-signals":{}},"title":{"Chap_6.html#laboratory-exercise-63":{},"Chap_6.html#problem-63":{}}}],["6.30",{"_index":2694,"text":{"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{}},"title":{}}],["6.31",{"_index":2697,"text":{"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{}},"title":{}}],["6.32",{"_index":1052,"text":{"Chap_11.html":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{},"Chap_6.html#problem-66":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_9.html":{},"Chap_9.html#the-matched-filter-as-an-autocorrelation":{}},"title":{}}],["6.33",{"_index":2702,"text":{"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{}},"title":{}}],["6.34",{"_index":2704,"text":{"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{}},"title":{}}],["6.35",{"_index":2706,"text":{"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{}},"title":{}}],["6.36",{"_index":2709,"text":{"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{}},"title":{}}],["6.37",{"_index":2750,"text":{"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{}},"title":{}}],["6.38",{"_index":2754,"text":{"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{}},"title":{}}],["6.39",{"_index":2782,"text":{"Chap_6.html":{},"Chap_6.html#problem-66":{}},"title":{}}],["6.4",{"_index":2624,"text":{"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{},"Chap_6.html#interpretation-of-the-convolution-result":{},"Chap_9.html":{},"Chap_9.html#performance-in-the-presence-of-noise":{}},"title":{"Chap_6.html#laboratory-exercise-64":{},"Chap_6.html#problem-64":{}}}],["6.5",{"_index":2628,"text":{"Chap_6.html":{},"Chap_6.html#interpretation-of-the-convolution-result":{}},"title":{"Chap_6.html#laboratory-exercise-65":{},"Chap_6.html#problem-65":{}}}],["6.5.2",{"_index":3185,"text":{"Chap_7.html":{},"Chap_7.html#tethered-particle-motion":{}},"title":{}}],["6.6",{"_index":2633,"text":{"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_6.html#the-mean":{}},"title":{"Chap_6.html#laboratory-exercise-66":{},"Chap_6.html#problem-66":{}}}],["6.7",{"_index":2634,"text":{"Chap_6.html":{},"Chap_6.html#the-mean":{}},"title":{"Chap_6.html#laboratory-exercise-67":{}}}],["6.8",{"_index":2635,"text":{"Chap_6.html":{},"Chap_6.html#the-mean":{}},"title":{"Chap_6.html#laboratory-exercise-68":{}}}],["6.86",{"_index":3216,"text":{"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{}},"title":{}}],["6.9",{"_index":2639,"text":{"Chap_6.html":{},"Chap_6.html#the-mean":{},"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#expected-value":{},"Chap_7.html#expected-value_1":{}},"title":{}}],["60",{"_index":1578,"text":{"Chap_12.html":{},"Chap_12.html#problem-123":{},"Chap_4.html":{},"Chap_4.html#the-mechanics-of-correlations":{}},"title":{}}],["64",{"_index":1388,"text":{"Chap_12.html":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{}},"title":{}}],["642\\mu",{"_index":3105,"text":{"Chap_7.html":{},"Chap_7.html#power-spectral-density_1":{}},"title":{}}],["6444",{"_index":3419,"text":{"Chap_7.html":{},"Chap_7.html#problem-711":{}},"title":{}}],["6\\left",{"_index":2123,"text":{"Chap_4.html":{},"Chap_4.html#example-average-experience":{}},"title":{}}],["6\\pi",{"_index":2878,"text":{"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#problem-77":{}},"title":{}}],["6^2}\\left",{"_index":2142,"text":{"Chap_4.html":{},"Chap_4.html#example-dice-money":{}},"title":{}}],["7",{"_index":1134,"text":{"Chap_11.html":{},"Chap_11.html#langevin-redux":{},"Chap_11.html#problem-119":{},"Chap_2.html":{},"Chap_2.html#prologue":{},"Chap_4.html":{},"Chap_4.html#example-is-that-coin-fair":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_6.html":{},"Chap_6.html#problem-63":{},"Chap_7.html":{},"Chap_7.html#tethered-particle-motion":{},"Chap_9.html":{},"Chap_9.html#problem-91":{}},"title":{"Chap_7.html":{}}}],["7(2",{"_index":3547,"text":{"Chap_8.html":{},"Chap_8.html#problem-83":{}},"title":{}}],["7.1",{"_index":1140,"text":{"Chap_11.html":{},"Chap_11.html#langevin-redux":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#descriptive-statistic-variance":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#impulse-invariant-sampling":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#problem-71":{},"Chap_7.html#problem-79":{},"Chap_7.html#tethered-particle-motion":{},"Chap_7.html#the-langevin-equation-a-case-study":{}},"title":{"Chap_7.html#problem-71":{}}}],["7.10",{"_index":2930,"text":{"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#one-step-further":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#power-spectral-density_2":{},"Chap_7.html#the-langevin-velocity-equation":{}},"title":{"Chap_7.html#problem-710":{}}}],["7.11",{"_index":2940,"text":{"Chap_7.html":{},"Chap_7.html#autocorrelation-function":{},"Chap_7.html#descriptive-statistic-variance":{},"Chap_7.html#problem-74":{}},"title":{"Chap_7.html#problem-711":{}}}],["7.12",{"_index":2943,"text":{"Chap_7.html":{},"Chap_7.html#autocorrelation-function":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#problem-74":{},"Chap_7.html#problem-75":{}},"title":{}}],["7.13",{"_index":2946,"text":{"Chap_7.html":{},"Chap_7.html#power-spectral-density":{},"Chap_7.html#problem-75":{}},"title":{}}],["7.14",{"_index":1064,"text":{"Chap_11.html":{},"Chap_11.html#langevin-redux":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function_1":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#power-spectral-density":{}},"title":{}}],["7.15",{"_index":2955,"text":{"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{}},"title":{}}],["7.16",{"_index":2957,"text":{"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{}},"title":{}}],["7.17",{"_index":2962,"text":{"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{}},"title":{}}],["7.18",{"_index":2995,"text":{"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{}},"title":{}}],["7.19",{"_index":2998,"text":{"Chap_7.html":{},"Chap_7.html#descriptive-statistic-variance":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#problem-78":{}},"title":{}}],["7.1[a,b",{"_index":2907,"text":{"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{}},"title":{}}],["7.1c",{"_index":2919,"text":{"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{}},"title":{}}],["7.2",{"_index":2822,"text":{"Chap_7.html":{},"Chap_7.html#descriptive-statistic-variance":{},"Chap_7.html#impulse-invariant-sampling":{},"Chap_7.html#one-step-further":{},"Chap_7.html#power-spectral-density":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#tethered-particle-motion":{}},"title":{"Chap_7.html#problem-72":{}}}],["7.20",{"_index":3018,"text":{"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#one-step-further":{}},"title":{}}],["7.21",{"_index":3024,"text":{"Chap_7.html":{},"Chap_7.html#the-langevin-position-equation":{}},"title":{}}],["7.22",{"_index":3028,"text":{"Chap_7.html":{},"Chap_7.html#the-langevin-position-equation":{}},"title":{}}],["7.23",{"_index":3032,"text":{"Chap_7.html":{},"Chap_7.html#expected-value":{},"Chap_7.html#the-langevin-position-equation":{}},"title":{}}],["7.24",{"_index":3039,"text":{"Chap_7.html":{},"Chap_7.html#the-langevin-position-equation":{}},"title":{}}],["7.25",{"_index":3042,"text":{"Chap_7.html":{},"Chap_7.html#expected-value":{}},"title":{}}],["7.26",{"_index":3047,"text":{"Chap_7.html":{},"Chap_7.html#autocorrelation-function_1":{},"Chap_7.html#expected-value":{}},"title":{}}],["7.27",{"_index":3056,"text":{"Chap_7.html":{},"Chap_7.html#expected-value":{},"Chap_7.html#power-spectral-density_1":{}},"title":{}}],["7.28",{"_index":3068,"text":{"Chap_7.html":{},"Chap_7.html#autocorrelation-function_1":{}},"title":{}}],["7.29",{"_index":3069,"text":{"Chap_7.html":{},"Chap_7.html#autocorrelation-function_1":{},"Chap_7.html#autocorrelation-function_2":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#problem-76":{}},"title":{}}],["7.3",{"_index":2829,"text":{"Chap_7.html":{},"Chap_7.html#autocorrelation-function_1":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#how-big-is-big-how-small-is-small":{},"Chap_7.html#impulse-invariant-sampling":{}},"title":{"Chap_7.html#problem-73":{}}}],["7.30",{"_index":3070,"text":{"Chap_7.html":{},"Chap_7.html#autocorrelation-function_1":{},"Chap_7.html#autocorrelation-function_2":{}},"title":{}}],["7.31",{"_index":3077,"text":{"Chap_7.html":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#problem-76":{}},"title":{}}],["7.32",{"_index":3087,"text":{"Chap_7.html":{},"Chap_7.html#descriptive-statistic-variance":{},"Chap_7.html#power-spectral-density_1":{}},"title":{}}],["7.33",{"_index":3094,"text":{"Chap_7.html":{},"Chap_7.html#power-spectral-density_1":{}},"title":{}}],["7.34",{"_index":3096,"text":{"Chap_7.html":{},"Chap_7.html#power-spectral-density_1":{}},"title":{}}],["7.35",{"_index":3100,"text":{"Chap_7.html":{},"Chap_7.html#power-spectral-density_1":{}},"title":{}}],["7.36",{"_index":3118,"text":{"Chap_7.html":{},"Chap_7.html#descriptive-statistic-variance":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#problem-77":{},"Chap_7.html#problem-78":{}},"title":{}}],["7.37",{"_index":3169,"text":{"Chap_7.html":{},"Chap_7.html#problem-710":{},"Chap_7.html#tethered-particle-motion":{}},"title":{}}],["7.38",{"_index":3184,"text":{"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#tethered-particle-motion":{}},"title":{}}],["7.39",{"_index":3188,"text":{"Chap_7.html":{},"Chap_7.html#tethered-particle-motion":{}},"title":{}}],["7.4",{"_index":2835,"text":{"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#impulse-invariant-sampling":{},"Chap_7.html#power-spectral-density_1":{}},"title":{"Chap_7.html#problem-74":{}}}],["7.40",{"_index":3223,"text":{"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#one-step-further":{}},"title":{}}],["7.41",{"_index":3236,"text":{"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#problem-710":{}},"title":{}}],["7.42",{"_index":3249,"text":{"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{}},"title":{}}],["7.43",{"_index":3262,"text":{"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period_1":{}},"title":{}}],["7.44",{"_index":3274,"text":{"Chap_7.html":{},"Chap_7.html#autocorrelation-function_2":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#descriptive-statistic-variance":{},"Chap_7.html#problem-711":{}},"title":{}}],["7.45",{"_index":3287,"text":{"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#power-spectral-density_2":{}},"title":{}}],["7.46",{"_index":3296,"text":{"Chap_7.html":{},"Chap_7.html#expected-value_1":{}},"title":{}}],["7.47",{"_index":3300,"text":{"Chap_7.html":{},"Chap_7.html#autocorrelation-function_2":{}},"title":{}}],["7.48",{"_index":3319,"text":{"Chap_7.html":{},"Chap_7.html#power-spectral-density_2":{}},"title":{}}],["7.49",{"_index":3332,"text":{"Chap_7.html":{},"Chap_7.html#descriptive-statistic-variance":{},"Chap_7.html#problem-711":{}},"title":{}}],["7.5",{"_index":1141,"text":{"Chap_11.html":{},"Chap_11.html#langevin-redux":{},"Chap_7.html":{},"Chap_7.html#impulse-invariant-sampling":{},"Chap_7.html#problem-71":{},"Chap_7.html#tethered-particle-motion":{}},"title":{"Chap_7.html#problem-75":{}}}],["7.50",{"_index":3338,"text":{"Chap_7.html":{},"Chap_7.html#descriptive-statistic-variance":{}},"title":{}}],["7.51",{"_index":3341,"text":{"Chap_7.html":{},"Chap_7.html#descriptive-statistic-variance":{},"Chap_7.html#problem-711":{},"Chap_7.html#problem-78":{}},"title":{}}],["7.52",{"_index":3345,"text":{"Chap_7.html":{},"Chap_7.html#one-step-further":{}},"title":{}}],["7.53",{"_index":3380,"text":{"Chap_7.html":{},"Chap_7.html#problem-77":{}},"title":{}}],["7.55",{"_index":3212,"text":{"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{}},"title":{}}],["7.6",{"_index":2229,"text":{"Chap_4.html":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#problem-79":{}},"title":{"Chap_7.html#problem-76":{}}}],["7.7",{"_index":2896,"text":{"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#power-spectral-density_2":{}},"title":{"Chap_7.html#problem-77":{}}}],["7.8",{"_index":2924,"text":{"Chap_7.html":{},"Chap_7.html#autocorrelation-function":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#power-spectral-density_2":{},"Chap_7.html#the-langevin-velocity-equation":{}},"title":{"Chap_7.html#problem-78":{}}}],["7.9",{"_index":2925,"text":{"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#one-step-further":{},"Chap_7.html#power-spectral-density":{},"Chap_7.html#the-langevin-velocity-equation":{}},"title":{"Chap_7.html#problem-79":{}}}],["750",{"_index":2614,"text":{"Chap_5.html":{},"Chap_5.html#laboratory-exercise-51":{}},"title":{}}],["755",{"_index":3214,"text":{"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#power-spectral-density_2":{}},"title":{}}],["8",{"_index":584,"text":{"Chap_10.html":{},"Chap_10.html#classic-example-classic-result":{},"Chap_11.html":{},"Chap_11.html#example-estimating-the-poisson-rate":{},"Chap_4.html":{},"Chap_4.html#describing-the-time-average":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#problem-711":{}},"title":{"Chap_8.html":{}}}],["8(1",{"_index":1262,"text":{"Chap_11.html":{},"Chap_11.html#laboratory-exercise-113":{}},"title":{}}],["8.1",{"_index":3421,"text":{"Chap_8.html":{},"Chap_8.html#example-cocktail-party-noise":{},"Chap_8.html#example-filtering-noise":{}},"title":{"Chap_8.html#problem-81":{}}}],["8.10",{"_index":1285,"text":{"Chap_12.html":{},"Chap_12.html#spectral-estimation":{},"Chap_8.html":{},"Chap_8.html#example-cocktail-party-noise":{}},"title":{}}],["8.11",{"_index":3470,"text":{"Chap_8.html":{},"Chap_8.html#example-cocktail-party-noise":{}},"title":{}}],["8.12",{"_index":3473,"text":{"Chap_8.html":{},"Chap_8.html#example-cocktail-party-noise":{},"Chap_8.html#problem-81":{}},"title":{}}],["8.13",{"_index":3474,"text":{"Chap_8.html":{},"Chap_8.html#example-cocktail-party-noise":{}},"title":{}}],["8.14",{"_index":3475,"text":{"Chap_8.html":{},"Chap_8.html#example-cocktail-party-noise":{}},"title":{}}],["8.15",{"_index":3495,"text":{"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{}},"title":{}}],["8.16",{"_index":3497,"text":{"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{}},"title":{}}],["8.17",{"_index":3504,"text":{"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{}},"title":{}}],["8.18",{"_index":3512,"text":{"Chap_8.html":{},"Chap_8.html#problem-81":{}},"title":{}}],["8.19",{"_index":3518,"text":{"Chap_8.html":{},"Chap_8.html#problem-82":{}},"title":{}}],["8.2",{"_index":585,"text":{"Chap_10.html":{},"Chap_10.html#classic-example-classic-result":{},"Chap_12.html":{},"Chap_12.html#spectral-estimation":{},"Chap_8.html":{},"Chap_8.html#example-cocktail-party-noise":{},"Chap_8.html#snr-for-deterministic-signals-in-the-presence-of-noise":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{},"Chap_9.html":{},"Chap_9.html#setting-up-the-problem":{}},"title":{"Chap_8.html#problem-82":{}}}],["8.20",{"_index":3533,"text":{"Chap_8.html":{},"Chap_8.html#problem-83":{}},"title":{}}],["8.21",{"_index":3534,"text":{"Chap_8.html":{},"Chap_8.html#problem-83":{}},"title":{}}],["8.22",{"_index":3539,"text":{"Chap_8.html":{},"Chap_8.html#problem-83":{}},"title":{}}],["8.23",{"_index":3542,"text":{"Chap_8.html":{},"Chap_8.html#problem-83":{}},"title":{}}],["8.3",{"_index":3431,"text":{"Chap_8.html":{},"Chap_8.html#problem-82":{},"Chap_8.html#snr-for-deterministic-signals-in-the-presence-of-noise":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{},"Chap_9.html":{},"Chap_9.html#performance-in-the-presence-of-noise":{}},"title":{"Chap_8.html#problem-83":{}}}],["8.4",{"_index":3436,"text":{"Chap_8.html":{},"Chap_8.html#problem-83":{},"Chap_8.html#snr-for-random-signals-in-the-presence-of-noise":{}},"title":{}}],["8.5",{"_index":3440,"text":{"Chap_8.html":{},"Chap_8.html#snr-for-random-signals-in-the-presence-of-noise":{}},"title":{}}],["8.6",{"_index":3443,"text":{"Chap_8.html":{},"Chap_8.html#snr-for-random-signals-in-the-presence-of-noise":{}},"title":{}}],["8.7",{"_index":3449,"text":{"Chap_8.html":{},"Chap_8.html#snr-for-random-signals-in-the-presence-of-noise":{}},"title":{}}],["8.8",{"_index":3452,"text":{"Chap_8.html":{},"Chap_8.html#example-cocktail-party-noise":{},"Chap_8.html#snr-for-random-signals-in-the-presence-of-noise":{}},"title":{}}],["8.9",{"_index":3457,"text":{"Chap_8.html":{},"Chap_8.html#example-not-too-noisy":{}},"title":{}}],["81",{"_index":2364,"text":{"Chap_4.html":{},"Chap_4.html#laboratory-exercise-41":{},"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small":{}},"title":{}}],["816432",{"_index":3744,"text":{"info.html":{},"info.html#registration":{}},"title":{}}],["8{\\left",{"_index":2773,"text":{"Chap_6.html":{},"Chap_6.html#problem-62":{}},"title":{}}],["8{k^2}{m^2",{"_index":3266,"text":{"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period_1":{}},"title":{}}],["9",{"_index":1463,"text":{"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_4.html":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_7.html":{},"Chap_7.html#one-step-further":{}},"title":{"Chap_9.html":{}}}],["9.1",{"_index":3551,"text":{"Chap_9.html":{},"Chap_9.html#example-matching-your-filter":{},"Chap_9.html#performance-in-the-presence-of-noise":{},"Chap_9.html#setting-up-the-problem":{},"Chap_9.html#the-matched-filter":{},"Chap_9.html#the-matched-filter-as-an-autocorrelation":{}},"title":{"Chap_9.html#laboratory-exercise-91":{},"Chap_9.html#problem-91":{}}}],["9.10",{"_index":3576,"text":{"Chap_9.html":{},"Chap_9.html#the-classic-example":{},"Chap_9.html#using-cauchy-schwartz":{}},"title":{}}],["9.11",{"_index":3577,"text":{"Chap_9.html":{},"Chap_9.html#using-cauchy-schwartz":{}},"title":{}}],["9.12",{"_index":721,"text":{"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_9.html":{},"Chap_9.html#the-classic-example":{}},"title":{}}],["9.13",{"_index":3579,"text":{"Chap_9.html":{},"Chap_9.html#the-classic-example":{}},"title":{}}],["9.14",{"_index":3581,"text":{"Chap_9.html":{},"Chap_9.html#example-matching-your-filter":{}},"title":{}}],["9.15",{"_index":3587,"text":{"Chap_9.html":{},"Chap_9.html#example-matching-your-filter":{},"Chap_9.html#problem-91":{},"Chap_9.html#the-matched-filter-as-an-autocorrelation":{}},"title":{}}],["9.16",{"_index":3588,"text":{"Chap_9.html":{},"Chap_9.html#the-matched-filter-as-an-autocorrelation":{}},"title":{}}],["9.17",{"_index":3591,"text":{"Chap_9.html":{},"Chap_9.html#the-matched-filter-as-an-autocorrelation":{}},"title":{}}],["9.18",{"_index":3619,"text":{"Chap_9.html":{},"Chap_9.html#problem-92":{}},"title":{}}],["9.2",{"_index":3556,"text":{"Chap_9.html":{},"Chap_9.html#laboratory-exercise-91":{},"Chap_9.html#performance-in-the-presence-of-noise":{},"Chap_9.html#problem-91":{},"Chap_9.html#problem-92":{},"Chap_9.html#setting-up-the-problem":{},"Chap_9.html#using-cauchy-schwartz":{}},"title":{"Chap_9.html#laboratory-exercise-92":{},"Chap_9.html#problem-92":{}}}],["9.3",{"_index":3558,"text":{"Chap_9.html":{},"Chap_9.html#setting-up-the-problem":{}},"title":{"Chap_9.html#laboratory-exercise-93":{}}}],["9.4",{"_index":3561,"text":{"Chap_9.html":{},"Chap_9.html#setting-up-the-problem":{},"Chap_9.html#using-cauchy-schwartz":{}},"title":{}}],["9.5",{"_index":3564,"text":{"Chap_9.html":{},"Chap_9.html#using-cauchy-schwartz":{}},"title":{}}],["9.6",{"_index":3568,"text":{"Chap_9.html":{},"Chap_9.html#using-cauchy-schwartz":{}},"title":{}}],["9.7",{"_index":3570,"text":{"Chap_9.html":{},"Chap_9.html#using-cauchy-schwartz":{}},"title":{}}],["9.8",{"_index":2228,"text":{"Chap_4.html":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_9.html":{},"Chap_9.html#using-cauchy-schwartz":{}},"title":{}}],["9.9",{"_index":3574,"text":{"Chap_9.html":{},"Chap_9.html#using-cauchy-schwartz":{}},"title":{}}],["90",{"_index":2203,"text":{"Chap_4.html":{},"Chap_4.html#the-mechanics-of-correlations":{},"info.html":{},"info.html#registration":{}},"title":{}}],["91",{"_index":2591,"text":{"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{}},"title":{}}],["97.1",{"_index":3327,"text":{"Chap_7.html":{},"Chap_7.html#power-spectral-density_2":{}},"title":{}}],["978",{"_index":3743,"text":{"info.html":{},"info.html#registration":{}},"title":{}}],["_",{"_index":2784,"text":{"Chap_6.html":{},"Chap_6.html#laboratory-exercise-63":{}},"title":{}}],["_0",{"_index":2685,"text":{"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{}},"title":{}}],["_0})\\delta",{"_index":2684,"text":{"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{}},"title":{}}],["_1",{"_index":3247,"text":{"Chap_7.html":{},"Chap_7.html#autocorrelation-function_2":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#descriptive-statistic-variance":{},"Chap_7.html#expected-value_1":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#power-spectral-density_2":{},"Chap_7.html#problem-710":{},"Chap_7.html#problem-711":{}},"title":{}}],["_1^2",{"_index":3312,"text":{"Chap_7.html":{},"Chap_7.html#autocorrelation-function_2":{},"Chap_7.html#descriptive-statistic-variance":{},"Chap_7.html#power-spectral-density_2":{}},"title":{}}],["_1^2)(1",{"_index":3316,"text":{"Chap_7.html":{},"Chap_7.html#autocorrelation-function_2":{},"Chap_7.html#descriptive-statistic-variance":{}},"title":{}}],["_1^n",{"_index":3282,"text":{"Chap_7.html":{},"Chap_7.html#autocorrelation-function_2":{},"Chap_7.html#choosing-the-sampling-period_1":{}},"title":{}}],["_1^{1",{"_index":3313,"text":{"Chap_7.html":{},"Chap_7.html#autocorrelation-function_2":{}},"title":{}}],["_1^{n",{"_index":3305,"text":{"Chap_7.html":{},"Chap_7.html#autocorrelation-function_2":{}},"title":{}}],["_1}(1",{"_index":3334,"text":{"Chap_7.html":{},"Chap_7.html#descriptive-statistic-variance":{}},"title":{}}],["_1})\\left",{"_index":3309,"text":{"Chap_7.html":{},"Chap_7.html#autocorrelation-function_2":{},"Chap_7.html#descriptive-statistic-variance":{}},"title":{}}],["_1})}^2}\\left",{"_index":3336,"text":{"Chap_7.html":{},"Chap_7.html#descriptive-statistic-variance":{}},"title":{}}],["_1},{\\rho",{"_index":3285,"text":{"Chap_7.html":{},"Chap_7.html#autocorrelation-function_2":{},"Chap_7.html#choosing-the-sampling-period_1":{}},"title":{}}],["_1}\\co",{"_index":3324,"text":{"Chap_7.html":{},"Chap_7.html#power-spectral-density_2":{}},"title":{}}],["_1}t",{"_index":3251,"text":{"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{}},"title":{}}],["_1}{\\rho",{"_index":3292,"text":{"Chap_7.html":{},"Chap_7.html#autocorrelation-function_2":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#descriptive-statistic-variance":{},"Chap_7.html#expected-value_1":{}},"title":{}}],["_1}{t_",{"_index":3277,"text":{"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period_1":{}},"title":{}}],["_1}{z",{"_index":3288,"text":{"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period_1":{}},"title":{}}],["_1}}}^n",{"_index":3279,"text":{"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period_1":{}},"title":{}}],["_2",{"_index":3248,"text":{"Chap_7.html":{},"Chap_7.html#autocorrelation-function_2":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#descriptive-statistic-variance":{},"Chap_7.html#expected-value_1":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#power-spectral-density_2":{},"Chap_7.html#problem-710":{},"Chap_7.html#problem-711":{}},"title":{}}],["_2^2",{"_index":3314,"text":{"Chap_7.html":{},"Chap_7.html#autocorrelation-function_2":{},"Chap_7.html#descriptive-statistic-variance":{},"Chap_7.html#power-spectral-density_2":{}},"title":{}}],["_2^n",{"_index":3283,"text":{"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period_1":{}},"title":{}}],["_2^n)(\\rho",{"_index":3304,"text":{"Chap_7.html":{},"Chap_7.html#autocorrelation-function_2":{}},"title":{}}],["_2^{1",{"_index":3310,"text":{"Chap_7.html":{},"Chap_7.html#autocorrelation-function_2":{}},"title":{}}],["_2^{n",{"_index":3306,"text":{"Chap_7.html":{},"Chap_7.html#autocorrelation-function_2":{}},"title":{}}],["_2}(1",{"_index":3333,"text":{"Chap_7.html":{},"Chap_7.html#descriptive-statistic-variance":{}},"title":{}}],["_2})(1",{"_index":3317,"text":{"Chap_7.html":{},"Chap_7.html#autocorrelation-function_2":{},"Chap_7.html#descriptive-statistic-variance":{}},"title":{}}],["_2})x[n",{"_index":3293,"text":{"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period_1":{}},"title":{}}],["_2}){z",{"_index":3291,"text":{"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period_1":{}},"title":{}}],["_2})}^2}}}{{({\\lambda",{"_index":3321,"text":{"Chap_7.html":{},"Chap_7.html#power-spectral-density_2":{}},"title":{}}],["_2})}}{{1",{"_index":3299,"text":{"Chap_7.html":{},"Chap_7.html#expected-value_1":{}},"title":{}}],["_2})}}{{\\sqrt",{"_index":3295,"text":{"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period_1":{}},"title":{}}],["_2}\\co",{"_index":3325,"text":{"Chap_7.html":{},"Chap_7.html#power-spectral-density_2":{}},"title":{}}],["_2}t",{"_index":3252,"text":{"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{}},"title":{}}],["_2}x[n",{"_index":3294,"text":{"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period_1":{}},"title":{}}],["_2}{t_",{"_index":3280,"text":{"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period_1":{}},"title":{}}],["_2}{z",{"_index":3289,"text":{"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period_1":{}},"title":{}}],["_2}}}^n",{"_index":3281,"text":{"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period_1":{}},"title":{}}],["_3",{"_index":2060,"text":{"Chap_4.html":{},"Chap_4.html#example-fair-chance":{}},"title":{}}],["_5",{"_index":2061,"text":{"Chap_4.html":{},"Chap_4.html#example-fair-chance":{}},"title":{}}],["_7",{"_index":2063,"text":{"Chap_4.html":{},"Chap_4.html#example-fair-chance":{}},"title":{}}],["_a",{"_index":831,"text":{"Chap_11.html":{},"Chap_11.html#aspects-of-estimation":{},"Chap_11.html#example-estimating-the-poisson-rate":{},"Chap_7.html":{},"Chap_7.html#descriptive-statistic-variance":{}},"title":{}}],["_a^2",{"_index":964,"text":{"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{}},"title":{}}],["_a}}}{{{t_",{"_index":3344,"text":{"Chap_7.html":{},"Chap_7.html#descriptive-statistic-variance":{}},"title":{}}],["_c",{"_index":2899,"text":{"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#power-spectral-density_2":{}},"title":{}}],["_d",{"_index":3342,"text":{"Chap_7.html":{},"Chap_7.html#descriptive-statistic-variance":{},"Chap_7.html#one-step-further":{},"Chap_7.html#problem-711":{}},"title":{}}],["_f",{"_index":2936,"text":{"Chap_7.html":{},"Chap_7.html#the-langevin-velocity-equation":{}},"title":{}}],["_f^2",{"_index":2933,"text":{"Chap_7.html":{},"Chap_7.html#the-langevin-velocity-equation":{}},"title":{}}],["_g",{"_index":836,"text":{"Chap_11.html":{},"Chap_11.html#aspects-of-estimation":{}},"title":{}}],["_h",{"_index":841,"text":{"Chap_11.html":{},"Chap_11.html#aspects-of-estimation":{}},"title":{}}],["_k",{"_index":2556,"text":{"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{}},"title":{}}],["_m",{"_index":2703,"text":{"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{}},"title":{}}],["_m}k",{"_index":2711,"text":{"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{}},"title":{}}],["_n^2",{"_index":1000,"text":{"Chap_11.html":{},"Chap_11.html#estimating-the-mean":{}},"title":{}}],["_o",{"_index":879,"text":{"Chap_11.html":{},"Chap_11.html#maximum-likelihood-estimation":{},"Chap_11.html#problem-116":{},"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{}},"title":{}}],["_o})}^2",{"_index":1194,"text":{"Chap_11.html":{},"Chap_11.html#problem-116":{}},"title":{}}],["_s",{"_index":2359,"text":{"Chap_4.html":{},"Chap_4.html#problem-48":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#impulse-invariant-sampling":{}},"title":{}}],["_v",{"_index":2965,"text":{"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{}},"title":{}}],["_v^2",{"_index":2963,"text":{"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{}},"title":{}}],["_x",{"_index":1201,"text":{"Chap_11.html":{},"Chap_11.html#problem-117":{},"Chap_4.html":{},"Chap_4.html#problem-44":{},"Chap_4.html#problem-45":{},"Chap_4.html#problem-49":{}},"title":{}}],["_x^2",{"_index":1005,"text":{"Chap_11.html":{},"Chap_11.html#estimating-the-mean":{},"Chap_11.html#problem-117":{},"Chap_4.html":{},"Chap_4.html#example-is-that-coin-fair":{},"Chap_4.html#problem-44":{},"Chap_4.html#problem-45":{},"Chap_4.html#properties-of-averaging":{},"Chap_5.html":{},"Chap_5.html#correlations-simple-and-complex":{},"Chap_5.html#problem-53":{},"Chap_7.html":{},"Chap_7.html#power-spectral-density_1":{}},"title":{}}],["_x^2}}\\sum\\limits_{n",{"_index":1209,"text":{"Chap_11.html":{},"Chap_11.html#problem-117":{}},"title":{}}],["_x^2}}{n",{"_index":1008,"text":{"Chap_11.html":{},"Chap_11.html#estimating-the-mean":{}},"title":{}}],["_x}/{\\mu",{"_index":2341,"text":{"Chap_4.html":{},"Chap_4.html#problem-44":{}},"title":{}}],["_y",{"_index":2335,"text":{"Chap_4.html":{},"Chap_4.html#problem-44":{}},"title":{}}],["_y^2",{"_index":2336,"text":{"Chap_4.html":{},"Chap_4.html#problem-44":{}},"title":{}}],["_z",{"_index":2363,"text":{"Chap_4.html":{},"Chap_4.html#problem-49":{}},"title":{}}],["_{0",{"_index":1112,"text":{"Chap_11.html":{},"Chap_11.html#langevin-redux":{}},"title":{}}],["_{10}}\\left",{"_index":2564,"text":{"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_8.html":{},"Chap_8.html#example-cocktail-party-noise":{},"Chap_8.html#example-not-too-noisy":{},"Chap_8.html#snr-for-deterministic-signals-in-the-presence-of-noise":{},"Chap_8.html#snr-for-random-signals-in-the-presence-of-noise":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{}},"title":{}}],["_{2n",{"_index":2058,"text":{"Chap_4.html":{},"Chap_4.html#example-fair-chance":{},"Chap_4.html#the-ergodic-process":{}},"title":{}}],["_{\\max",{"_index":1054,"text":{"Chap_11.html":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_11.html#trouble-in-paradise":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{}},"title":{}}],["_{bb}}[k",{"_index":3535,"text":{"Chap_8.html":{},"Chap_8.html#problem-83":{}},"title":{}}],["_{cc}}[k",{"_index":2752,"text":{"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{}},"title":{}}],["_{cc}}[m",{"_index":2756,"text":{"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{}},"title":{}}],["_{cc}}[n",{"_index":2753,"text":{"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{}},"title":{}}],["_{cg}}[k",{"_index":2751,"text":{"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{}},"title":{}}],["_{cg}}[k\\rbrack",{"_index":2758,"text":{"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{}},"title":{}}],["_{cg}}[n",{"_index":2755,"text":{"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{}},"title":{}}],["_{ee}}[k",{"_index":1218,"text":{"Chap_11.html":{},"Chap_11.html#problem-118":{}},"title":{}}],["_{ff}}(\\tau",{"_index":2794,"text":{"Chap_7.html":{},"Chap_7.html#the-langevin-equation-a-case-study":{}},"title":{}}],["_{ff}}[0",{"_index":2932,"text":{"Chap_7.html":{},"Chap_7.html#the-langevin-velocity-equation":{}},"title":{}}],["_{ff}}[k",{"_index":2926,"text":{"Chap_7.html":{},"Chap_7.html#autocorrelation-function":{},"Chap_7.html#power-spectral-density":{},"Chap_7.html#the-langevin-velocity-equation":{}},"title":{}}],["_{hh",{"_index":2976,"text":{"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#power-spectral-density_1":{}},"title":{}}],["_{hh}}(\\tau",{"_index":2980,"text":{"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#power-spectral-density_1":{}},"title":{}}],["_{hh}}[k",{"_index":2666,"text":{"Chap_6.html":{},"Chap_6.html#the-autocorrelation-function":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function":{},"Chap_7.html#autocorrelation-function_2":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#power-spectral-density":{},"Chap_7.html#power-spectral-density_1":{}},"title":{}}],["_{hh}}[m",{"_index":2664,"text":{"Chap_6.html":{},"Chap_6.html#the-autocorrelation-function":{}},"title":{}}],["_{k",{"_index":1113,"text":{"Chap_11.html":{},"Chap_11.html#langevin-redux":{}},"title":{}}],["_{ml",{"_index":875,"text":{"Chap_11.html":{},"Chap_11.html#example-estimating-the-poisson-rate":{},"Chap_11.html#maximum-likelihood-estimation":{},"Chap_11.html#problem-114":{}},"title":{}}],["_{nn",{"_index":3430,"text":{"Chap_8.html":{},"Chap_8.html#example-not-too-noisy":{},"Chap_8.html#snr-for-deterministic-signals-in-the-presence-of-noise":{},"Chap_8.html#snr-for-random-signals-in-the-presence-of-noise":{}},"title":{}}],["_{nn}^2",{"_index":3444,"text":{"Chap_8.html":{},"Chap_8.html#snr-for-random-signals-in-the-presence-of-noise":{}},"title":{}}],["_{nn}}[0",{"_index":3445,"text":{"Chap_8.html":{},"Chap_8.html#example-cocktail-party-noise":{},"Chap_8.html#snr-for-random-signals-in-the-presence-of-noise":{}},"title":{}}],["_{nn}}[k",{"_index":699,"text":{"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#problem-103":{},"Chap_8.html":{},"Chap_8.html#problem-83":{}},"title":{}}],["_{nx}}[k",{"_index":542,"text":{"Chap_10.html":{},"Chap_10.html#classic-example-classic-result":{}},"title":{}}],["_{pp}}[k",{"_index":2567,"text":{"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{}},"title":{}}],["_{pp}}\\lbrack",{"_index":2584,"text":{"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{}},"title":{}}],["_{rm",{"_index":1468,"text":{"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{}},"title":{}}],["_{rr}}[k",{"_index":439,"text":{"Chap_10.html":{},"Chap_10.html#classic-example-classic-result":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#problem-103":{},"Chap_10.html#the-wiener-hopf-equation":{}},"title":{}}],["_{rr}}[m",{"_index":521,"text":{"Chap_10.html":{},"Chap_10.html#what-is-that-least-mean-square-error":{}},"title":{}}],["_{rx}^*[i",{"_index":418,"text":{"Chap_10.html":{},"Chap_10.html#correlation-returns":{}},"title":{}}],["_{rx}}[i",{"_index":419,"text":{"Chap_10.html":{},"Chap_10.html#correlation-returns":{}},"title":{}}],["_{rx}}[k",{"_index":438,"text":{"Chap_10.html":{},"Chap_10.html#classic-example-classic-result":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#the-wiener-hopf-equation":{},"Chap_10.html#what-is-that-least-mean-square-error":{}},"title":{}}],["_{rx}}[m]h[m",{"_index":524,"text":{"Chap_10.html":{},"Chap_10.html#what-is-that-least-mean-square-error":{}},"title":{}}],["_{ss",{"_index":3442,"text":{"Chap_8.html":{},"Chap_8.html#snr-for-random-signals-in-the-presence-of-noise":{}},"title":{}}],["_{ss}}[0",{"_index":3446,"text":{"Chap_8.html":{},"Chap_8.html#example-cocktail-party-noise":{},"Chap_8.html#snr-for-random-signals-in-the-presence-of-noise":{}},"title":{}}],["_{ss}}[0]}}{{{\\varphi",{"_index":3454,"text":{"Chap_8.html":{},"Chap_8.html#snr-for-random-signals-in-the-presence-of-noise":{}},"title":{}}],["_{ss}}[k",{"_index":3540,"text":{"Chap_8.html":{},"Chap_8.html#problem-83":{}},"title":{}}],["_{ss}}}}{{{\\sigma",{"_index":3439,"text":{"Chap_8.html":{},"Chap_8.html#snr-for-random-signals-in-the-presence-of-noise":{}},"title":{}}],["_{tt}}[k",{"_index":1278,"text":{"Chap_12.html":{},"Chap_12.html#spectral-estimation":{},"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{}},"title":{}}],["_{tt}}\\lbrack",{"_index":2582,"text":{"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{}},"title":{}}],["_{v,a}^2",{"_index":2992,"text":{"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{}},"title":{}}],["_{v,d}^2",{"_index":2993,"text":{"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{}},"title":{}}],["_{vv",{"_index":2979,"text":{"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{}},"title":{}}],["_{vv}}[0",{"_index":2964,"text":{"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{}},"title":{}}],["_{vv}}[k",{"_index":1067,"text":{"Chap_11.html":{},"Chap_11.html#langevin-redux":{},"Chap_11.html#problem-119":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#power-spectral-density":{},"Chap_7.html#problem-74":{}},"title":{}}],["_{vv}}[k\\rbrack",{"_index":1129,"text":{"Chap_11.html":{},"Chap_11.html#langevin-redux":{},"Chap_7.html":{},"Chap_7.html#power-spectral-density":{}},"title":{}}],["_{vv}}[k]{\\varphi",{"_index":1109,"text":{"Chap_11.html":{},"Chap_11.html#langevin-redux":{}},"title":{}}],["_{vv}}[k]}_{m",{"_index":1110,"text":{"Chap_11.html":{},"Chap_11.html#langevin-redux":{}},"title":{}}],["_{vv}}[m",{"_index":1084,"text":{"Chap_11.html":{},"Chap_11.html#langevin-redux":{},"Chap_11.html#problem-1110":{}},"title":{}}],["_{x,a}^2",{"_index":3119,"text":{"Chap_7.html":{},"Chap_7.html#descriptive-statistic-variance":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#problem-78":{}},"title":{}}],["_{x,d}^2",{"_index":3120,"text":{"Chap_7.html":{},"Chap_7.html#descriptive-statistic-variance":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#problem-77":{},"Chap_7.html#problem-78":{}},"title":{}}],["_{x[n]}^2",{"_index":2181,"text":{"Chap_4.html":{},"Chap_4.html#properties-of-averaging":{}},"title":{}}],["_{xi",{"_index":2598,"text":{"Chap_5.html":{},"Chap_5.html#problem-55":{}},"title":{}}],["_{xr",{"_index":417,"text":{"Chap_10.html":{},"Chap_10.html#correlation-returns":{}},"title":{}}],["_{xx",{"_index":2400,"text":{"Chap_5.html":{},"Chap_5.html#correlations-simple-and-complex":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_6.html":{},"Chap_6.html#the-autocorrelation-function":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_7.html":{},"Chap_7.html#power-spectral-density_1":{}},"title":{}}],["_{xx}^*[k",{"_index":2508,"text":{"Chap_5.html":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{}},"title":{}}],["_{xx}^2[m",{"_index":1037,"text":{"Chap_11.html":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_11.html#problem-119":{}},"title":{}}],["_{xx}}(\\tau",{"_index":2280,"text":{"Chap_4.html":{},"Chap_4.html#example-is-that-coin-fair":{}},"title":{}}],["_{xx}}[0",{"_index":510,"text":{"Chap_10.html":{},"Chap_10.html#what-is-that-least-mean-square-error":{},"Chap_5.html":{},"Chap_5.html#correlations-simple-and-complex":{},"Chap_5.html#example-pink-noise":{},"Chap_5.html#problem-56":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_7.html":{},"Chap_7.html#power-spectral-density_1":{},"Chap_9.html":{},"Chap_9.html#the-matched-filter-as-an-autocorrelation":{}},"title":{}}],["_{xx}}[k",{"_index":549,"text":{"Chap_10.html":{},"Chap_10.html#classic-example-classic-result":{},"Chap_10.html#problem-103":{},"Chap_11.html":{},"Chap_11.html#aspects-of-estimation":{},"Chap_11.html#estimating-the-autocorrelation-function":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_11.html#problem-118":{},"Chap_11.html#problem-119":{},"Chap_11.html#trouble-in-paradise":{},"Chap_12.html":{},"Chap_12.html#spectral-estimation":{},"Chap_12.html#the-periodogram-unbiased":{},"Chap_4.html":{},"Chap_4.html#describing-the-time-average":{},"Chap_4.html#example-is-that-coin-fair":{},"Chap_4.html#the-ergodic-process":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#correlations-and-memory":{},"Chap_5.html#correlations-simple-and-complex":{},"Chap_5.html#example-delayed-effect":{},"Chap_5.html#example-pink-noise":{},"Chap_5.html#example-white-noise":{},"Chap_5.html#fourier-description-of-correlation-functions":{},"Chap_5.html#problem-52":{},"Chap_5.html#problem-53":{},"Chap_5.html#problem-54":{},"Chap_5.html#problem-56":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_6.html":{},"Chap_6.html#filtering-of-stochastic-signals":{},"Chap_6.html#interpretation-of-the-convolution-result":{},"Chap_6.html#problem-62":{},"Chap_6.html#problem-64":{},"Chap_6.html#the-autocorrelation-function":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function_1":{},"Chap_7.html#autocorrelation-function_2":{},"Chap_7.html#descriptive-statistic-variance":{},"Chap_7.html#power-spectral-density_2":{},"Chap_8.html":{},"Chap_8.html#example-filtering-noise":{},"Chap_8.html#problem-81":{},"Chap_9.html":{},"Chap_9.html#the-matched-filter-as-an-autocorrelation":{}},"title":{}}],["_{xx}}[k\\rbrack",{"_index":3326,"text":{"Chap_7.html":{},"Chap_7.html#power-spectral-density_2":{}},"title":{}}],["_{xx}}[k],{s_{xx}}(\\omega",{"_index":2491,"text":{"Chap_5.html":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{}},"title":{}}],["_{xx}}[k]\\co",{"_index":2603,"text":{"Chap_5.html":{},"Chap_5.html#problem-56":{}},"title":{}}],["_{xx}}[k]{e",{"_index":1306,"text":{"Chap_12.html":{},"Chap_12.html#the-periodogram-unbiased":{},"Chap_12.html#windowed-observations":{},"Chap_5.html":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{}},"title":{}}],["_{xx}}[m",{"_index":1038,"text":{"Chap_11.html":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_11.html#problem-119":{},"Chap_4.html":{},"Chap_4.html#cross-covariance":{}},"title":{}}],["_{xx}}[n",{"_index":3592,"text":{"Chap_9.html":{},"Chap_9.html#the-matched-filter-as-an-autocorrelation":{}},"title":{}}],["_{xx}}[n,k",{"_index":2189,"text":{"Chap_4.html":{},"Chap_4.html#auto-covariance":{},"Chap_4.html#autocorrelation":{},"Chap_4.html#cross-covariance":{}},"title":{}}],["_{xx}}[n,n",{"_index":2192,"text":{"Chap_4.html":{},"Chap_4.html#auto-covariance":{},"Chap_4.html#autocorrelation":{},"Chap_4.html#cross-covariance":{}},"title":{}}],["_{xy}}[k",{"_index":2390,"text":{"Chap_5.html":{},"Chap_5.html#correlations-and-memory":{},"Chap_5.html#correlations-simple-and-complex":{},"Chap_5.html#problem-55":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_6.html":{},"Chap_6.html#filtering-of-stochastic-signals":{},"Chap_6.html#the-cross-correlation-function":{}},"title":{}}],["_{xy}}[k]{",{"_index":2518,"text":{"Chap_5.html":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{}},"title":{}}],["_{xy}}[m",{"_index":2262,"text":{"Chap_4.html":{},"Chap_4.html#cross-covariance":{}},"title":{}}],["_{xy}}[n,k",{"_index":2249,"text":{"Chap_4.html":{},"Chap_4.html#cross-correlation":{},"Chap_4.html#cross-covariance":{}},"title":{}}],["_{xy}}[n,n",{"_index":2252,"text":{"Chap_4.html":{},"Chap_4.html#cross-correlation":{},"Chap_4.html#cross-covariance":{}},"title":{}}],["_{yi",{"_index":2657,"text":{"Chap_6.html":{},"Chap_6.html#the-autocorrelation-function":{}},"title":{}}],["_{yx",{"_index":2401,"text":{"Chap_5.html":{},"Chap_5.html#correlations-simple-and-complex":{}},"title":{}}],["_{yx}}[k",{"_index":692,"text":{"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{}},"title":{}}],["_{yy}}(\\tau",{"_index":3376,"text":{"Chap_7.html":{},"Chap_7.html#problem-73":{}},"title":{}}],["_{yy}}[0",{"_index":2681,"text":{"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{}},"title":{}}],["_{yy}}[k",{"_index":698,"text":{"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_5.html":{},"Chap_5.html#example-delayed-effect":{},"Chap_6.html":{},"Chap_6.html#interpretation-of-the-convolution-result":{},"Chap_6.html#problem-61":{},"Chap_6.html#problem-62":{},"Chap_6.html#the-autocorrelation-function":{},"Chap_6.html#the-cross-correlation-function":{}},"title":{}}],["_{yy}}[n,n",{"_index":2646,"text":{"Chap_6.html":{},"Chap_6.html#the-autocorrelation-function":{}},"title":{}}],["_{{x_n}}^2",{"_index":2260,"text":{"Chap_4.html":{},"Chap_4.html#cross-covariance":{}},"title":{}}],["a:}&{440\\,{\\rm{hz",{"_index":1569,"text":{"Chap_12.html":{},"Chap_12.html#problem-123":{}},"title":{}}],["a\\,\\delta",{"_index":2278,"text":{"Chap_4.html":{},"Chap_4.html#example-is-that-coin-fair":{},"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{}},"title":{}}],["a\\,e\\left",{"_index":2173,"text":{"Chap_4.html":{},"Chap_4.html#properties-of-averaging":{}},"title":{}}],["a\\,x",{"_index":2333,"text":{"Chap_4.html":{},"Chap_4.html#problem-44":{}},"title":{}}],["a\\,x[n",{"_index":2166,"text":{"Chap_4.html":{},"Chap_4.html#properties-of-averaging":{}},"title":{}}],["a\\,x\\,p(x[n])dx",{"_index":2169,"text":{"Chap_4.html":{},"Chap_4.html#properties-of-averaging":{}},"title":{}}],["a\\,{m_{x[n",{"_index":2172,"text":{"Chap_4.html":{},"Chap_4.html#properties-of-averaging":{}},"title":{}}],["a\\,{x_1",{"_index":2176,"text":{"Chap_4.html":{},"Chap_4.html#properties-of-averaging":{}},"title":{}}],["a\\frac{{({\\rho",{"_index":3308,"text":{"Chap_7.html":{},"Chap_7.html#autocorrelation-function_2":{},"Chap_7.html#descriptive-statistic-variance":{}},"title":{}}],["a\\int\\limits_",{"_index":2170,"text":{"Chap_4.html":{},"Chap_4.html#properties-of-averaging":{}},"title":{}}],["a\\sum\\limits_{n",{"_index":3303,"text":{"Chap_7.html":{},"Chap_7.html#autocorrelation-function_2":{}},"title":{}}],["a^n}u[n",{"_index":2599,"text":{"Chap_5.html":{},"Chap_5.html#problem-55":{}},"title":{}}],["a^{\\left",{"_index":3513,"text":{"Chap_8.html":{},"Chap_8.html#problem-81":{}},"title":{}}],["a_k",{"_index":2763,"text":{"Chap_6.html":{},"Chap_6.html#problem-61":{}},"title":{}}],["a_k}\\delta",{"_index":2762,"text":{"Chap_6.html":{},"Chap_6.html#problem-61":{}},"title":{}}],["a_k}{",{"_index":2848,"text":{"Chap_7.html":{},"Chap_7.html#impulse-invariant-sampling":{}},"title":{}}],["abil",{"_index":1711,"text":{"Chap_13.html":{},"Chap_13.html#epilogue":{}},"title":{}}],["abov",{"_index":266,"text":{"Chap_1.html":{},"Chap_1.html#enhanced-experience":{},"Chap_10.html":{},"Chap_10.html#using-the-least-mean-square-error-criterion":{},"Chap_11.html":{},"Chap_11.html#estimating-the-autocorrelation-function":{},"Chap_11.html#trouble-in-paradise":{},"Chap_13.html":{},"Chap_13.html#appendix-i-mean-square-error-minimization":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#example-fair-chance":{},"Chap_4.html#the-ergodic-process":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#impulse-invariant-sampling":{},"Chap_7.html#one-step-further":{},"Chap_7.html#power-spectral-density_2":{},"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{},"info.html":{},"info.html#tips-short-cuts":{}},"title":{}}],["absolut",{"_index":365,"text":{"Chap_10.html":{},"Chap_10.html#using-the-least-mean-square-error-criterion":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#fourier-description-of-correlation-functions":{},"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{}},"title":{}}],["abstract",{"_index":2713,"text":{"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{},"Chap_7.html":{},"Chap_7.html#problem-78":{}},"title":{}}],["accept",{"_index":1352,"text":{"Chap_12.html":{},"Chap_12.html#other-windows":{},"Chap_12.html#windowed-observations":{},"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{}},"title":{}}],["accompani",{"_index":2310,"text":{"Chap_4.html":{},"Chap_4.html#problem-42":{}},"title":{}}],["accomplish",{"_index":1600,"text":{"Chap_13.html":{},"Chap_13.html#appendix-i-mean-square-error-minimization":{}},"title":{}}],["accord",{"_index":1513,"text":{"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_5.html":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_6.html":{},"Chap_6.html#interpretation-of-the-convolution-result":{},"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_8.html":{},"Chap_8.html#example-not-too-noisy":{},"Chap_9.html":{},"Chap_9.html#performance-in-the-presence-of-noise":{},"Chap_9.html#problem-92":{},"Chap_9.html#using-cauchy-schwartz":{}},"title":{}}],["accur",{"_index":951,"text":{"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{}},"title":{}}],["accuraci",{"_index":977,"text":{"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_11.html#laboratory-exercise-112":{},"Chap_12.html":{},"Chap_12.html#problem-123":{},"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{}},"title":{}}],["achiev",{"_index":274,"text":{"Chap_10.html":{},"Chap_10.html#laboratory-exercise-102":{},"Chap_10.html#the-wiener-filter":{},"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#problem-122":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_9.html":{},"Chap_9.html#laboratory-exercise-93":{}},"title":{}}],["acknowledg",{"_index":3673,"text":{"info.html":{},"info.html#acknowledgments":{},"info.html#weather-data":{}},"title":{"info.html#acknowledgments":{}}}],["acoust",{"_index":659,"text":{"Chap_10.html":{},"Chap_10.html#example-sound-of-distorted-music":{}},"title":{}}],["acquir",{"_index":770,"text":{"Chap_10.html":{},"Chap_10.html#laboratory-exercise-104":{},"Chap_11.html":{},"Chap_11.html#maximum-likelihood-estimation":{}},"title":{}}],["act",{"_index":215,"text":{"Chap_1.html":{},"Chap_1.html#enhanced-experience":{},"Chap_10.html":{}},"title":{"Chap_10.html#example-cleaning-up-our-act":{}}}],["activ",{"_index":3659,"text":{"info.html":{},"info.html#tips-short-cuts":{}},"title":{}}],["actual",{"_index":917,"text":{"Chap_11.html":{},"Chap_11.html#example-estimating-the-poisson-rate":{},"Chap_12.html":{},"Chap_12.html#problem-122":{},"Chap_5.html":{},"Chap_5.html#laboratory-exercise-51":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_9.html":{},"Chap_9.html#the-matched-filter-as-an-autocorrelation":{}},"title":{}}],["ad",{"_index":679,"text":{"Chap_10.html":{},"Chap_10.html#example-cleaning-up-our-act":{},"Chap_7.html":{},"Chap_7.html#power-spectral-density_1":{}},"title":{}}],["adam",{"_index":1268,"text":{"Chap_11.html":{},"Chap_11.html#laboratory-exercise-113":{},"Chap_12.html":{},"Chap_12.html#laboratory-exercise-124":{}},"title":{}}],["addison",{"_index":2378,"text":{"Chap_4.html":{},"Chap_4.html#laboratory-exercise-42":{},"Chap_7.html":{},"Chap_7.html#problem-711":{},"Chap_8.html":{},"Chap_8.html#problem-83":{}},"title":{}}],["addit",{"_index":78,"text":{"Chap_1.html":{},"Chap_1.html#how-to-use-this-ibook":{},"Chap_10.html":{},"Chap_10.html#example-cleaning-up-our-act":{},"Chap_10.html#problem-103":{},"Chap_10.html#the-more-general-restoration-case-noise-distortion":{},"Chap_10.html#the-restoration-case-noise":{},"Chap_12.html":{},"Chap_12.html#other-windows":{},"Chap_6.html":{},"Chap_6.html#the-mean":{},"Chap_7.html":{},"Chap_7.html#power-spectral-density_1":{},"Chap_8.html":{},"Chap_8.html#example-cocktail-party-noise":{},"Chap_8.html#example-filtering-noise":{},"Chap_8.html#problem-83":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{},"Chap_9.html":{},"Chap_9.html#problem-91":{},"Chap_9.html#problem-92":{},"info.html":{},"info.html#tips-short-cuts":{}},"title":{}}],["address",{"_index":280,"text":{"Chap_10.html":{},"Chap_10.html#the-wiener-filter":{},"Chap_11.html":{},"Chap_11.html#aspects-of-estimation":{},"Chap_12.html":{},"Chap_12.html#problem-122":{},"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{}},"title":{}}],["adjust",{"_index":160,"text":{"Chap_1.html":{},"Chap_1.html#sound-of-music":{},"info.html":{},"info.html#musical-data":{}},"title":{}}],["admit",{"_index":465,"text":{"Chap_10.html":{},"Chap_10.html#the-wiener-hopf-equation":{},"Chap_12.html":{},"Chap_12.html#spectral-estimation":{}},"title":{}}],["ado",{"_index":2488,"text":{"Chap_5.html":{},"Chap_5.html#a-digression":{}},"title":{}}],["advantag",{"_index":2818,"text":{"Chap_7.html":{},"Chap_7.html#from-t-to-n":{}},"title":{}}],["ae\\left",{"_index":2164,"text":{"Chap_4.html":{},"Chap_4.html#properties-of-averaging":{}},"title":{}}],["affect",{"_index":1362,"text":{"Chap_12.html":{},"Chap_12.html#windowed-observations":{},"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#one-step-further":{},"Chap_7.html#tethered-particle-motion":{}},"title":{}}],["again",{"_index":429,"text":{"Chap_10.html":{},"Chap_10.html#correlation-returns":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#example-cleaning-up-our-act":{},"Chap_10.html#the-more-general-restoration-case-noise-distortion":{},"Chap_10.html#what-is-that-least-mean-square-error":{},"Chap_11.html":{},"Chap_11.html#problem-119":{},"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#the-periodogram-unbiased":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_3.html#problem-310":{},"Chap_3.html#problem-39":{},"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#example-fair-chance":{},"Chap_4.html#example-is-that-coin-fair":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_6.html":{},"Chap_6.html#the-autocorrelation-function":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function_1":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#descriptive-statistic-variance":{},"Chap_7.html#power-spectral-density":{},"Chap_7.html#the-langevin-position-equation":{}},"title":{}}],["ago",{"_index":2416,"text":{"Chap_5.html":{},"Chap_5.html#correlations-and-memory":{},"Chap_7.html":{},"Chap_7.html#tethered-particle-motion":{}},"title":{}}],["agre",{"_index":1233,"text":{"Chap_11.html":{},"Chap_11.html#problem-119":{}},"title":{}}],["aid",{"_index":1294,"text":{"Chap_12.html":{},"Chap_12.html#spectral-estimation":{},"Chap_4.html":{},"Chap_4.html#laboratory-exercise-42":{}},"title":{}}],["aim",{"_index":1805,"text":{"Chap_2.html":{},"Chap_2.html#problem-21":{}},"title":{}}],["air",{"_index":2423,"text":{"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"info.html":{},"info.html#cover":{}},"title":{}}],["airport",{"_index":2231,"text":{"Chap_4.html":{},"Chap_4.html#the-mechanics-of-correlations":{}},"title":{}}],["al",{"_index":3152,"text":{"Chap_7.html":{},"Chap_7.html#tethered-particle-motion":{}},"title":{}}],["algebra",{"_index":504,"text":{"Chap_10.html":{},"Chap_10.html#what-is-that-least-mean-square-error":{}},"title":{}}],["algorithm",{"_index":805,"text":{"Chap_10.html":{},"Chap_10.html#laboratory-exercise-105":{}},"title":{}}],["alias",{"_index":2850,"text":{"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#impulse-invariant-sampling":{}},"title":{}}],["allegro",{"_index":3727,"text":{"info.html":{},"info.html#musical-data":{}},"title":{}}],["alli",{"_index":1764,"text":{"Chap_2.html":{},"Chap_2.html#prologue":{}},"title":{}}],["allow",{"_index":2277,"text":{"Chap_4.html":{},"Chap_4.html#example-is-that-coin-fair":{},"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{},"Chap_7.html":{},"Chap_7.html#descriptive-statistic-variance":{},"Chap_7.html#why-this-case-study":{},"Chap_9.html":{},"Chap_9.html#performance-in-the-presence-of-noise":{}},"title":{}}],["alon",{"_index":2051,"text":{"Chap_4.html":{},"Chap_4.html#characterization-of-random-signals":{}},"title":{}}],["along",{"_index":2644,"text":{"Chap_6.html":{},"Chap_6.html#the-autocorrelation-function":{},"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{}},"title":{}}],["alpha",{"_index":1283,"text":{"Chap_12.html":{},"Chap_12.html#spectral-estimation":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_3.html#problem-33":{},"Chap_3.html#problem-35":{},"Chap_8.html":{},"Chap_8.html#example-cocktail-party-noise":{},"Chap_8.html#example-filtering-noise":{}},"title":{}}],["alreadi",{"_index":454,"text":{"Chap_10.html":{},"Chap_10.html#the-wiener-hopf-equation":{},"Chap_11.html":{},"Chap_11.html#langevin-redux":{},"Chap_4.html":{},"Chap_4.html#properties-of-averaging":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{}},"title":{}}],["alter",{"_index":2345,"text":{"Chap_4.html":{},"Chap_4.html#problem-47":{}},"title":{}}],["altern",{"_index":1580,"text":{"Chap_12.html":{},"Chap_12.html#problem-123":{},"Chap_2.html":{},"Chap_2.html#prologue":{},"Chap_5.html":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{}},"title":{}}],["although",{"_index":2106,"text":{"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#example-dice-money":{},"Chap_7.html":{},"Chap_7.html#power-spectral-density":{},"Chap_7.html#why-this-case-study":{}},"title":{}}],["altman",{"_index":3397,"text":{"Chap_7.html":{},"Chap_7.html#problem-711":{}},"title":{}}],["alway",{"_index":946,"text":{"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_4.html":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_9.html":{},"Chap_9.html#the-matched-filter":{}},"title":{}}],["amen",{"_index":3093,"text":{"Chap_7.html":{},"Chap_7.html#power-spectral-density_1":{}},"title":{}}],["amount",{"_index":250,"text":{"Chap_1.html":{},"Chap_1.html#enhanced-experience":{},"Chap_10.html":{},"Chap_10.html#laboratory-exercise-102":{},"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#laboratory-exercise-123":{},"Chap_12.html#the-periodogram-unbiased":{},"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_7.html":{},"Chap_7.html#power-spectral-density_1":{},"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{}},"title":{}}],["amp",{"_index":809,"text":{},"title":{"Chap_10.html#the-more-general-restoration-case-noise-distortion":{},"Chap_4.html#example-dice-money":{},"info.html#tips-short-cuts":{}}}],["amplif",{"_index":725,"text":{"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{}},"title":{}}],["amplifi",{"_index":3555,"text":{"Chap_9.html":{},"Chap_9.html#the-matched-filter":{}},"title":{}}],["amplitud",{"_index":1536,"text":{"Chap_12.html":{},"Chap_12.html#problem-122":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_5.html":{},"Chap_5.html#example-white-noise":{},"Chap_6.html":{},"Chap_6.html#laboratory-exercise-67":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#how-big-is-big-how-small-is-small":{},"Chap_7.html#power-spectral-density_2":{},"Chap_8.html":{},"Chap_8.html#snr-for-deterministic-signals-in-the-presence-of-noise":{},"Chap_8.html#snr-for-random-signals-in-the-presence-of-noise":{}},"title":{}}],["amsterdam",{"_index":2230,"text":{"Chap_4.html":{},"Chap_4.html#the-mechanics-of-correlations":{}},"title":{}}],["analog",{"_index":664,"text":{"Chap_10.html":{},"Chap_10.html#example-sound-of-distorted-music":{},"Chap_10.html#problem-104":{},"Chap_7.html":{},"Chap_7.html#descriptive-statistic-variance":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#problem-78":{}},"title":{}}],["analys",{"_index":1803,"text":{"Chap_2.html":{},"Chap_2.html#problem-21":{}},"title":{}}],["analysi",{"_index":792,"text":{"Chap_10.html":{},"Chap_10.html#laboratory-exercise-105":{},"Chap_11.html":{},"Chap_11.html#laboratory-exercise-113":{},"Chap_12.html":{},"Chap_12.html#laboratory-exercise-124":{},"Chap_13.html":{},"Chap_13.html#epilogue":{},"Chap_2.html":{},"Chap_2.html#prologue":{},"Chap_6.html":{},"Chap_6.html#laboratory-exercise-62":{},"Chap_7.html":{},"Chap_7.html#descriptive-statistic-variance":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#one-step-further":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#why-this-case-study":{},"Chap_9.html":{},"Chap_9.html#laboratory-exercise-93":{}},"title":{}}],["analyt",{"_index":1275,"text":{"Chap_12.html":{},"Chap_12.html#spectral-estimation":{},"Chap_3.html":{},"Chap_3.html#problem-310":{},"Chap_8.html":{},"Chap_8.html#problem-83":{}},"title":{}}],["analyz",{"_index":1136,"text":{"Chap_11.html":{},"Chap_11.html#langevin-redux":{},"Chap_12.html":{},"Chap_12.html#other-windows":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_2.html":{},"Chap_2.html#prologue":{},"Chap_6.html":{},"Chap_6.html#laboratory-exercise-61":{},"Chap_7.html":{},"Chap_7.html#from-t-to-n":{},"Chap_7.html#the-langevin-equation-a-case-study":{},"Chap_7.html#the-langevin-position-equation":{},"Chap_7.html#why-this-case-study":{}},"title":{}}],["and/or",{"_index":301,"text":{"Chap_10.html":{},"Chap_10.html#the-restoration-case-noise":{},"Chap_2.html":{},"Chap_2.html#prologue":{},"Chap_6.html":{},"Chap_6.html#laboratory-exercise-63":{},"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{}},"title":{}}],["android",{"_index":24,"text":{"Chap_1.html":{},"Chap_1.html#enhanced-experience":{},"Chap_1.html#how-to-use-this-ibook":{}},"title":{}}],["angl",{"_index":3633,"text":{"Chap_9.html":{},"Chap_9.html#laboratory-exercise-93":{}},"title":{}}],["anim",{"_index":149,"text":{"Chap_1.html":{},"Chap_1.html#at-the-movies":{},"Chap_1.html#sound-of-music":{},"Chap_9.html":{},"Chap_9.html#performance-in-the-presence-of-noise":{}},"title":{}}],["anjella",{"_index":3687,"text":{"info.html":{},"info.html#acknowledgments":{}},"title":{}}],["anoth",{"_index":1003,"text":{"Chap_11.html":{},"Chap_11.html#estimating-the-mean":{},"Chap_11.html#laboratory-exercise-111":{},"Chap_12.html":{},"Chap_12.html#windowed-observations":{},"Chap_2.html":{},"Chap_2.html#prologue":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_4.html":{},"Chap_4.html#correlation-the-workhorse":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#example-fair-chance":{},"Chap_4.html#properties-of-averaging":{},"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_6.html":{},"Chap_6.html#problem-64":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_9.html":{},"Chap_9.html#problem-92":{}},"title":{}}],["answer",{"_index":930,"text":{"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_11.html#laboratory-exercise-112":{},"Chap_3.html":{},"Chap_3.html#problem-310":{},"Chap_3.html#problem-38":{},"Chap_3.html#problem-39":{},"Chap_5.html":{},"Chap_5.html#problem-55":{},"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{},"Chap_6.html#problem-61":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function":{},"Chap_7.html#problem-71":{},"Chap_7.html#problem-78":{}},"title":{}}],["anyth",{"_index":2160,"text":{"Chap_4.html":{},"Chap_4.html#example-dice-money":{}},"title":{}}],["apach",{"_index":3711,"text":{"info.html":{},"info.html#technical-details":{}},"title":{}}],["apart",{"_index":2204,"text":{"Chap_4.html":{},"Chap_4.html#the-mechanics-of-correlations":{}},"title":{}}],["apertur",{"_index":771,"text":{"Chap_10.html":{},"Chap_10.html#laboratory-exercise-104":{}},"title":{}}],["app",{"_index":3698,"text":{"info.html":{},"info.html#technical-details":{}},"title":{}}],["appeal",{"_index":2929,"text":{"Chap_7.html":{},"Chap_7.html#the-langevin-velocity-equation":{}},"title":{}}],["appear",{"_index":1844,"text":{"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#power-spectral-density_1":{},"info.html":{},"info.html#tips-short-cuts":{}},"title":{}}],["appendic",{"_index":1593,"text":{"Chap_13.html":{}},"title":{"Chap_13.html":{},"Chap_13.html#appendices":{}}}],["appendix",{"_index":345,"text":{"Chap_10.html":{},"Chap_10.html#expressing-the-mean-square-error":{},"Chap_10.html#using-the-least-mean-square-error-criterion":{},"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_13.html":{}},"title":{"Chap_13.html#appendix-i-mean-square-error-minimization":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{}}}],["appl",{"_index":201,"text":{"Chap_1.html":{},"Chap_1.html#enhanced-experience":{},"info.html":{},"info.html#technical-details":{},"info.html#tips-short-cuts":{}},"title":{}}],["appli",{"_index":395,"text":{"Chap_10.html":{},"Chap_10.html#expressing-the-mean-square-error":{},"Chap_10.html#laboratory-exercise-103":{},"Chap_11.html":{},"Chap_11.html#estimating-the-autocorrelation-function":{},"Chap_11.html#example-estimating-the-poisson-rate":{},"Chap_12.html":{},"Chap_12.html#spectral-estimation":{},"Chap_13.html":{},"Chap_13.html#appendix-i-mean-square-error-minimization":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_4.html":{},"Chap_4.html#other-averages":{},"Chap_4.html#problem-44":{},"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{},"Chap_6.html#interpretation-of-the-convolution-result":{},"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small":{},"Chap_8.html":{},"Chap_8.html#problem-83":{},"Chap_9.html":{},"Chap_9.html#using-cauchy-schwartz":{}},"title":{}}],["applic",{"_index":467,"text":{"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#the-wiener-hopf-equation":{},"Chap_11.html":{},"Chap_11.html#laboratory-exercise-113":{},"Chap_11.html#langevin-redux":{},"Chap_12.html":{},"Chap_12.html#laboratory-exercise-124":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_13.html#epilogue":{},"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_5.html#problem-53":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_7.html":{},"Chap_7.html#expected-value":{},"Chap_7.html#problem-78":{},"Chap_7.html#why-this-case-study":{},"Chap_8.html":{},"Chap_8.html#example-filtering-noise":{},"Chap_8.html#problem-82":{}},"title":{}}],["appreci",{"_index":1058,"text":{"Chap_11.html":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_7.html":{},"Chap_7.html#descriptive-statistic-variance":{},"Chap_7.html#how-big-is-big-how-small-is-small":{},"Chap_7.html#tethered-particle-motion":{}},"title":{}}],["approach",{"_index":372,"text":{"Chap_10.html":{},"Chap_10.html#using-the-least-mean-square-error-criterion":{},"Chap_10.html#why-we-avoid-the-inverse-filter":{},"Chap_11.html":{},"Chap_11.html#estimating-the-mean":{},"Chap_11.html#maximum-likelihood-estimation":{},"Chap_11.html#trouble-in-paradise":{},"Chap_12.html":{},"Chap_12.html#windowed-observations":{},"Chap_13.html":{},"Chap_13.html#epilogue":{},"Chap_2.html":{},"Chap_2.html#prologue":{},"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{}},"title":{}}],["appropri",{"_index":1700,"text":{"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_2.html":{},"Chap_2.html#prologue":{},"Chap_5.html":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#how-big-is-big-how-small-is-small":{},"Chap_7.html#impulse-invariant-sampling":{}},"title":{}}],["approx",{"_index":580,"text":{"Chap_10.html":{},"Chap_10.html#classic-example-classic-result":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_11.html":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_4.html":{},"Chap_4.html#example-fair-chance":{},"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#power-spectral-density_2":{},"Chap_7.html#problem-710":{}},"title":{}}],["approxim",{"_index":2213,"text":{"Chap_4.html":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#how-big-is-big-how-small-is-small":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#power-spectral-density_1":{}},"title":{}}],["apr",{"_index":2210,"text":{"Chap_4.html":{},"Chap_4.html#the-mechanics-of-correlations":{}},"title":{}}],["arbitrari",{"_index":1989,"text":{"Chap_3.html":{},"Chap_3.html#problem-38":{}},"title":{}}],["area",{"_index":1868,"text":{"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_7.html":{},"Chap_7.html#why-this-case-study":{},"Chap_9.html":{},"Chap_9.html#the-matched-filter-as-an-autocorrelation":{}},"title":{}}],["argu",{"_index":2626,"text":{"Chap_6.html":{},"Chap_6.html#interpretation-of-the-convolution-result":{}},"title":{}}],["aris",{"_index":2631,"text":{"Chap_6.html":{},"Chap_6.html#interpretation-of-the-convolution-result":{}},"title":{}}],["arithmet",{"_index":828,"text":{"Chap_11.html":{},"Chap_11.html#aspects-of-estimation":{},"Chap_11.html#estimating-the-mean":{},"Chap_11.html#example-estimating-the-poisson-rate":{},"Chap_11.html#problem-117":{},"Chap_12.html":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_4.html":{},"Chap_4.html#example-fair-chance":{},"Chap_4.html#laboratory-exercise-42":{}},"title":{}}],["around",{"_index":130,"text":{"Chap_1.html":{},"Chap_12.html":{},"Chap_12.html#problem-121":{},"Chap_12.html#problem-122":{},"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{}},"title":{"Chap_1.html#getting-around":{}}}],["arriv",{"_index":2954,"text":{"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{}},"title":{}}],["arrow",{"_index":208,"text":{"Chap_1.html":{},"Chap_1.html#enhanced-experience":{},"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{},"info.html":{},"info.html#tips-short-cuts":{}},"title":{}}],["ask",{"_index":929,"text":{"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_2.html":{},"Chap_2.html#prologue":{},"Chap_4.html":{},"Chap_4.html#autocorrelation":{},"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{}},"title":{}}],["aspect",{"_index":168,"text":{"Chap_1.html":{},"Chap_1.html#at-the-movies":{},"Chap_11.html":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_12.html":{},"Chap_12.html#laboratory-exercise-121":{},"info.html":{},"info.html#contact":{}},"title":{"Chap_11.html":{},"Chap_11.html#aspects-of-estimation":{}}}],["assess",{"_index":1439,"text":{"Chap_12.html":{},"Chap_12.html#other-windows":{},"Chap_12.html#problem-122":{}},"title":{}}],["assign",{"_index":3022,"text":{"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_9.html":{},"Chap_9.html#problem-92":{}},"title":{}}],["associ",{"_index":1162,"text":{"Chap_11.html":{},"Chap_11.html#problem-115":{},"Chap_11.html#problem-117":{},"Chap_11.html#trouble-in-paradise":{},"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#problem-121":{},"Chap_12.html#problem-122":{},"Chap_12.html#windowed-observations":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_3.html#problem-38":{},"Chap_4.html":{},"Chap_4.html#autocorrelation":{},"Chap_4.html#characterization-of-random-signals":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#example-dice-money":{},"Chap_4.html#example-fair-chance":{},"Chap_4.html#example-is-that-coin-fair":{},"Chap_4.html#problem-41":{},"Chap_5.html":{},"Chap_5.html#example-delayed-effect":{},"Chap_5.html#fourier-description-of-correlation-functions":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#expected-value":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#impulse-invariant-sampling":{},"Chap_7.html#power-spectral-density":{},"Chap_7.html#problem-710":{},"Chap_7.html#tethered-particle-motion":{},"info.html":{},"info.html#cover":{},"info.html#technical-details":{}},"title":{}}],["assum",{"_index":305,"text":{"Chap_10.html":{},"Chap_10.html#example-cleaning-up-our-act":{},"Chap_10.html#example-sound-of-distorted-music":{},"Chap_10.html#problem-103":{},"Chap_10.html#the-more-general-restoration-case-noise-distortion":{},"Chap_10.html#the-restoration-case-noise":{},"Chap_11.html":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_11.html#maximum-likelihood-estimation":{},"Chap_11.html#problem-112":{},"Chap_11.html#problem-118":{},"Chap_11.html#problem-119":{},"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_3.html#introduction":{},"Chap_3.html#what-is-a-random-signal":{},"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#example-dice-money":{},"Chap_4.html#example-is-that-coin-fair":{},"Chap_4.html#problem-47":{},"Chap_5.html":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{},"Chap_6.html#filtering-of-stochastic-signals":{},"Chap_6.html#interpretation-of-the-convolution-result":{},"Chap_7.html":{},"Chap_7.html#expected-value":{},"Chap_8.html":{},"Chap_8.html#snr-for-random-signals-in-the-presence-of-noise":{},"Chap_9.html":{},"Chap_9.html#problem-91":{},"Chap_9.html#setting-up-the-problem":{}},"title":{}}],["assumpt",{"_index":391,"text":{"Chap_10.html":{},"Chap_10.html#expressing-the-mean-square-error":{},"Chap_10.html#laboratory-exercise-105":{},"Chap_11.html":{},"Chap_11.html#estimating-the-mean":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_11.html#langevin-redux":{},"Chap_12.html":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_4.html":{},"Chap_4.html#example-is-that-coin-fair":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_5.html":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{},"Chap_7.html":{},"Chap_7.html#the-langevin-equation-a-case-study":{},"Chap_8.html":{},"Chap_8.html#example-not-too-noisy":{},"Chap_8.html#snr-for-random-signals-in-the-presence-of-noise":{}},"title":{}}],["assur",{"_index":392,"text":{"Chap_10.html":{},"Chap_10.html#expressing-the-mean-square-error":{}},"title":{}}],["astronomi",{"_index":1833,"text":{"Chap_3.html":{},"Chap_3.html#what-is-a-random-signal":{}},"title":{}}],["asymptot",{"_index":1012,"text":{"Chap_11.html":{},"Chap_11.html#estimating-the-mean":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{}},"title":{}}],["atom",{"_index":2311,"text":{"Chap_4.html":{},"Chap_4.html#problem-42":{},"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{}},"title":{}}],["attach",{"_index":3142,"text":{"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#tethered-particle-motion":{}},"title":{}}],["attain",{"_index":2708,"text":{"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_9.html":{},"Chap_9.html#using-cauchy-schwartz":{}},"title":{}}],["attempt",{"_index":297,"text":{"Chap_10.html":{},"Chap_10.html#the-restoration-case-noise":{},"Chap_13.html":{},"Chap_13.html#epilogue":{},"Chap_8.html":{},"Chap_8.html#example-filtering-noise":{},"Chap_9.html":{},"Chap_9.html#the-matched-filter":{}},"title":{}}],["attent",{"_index":3194,"text":{"Chap_7.html":{},"Chap_7.html#tethered-particle-motion":{},"Chap_8.html":{},"Chap_8.html#example-filtering-noise":{}},"title":{}}],["attenu",{"_index":582,"text":{"Chap_10.html":{},"Chap_10.html#classic-example-classic-result":{}},"title":{}}],["attest",{"_index":2742,"text":{"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{}},"title":{}}],["audio",{"_index":38,"text":{"Chap_1.html":{},"Chap_1.html#how-to-use-this-ibook":{},"Chap_1.html#sound-of-music":{},"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#example-sound-of-distorted-music":{},"Chap_10.html#problem-104":{},"info.html":{},"info.html#musical-data":{}},"title":{}}],["aug",{"_index":2729,"text":{"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{}},"title":{}}],["august",{"_index":2196,"text":{"Chap_4.html":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{}},"title":{}}],["author",{"_index":1786,"text":{"Chap_2.html":{},"Chap_2.html#prologue":{},"info.html":{},"info.html#authors":{},"info.html#usage":{}},"title":{"info.html#authors":{}}}],["auto",{"_index":2241,"text":{"Chap_4.html":{},"Chap_4.html#auto-covariance":{},"Chap_5.html":{},"Chap_5.html#correlations-simple-and-complex":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_6.html":{},"Chap_6.html#problem-63":{}},"title":{"Chap_4.html#auto-covariance":{}}}],["autocorrel",{"_index":505,"text":{"Chap_10.html":{},"Chap_10.html#problem-103":{},"Chap_10.html#what-is-that-least-mean-square-error":{},"Chap_11.html":{},"Chap_11.html#estimating-the-autocorrelation-function":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_11.html#laboratory-exercise-113":{},"Chap_11.html#langevin-redux":{},"Chap_11.html#problem-118":{},"Chap_11.html#problem-119":{},"Chap_11.html#trouble-in-paradise":{},"Chap_12.html":{},"Chap_12.html#spectral-estimation":{},"Chap_4.html":{},"Chap_4.html#autocorrelation":{},"Chap_4.html#correlation-the-workhorse":{},"Chap_4.html#describing-the-time-average":{},"Chap_4.html#example-is-that-coin-fair":{},"Chap_4.html#the-ergodic-process":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#correlations-simple-and-complex":{},"Chap_5.html#example-delayed-effect":{},"Chap_5.html#example-pink-noise":{},"Chap_5.html#example-white-noise":{},"Chap_5.html#fourier-description-of-correlation-functions":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_5.html#problem-54":{},"Chap_5.html#problem-56":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{},"Chap_6.html#filtering-of-stochastic-signals":{},"Chap_6.html#interpretation-of-the-convolution-result":{},"Chap_6.html#laboratory-exercise-63":{},"Chap_6.html#laboratory-exercise-67":{},"Chap_6.html#problem-64":{},"Chap_6.html#the-autocorrelation-function":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function":{},"Chap_7.html#autocorrelation-function_1":{},"Chap_7.html#autocorrelation-function_2":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#power-spectral-density":{},"Chap_7.html#power-spectral-density_2":{},"Chap_7.html#problem-73":{},"Chap_7.html#problem-74":{},"Chap_7.html#the-langevin-equation-a-case-study":{},"Chap_7.html#why-this-case-study":{},"Chap_8.html":{},"Chap_8.html#problem-81":{},"Chap_8.html#problem-83":{},"Chap_8.html#snr-for-random-signals-in-the-presence-of-noise":{},"Chap_9.html":{},"Chap_9.html#the-matched-filter-as-an-autocorrelation":{},"info.html":{},"info.html#cover":{}},"title":{"Chap_11.html#estimating-the-autocorrelation-function":{},"Chap_4.html#autocorrelation":{},"Chap_6.html#the-autocorrelation-function":{},"Chap_7.html#autocorrelation-function":{},"Chap_7.html#autocorrelation-function_1":{},"Chap_7.html#autocorrelation-function_2":{},"Chap_9.html#the-matched-filter-as-an-autocorrelation":{}}}],["automat",{"_index":1705,"text":{"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{}},"title":{}}],["automobil",{"_index":2722,"text":{"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{}},"title":{}}],["avail",{"_index":210,"text":{"Chap_1.html":{},"Chap_1.html#enhanced-experience":{},"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_11.html":{},"Chap_11.html#estimating-the-autocorrelation-function":{},"Chap_12.html":{},"Chap_12.html#laboratory-exercise-122":{},"Chap_12.html#laboratory-exercise-124":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_3.html#what-is-a-random-signal":{},"Chap_4.html":{},"Chap_4.html#properties-of-averaging":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_9.html":{},"Chap_9.html#the-matched-filter":{}},"title":{}}],["averag",{"_index":927,"text":{"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_11.html#estimating-the-autocorrelation-function":{},"Chap_11.html#example-estimating-the-poisson-rate":{},"Chap_12.html":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_3.html":{},"Chap_3.html#what-is-a-random-signal":{},"Chap_4.html":{},"Chap_4.html#characterization-of-random-signals":{},"Chap_4.html#correlation-the-workhorse":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#describing-the-time-average":{},"Chap_4.html#example-average-experience":{},"Chap_4.html#example-dice-money":{},"Chap_4.html#example-fair-chance":{},"Chap_4.html#example-is-that-coin-fair":{},"Chap_4.html#other-averages":{},"Chap_4.html#problem-44":{},"Chap_4.html#properties-of-averaging":{},"Chap_4.html#the-ergodic-process":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_5.html":{},"Chap_5.html#example-pink-noise":{},"Chap_5.html#laboratory-exercise-51":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_6.html#the-mean":{},"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#expected-value":{},"Chap_7.html#how-big-is-big-how-small-is-small":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#the-langevin-velocity-equation":{},"Chap_8.html":{},"Chap_8.html#snr-for-random-signals-in-the-presence-of-noise":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{},"info.html":{},"info.html#cover":{}},"title":{"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#describing-the-time-average":{},"Chap_4.html#example-average-experience":{},"Chap_4.html#other-averages":{},"Chap_4.html#properties-of-averaging":{}}}],["average\u2014ani",{"_index":2297,"text":{"Chap_4.html":{},"Chap_4.html#the-ergodic-process":{}},"title":{}}],["average\u2014just",{"_index":2938,"text":{"Chap_7.html":{},"Chap_7.html#the-langevin-velocity-equation":{}},"title":{}}],["average\u2014wheth",{"_index":2298,"text":{"Chap_4.html":{},"Chap_4.html#the-ergodic-process":{}},"title":{}}],["avoid",{"_index":611,"text":{"Chap_10.html":{},"Chap_10.html#why-we-avoid-the-inverse-filter":{},"Chap_5.html":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#choosing-the-sampling-period_1":{}},"title":{"Chap_10.html#why-we-avoid-the-inverse-filter":{}}}],["away",{"_index":3155,"text":{"Chap_7.html":{},"Chap_7.html#tethered-particle-motion":{}},"title":{}}],["ax",{"_index":2912,"text":{"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#choosing-the-sampling-period_1":{}},"title":{}}],["ax[n",{"_index":2163,"text":{"Chap_4.html":{},"Chap_4.html#properties-of-averaging":{}},"title":{}}],["axi",{"_index":1520,"text":{"Chap_12.html":{},"Chap_12.html#problem-121":{},"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{}},"title":{}}],["axial",{"_index":2875,"text":{"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small":{}},"title":{}}],["a{{\\left",{"_index":2303,"text":{"Chap_4.html":{},"Chap_4.html#problem-41":{}},"title":{}}],["b",{"_index":586,"text":{"Chap_10.html":{},"Chap_10.html#classic-example-classic-result":{},"Chap_10.html#problem-102":{},"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_11.html#estimating-the-mean":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_11.html#problem-115":{},"Chap_11.html#problem-116":{},"Chap_11.html#problem-117":{},"Chap_12.html":{},"Chap_12.html#the-periodogram-unbiased":{},"Chap_13.html":{},"Chap_13.html#epilogue":{},"Chap_4.html":{},"Chap_4.html#laboratory-exercise-42":{},"Chap_4.html#problem-44":{},"Chap_5.html":{},"Chap_5.html#example-pink-noise":{},"Chap_5.html#laboratory-exercise-51":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#power-spectral-density":{},"Chap_7.html#power-spectral-density_2":{},"Chap_7.html#problem-711":{},"Chap_8.html":{},"Chap_8.html#problem-83":{},"Chap_9.html":{},"Chap_9.html#laboratory-exercise-93":{},"Chap_9.html#problem-91":{}},"title":{}}],["b(\\omega",{"_index":1300,"text":{"Chap_12.html":{},"Chap_12.html#the-periodogram-unbiased":{}},"title":{}}],["b>0",{"_index":1962,"text":{"Chap_3.html":{},"Chap_3.html#problem-34":{}},"title":{}}],["b[n",{"_index":3532,"text":{"Chap_8.html":{},"Chap_8.html#problem-83":{}},"title":{}}],["b\\,e\\left",{"_index":2178,"text":{"Chap_4.html":{},"Chap_4.html#properties-of-averaging":{}},"title":{}}],["b\\,{x_2",{"_index":2177,"text":{"Chap_4.html":{},"Chap_4.html#properties-of-averaging":{}},"title":{}}],["b\\delta",{"_index":2710,"text":{"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{}},"title":{}}],["b\\in\\mathbb{r}\\text",{"_index":1961,"text":{"Chap_3.html":{},"Chap_3.html#problem-34":{}},"title":{}}],["b^2}(\\theta",{"_index":1196,"text":{"Chap_11.html":{},"Chap_11.html#problem-116":{}},"title":{}}],["b_i}(\\omega",{"_index":1405,"text":{"Chap_12.html":{},"Chap_12.html#the-periodogram-what-about-convergence":{}},"title":{}}],["b_p}(\\omega",{"_index":1410,"text":{"Chap_12.html":{},"Chap_12.html#the-periodogram-what-about-convergence":{}},"title":{}}],["bacal",{"_index":183,"text":{"Chap_1.html":{},"Chap_1.html#at-the-movies":{}},"title":{}}],["back",{"_index":2308,"text":{"Chap_4.html":{},"Chap_4.html#problem-42":{},"Chap_7.html":{},"Chap_7.html#expected-value":{},"Chap_7.html#the-langevin-equation-a-case-study":{}},"title":{}}],["background",{"_index":92,"text":{"Chap_1.html":{},"Chap_1.html#highlighting":{}},"title":{}}],["backward",{"_index":2815,"text":{"Chap_7.html":{},"Chap_7.html#from-t-to-n":{}},"title":{}}],["balanc",{"_index":2081,"text":{"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_7.html":{},"Chap_7.html#problem-710":{}},"title":{}}],["band",{"_index":568,"text":{"Chap_10.html":{},"Chap_10.html#classic-example-classic-result":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#example-sound-of-distorted-music":{},"Chap_10.html#why-we-avoid-the-inverse-filter":{},"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{}},"title":{}}],["bandlimit",{"_index":1694,"text":{"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#impulse-invariant-sampling":{}},"title":{}}],["bandpass",{"_index":628,"text":{"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#why-we-avoid-the-inverse-filter":{},"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{}},"title":{}}],["bandwidth",{"_index":1365,"text":{"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#other-windows":{},"Chap_12.html#problem-122":{},"Chap_12.html#windowed-observations":{},"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{}},"title":{}}],["bang",{"_index":1589,"text":{"Chap_12.html":{},"Chap_12.html#laboratory-exercise-124":{}},"title":{}}],["bar",{"_index":263,"text":{"Chap_1.html":{},"Chap_1.html#enhanced-experience":{},"Chap_4.html":{},"Chap_4.html#laboratory-exercise-41":{},"Chap_7.html":{},"Chap_7.html#tethered-particle-motion":{},"info.html":{},"info.html#tips-short-cuts":{}},"title":{}}],["barrel",{"_index":2716,"text":{"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{}},"title":{}}],["bartlett",{"_index":1043,"text":{"Chap_11.html":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_11.html#laboratory-exercise-113":{},"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#other-windows":{},"Chap_12.html#problem-121":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_12.html#windowed-observations":{}},"title":{}}],["bartlett\u2019",{"_index":1395,"text":{"Chap_12.html":{},"Chap_12.html#the-periodogram-what-about-convergence":{}},"title":{}}],["base",{"_index":379,"text":{"Chap_10.html":{},"Chap_10.html#example-sound-of-distorted-music":{},"Chap_10.html#expressing-the-mean-square-error":{},"Chap_11.html":{},"Chap_11.html#estimating-the-mean":{},"Chap_11.html#langevin-redux":{},"Chap_11.html#problem-116":{},"Chap_11.html#problem-117":{},"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#the-periodogram-unbiased":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_4.html":{},"Chap_4.html#characterization-of-random-signals":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#example-average-experience":{},"Chap_4.html#example-dice-money":{},"Chap_4.html#example-fair-chance":{},"Chap_4.html#laboratory-exercise-41":{},"Chap_4.html#problem-49":{},"Chap_4.html#properties-of-averaging":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_5.html":{},"Chap_5.html#correlations-simple-and-complex":{},"Chap_5.html#problem-52":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_6.html":{},"Chap_6.html#laboratory-exercise-63":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#from-t-to-n":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#one-step-further":{},"Chap_7.html#problem-711":{},"Chap_7.html#the-langevin-velocity-equation":{},"Chap_9.html":{},"Chap_9.html#problem-91":{}},"title":{}}],["baseband",{"_index":1653,"text":{"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_3.html":{},"Chap_3.html#problem-32":{},"Chap_3.html#problem-39":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_7.html":{},"Chap_7.html#power-spectral-density":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#power-spectral-density_2":{},"Chap_8.html":{},"Chap_8.html#problem-83":{}},"title":{}}],["basepair",{"_index":3206,"text":{"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{}},"title":{}}],["basi",{"_index":1078,"text":{"Chap_11.html":{},"Chap_11.html#langevin-redux":{},"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{}},"title":{}}],["basic",{"_index":343,"text":{"Chap_10.html":{},"Chap_10.html#using-the-least-mean-square-error-criterion":{},"Chap_12.html":{},"Chap_12.html#spectral-estimation":{},"Chap_12.html#the-periodogram-unbiased":{},"Chap_13.html":{},"Chap_13.html#epilogue":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_3.html#what-is-a-random-signal":{},"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_6.html":{},"Chap_6.html#interpretation-of-the-convolution-result":{},"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{}},"title":{"Chap_3.html#the-basics":{}}}],["bath",{"_index":2868,"text":{"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#how-big-is-big-how-small-is-small":{}},"title":{}}],["batter",{"_index":2860,"text":{"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#how-big-is-big-how-small-is-small":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{}},"title":{}}],["bbb",{"_index":2107,"text":{"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{}},"title":{}}],["be",{"_index":13,"text":{"Chap_1.html":{},"Chap_1.html#highlighting":{},"Chap_1.html#how-to-use-this-ibook":{},"Chap_12.html":{},"Chap_12.html#the-periodogram-unbiased":{},"Chap_12.html#windowed-observations":{},"Chap_2.html":{},"Chap_2.html#prologue":{},"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{},"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{},"Chap_9.html":{},"Chap_9.html#problem-92":{}},"title":{}}],["bead",{"_index":3198,"text":{"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{}},"title":{}}],["bear",{"_index":3434,"text":{"Chap_8.html":{},"Chap_8.html#snr-for-random-signals-in-the-presence-of-noise":{}},"title":{}}],["becom",{"_index":298,"text":{"Chap_10.html":{},"Chap_10.html#problem-102":{},"Chap_10.html#the-restoration-case-noise":{},"Chap_10.html#what-is-that-least-mean-square-error":{},"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_11.html#langevin-redux":{},"Chap_11.html#problem-1110":{},"Chap_11.html#problem-117":{},"Chap_12.html":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_5.html":{},"Chap_5.html#correlations-and-memory":{},"Chap_5.html#problem-52":{},"Chap_7.html":{},"Chap_7.html#descriptive-statistic-variance":{},"Chap_7.html#problem-711":{}},"title":{}}],["befor",{"_index":607,"text":{"Chap_10.html":{},"Chap_10.html#the-more-general-restoration-case-noise-distortion":{},"Chap_12.html":{},"Chap_12.html#laboratory-exercise-124":{},"Chap_13.html":{},"Chap_13.html#epilogue":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#power-spectral-density_1":{},"Chap_9.html":{},"Chap_9.html#problem-92":{}},"title":{}}],["begin",{"_index":808,"text":{"Chap_10.html":{},"Chap_10.html#laboratory-exercise-105":{},"Chap_11.html":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_12.html":{},"Chap_12.html#spectral-estimation":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_3.html":{},"Chap_3.html#what-is-a-random-signal":{},"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_6.html":{},"Chap_6.html#filtering-of-stochastic-signals":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_7.html":{},"Chap_7.html#the-langevin-equation-a-case-study":{},"Chap_7.html#the-langevin-velocity-equation":{},"Chap_8.html":{},"Chap_8.html#example-filtering-noise":{},"Chap_8.html#snr-for-random-signals-in-the-presence-of-noise":{}},"title":{}}],["begin{align",{"_index":97,"text":{"Chap_1.html":{},"Chap_1.html#highlighting":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_3.html#the-basics":{}},"title":{}}],["begin{aligned}\\sigma_v^2",{"_index":2985,"text":{"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{}},"title":{}}],["begin{aligned}\\sigma_x^2",{"_index":3115,"text":{"Chap_7.html":{},"Chap_7.html#power-spectral-density_1":{}},"title":{}}],["begin{aligned}x[n]&=\\alpha^n",{"_index":1934,"text":{"Chap_3.html":{},"Chap_3.html#problem-33":{}},"title":{}}],["begin{array}{*{20}{c",{"_index":1326,"text":{"Chap_12.html":{},"Chap_12.html#windowed-observations":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_8.html":{},"Chap_8.html#problem-83":{}},"title":{}}],["begin{array}{*{20}{l",{"_index":348,"text":{"Chap_10.html":{},"Chap_10.html#classic-example-classic-result":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#expressing-the-mean-square-error":{},"Chap_10.html#using-the-least-mean-square-error-criterion":{},"Chap_10.html#what-is-that-least-mean-square-error":{},"Chap_11.html":{},"Chap_11.html#example-estimating-the-poisson-rate":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_11.html#langevin-redux":{},"Chap_11.html#problem-119":{},"Chap_11.html#trouble-in-paradise":{},"Chap_12.html":{},"Chap_12.html#problem-123":{},"Chap_12.html#the-periodogram-unbiased":{},"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_4.html":{},"Chap_4.html#auto-covariance":{},"Chap_4.html#autocorrelation":{},"Chap_4.html#cross-correlation":{},"Chap_4.html#cross-covariance":{},"Chap_4.html#describing-the-time-average":{},"Chap_4.html#example-dice-money":{},"Chap_4.html#example-is-that-coin-fair":{},"Chap_4.html#problem-41":{},"Chap_4.html#properties-of-averaging":{},"Chap_4.html#the-ergodic-process":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#correlations-simple-and-complex":{},"Chap_5.html#example-delayed-effect":{},"Chap_5.html#example-pink-noise":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{},"Chap_6.html#filtering-of-stochastic-signals":{},"Chap_6.html#problem-61":{},"Chap_6.html#problem-63":{},"Chap_6.html#the-autocorrelation-function":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_6.html#the-mean":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#expected-value":{},"Chap_7.html#expected-value_1":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#power-spectral-density":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#tethered-particle-motion":{},"Chap_7.html#the-langevin-position-equation":{},"Chap_7.html#the-langevin-velocity-equation":{},"Chap_8.html":{},"Chap_8.html#example-cocktail-party-noise":{},"Chap_8.html#example-not-too-noisy":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{},"Chap_9.html":{},"Chap_9.html#example-matching-your-filter":{},"Chap_9.html#setting-up-the-problem":{}},"title":{}}],["begin{array}{l",{"_index":427,"text":{"Chap_10.html":{},"Chap_10.html#correlation-returns":{},"Chap_11.html":{},"Chap_11.html#langevin-redux":{},"Chap_12.html":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_4.html":{},"Chap_4.html#cross-covariance":{},"Chap_4.html#other-averages":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#correlations-and-memory":{},"Chap_5.html#correlations-simple-and-complex":{},"Chap_5.html#problem-56":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_6.html":{},"Chap_6.html#filtering-of-stochastic-signals":{},"Chap_6.html#the-autocorrelation-function":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function_2":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#descriptive-statistic-variance":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#impulse-invariant-sampling":{},"Chap_7.html#one-step-further":{},"Chap_7.html#the-langevin-equation-a-case-study":{},"Chap_7.html#the-langevin-position-equation":{},"Chap_7.html#the-langevin-velocity-equation":{},"Chap_8.html":{},"Chap_8.html#example-filtering-noise":{}},"title":{}}],["begin{cas",{"_index":1862,"text":{"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_3.html#problem-310":{}},"title":{}}],["begun",{"_index":1133,"text":{"Chap_11.html":{},"Chap_11.html#langevin-redux":{}},"title":{}}],["behav",{"_index":1378,"text":{"Chap_12.html":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function_2":{},"Chap_7.html#power-spectral-density_1":{}},"title":{}}],["behavior",{"_index":617,"text":{"Chap_10.html":{},"Chap_10.html#why-we-avoid-the-inverse-filter":{},"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_11.html#langevin-redux":{},"Chap_12.html":{},"Chap_12.html#windowed-observations":{},"Chap_4.html":{},"Chap_4.html#correlation-the-workhorse":{},"Chap_4.html#example-dice-money":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_7.html":{},"Chap_7.html#one-step-further":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#tethered-particle-motion":{}},"title":{}}],["behaviour",{"_index":1802,"text":{"Chap_2.html":{},"Chap_2.html#problem-21":{}},"title":{}}],["believ",{"_index":1713,"text":{"Chap_13.html":{},"Chap_13.html#epilogue":{}},"title":{}}],["below",{"_index":1310,"text":{"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#the-periodogram-unbiased":{},"Chap_3.html":{},"Chap_3.html#problem-310":{},"Chap_3.html#problem-32":{},"Chap_3.html#problem-33":{},"Chap_3.html#problem-34":{},"Chap_3.html#the-basics":{},"Chap_5.html":{},"Chap_5.html#correlations-simple-and-complex":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_6.html":{},"Chap_6.html#interpretation-of-the-convolution-result":{},"Chap_6.html#problem-63":{},"Chap_7.html":{},"Chap_7.html#the-langevin-velocity-equation":{},"Chap_8.html":{},"Chap_8.html#problem-83":{},"Chap_9.html":{},"Chap_9.html#example-matching-your-filter":{},"info.html":{},"info.html#tips-short-cuts":{}},"title":{}}],["bend",{"_index":3231,"text":{"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{}},"title":{}}],["benzin",{"_index":2724,"text":{"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{}},"title":{}}],["best",{"_index":303,"text":{"Chap_10.html":{},"Chap_10.html#the-restoration-case-noise":{},"Chap_11.html":{},"Chap_11.html#problem-115":{},"Chap_12.html":{},"Chap_12.html#other-windows":{},"Chap_13.html":{},"Chap_13.html#epilogue":{}},"title":{}}],["bet",{"_index":1839,"text":{"Chap_3.html":{},"Chap_3.html#problem-37":{},"Chap_3.html#what-is-a-random-signal":{}},"title":{"Chap_3.html#example-dont-bet-on-it":{}}}],["beta",{"_index":1938,"text":{"Chap_3.html":{},"Chap_3.html#problem-33":{},"Chap_4.html":{},"Chap_4.html#problem-42":{},"Chap_8.html":{},"Chap_8.html#example-cocktail-party-noise":{}},"title":{}}],["beta)=p_{x}(\\alpha)p_{y}(\\beta",{"_index":1898,"text":{"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{}},"title":{}}],["better",{"_index":559,"text":{"Chap_10.html":{},"Chap_10.html#classic-example-classic-result":{},"Chap_11.html":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_12.html":{},"Chap_12.html#problem-122":{},"Chap_7.html":{},"Chap_7.html#expected-value":{},"Chap_9.html":{},"Chap_9.html#laboratory-exercise-92":{}},"title":{}}],["between",{"_index":325,"text":{"Chap_10.html":{},"Chap_10.html#correlation-returns":{},"Chap_10.html#problem-104":{},"Chap_10.html#the-more-general-restoration-case-noise-distortion":{},"Chap_10.html#the-restoration-case-noise":{},"Chap_10.html#the-wiener-hopf-equation":{},"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_11.html#estimating-the-autocorrelation-function":{},"Chap_11.html#problem-114":{},"Chap_11.html#trouble-in-paradise":{},"Chap_12.html":{},"Chap_12.html#problem-121":{},"Chap_12.html#problem-122":{},"Chap_12.html#problem-123":{},"Chap_12.html#windowed-observations":{},"Chap_13.html":{},"Chap_13.html#appendix-i-mean-square-error-minimization":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_3.html#what-is-a-random-signal":{},"Chap_4.html":{},"Chap_4.html#cross-covariance":{},"Chap_4.html#describing-the-time-average":{},"Chap_4.html#problem-42":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_5.html":{},"Chap_5.html#correlations-and-memory":{},"Chap_5.html#correlations-simple-and-complex":{},"Chap_5.html#example-pink-noise":{},"Chap_5.html#laboratory-exercise-51":{},"Chap_5.html#problem-55":{},"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{},"Chap_6.html#filtering-of-stochastic-signals":{},"Chap_6.html#interpretation-of-the-convolution-result":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#descriptive-statistic-variance":{},"Chap_7.html#how-big-is-big-how-small-is-small":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#power-spectral-density_2":{},"Chap_7.html#problem-73":{},"Chap_7.html#problem-77":{},"Chap_7.html#problem-78":{},"Chap_8.html":{},"Chap_8.html#example-filtering-noise":{},"Chap_8.html#problem-82":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{},"Chap_9.html":{},"Chap_9.html#laboratory-exercise-93":{},"Chap_9.html#problem-92":{},"Chap_9.html#the-matched-filter-as-an-autocorrelation":{}},"title":{}}],["beyond",{"_index":461,"text":{"Chap_10.html":{},"Chap_10.html#the-wiener-hopf-equation":{}},"title":{}}],["bf{a",{"_index":3635,"text":{"Chap_9.html":{},"Chap_9.html#laboratory-exercise-93":{}},"title":{}}],["bf{b",{"_index":3636,"text":{"Chap_9.html":{},"Chap_9.html#laboratory-exercise-93":{}},"title":{}}],["bf{e",{"_index":1614,"text":{"Chap_13.html":{},"Chap_13.html#appendix-i-mean-square-error-minimization":{}},"title":{}}],["bf{r",{"_index":1612,"text":{"Chap_13.html":{},"Chap_13.html#appendix-i-mean-square-error-minimization":{}},"title":{}}],["bf{x",{"_index":1616,"text":{"Chap_13.html":{},"Chap_13.html#appendix-i-mean-square-error-minimization":{}},"title":{}}],["bf{x}}_{\\bf{e",{"_index":1615,"text":{"Chap_13.html":{},"Chap_13.html#appendix-i-mean-square-error-minimization":{}},"title":{}}],["bia",{"_index":937,"text":{"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_11.html#estimating-the-mean":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_11.html#problem-116":{},"Chap_11.html#problem-117":{},"Chap_12.html":{},"Chap_12.html#spectral-estimation":{},"Chap_12.html#the-periodogram-unbiased":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_12.html#windowed-observations":{}},"title":{}}],["bias",{"_index":1156,"text":{"Chap_11.html":{},"Chap_11.html#trouble-in-paradise":{},"Chap_12.html":{},"Chap_12.html#the-periodogram-unbiased":{}},"title":{}}],["biased\u2014an",{"_index":1010,"text":{"Chap_11.html":{},"Chap_11.html#estimating-the-mean":{}},"title":{}}],["big",{"_index":1588,"text":{"Chap_12.html":{},"Chap_12.html#laboratory-exercise-124":{},"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{}},"title":{"Chap_7.html#how-big-is-big-how-small-is-small":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{}}}],["bilinear",{"_index":2816,"text":{"Chap_7.html":{},"Chap_7.html#from-t-to-n":{}},"title":{}}],["bilt",{"_index":2548,"text":{"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"info.html":{},"info.html#cover":{}},"title":{}}],["binari",{"_index":2783,"text":{"Chap_6.html":{},"Chap_6.html#laboratory-exercise-62":{}},"title":{}}],["bind",{"_index":3360,"text":{"Chap_7.html":{},"Chap_7.html#one-step-further":{}},"title":{}}],["bio)phys",{"_index":3370,"text":{"Chap_7.html":{},"Chap_7.html#why-this-case-study":{}},"title":{}}],["biolog",{"_index":3489,"text":{"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{}},"title":{}}],["biomolecular",{"_index":3242,"text":{"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{}},"title":{}}],["biophys",{"_index":3128,"text":{"Chap_7.html":{},"Chap_7.html#tethered-particle-motion":{}},"title":{}}],["bit",{"_index":3586,"text":{"Chap_9.html":{},"Chap_9.html#example-matching-your-filter":{}},"title":{}}],["bivari",{"_index":2220,"text":{"Chap_4.html":{},"Chap_4.html#the-mechanics-of-correlations":{}},"title":{}}],["black",{"_index":3243,"text":{"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{}},"title":{}}],["block",{"_index":1330,"text":{"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#other-windows":{},"Chap_12.html#problem-121":{},"Chap_12.html#problem-122":{},"Chap_12.html#windowed-observations":{},"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{}},"title":{}}],["blow",{"_index":1146,"text":{"Chap_11.html":{},"Chap_11.html#trouble-in-paradise":{}},"title":{}}],["blue",{"_index":591,"text":{"Chap_10.html":{},"Chap_10.html#classic-example-classic-result":{},"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_11.html#langevin-redux":{},"Chap_12.html":{},"Chap_12.html#problem-121":{},"Chap_12.html#problem-122":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#power-spectral-density":{},"Chap_7.html#tethered-particle-motion":{},"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{}},"title":{}}],["blur",{"_index":599,"text":{"Chap_10.html":{},"Chap_10.html#the-more-general-restoration-case-noise-distortion":{}},"title":{}}],["bo",{"_index":825,"text":{"Chap_11.html":{},"Chap_11.html#aspects-of-estimation":{},"Chap_11.html#laboratory-exercise-113":{}},"title":{}}],["board",{"_index":986,"text":{"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{}},"title":{}}],["bode",{"_index":3241,"text":{"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_8.html":{},"Chap_8.html#snr-for-deterministic-signals-in-the-presence-of-noise":{}},"title":{}}],["bodi",{"_index":2082,"text":{"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{}},"title":{}}],["bogart",{"_index":181,"text":{"Chap_1.html":{},"Chap_1.html#at-the-movies":{}},"title":{}}],["boltzmann",{"_index":3016,"text":{"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#one-step-further":{}},"title":{}}],["book",{"_index":1719,"text":{"Chap_13.html":{},"Chap_13.html#epilogue":{},"Chap_4.html":{},"Chap_4.html#characterization-of-random-signals":{},"info.html":{},"info.html#authors":{},"info.html#copyright":{},"info.html#tips-short-cuts":{}},"title":{}}],["both",{"_index":40,"text":{"Chap_1.html":{},"Chap_1.html#highlighting":{},"Chap_1.html#how-to-use-this-ibook":{},"Chap_10.html":{},"Chap_10.html#as-seen-from-the-fourier-domain":{},"Chap_10.html#classic-example-classic-result":{},"Chap_10.html#correlation-returns":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#problem-102":{},"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_12.html":{},"Chap_12.html#the-periodogram-unbiased":{},"Chap_12.html#windowed-observations":{},"Chap_13.html":{},"Chap_13.html#appendix-i-mean-square-error-minimization":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_2.html":{},"Chap_2.html#prologue":{},"Chap_3.html":{},"Chap_3.html#what-is-a-random-signal":{},"Chap_4.html":{},"Chap_4.html#describing-the-time-average":{},"Chap_4.html#example-dice-money":{},"Chap_4.html#problem-44":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#correlations-and-spectra":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#power-spectral-density_2":{},"Chap_7.html#the-langevin-equation-a-case-study":{},"Chap_8.html":{},"Chap_8.html#snr-for-random-signals-in-the-presence-of-noise":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{},"Chap_9.html":{},"Chap_9.html#the-classic-example":{},"Chap_9.html#the-matched-filter":{},"info.html":{},"info.html#technical-details":{}},"title":{}}],["bottom",{"_index":633,"text":{"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#example-cleaning-up-our-act":{},"Chap_10.html#why-we-avoid-the-inverse-filter":{},"Chap_11.html":{},"Chap_11.html#estimating-the-autocorrelation-function":{},"Chap_12.html":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_12.html#windowed-observations":{},"Chap_4.html":{},"Chap_4.html#example-is-that-coin-fair":{},"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{},"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{},"Chap_9.html":{},"Chap_9.html#example-matching-your-filter":{},"Chap_9.html#performance-in-the-presence-of-noise":{},"info.html":{},"info.html#tips-short-cuts":{}},"title":{}}],["bound",{"_index":1144,"text":{"Chap_11.html":{},"Chap_11.html#trouble-in-paradise":{},"Chap_12.html":{},"Chap_12.html#problem-122":{},"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{}},"title":{}}],["bowl",{"_index":3612,"text":{"Chap_9.html":{},"Chap_9.html#problem-92":{}},"title":{}}],["box",{"_index":2309,"text":{"Chap_4.html":{},"Chap_4.html#problem-42":{}},"title":{}}],["bp",{"_index":3205,"text":{"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{}},"title":{}}],["brace",{"_index":1304,"text":{"Chap_12.html":{},"Chap_12.html#the-periodogram-unbiased":{},"Chap_6.html":{},"Chap_6.html#the-autocorrelation-function":{},"Chap_6.html#the-cross-correlation-function":{}},"title":{}}],["brent",{"_index":2718,"text":{"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{}},"title":{}}],["bridg",{"_index":1243,"text":{"Chap_11.html":{},"Chap_11.html#laboratory-exercise-113":{}},"title":{}}],["brief",{"_index":164,"text":{"Chap_1.html":{},"Chap_1.html#sound-of-music":{}},"title":{}}],["briefli",{"_index":2369,"text":{"Chap_4.html":{},"Chap_4.html#laboratory-exercise-42":{}},"title":{}}],["bright",{"_index":2368,"text":{"Chap_4.html":{},"Chap_4.html#laboratory-exercise-42":{},"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{}},"title":{}}],["bring",{"_index":2428,"text":{"Chap_5.html":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_7.html":{},"Chap_7.html#expected-value":{}},"title":{}}],["broad",{"_index":3554,"text":{"Chap_9.html":{},"Chap_9.html#the-matched-filter":{}},"title":{}}],["bronshtein",{"_index":3396,"text":{"Chap_7.html":{},"Chap_7.html#problem-711":{}},"title":{}}],["brooks/col",{"_index":1737,"text":{"Chap_13.html":{},"Chap_13.html#epilogue":{}},"title":{}}],["brother",{"_index":178,"text":{"Chap_1.html":{},"Chap_1.html#at-the-movies":{}},"title":{}}],["brownian",{"_index":2806,"text":{"Chap_7.html":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#the-langevin-equation-a-case-study":{},"Chap_7.html#the-langevin-position-equation":{},"Chap_8.html":{},"Chap_8.html#problem-83":{}},"title":{}}],["browser",{"_index":58,"text":{"Chap_1.html":{},"Chap_1.html#how-to-use-this-ibook":{},"info.html":{},"info.html#musical-data":{}},"title":{}}],["bruin",{"_index":3684,"text":{"info.html":{},"info.html#acknowledgments":{}},"title":{}}],["buck",{"_index":2384,"text":{"Chap_4.html":{},"Chap_4.html#laboratory-exercise-42":{},"Chap_5.html":{},"Chap_5.html#laboratory-exercise-51":{}},"title":{}}],["buffon\u2019",{"_index":955,"text":{"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{}},"title":{}}],["built",{"_index":150,"text":{"Chap_1.html":{},"Chap_1.html#sound-of-music":{}},"title":{}}],["bullet",{"_index":366,"text":{"Chap_10.html":{},"Chap_10.html#expressing-the-mean-square-error":{},"Chap_10.html#using-the-least-mean-square-error-criterion":{},"Chap_11.html":{},"Chap_11.html#estimating-the-mean":{},"Chap_11.html#problem-118":{},"Chap_12.html":{},"Chap_12.html#problem-123":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_13.html":{},"Chap_13.html#appendix-i-mean-square-error-minimization":{},"Chap_4.html":{},"Chap_4.html#example-dice-money":{},"Chap_4.html#example-is-that-coin-fair":{},"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_6.html":{},"Chap_6.html#laboratory-exercise-63":{},"Chap_6.html#the-autocorrelation-function":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_9.html":{},"Chap_9.html#laboratory-exercise-93":{}},"title":{}}],["bullsey",{"_index":987,"text":{"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{}},"title":{}}],["busi",{"_index":3671,"text":{"info.html":{},"info.html#contact":{}},"title":{}}],["bx}}&x\\geq0\\\\0&x<0\\end{cases}\\quad",{"_index":1960,"text":{"Chap_3.html":{},"Chap_3.html#problem-34":{}},"title":{}}],["c",{"_index":1230,"text":{"Chap_11.html":{},"Chap_11.html#problem-119":{},"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#problem-42":{},"Chap_4.html#properties-of-averaging":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#how-big-is-big-how-small-is-small":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#problem-711":{},"Chap_9.html":{},"Chap_9.html#laboratory-exercise-93":{},"Chap_9.html#problem-91":{},"Chap_9.html#using-cauchy-schwartz":{}},"title":{}}],["c/\\lambda",{"_index":2616,"text":{"Chap_5.html":{},"Chap_5.html#laboratory-exercise-51":{}},"title":{}}],["c[n",{"_index":2720,"text":{"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{}},"title":{}}],["c[n\\rbrack",{"_index":2731,"text":{"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{}},"title":{}}],["c\\,{\\bf{b",{"_index":3641,"text":{"Chap_9.html":{},"Chap_9.html#laboratory-exercise-93":{}},"title":{}}],["c\\,{w^*}(\\omega",{"_index":3567,"text":{"Chap_9.html":{},"Chap_9.html#using-cauchy-schwartz":{}},"title":{}}],["c\\frac{{{x^*}(\\omega",{"_index":3575,"text":{"Chap_9.html":{},"Chap_9.html#using-cauchy-schwartz":{}},"title":{}}],["c_{xx}}[k",{"_index":1026,"text":{"Chap_11.html":{},"Chap_11.html#estimating-the-autocorrelation-function":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_11.html#trouble-in-paradise":{},"Chap_12.html":{},"Chap_12.html#the-periodogram-unbiased":{}},"title":{}}],["calcul",{"_index":802,"text":{"Chap_10.html":{},"Chap_10.html#laboratory-exercise-105":{},"Chap_11.html":{},"Chap_11.html#estimating-the-autocorrelation-function":{},"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_3.html":{},"Chap_3.html#introduction":{},"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#example-dice-money":{},"Chap_4.html#problem-44":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function":{},"Chap_7.html#autocorrelation-function_1":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#expected-value":{},"Chap_7.html#power-spectral-density":{},"Chap_7.html#power-spectral-density_1":{},"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{}},"title":{}}],["calculu",{"_index":3543,"text":{"Chap_8.html":{},"Chap_8.html#problem-83":{}},"title":{}}],["california",{"_index":1735,"text":{"Chap_13.html":{},"Chap_13.html#epilogue":{}},"title":{}}],["call",{"_index":293,"text":{"Chap_10.html":{},"Chap_10.html#the-restoration-case-noise":{},"Chap_11.html":{},"Chap_11.html#problem-119":{},"Chap_3.html":{},"Chap_3.html#what-is-a-random-signal":{},"Chap_4.html":{},"Chap_4.html#problem-47":{},"Chap_4.html#properties-of-averaging":{},"Chap_5.html":{},"Chap_5.html#fourier-description-of-correlation-functions":{},"Chap_9.html":{},"Chap_9.html#example-matching-your-filter":{}},"title":{}}],["camera",{"_index":83,"text":{"Chap_1.html":{},"Chap_1.html#how-to-use-this-ibook":{},"Chap_10.html":{},"Chap_10.html#laboratory-exercise-104":{},"Chap_10.html#the-more-general-restoration-case-noise-distortion":{},"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{},"info.html":{},"info.html#tips-short-cuts":{}},"title":{}}],["cancel",{"_index":3050,"text":{"Chap_7.html":{},"Chap_7.html#expected-value":{}},"title":{}}],["can\u2014with",{"_index":421,"text":{"Chap_10.html":{},"Chap_10.html#correlation-returns":{}},"title":{}}],["capabl",{"_index":1766,"text":{"Chap_2.html":{},"Chap_2.html#prologue":{}},"title":{}}],["captur",{"_index":2291,"text":{"Chap_4.html":{},"Chap_4.html#describing-the-time-average":{}},"title":{}}],["care",{"_index":1745,"text":{"Chap_13.html":{},"Chap_13.html#epilogue":{}},"title":{}}],["carefulli",{"_index":3375,"text":{"Chap_7.html":{},"Chap_7.html#problem-72":{}},"title":{}}],["carri",{"_index":1830,"text":{"Chap_3.html":{},"Chap_3.html#what-is-a-random-signal":{}},"title":{}}],["case",{"_index":95,"text":{"Chap_1.html":{},"Chap_1.html#enhanced-experience":{},"Chap_1.html#highlighting":{},"Chap_10.html":{},"Chap_10.html#classic-example-classic-result":{},"Chap_10.html#example-cleaning-up-our-act":{},"Chap_10.html#example-sound-of-distorted-music":{},"Chap_10.html#the-wiener-hopf-equation":{},"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_11.html#langevin-redux":{},"Chap_11.html#maximum-likelihood-estimation":{},"Chap_11.html#problem-118":{},"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_13.html":{},"Chap_13.html#appendix-i-mean-square-error-minimization":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_3.html":{},"Chap_3.html#problem-310":{},"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#example-dice-money":{},"Chap_4.html#example-fair-chance":{},"Chap_4.html#example-is-that-coin-fair":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#correlations-and-memory":{},"Chap_5.html#example-delayed-effect":{},"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function_2":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#from-t-to-n":{},"Chap_7.html#how-big-is-big-how-small-is-small":{},"Chap_7.html#impulse-invariant-sampling":{},"Chap_7.html#the-langevin-equation-a-case-study":{},"Chap_7.html#why-this-case-study":{},"Chap_8.html":{},"Chap_8.html#example-filtering-noise":{},"Chap_8.html#problem-82":{},"Chap_8.html#snr-for-random-signals-in-the-presence-of-noise":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{}},"title":{"Chap_10.html#the-more-general-restoration-case-noise-distortion":{},"Chap_10.html#the-restoration-case-noise":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{},"Chap_7.html":{},"Chap_7.html#the-langevin-equation-a-case-study":{},"Chap_7.html#why-this-case-study":{}}}],["cast",{"_index":1529,"text":{"Chap_12.html":{},"Chap_12.html#problem-122":{}},"title":{}}],["castleman",{"_index":375,"text":{"Chap_10.html":{},"Chap_10.html#laboratory-exercise-105":{},"Chap_10.html#using-the-least-mean-square-error-criterion":{}},"title":{}}],["cat",{"_index":2307,"text":{"Chap_4.html":{},"Chap_4.html#problem-42":{}},"title":{}}],["cauchi",{"_index":1681,"text":{"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_9.html":{},"Chap_9.html#laboratory-exercise-93":{},"Chap_9.html#using-cauchy-schwartz":{}},"title":{"Chap_9.html#using-cauchy-schwartz":{}}}],["caus",{"_index":621,"text":{"Chap_10.html":{},"Chap_10.html#why-we-avoid-the-inverse-filter":{},"Chap_12.html":{},"Chap_12.html#problem-122":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#expected-value":{},"Chap_7.html#one-step-further":{}},"title":{}}],["causal",{"_index":451,"text":{"Chap_10.html":{},"Chap_10.html#the-wiener-hopf-equation":{},"Chap_6.html":{},"Chap_6.html#problem-64":{},"Chap_7.html":{},"Chap_7.html#impulse-invariant-sampling":{},"Chap_7.html#problem-71":{},"Chap_7.html#the-langevin-position-equation":{}},"title":{}}],["caveat",{"_index":1567,"text":{"Chap_12.html":{},"Chap_12.html#problem-123":{},"Chap_3.html":{},"Chap_3.html#problem-310":{},"Chap_4.html":{},"Chap_4.html#example-dice-money":{}},"title":{}}],["caveats\u2014b",{"_index":423,"text":{"Chap_10.html":{},"Chap_10.html#correlation-returns":{}},"title":{}}],["ccd",{"_index":3492,"text":{"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{}},"title":{}}],["cell",{"_index":2216,"text":{"Chap_4.html":{},"Chap_4.html#the-mechanics-of-correlations":{}},"title":{}}],["center",{"_index":985,"text":{"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_12.html":{},"Chap_12.html#problem-122":{},"Chap_12.html#windowed-observations":{},"Chap_3.html":{},"Chap_3.html#problem-310":{},"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{}},"title":{}}],["centimet",{"_index":1241,"text":{"Chap_11.html":{},"Chap_11.html#laboratory-exercise-113":{}},"title":{}}],["central",{"_index":935,"text":{"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_12.html":{},"Chap_12.html#spectral-estimation":{},"Chap_12.html#windowed-observations":{},"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small":{}},"title":{}}],["centuri",{"_index":481,"text":{"Chap_10.html":{},"Chap_10.html#the-wiener-hopf-equation":{},"Chap_2.html":{},"Chap_2.html#prologue":{},"Chap_4.html":{},"Chap_4.html#laboratory-exercise-42":{},"Chap_4.html#the-mechanics-of-correlations":{}},"title":{}}],["certain",{"_index":944,"text":{"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_12.html":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_12.html#windowed-observations":{},"Chap_4.html":{},"Chap_4.html#describing-the-time-average":{},"Chap_4.html#properties-of-averaging":{},"info.html":{},"info.html#technical-details":{}},"title":{}}],["certainli",{"_index":649,"text":{"Chap_10.html":{},"Chap_10.html#example-sound-of-distorted-music":{},"Chap_5.html":{},"Chap_5.html#example-pink-noise":{}},"title":{}}],["certainti",{"_index":3435,"text":{"Chap_8.html":{},"Chap_8.html#snr-for-random-signals-in-the-presence-of-noise":{}},"title":{}}],["chain",{"_index":3144,"text":{"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#tethered-particle-motion":{}},"title":{}}],["chamber",{"_index":3210,"text":{"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#one-step-further":{}},"title":{}}],["championship",{"_index":3609,"text":{"Chap_9.html":{},"Chap_9.html#problem-92":{}},"title":{}}],["chanc",{"_index":2054,"text":{"Chap_4.html":{},"Chap_4.html#example-dice-money":{}},"title":{"Chap_4.html#example-fair-chance":{}}}],["chang",{"_index":750,"text":{"Chap_10.html":{},"Chap_10.html#problem-102":{},"Chap_11.html":{},"Chap_11.html#estimating-the-autocorrelation-function":{},"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_13.html#epilogue":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#one-step-further":{},"Chap_7.html#problem-78":{},"Chap_7.html#problem-79":{},"Chap_7.html#tethered-particle-motion":{},"Chap_8.html":{},"Chap_8.html#characterizing-signal-to-noise-ratios":{},"Chap_8.html#problem-82":{}},"title":{}}],["chapter",{"_index":138,"text":{"Chap_1.html":{},"Chap_1.html#enhanced-experience":{},"Chap_1.html#getting-around":{},"Chap_10.html":{},"Chap_10.html#classic-example-classic-result":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#laboratory-exercise-105":{},"Chap_10.html#problem-104":{},"Chap_10.html#the-wiener-filter":{},"Chap_11.html":{},"Chap_11.html#aspects-of-estimation":{},"Chap_11.html#example-estimating-the-poisson-rate":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_11.html#langevin-redux":{},"Chap_11.html#maximum-likelihood-estimation":{},"Chap_11.html#problem-119":{},"Chap_11.html#trouble-in-paradise":{},"Chap_12.html":{},"Chap_12.html#problem-122":{},"Chap_12.html#spectral-estimation":{},"Chap_2.html":{},"Chap_2.html#prologue":{},"Chap_3.html":{},"Chap_3.html#problem-39":{},"Chap_4.html":{},"Chap_4.html#properties-of-averaging":{},"Chap_4.html#the-ergodic-process":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#correlations-and-spectra":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function_1":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#expected-value":{},"Chap_7.html#power-spectral-density":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#problem-78":{},"Chap_7.html#why-this-case-study":{},"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{},"Chap_9.html":{},"Chap_9.html#problem-91":{},"Chap_9.html#problem-92":{},"info.html":{},"info.html#tips-short-cuts":{}},"title":{}}],["charact",{"_index":245,"text":{"Chap_1.html":{},"Chap_1.html#enhanced-experience":{},"Chap_10.html":{},"Chap_10.html#the-wiener-hopf-equation":{}},"title":{}}],["character",{"_index":1217,"text":{"Chap_11.html":{},"Chap_11.html#problem-118":{},"Chap_3.html":{},"Chap_3.html#what-is-a-random-signal":{},"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_6.html":{},"Chap_6.html#filtering-of-stochastic-signals":{},"Chap_7.html":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#problem-711":{},"Chap_8.html":{},"Chap_8.html#characterizing-signal-to-noise-ratios":{},"Chap_8.html#example-cocktail-party-noise":{},"Chap_9.html":{},"Chap_9.html#setting-up-the-problem":{}},"title":{"Chap_4.html":{},"Chap_4.html#characterization-of-random-signals":{},"Chap_8.html":{},"Chap_8.html#characterizing-signal-to-noise-ratios":{}}}],["characterist",{"_index":1524,"text":{"Chap_12.html":{},"Chap_12.html#problem-122":{},"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#the-langevin-velocity-equation":{},"info.html":{},"info.html#technical-details":{}},"title":{}}],["charli",{"_index":3734,"text":{"info.html":{},"info.html#musical-data":{}},"title":{}}],["chart",{"_index":2365,"text":{"Chap_4.html":{},"Chap_4.html#laboratory-exercise-41":{}},"title":{}}],["chemistri",{"_index":3399,"text":{"Chap_7.html":{},"Chap_7.html#problem-711":{}},"title":{}}],["chi",{"_index":1210,"text":{"Chap_11.html":{},"Chap_11.html#problem-117":{}},"title":{}}],["chines",{"_index":9,"text":{"Chap_1.html":{}},"title":{}}],["choic",{"_index":276,"text":{"Chap_10.html":{},"Chap_10.html#the-wiener-filter":{},"Chap_10.html#the-wiener-hopf-equation":{},"Chap_11.html":{},"Chap_11.html#aspects-of-estimation":{},"Chap_11.html#trouble-in-paradise":{},"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#problem-122":{},"Chap_12.html#problem-123":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_4.html":{},"Chap_4.html#example-dice-money":{},"Chap_6.html":{},"Chap_6.html#problem-61":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#power-spectral-density":{},"Chap_9.html":{},"Chap_9.html#the-matched-filter-as-an-autocorrelation":{},"Chap_9.html#using-cauchy-schwartz":{}},"title":{}}],["choos",{"_index":339,"text":{"Chap_10.html":{},"Chap_10.html#using-the-least-mean-square-error-criterion":{},"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_11.html#maximum-likelihood-estimation":{},"Chap_11.html#problem-117":{},"Chap_11.html#trouble-in-paradise":{},"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#the-periodogram-unbiased":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_3.html#what-is-a-random-signal":{},"Chap_4.html":{},"Chap_4.html#laboratory-exercise-42":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#choosing-the-sampling-period_1":{},"info.html":{},"info.html#tips-short-cuts":{}},"title":{"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#choosing-the-sampling-period_1":{}}}],["chosen",{"_index":1478,"text":{"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#example-dice-money":{},"Chap_4.html#laboratory-exercise-42":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#impulse-invariant-sampling":{},"Chap_7.html#power-spectral-density_2":{},"Chap_7.html#why-this-case-study":{},"info.html":{},"info.html#tips-short-cuts":{}},"title":{}}],["chrome",{"_index":62,"text":{"Chap_1.html":{},"Chap_1.html#how-to-use-this-ibook":{}},"title":{}}],["circumst",{"_index":945,"text":{"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_5.html":{},"Chap_5.html#problem-56":{},"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_7.html":{},"Chap_7.html#problem-72":{}},"title":{}}],["class",{"_index":1808,"text":{"Chap_3.html":{},"Chap_3.html#introduction":{},"Chap_3.html#problem-310":{},"Chap_3.html#what-is-a-random-signal":{},"Chap_5.html":{},"Chap_5.html#problem-52":{},"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{}},"title":{}}],["classic",{"_index":535,"text":{"Chap_10.html":{},"Chap_3.html":{},"Chap_3.html#what-is-a-random-signal":{},"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_9.html":{},"info.html":{},"info.html#tips-short-cuts":{}},"title":{"Chap_10.html#classic-example-classic-result":{},"Chap_9.html#the-classic-example":{}}}],["classroom",{"_index":236,"text":{"Chap_1.html":{},"Chap_1.html#enhanced-experience":{}},"title":{}}],["clean",{"_index":673,"text":{"Chap_10.html":{},"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{}},"title":{"Chap_10.html#example-cleaning-up-our-act":{}}}],["clear",{"_index":1089,"text":{"Chap_11.html":{},"Chap_11.html#langevin-redux":{},"Chap_12.html":{},"Chap_12.html#spectral-estimation":{},"Chap_12.html#the-periodogram-unbiased":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_4.html":{},"Chap_4.html#autocorrelation":{},"Chap_4.html#the-ergodic-process":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function_1":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#power-spectral-density":{}},"title":{}}],["clearli",{"_index":1155,"text":{"Chap_11.html":{},"Chap_11.html#trouble-in-paradise":{},"Chap_12.html":{},"Chap_12.html#the-periodogram-unbiased":{},"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function":{}},"title":{}}],["click",{"_index":123,"text":{"Chap_1.html":{},"Chap_1.html#at-the-movies":{},"Chap_1.html#enhanced-experience":{},"Chap_1.html#getting-around":{},"Chap_1.html#outside-this-device":{},"Chap_1.html#sound-of-music":{},"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#example-sound-of-distorted-music":{},"Chap_10.html#laboratory-exercise-101":{},"Chap_10.html#laboratory-exercise-102":{},"Chap_10.html#laboratory-exercise-103":{},"Chap_10.html#laboratory-exercise-104":{},"Chap_10.html#laboratory-exercise-105":{},"Chap_11.html":{},"Chap_11.html#laboratory-exercise-111":{},"Chap_11.html#laboratory-exercise-112":{},"Chap_11.html#laboratory-exercise-113":{},"Chap_12.html":{},"Chap_12.html#laboratory-exercise-121":{},"Chap_12.html#laboratory-exercise-122":{},"Chap_12.html#laboratory-exercise-123":{},"Chap_12.html#laboratory-exercise-124":{},"Chap_4.html":{},"Chap_4.html#laboratory-exercise-41":{},"Chap_4.html#laboratory-exercise-42":{},"Chap_5.html":{},"Chap_5.html#laboratory-exercise-51":{},"Chap_6.html":{},"Chap_6.html#laboratory-exercise-61":{},"Chap_6.html#laboratory-exercise-62":{},"Chap_6.html#laboratory-exercise-63":{},"Chap_6.html#laboratory-exercise-64":{},"Chap_6.html#laboratory-exercise-65":{},"Chap_6.html#laboratory-exercise-66":{},"Chap_6.html#laboratory-exercise-67":{},"Chap_6.html#laboratory-exercise-68":{},"Chap_9.html":{},"Chap_9.html#laboratory-exercise-91":{},"Chap_9.html#laboratory-exercise-92":{},"Chap_9.html#laboratory-exercise-93":{},"info.html":{},"info.html#tips-short-cuts":{}},"title":{}}],["cliff",{"_index":780,"text":{"Chap_10.html":{},"Chap_10.html#laboratory-exercise-105":{},"Chap_4.html":{},"Chap_4.html#laboratory-exercise-42":{},"Chap_5.html":{},"Chap_5.html#laboratory-exercise-51":{},"Chap_7.html":{},"Chap_7.html#problem-711":{}},"title":{}}],["climat",{"_index":2223,"text":{"Chap_4.html":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_5.html":{}},"title":{"Chap_5.html#predicting-the-natural-climate-a-case-study":{}}}],["clip",{"_index":174,"text":{"Chap_1.html":{},"Chap_1.html#at-the-movies":{}},"title":{}}],["close",{"_index":1763,"text":{"Chap_2.html":{},"Chap_2.html#prologue":{}},"title":{}}],["co",{"_index":1289,"text":{"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#spectral-estimation":{},"Chap_5.html":{},"Chap_5.html#problem-56":{},"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#power-spectral-density":{},"Chap_7.html#power-spectral-density_1":{},"Chap_8.html":{},"Chap_8.html#example-cocktail-party-noise":{},"Chap_8.html#example-filtering-noise":{},"Chap_9.html":{},"Chap_9.html#laboratory-exercise-93":{}},"title":{}}],["cocktail",{"_index":3464,"text":{"Chap_8.html":{}},"title":{"Chap_8.html#example-cocktail-party-noise":{}}}],["coeffici",{"_index":1594,"text":{"Chap_13.html":{},"Chap_13.html#appendix-i-mean-square-error-minimization":{},"Chap_4.html":{},"Chap_4.html#problem-44":{},"Chap_7.html":{},"Chap_7.html#from-t-to-n":{},"Chap_7.html#problem-77":{},"Chap_7.html#the-langevin-equation-a-case-study":{}},"title":{}}],["coin",{"_index":861,"text":{"Chap_11.html":{},"Chap_11.html#maximum-likelihood-estimation":{},"Chap_11.html#problem-113":{},"Chap_4.html":{},"Chap_4.html#characterization-of-random-signals":{},"Chap_4.html#example-dice-money":{},"Chap_4.html#example-fair-chance":{},"Chap_4.html#example-is-that-coin-fair":{},"Chap_4.html#laboratory-exercise-41":{},"Chap_4.html#problem-47":{},"Chap_4.html#the-ergodic-process":{},"Chap_6.html":{},"Chap_6.html#laboratory-exercise-62":{}},"title":{"Chap_4.html#example-is-that-coin-fair":{}}}],["coincid",{"_index":2796,"text":{"Chap_7.html":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#the-langevin-equation-a-case-study":{}},"title":{}}],["colbi",{"_index":3413,"text":{"Chap_7.html":{},"Chap_7.html#problem-711":{}},"title":{}}],["collabor",{"_index":3680,"text":{"info.html":{},"info.html#acknowledgments":{}},"title":{}}],["collect",{"_index":846,"text":{"Chap_11.html":{},"Chap_11.html#aspects-of-estimation":{},"Chap_11.html#langevin-redux":{},"Chap_11.html#maximum-likelihood-estimation":{},"Chap_11.html#problem-116":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_4.html":{},"Chap_4.html#characterization-of-random-signals":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{}},"title":{}}],["collis",{"_index":2792,"text":{"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small":{},"Chap_7.html#tethered-particle-motion":{},"Chap_7.html#the-langevin-equation-a-case-study":{}},"title":{}}],["color",{"_index":767,"text":{"Chap_10.html":{},"Chap_10.html#laboratory-exercise-102":{},"Chap_5.html":{},"Chap_5.html#laboratory-exercise-51":{}},"title":{}}],["column",{"_index":3511,"text":{"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{}},"title":{}}],["combin",{"_index":390,"text":{"Chap_10.html":{},"Chap_10.html#classic-example-classic-result":{},"Chap_10.html#expressing-the-mean-square-error":{},"Chap_11.html":{},"Chap_11.html#langevin-redux":{},"Chap_13.html":{},"Chap_13.html#appendix-i-mean-square-error-minimization":{},"Chap_9.html":{},"Chap_9.html#using-cauchy-schwartz":{}},"title":{}}],["come",{"_index":1418,"text":{"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_4.html":{},"Chap_4.html#example-dice-money":{},"Chap_4.html#problem-47":{},"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#the-langevin-velocity-equation":{}},"title":{}}],["comment",{"_index":231,"text":{"Chap_1.html":{},"Chap_1.html#enhanced-experience":{},"info.html":{},"info.html#contact":{}},"title":{}}],["commerci",{"_index":246,"text":{"Chap_1.html":{},"Chap_1.html#enhanced-experience":{}},"title":{}}],["common",{"_index":538,"text":{"Chap_10.html":{},"Chap_10.html#classic-example-classic-result":{},"Chap_4.html":{},"Chap_4.html#properties-of-averaging":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#problem-52":{},"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{}},"title":{}}],["commun",{"_index":786,"text":{"Chap_10.html":{},"Chap_10.html#laboratory-exercise-105":{},"Chap_13.html":{},"Chap_13.html#epilogue":{},"Chap_9.html":{},"Chap_9.html#laboratory-exercise-93":{},"Chap_9.html#problem-92":{},"Chap_9.html#the-matched-filter":{}},"title":{}}],["commut",{"_index":1796,"text":{"Chap_2.html":{},"Chap_2.html#problem-21":{}},"title":{}}],["compar",{"_index":1347,"text":{"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#problem-122":{},"Chap_12.html#windowed-observations":{},"Chap_5.html":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#how-big-is-big-how-small-is-small":{},"Chap_7.html#power-spectral-density_1":{}},"title":{}}],["comparison",{"_index":1341,"text":{"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#windowed-observations":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#power-spectral-density_1":{}},"title":{}}],["compat",{"_index":3123,"text":{"Chap_7.html":{},"Chap_7.html#power-spectral-density_1":{}},"title":{}}],["complet",{"_index":581,"text":{"Chap_10.html":{},"Chap_10.html#classic-example-classic-result":{},"Chap_2.html":{},"Chap_2.html#prologue":{},"Chap_4.html":{},"Chap_4.html#describing-the-time-average":{},"Chap_4.html#laboratory-exercise-42":{},"info.html":{},"info.html#tips-short-cuts":{}},"title":{}}],["completely\u2014reduc",{"_index":737,"text":{"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{}},"title":{}}],["complex",{"_index":111,"text":{"Chap_1.html":{},"Chap_1.html#highlighting":{},"Chap_10.html":{},"Chap_10.html#problem-102":{},"Chap_12.html":{},"Chap_12.html#spectral-estimation":{},"Chap_13.html":{},"Chap_13.html#epilogue":{},"Chap_2.html":{},"Chap_2.html#prologue":{},"Chap_3.html":{},"Chap_3.html#problem-38":{},"Chap_4.html":{},"Chap_4.html#cross-covariance":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#example-dice-money":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_5.html":{},"Chap_5.html#fourier-description-of-correlation-functions":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{},"Chap_6.html#filtering-of-stochastic-signals":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_6.html#the-mean":{},"Chap_7.html":{},"Chap_7.html#descriptive-statistic-variance":{},"Chap_9.html":{},"Chap_9.html#laboratory-exercise-93":{}},"title":{"Chap_5.html#correlations-simple-and-complex":{}}}],["complic",{"_index":821,"text":{"Chap_11.html":{},"Chap_11.html#aspects-of-estimation":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_11.html#problem-119":{},"Chap_12.html":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_4.html":{},"Chap_4.html#example-dice-money":{},"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function_2":{}},"title":{}}],["compon",{"_index":1086,"text":{"Chap_11.html":{},"Chap_11.html#langevin-redux":{},"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_6.html#the-mean":{},"Chap_7.html":{},"Chap_7.html#expected-value":{},"Chap_9.html":{},"Chap_9.html#the-matched-filter":{}},"title":{}}],["compos",{"_index":308,"text":{"Chap_10.html":{},"Chap_10.html#the-restoration-case-noise":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_7.html":{},"Chap_7.html#tethered-particle-motion":{},"info.html":{},"info.html#musical-data":{}},"title":{}}],["composit",{"_index":1881,"text":{"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{}},"title":{}}],["compris",{"_index":3244,"text":{"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{}},"title":{}}],["compromis",{"_index":1421,"text":{"Chap_12.html":{},"Chap_12.html#the-periodogram-what-about-convergence":{}},"title":{}}],["comput",{"_index":64,"text":{"Chap_1.html":{},"Chap_1.html#how-to-use-this-ibook":{},"Chap_11.html":{},"Chap_11.html#estimating-the-autocorrelation-function":{},"Chap_11.html#langevin-redux":{},"Chap_12.html":{},"Chap_12.html#the-periodogram-unbiased":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_3.html":{},"Chap_3.html#problem-31":{},"Chap_3.html#problem-32":{},"Chap_3.html#the-basics":{},"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#describing-the-time-average":{},"Chap_4.html#example-fair-chance":{},"Chap_4.html#the-ergodic-process":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function":{},"Chap_7.html#autocorrelation-function_2":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#power-spectral-density_2":{},"Chap_9.html":{},"Chap_9.html#problem-92":{},"Chap_9.html#the-matched-filter-as-an-autocorrelation":{}},"title":{}}],["computer\u2014mak",{"_index":30,"text":{"Chap_1.html":{},"Chap_1.html#how-to-use-this-ibook":{}},"title":{}}],["concaten",{"_index":2013,"text":{"Chap_3.html":{},"Chap_3.html#problem-310":{}},"title":{}}],["concentr",{"_index":463,"text":{"Chap_10.html":{},"Chap_10.html#the-wiener-hopf-equation":{},"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_7.html":{},"Chap_7.html#one-step-further":{},"Chap_7.html#tethered-particle-motion":{}},"title":{}}],["concept",{"_index":773,"text":{"Chap_10.html":{},"Chap_10.html#laboratory-exercise-105":{},"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_12.html":{},"Chap_12.html#windowed-observations":{},"Chap_13.html":{},"Chap_13.html#epilogue":{},"Chap_2.html":{},"Chap_2.html#prologue":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_3.html#what-is-a-random-signal":{},"Chap_4.html":{},"Chap_4.html#characterization-of-random-signals":{},"Chap_4.html#laboratory-exercise-42":{},"Chap_4.html#other-averages":{},"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_6.html":{},"Chap_6.html#interpretation-of-the-convolution-result":{},"Chap_7.html":{},"Chap_7.html#tethered-particle-motion":{},"Chap_7.html#the-langevin-equation-a-case-study":{},"Chap_8.html":{},"Chap_8.html#example-cocktail-party-noise":{},"Chap_8.html#example-not-too-noisy":{},"Chap_9.html":{},"Chap_9.html#performance-in-the-presence-of-noise":{}},"title":{}}],["concern",{"_index":1033,"text":{"Chap_11.html":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_11.html#trouble-in-paradise":{},"Chap_12.html":{},"Chap_12.html#problem-123":{},"Chap_3.html":{},"Chap_3.html#what-is-a-random-signal":{},"Chap_4.html":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_7.html":{},"Chap_7.html#problem-78":{}},"title":{}}],["concerto",{"_index":646,"text":{"Chap_10.html":{},"Chap_10.html#example-sound-of-distorted-music":{},"info.html":{},"info.html#musical-data":{}},"title":{}}],["conclud",{"_index":1384,"text":{"Chap_12.html":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_6.html":{},"Chap_6.html#the-autocorrelation-function":{},"Chap_7.html":{},"Chap_7.html#problem-710":{}},"title":{}}],["conclus",{"_index":1316,"text":{"Chap_12.html":{},"Chap_12.html#the-periodogram-unbiased":{},"Chap_5.html":{},"Chap_5.html#example-delayed-effect":{},"Chap_6.html":{},"Chap_6.html#the-autocorrelation-function":{},"Chap_7.html":{},"Chap_7.html#impulse-invariant-sampling":{}},"title":{}}],["condit",{"_index":457,"text":{"Chap_10.html":{},"Chap_10.html#the-wiener-hopf-equation":{},"Chap_12.html":{},"Chap_12.html#other-windows":{},"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#problem-49":{},"Chap_4.html#the-ergodic-process":{},"Chap_5.html":{},"Chap_5.html#fourier-description-of-correlation-functions":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_6.html":{},"Chap_6.html#interpretation-of-the-convolution-result":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_8.html":{},"Chap_8.html#problem-83":{}},"title":{}}],["confidence\u2014th",{"_index":2079,"text":{"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{}},"title":{}}],["confin",{"_index":2923,"text":{"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_8.html":{},"Chap_8.html#example-not-too-noisy":{}},"title":{}}],["confront",{"_index":1424,"text":{"Chap_12.html":{},"Chap_12.html#the-periodogram-what-about-convergence":{}},"title":{}}],["conjug",{"_index":2239,"text":{"Chap_4.html":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_5.html":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_9.html":{},"Chap_9.html#laboratory-exercise-93":{}},"title":{}}],["consequ",{"_index":1093,"text":{"Chap_11.html":{},"Chap_11.html#langevin-redux":{},"Chap_11.html#problem-117":{},"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#laboratory-exercise-122":{},"Chap_12.html#problem-123":{},"Chap_4.html":{},"Chap_4.html#problem-44":{},"Chap_4.html#problem-48":{},"Chap_4.html#the-ergodic-process":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_5.html":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_7.html":{},"Chap_7.html#expected-value":{}},"title":{}}],["consid",{"_index":106,"text":{"Chap_1.html":{},"Chap_1.html#enhanced-experience":{},"Chap_1.html#highlighting":{},"Chap_10.html":{},"Chap_10.html#classic-example-classic-result":{},"Chap_10.html#example-sound-of-distorted-music":{},"Chap_10.html#problem-102":{},"Chap_10.html#problem-103":{},"Chap_11.html":{},"Chap_11.html#estimating-the-mean":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_11.html#problem-115":{},"Chap_11.html#problem-117":{},"Chap_11.html#trouble-in-paradise":{},"Chap_12.html":{},"Chap_12.html#problem-122":{},"Chap_12.html#the-periodogram-unbiased":{},"Chap_12.html#windowed-observations":{},"Chap_13.html":{},"Chap_13.html#appendix-i-mean-square-error-minimization":{},"Chap_2.html":{},"Chap_2.html#prologue":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_3.html#problem-310":{},"Chap_4.html":{},"Chap_4.html#characterization-of-random-signals":{},"Chap_4.html#cross-correlation":{},"Chap_4.html#example-dice-money":{},"Chap_4.html#problem-41":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#correlations-and-memory":{},"Chap_5.html#example-delayed-effect":{},"Chap_5.html#example-white-noise":{},"Chap_5.html#problem-53":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_6.html":{},"Chap_6.html#problem-66":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function_2":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#how-big-is-big-how-small-is-small":{},"Chap_7.html#problem-710":{},"Chap_7.html#problem-72":{},"Chap_7.html#problem-73":{},"Chap_7.html#problem-77":{},"Chap_7.html#tethered-particle-motion":{},"Chap_7.html#the-langevin-equation-a-case-study":{},"Chap_8.html":{},"Chap_8.html#example-filtering-noise":{},"Chap_9.html":{},"Chap_9.html#laboratory-exercise-93":{},"Chap_9.html#problem-91":{}},"title":{}}],["consider",{"_index":265,"text":{"Chap_1.html":{},"Chap_1.html#enhanced-experience":{},"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_2.html":{},"Chap_2.html#prologue":{},"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{}},"title":{}}],["considerably\u2014but",{"_index":736,"text":{"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{}},"title":{}}],["consist",{"_index":442,"text":{"Chap_10.html":{},"Chap_10.html#the-wiener-hopf-equation":{},"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_11.html#estimating-the-mean":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_11.html#laboratory-exercise-113":{},"Chap_11.html#problem-117":{},"Chap_11.html#trouble-in-paradise":{},"Chap_12.html":{},"Chap_12.html#problem-121":{},"Chap_12.html#problem-123":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_4.html":{},"Chap_4.html#laboratory-exercise-42":{},"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_6.html":{},"Chap_6.html#filtering-of-stochastic-signals":{}},"title":{}}],["constant",{"_index":1076,"text":{"Chap_11.html":{},"Chap_11.html#langevin-redux":{},"Chap_11.html#problem-118":{},"Chap_11.html#problem-119":{},"Chap_3.html":{},"Chap_3.html#problem-34":{},"Chap_4.html":{},"Chap_4.html#problem-44":{},"Chap_4.html#properties-of-averaging":{},"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_6.html#the-mean":{},"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#from-t-to-n":{},"Chap_7.html#how-big-is-big-how-small-is-small":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#impulse-invariant-sampling":{},"Chap_7.html#one-step-further":{},"Chap_7.html#tethered-particle-motion":{},"Chap_8.html":{},"Chap_8.html#problem-82":{},"Chap_9.html":{},"Chap_9.html#using-cauchy-schwartz":{}},"title":{}}],["constrain",{"_index":3154,"text":{"Chap_7.html":{},"Chap_7.html#tethered-particle-motion":{}},"title":{}}],["constraint",{"_index":1426,"text":{"Chap_12.html":{},"Chap_12.html#the-periodogram-what-about-convergence":{}},"title":{}}],["construct",{"_index":1640,"text":{"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{}},"title":{}}],["consum",{"_index":2737,"text":{"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{}},"title":{}}],["contact",{"_index":3663,"text":{"info.html":{}},"title":{"info.html#contact":{}}}],["contact@socraticsoftware.org",{"_index":3672,"text":{"info.html":{},"info.html#contact":{}},"title":{}}],["contain",{"_index":797,"text":{"Chap_10.html":{},"Chap_10.html#laboratory-exercise-105":{},"Chap_3.html":{},"Chap_3.html#problem-35":{},"Chap_6.html":{},"Chap_6.html#problem-61":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#one-step-further":{},"Chap_7.html#tethered-particle-motion":{},"Chap_8.html":{},"Chap_8.html#problem-83":{},"Chap_9.html":{},"Chap_9.html#setting-up-the-problem":{}},"title":{}}],["contamin",{"_index":596,"text":{"Chap_10.html":{},"Chap_10.html#laboratory-exercise-103":{},"Chap_10.html#the-more-general-restoration-case-noise-distortion":{},"Chap_12.html":{},"Chap_12.html#windowed-observations":{},"Chap_8.html":{},"Chap_8.html#example-cocktail-party-noise":{},"Chap_8.html#example-not-too-noisy":{},"Chap_8.html#problem-83":{}},"title":{}}],["context",{"_index":15,"text":{"Chap_1.html":{},"Chap_1.html#how-to-use-this-ibook":{},"Chap_2.html":{},"Chap_2.html#prologue":{},"Chap_4.html":{},"Chap_4.html#characterization-of-random-signals":{},"Chap_7.html":{},"Chap_7.html#the-langevin-equation-a-case-study":{}},"title":{}}],["contigu",{"_index":1398,"text":{"Chap_12.html":{},"Chap_12.html#the-periodogram-what-about-convergence":{}},"title":{}}],["continu",{"_index":127,"text":{"Chap_1.html":{},"Chap_1.html#outside-this-device":{},"Chap_10.html":{},"Chap_10.html#laboratory-exercise-105":{},"Chap_10.html#problem-104":{},"Chap_10.html#the-more-general-restoration-case-noise-distortion":{},"Chap_10.html#what-is-that-least-mean-square-error":{},"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_11.html#estimating-the-mean":{},"Chap_11.html#langevin-redux":{},"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#laboratory-exercise-124":{},"Chap_12.html#other-windows":{},"Chap_12.html#problem-122":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_2.html":{},"Chap_2.html#prologue":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_3.html#problem-310":{},"Chap_3.html#problem-34":{},"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#example-is-that-coin-fair":{},"Chap_4.html#laboratory-exercise-42":{},"Chap_4.html#problem-48":{},"Chap_6.html":{},"Chap_6.html#laboratory-exercise-62":{},"Chap_6.html#laboratory-exercise-65":{},"Chap_6.html#laboratory-exercise-66":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_7.html":{},"Chap_7.html#descriptive-statistic-variance":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#expected-value":{},"Chap_7.html#from-t-to-n":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#problem-73":{},"Chap_7.html#problem-78":{},"Chap_7.html#the-langevin-position-equation":{},"Chap_7.html#why-this-case-study":{}},"title":{}}],["contour",{"_index":3207,"text":{"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{}},"title":{}}],["contrast",{"_index":3717,"text":{"info.html":{},"info.html#technical-details":{}},"title":{}}],["contribut",{"_index":2696,"text":{"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{},"info.html":{},"info.html#acknowledgments":{}},"title":{}}],["control",{"_index":1769,"text":{"Chap_2.html":{},"Chap_2.html#prologue":{},"Chap_7.html":{},"Chap_7.html#the-langevin-equation-a-case-study":{}},"title":{}}],["conveni",{"_index":976,"text":{"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_5.html":{},"Chap_5.html#laboratory-exercise-51":{}},"title":{}}],["convent",{"_index":2617,"text":{"Chap_5.html":{},"Chap_5.html#laboratory-exercise-51":{}},"title":{}}],["converg",{"_index":952,"text":{"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_11.html#estimating-the-mean":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_11.html#laboratory-exercise-113":{},"Chap_11.html#langevin-redux":{},"Chap_11.html#trouble-in-paradise":{},"Chap_12.html":{},"Chap_12.html#spectral-estimation":{},"Chap_12.html#the-periodogram-unbiased":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_7.html":{},"Chap_7.html#impulse-invariant-sampling":{}},"title":{"Chap_12.html#the-periodogram-what-about-convergence":{}}}],["convers",{"_index":3337,"text":{"Chap_7.html":{},"Chap_7.html#descriptive-statistic-variance":{}},"title":{}}],["convert",{"_index":3286,"text":{"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_8.html":{},"Chap_8.html#problem-83":{}},"title":{}}],["convey",{"_index":3603,"text":{"Chap_9.html":{},"Chap_9.html#problem-92":{}},"title":{}}],["convolut",{"_index":1338,"text":{"Chap_12.html":{},"Chap_12.html#problem-122":{},"Chap_12.html#windowed-observations":{},"Chap_2.html":{},"Chap_2.html#problem-21":{},"Chap_2.html#prologue":{},"Chap_3.html":{},"Chap_3.html#introduction":{},"Chap_3.html#problem-31":{},"Chap_3.html#the-basics":{},"Chap_5.html":{},"Chap_5.html#laboratory-exercise-51":{},"Chap_6.html":{},"Chap_6.html#filtering-of-stochastic-signals":{},"Chap_6.html#interpretation-of-the-convolution-result":{},"Chap_6.html#the-autocorrelation-function":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_9.html":{},"Chap_9.html#problem-91":{},"Chap_9.html#the-matched-filter-as-an-autocorrelation":{}},"title":{"Chap_6.html#interpretation-of-the-convolution-result":{}}}],["convolv",{"_index":1441,"text":{"Chap_12.html":{},"Chap_12.html#other-windows":{}},"title":{}}],["copi",{"_index":226,"text":{"Chap_1.html":{},"Chap_1.html#enhanced-experience":{}},"title":{}}],["copyright",{"_index":186,"text":{"Chap_1.html":{},"Chap_1.html#at-the-movies":{},"Chap_1.html#enhanced-experience":{},"info.html":{},"info.html#copyright":{}},"title":{"info.html#copyright":{}}}],["cordova",{"_index":3712,"text":{"info.html":{},"info.html#technical-details":{}},"title":{}}],["corey",{"_index":1783,"text":{"Chap_2.html":{},"Chap_2.html#prologue":{}},"title":{}}],["corner",{"_index":3650,"text":{"info.html":{},"info.html#tips-short-cuts":{}},"title":{}}],["correct",{"_index":2402,"text":{"Chap_5.html":{},"Chap_5.html#correlations-simple-and-complex":{},"Chap_5.html#problem-56":{},"Chap_7.html":{},"Chap_7.html#tethered-particle-motion":{}},"title":{}}],["correctli",{"_index":2205,"text":{"Chap_4.html":{},"Chap_4.html#the-mechanics-of-correlations":{}},"title":{}}],["correl",{"_index":404,"text":{"Chap_10.html":{},"Chap_10.html#correlation-returns":{},"Chap_11.html":{},"Chap_11.html#estimating-the-autocorrelation-function":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_11.html#trouble-in-paradise":{},"Chap_12.html":{},"Chap_12.html#spectral-estimation":{},"Chap_4.html":{},"Chap_4.html#cross-correlation":{},"Chap_5.html":{},"Chap_5.html#correlations-and-memory":{},"Chap_5.html#correlations-simple-and-complex":{},"Chap_5.html#laboratory-exercise-51":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_5.html#problem-55":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{},"Chap_6.html#filtering-of-stochastic-signals":{},"Chap_6.html#problem-63":{},"Chap_6.html#the-autocorrelation-function":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_8.html":{},"Chap_8.html#example-filtering-noise":{},"Chap_9.html":{},"Chap_9.html#performance-in-the-presence-of-noise":{},"Chap_9.html#problem-91":{},"Chap_9.html#the-matched-filter-as-an-autocorrelation":{}},"title":{"Chap_10.html#correlation-returns":{},"Chap_4.html#correlation-the-workhorse":{},"Chap_4.html#cross-correlation":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_5.html":{},"Chap_5.html#correlations-and-memory":{},"Chap_5.html#correlations-and-spectra":{},"Chap_5.html#correlations-simple-and-complex":{},"Chap_5.html#fourier-description-of-correlation-functions":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_6.html#the-cross-correlation-function":{}}}],["correspond",{"_index":1540,"text":{"Chap_12.html":{},"Chap_12.html#problem-122":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#expected-value":{},"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{},"Chap_9.html":{},"Chap_9.html#performance-in-the-presence-of-noise":{}},"title":{}}],["corre\u00adspond",{"_index":2770,"text":{"Chap_6.html":{},"Chap_6.html#problem-61":{}},"title":{}}],["corrupt",{"_index":300,"text":{"Chap_10.html":{},"Chap_10.html#example-cleaning-up-our-act":{},"Chap_10.html#laboratory-exercise-101":{},"Chap_10.html#problem-103":{},"Chap_10.html#the-restoration-case-noise":{},"Chap_9.html":{},"Chap_9.html#problem-91":{},"Chap_9.html#problem-92":{}},"title":{}}],["cos(5\\pi",{"_index":2038,"text":{"Chap_3.html":{},"Chap_3.html#problem-310":{}},"title":{}}],["cosin",{"_index":1455,"text":{"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_9.html":{},"Chap_9.html#laboratory-exercise-93":{}},"title":{}}],["count",{"_index":2067,"text":{"Chap_4.html":{},"Chap_4.html#example-fair-chance":{}},"title":{}}],["counterpart",{"_index":3106,"text":{"Chap_7.html":{},"Chap_7.html#power-spectral-density_1":{}},"title":{}}],["countri",{"_index":205,"text":{"Chap_1.html":{},"Chap_1.html#enhanced-experience":{}},"title":{}}],["cours",{"_index":65,"text":{"Chap_1.html":{},"Chap_1.html#how-to-use-this-ibook":{},"Chap_10.html":{},"Chap_10.html#as-seen-from-the-fourier-domain":{},"Chap_10.html#using-the-least-mean-square-error-criterion":{},"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_2.html":{},"Chap_2.html#prologue":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_4.html":{},"Chap_4.html#example-dice-money":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_6.html":{},"Chap_6.html#the-autocorrelation-function":{},"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_8.html":{},"Chap_8.html#example-filtering-noise":{},"Chap_8.html#problem-83":{},"Chap_9.html":{},"Chap_9.html#the-matched-filter":{}},"title":{}}],["courtesi",{"_index":3149,"text":{"Chap_7.html":{},"Chap_7.html#tethered-particle-motion":{}},"title":{}}],["covari",{"_index":2242,"text":{"Chap_4.html":{},"Chap_4.html#auto-covariance":{},"Chap_4.html#cross-covariance":{},"Chap_5.html":{},"Chap_5.html#correlations-and-memory":{},"Chap_5.html#correlations-simple-and-complex":{},"Chap_5.html#the-mechanics-of-correlations-redux":{}},"title":{"Chap_4.html#auto-covariance":{},"Chap_4.html#cross-covariance":{}}}],["cover",{"_index":1721,"text":{"Chap_13.html":{},"Chap_13.html#epilogue":{},"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"info.html":{},"info.html#copyright":{}},"title":{"info.html#cover":{}}}],["cox",{"_index":3063,"text":{"Chap_7.html":{},"Chap_7.html#expected-value":{},"Chap_7.html#problem-711":{}},"title":{}}],["cp",{"_index":2884,"text":{"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small":{}},"title":{}}],["cram\u00e9r",{"_index":1214,"text":{"Chap_11.html":{},"Chap_11.html#laboratory-exercise-113":{},"Chap_11.html#problem-117":{},"Chap_3.html":{},"Chap_3.html#problem-310":{},"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#laboratory-exercise-42":{}},"title":{}}],["criteria",{"_index":827,"text":{"Chap_11.html":{},"Chap_11.html#aspects-of-estimation":{},"Chap_11.html#maximum-likelihood-estimation":{},"Chap_12.html":{},"Chap_12.html#other-windows":{}},"title":{}}],["criterion",{"_index":328,"text":{"Chap_10.html":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{}},"title":{"Chap_10.html#using-the-least-mean-square-error-criterion":{}}}],["critic",{"_index":230,"text":{"Chap_1.html":{},"Chap_1.html#enhanced-experience":{},"Chap_13.html":{},"Chap_13.html#appendix-i-mean-square-error-minimization":{}},"title":{}}],["critically\\,damped\\,system",{"_index":3190,"text":{"Chap_7.html":{},"Chap_7.html#tethered-particle-motion":{}},"title":{}}],["cross",{"_index":411,"text":{"Chap_10.html":{},"Chap_10.html#correlation-returns":{},"Chap_4.html":{},"Chap_4.html#cross-correlation":{},"Chap_4.html#cross-covariance":{},"Chap_5.html":{},"Chap_5.html#correlations-and-memory":{},"Chap_5.html#correlations-simple-and-complex":{},"Chap_5.html#problem-55":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{},"Chap_6.html#filtering-of-stochastic-signals":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_9.html":{},"Chap_9.html#performance-in-the-presence-of-noise":{},"Chap_9.html#the-matched-filter-as-an-autocorrelation":{}},"title":{"Chap_4.html#cross-correlation":{},"Chap_4.html#cross-covariance":{},"Chap_6.html#the-cross-correlation-function":{}}}],["crosscorrel",{"_index":2435,"text":{"Chap_5.html":{},"Chap_5.html#the-mechanics-of-correlations-redux":{}},"title":{}}],["crowd",{"_index":3626,"text":{"Chap_9.html":{},"Chap_9.html#laboratory-exercise-92":{}},"title":{}}],["crucial",{"_index":2500,"text":{"Chap_5.html":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{}},"title":{}}],["crude",{"_index":2719,"text":{"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{}},"title":{}}],["ctrl",{"_index":3647,"text":{"info.html":{},"info.html#tips-short-cuts":{}},"title":{}}],["current",{"_index":85,"text":{"Chap_1.html":{},"Chap_1.html#how-to-use-this-ibook":{},"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{},"info.html":{},"info.html#tips-short-cuts":{}},"title":{}}],["curv",{"_index":796,"text":{"Chap_10.html":{},"Chap_10.html#laboratory-exercise-105":{},"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#power-spectral-density":{}},"title":{}}],["cut",{"_index":3643,"text":{"info.html":{}},"title":{"info.html#tips-short-cuts":{}}}],["cutoff",{"_index":3260,"text":{"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period_1":{}},"title":{}}],["c{v_i",{"_index":2342,"text":{"Chap_4.html":{},"Chap_4.html#problem-44":{}},"title":{}}],["c{v_x",{"_index":2340,"text":{"Chap_4.html":{},"Chap_4.html#problem-44":{}},"title":{}}],["c}_{xx}}[k",{"_index":1149,"text":{"Chap_11.html":{},"Chap_11.html#trouble-in-paradise":{},"Chap_12.html":{},"Chap_12.html#spectral-estimation":{},"Chap_12.html#the-periodogram-unbiased":{}},"title":{}}],["d",{"_index":1264,"text":{"Chap_11.html":{},"Chap_11.html#laboratory-exercise-113":{},"Chap_12.html":{},"Chap_12.html#laboratory-exercise-124":{},"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#power-spectral-density":{},"Chap_7.html#power-spectral-density_2":{},"Chap_7.html#problem-711":{},"Chap_7.html#problem-77":{},"Chap_7.html#problem-78":{},"Chap_8.html":{},"Chap_8.html#problem-83":{}},"title":{}}],["d\\omega",{"_index":503,"text":{"Chap_10.html":{},"Chap_10.html#problem-102":{},"Chap_10.html#what-is-that-least-mean-square-error":{},"Chap_5.html":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_8.html":{},"Chap_8.html#example-cocktail-party-noise":{},"Chap_9.html":{},"Chap_9.html#example-matching-your-filter":{},"Chap_9.html#setting-up-the-problem":{},"Chap_9.html#using-cauchy-schwartz":{}},"title":{}}],["d^m}{w_v}(q)/d{q^m",{"_index":1556,"text":{"Chap_12.html":{},"Chap_12.html#problem-122":{}},"title":{}}],["d_{ij",{"_index":3621,"text":{"Chap_9.html":{},"Chap_9.html#problem-92":{}},"title":{}}],["d_{xi",{"_index":3620,"text":{"Chap_9.html":{},"Chap_9.html#problem-92":{}},"title":{}}],["daili",{"_index":2538,"text":{"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{},"info.html":{},"info.html#cover":{}},"title":{}}],["damag",{"_index":299,"text":{"Chap_10.html":{},"Chap_10.html#the-restoration-case-noise":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{}},"title":{}}],["damp",{"_index":2805,"text":{"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#the-langevin-equation-a-case-study":{}},"title":{}}],["dark",{"_index":588,"text":{"Chap_10.html":{},"Chap_10.html#classic-example-classic-result":{},"Chap_12.html":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#power-spectral-density":{},"Chap_7.html#problem-711":{},"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{}},"title":{}}],["darkfield",{"_index":3176,"text":{"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#problem-711":{},"Chap_7.html#tethered-particle-motion":{}},"title":{}}],["dart",{"_index":980,"text":{"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{}},"title":{}}],["dash",{"_index":1522,"text":{"Chap_12.html":{},"Chap_12.html#problem-121":{},"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{}},"title":{}}],["data",{"_index":453,"text":{"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#the-wiener-hopf-equation":{},"Chap_11.html":{},"Chap_11.html#aspects-of-estimation":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_11.html#estimating-the-autocorrelation-function":{},"Chap_11.html#estimating-the-mean":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_11.html#langevin-redux":{},"Chap_11.html#maximum-likelihood-estimation":{},"Chap_11.html#problem-112":{},"Chap_11.html#problem-116":{},"Chap_11.html#trouble-in-paradise":{},"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#laboratory-exercise-123":{},"Chap_12.html#laboratory-exercise-124":{},"Chap_12.html#other-windows":{},"Chap_12.html#problem-122":{},"Chap_12.html#the-periodogram-unbiased":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_12.html#windowed-observations":{},"Chap_13.html":{},"Chap_13.html#appendix-i-mean-square-error-minimization":{},"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#the-ergodic-process":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{},"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#tethered-particle-motion":{},"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{},"Chap_9.html":{},"Chap_9.html#performance-in-the-presence-of-noise":{},"info.html":{},"info.html#weather-data":{}},"title":{"info.html#musical-data":{},"info.html#weather-data":{}}}],["date",{"_index":2199,"text":{"Chap_4.html":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{}},"title":{}}],["day",{"_index":1176,"text":{"Chap_11.html":{},"Chap_11.html#problem-113":{},"Chap_4.html":{},"Chap_4.html#correlation-the-workhorse":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{}},"title":{}}],["db",{"_index":1579,"text":{"Chap_12.html":{},"Chap_12.html#problem-123":{},"Chap_8.html":{},"Chap_8.html#example-cocktail-party-noise":{},"Chap_9.html":{},"Chap_9.html#performance-in-the-presence-of-noise":{}},"title":{}}],["dc",{"_index":2643,"text":{"Chap_6.html":{},"Chap_6.html#the-mean":{}},"title":{}}],["de",{"_index":2547,"text":{"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_7.html":{},"Chap_7.html#problem-711":{},"info.html":{},"info.html#acknowledgments":{},"info.html#cover":{}},"title":{}}],["deal",{"_index":1394,"text":{"Chap_12.html":{},"Chap_12.html#other-windows":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_7.html":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#tethered-particle-motion":{}},"title":{}}],["decay",{"_index":2320,"text":{"Chap_4.html":{},"Chap_4.html#problem-42":{},"Chap_7.html":{},"Chap_7.html#tethered-particle-motion":{},"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{}},"title":{}}],["decay\u2014a",{"_index":2317,"text":{"Chap_4.html":{},"Chap_4.html#problem-42":{}},"title":{}}],["decemb",{"_index":2541,"text":{"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"info.html":{},"info.html#cover":{}},"title":{}}],["decid",{"_index":1438,"text":{"Chap_12.html":{},"Chap_12.html#other-windows":{}},"title":{}}],["deck",{"_index":2355,"text":{"Chap_4.html":{},"Chap_4.html#problem-47":{}},"title":{}}],["decompos",{"_index":3630,"text":{"Chap_9.html":{},"Chap_9.html#laboratory-exercise-93":{}},"title":{}}],["deconstruct",{"_index":1106,"text":{"Chap_11.html":{},"Chap_11.html#langevin-redux":{}},"title":{}}],["decreas",{"_index":972,"text":{"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_11.html#estimating-the-mean":{},"Chap_11.html#langevin-redux":{},"Chap_11.html#problem-119":{},"Chap_12.html":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_4.html":{},"Chap_4.html#correlation-the-workhorse":{},"Chap_7.html":{},"Chap_7.html#one-step-further":{}},"title":{}}],["defici",{"_index":1373,"text":{"Chap_12.html":{},"Chap_12.html#the-periodogram-what-about-convergence":{}},"title":{}}],["defin",{"_index":321,"text":{"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#the-restoration-case-noise":{},"Chap_11.html":{},"Chap_11.html#aspects-of-estimation":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_11.html#example-estimating-the-poisson-rate":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#problem-121":{},"Chap_12.html#problem-122":{},"Chap_12.html#the-periodogram-unbiased":{},"Chap_3.html":{},"Chap_3.html#problem-310":{},"Chap_3.html#problem-35":{},"Chap_3.html#problem-38":{},"Chap_4.html":{},"Chap_4.html#auto-covariance":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#example-dice-money":{},"Chap_4.html#example-is-that-coin-fair":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#how-big-is-big-how-small-is-small":{},"Chap_7.html#problem-77":{},"Chap_8.html":{},"Chap_8.html#example-filtering-noise":{},"Chap_8.html#problem-83":{},"Chap_8.html#snr-for-deterministic-signals-in-the-presence-of-noise":{},"Chap_8.html#snr-for-random-signals-in-the-presence-of-noise":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{},"Chap_9.html":{},"Chap_9.html#setting-up-the-problem":{}},"title":{}}],["definit",{"_index":198,"text":{"Chap_1.html":{},"Chap_1.html#enhanced-experience":{},"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#the-restoration-case-noise":{},"Chap_10.html#what-is-that-least-mean-square-error":{},"Chap_11.html":{},"Chap_11.html#example-estimating-the-poisson-rate":{},"Chap_11.html#laboratory-exercise-113":{},"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#the-periodogram-unbiased":{},"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_3.html":{},"Chap_3.html#introduction":{},"Chap_4.html":{},"Chap_4.html#autocorrelation":{},"Chap_4.html#characterization-of-random-signals":{},"Chap_4.html#cross-covariance":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#example-is-that-coin-fair":{},"Chap_4.html#laboratory-exercise-42":{},"Chap_4.html#the-ergodic-process":{},"Chap_5.html":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_6.html#the-mean":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#descriptive-statistic-variance":{},"Chap_7.html#problem-711":{},"Chap_8.html":{},"Chap_8.html#example-not-too-noisy":{},"Chap_8.html#snr-for-random-signals-in-the-presence-of-noise":{},"Chap_9.html":{},"Chap_9.html#performance-in-the-presence-of-noise":{},"Chap_9.html#problem-92":{},"Chap_9.html#using-cauchy-schwartz":{}},"title":{}}],["degrad",{"_index":604,"text":{"Chap_10.html":{},"Chap_10.html#the-more-general-restoration-case-noise-distortion":{}},"title":{}}],["degre",{"_index":1211,"text":{"Chap_11.html":{},"Chap_11.html#problem-117":{},"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{}},"title":{}}],["delay",{"_index":2409,"text":{"Chap_5.html":{},"Chap_5.html#example-delayed-effect":{},"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{},"Chap_6.html#interpretation-of-the-convolution-result":{},"Chap_9.html":{},"Chap_9.html#performance-in-the-presence-of-noise":{}},"title":{"Chap_5.html#example-delayed-effect":{}}}],["delft",{"_index":1592,"text":{"Chap_12.html":{},"Chap_12.html#laboratory-exercise-124":{},"Chap_13.html":{},"Chap_13.html#epilogue":{}},"title":{}}],["delta",{"_index":1344,"text":{"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#windowed-observations":{},"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_3.html":{},"Chap_3.html#problem-32":{},"Chap_3.html#problem-35":{},"Chap_4.html":{},"Chap_4.html#laboratory-exercise-42":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#example-white-noise":{},"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{},"Chap_6.html#interpretation-of-the-convolution-result":{},"Chap_6.html#problem-61":{},"Chap_6.html#problem-64":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_8.html":{},"Chap_8.html#problem-82":{},"Chap_8.html#problem-83":{}},"title":{}}],["delta[n",{"_index":1911,"text":{"Chap_3.html":{},"Chap_3.html#problem-31":{}},"title":{}}],["demonstr",{"_index":3066,"text":{"Chap_7.html":{},"Chap_7.html#expected-value":{},"Chap_7.html#power-spectral-density_1":{}},"title":{}}],["den",{"_index":824,"text":{"Chap_11.html":{},"Chap_11.html#aspects-of-estimation":{},"Chap_11.html#laboratory-exercise-113":{}},"title":{}}],["denomin",{"_index":2997,"text":{"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{}},"title":{}}],["denot",{"_index":1466,"text":{"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#problem-78":{},"Chap_9.html":{},"Chap_9.html#laboratory-exercise-93":{}},"title":{}}],["densiti",{"_index":587,"text":{"Chap_10.html":{},"Chap_10.html#classic-example-classic-result":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#example-cleaning-up-our-act":{},"Chap_10.html#problem-103":{},"Chap_10.html#why-we-avoid-the-inverse-filter":{},"Chap_11.html":{},"Chap_11.html#problem-112":{},"Chap_11.html#problem-114":{},"Chap_11.html#problem-119":{},"Chap_11.html#trouble-in-paradise":{},"Chap_12.html":{},"Chap_12.html#problem-122":{},"Chap_12.html#spectral-estimation":{},"Chap_12.html#the-periodogram-unbiased":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_12.html#windowed-observations":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_3.html#problem-34":{},"Chap_3.html#problem-35":{},"Chap_3.html#problem-36":{},"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#laboratory-exercise-42":{},"Chap_4.html#problem-44":{},"Chap_5.html":{},"Chap_5.html#fourier-description-of-correlation-functions":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_5.html#problem-56":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_6.html":{},"Chap_6.html#laboratory-exercise-63":{},"Chap_6.html#laboratory-exercise-67":{},"Chap_6.html#problem-64":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#expected-value":{},"Chap_7.html#power-spectral-density":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#power-spectral-density_2":{},"Chap_7.html#problem-73":{},"Chap_7.html#problem-75":{},"Chap_7.html#problem-76":{},"Chap_7.html#the-langevin-equation-a-case-study":{},"Chap_7.html#why-this-case-study":{},"Chap_8.html":{},"Chap_8.html#example-cocktail-party-noise":{},"Chap_8.html#example-filtering-noise":{},"Chap_8.html#problem-81":{},"Chap_8.html#problem-83":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{},"Chap_9.html":{},"Chap_9.html#the-classic-example":{},"info.html":{},"info.html#cover":{}},"title":{"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_7.html#power-spectral-density":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#power-spectral-density_2":{}}}],["depart",{"_index":1590,"text":{"Chap_12.html":{},"Chap_12.html#laboratory-exercise-124":{}},"title":{}}],["depend",{"_index":456,"text":{"Chap_10.html":{},"Chap_10.html#the-wiener-hopf-equation":{},"Chap_11.html":{},"Chap_11.html#laboratory-exercise-111":{},"Chap_12.html":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_5.html":{},"Chap_5.html#correlations-and-memory":{},"Chap_5.html#problem-52":{},"Chap_7.html":{},"Chap_7.html#expected-value":{},"Chap_7.html#tethered-particle-motion":{},"info.html":{},"info.html#musical-data":{}},"title":{}}],["depict",{"_index":2446,"text":{"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_9.html":{},"Chap_9.html#the-matched-filter-as-an-autocorrelation":{}},"title":{}}],["depict\u2014with",{"_index":2078,"text":{"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{}},"title":{}}],["deriv",{"_index":919,"text":{"Chap_11.html":{},"Chap_11.html#example-estimating-the-poisson-rate":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_12.html":{},"Chap_12.html#problem-122":{},"Chap_13.html":{},"Chap_13.html#appendix-i-mean-square-error-minimization":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_3.html":{},"Chap_3.html#introduction":{},"Chap_4.html":{},"Chap_4.html#auto-covariance":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_5.html":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_6.html#the-mean":{},"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{}},"title":{}}],["describ",{"_index":53,"text":{"Chap_1.html":{},"Chap_1.html#how-to-use-this-ibook":{},"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_11.html#maximum-likelihood-estimation":{},"Chap_12.html":{},"Chap_12.html#other-windows":{},"Chap_12.html#problem-122":{},"Chap_2.html":{},"Chap_2.html#prologue":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_3.html#problem-310":{},"Chap_3.html#problem-32":{},"Chap_3.html#problem-37":{},"Chap_3.html#what-is-a-random-signal":{},"Chap_4.html":{},"Chap_4.html#correlation-the-workhorse":{},"Chap_4.html#example-fair-chance":{},"Chap_4.html#laboratory-exercise-41":{},"Chap_4.html#laboratory-exercise-42":{},"Chap_4.html#problem-41":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#correlations-simple-and-complex":{},"Chap_5.html#example-pink-noise":{},"Chap_5.html#laboratory-exercise-51":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_5.html#problem-52":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{},"Chap_6.html#filtering-of-stochastic-signals":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function_1":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#one-step-further":{},"Chap_7.html#power-spectral-density":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#problem-71":{},"Chap_7.html#problem-72":{},"Chap_7.html#problem-77":{},"Chap_7.html#tethered-particle-motion":{},"Chap_7.html#the-langevin-equation-a-case-study":{},"Chap_7.html#the-langevin-velocity-equation":{},"Chap_8.html":{},"Chap_8.html#example-cocktail-party-noise":{},"Chap_8.html#problem-82":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{},"Chap_9.html":{},"Chap_9.html#problem-92":{},"Chap_9.html#the-matched-filter-as-an-autocorrelation":{}},"title":{"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#describing-the-time-average":{}}}],["descript",{"_index":1714,"text":{"Chap_13.html":{},"Chap_13.html#epilogue":{},"Chap_3.html":{},"Chap_3.html#problem-33":{},"Chap_4.html":{},"Chap_4.html#characterization-of-random-signals":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#example-is-that-coin-fair":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_5.html":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#how-big-is-big-how-small-is-small":{},"Chap_7.html#one-step-further":{},"Chap_7.html#power-spectral-density":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#problem-71":{},"Chap_7.html#the-langevin-equation-a-case-study":{},"Chap_7.html#why-this-case-study":{},"Chap_8.html":{},"Chap_8.html#snr-for-deterministic-signals-in-the-presence-of-noise":{}},"title":{"Chap_5.html#fourier-description-of-correlation-functions":{},"Chap_7.html#descriptive-statistic-variance":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{}}}],["descriptor",{"_index":1135,"text":{"Chap_11.html":{},"Chap_11.html#langevin-redux":{}},"title":{}}],["design",{"_index":726,"text":{"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_9.html":{},"Chap_9.html#problem-92":{}},"title":{}}],["desir",{"_index":271,"text":{"Chap_10.html":{},"Chap_10.html#as-seen-from-the-fourier-domain":{},"Chap_10.html#classic-example-classic-result":{},"Chap_10.html#the-more-general-restoration-case-noise-distortion":{},"Chap_10.html#the-wiener-filter":{},"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_11.html#trouble-in-paradise":{},"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#problem-122":{},"Chap_12.html#windowed-observations":{},"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_13.html#epilogue":{}},"title":{}}],["desktop",{"_index":29,"text":{"Chap_1.html":{},"Chap_1.html#how-to-use-this-ibook":{}},"title":{}}],["detail",{"_index":1042,"text":{"Chap_11.html":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_4.html":{},"Chap_4.html#the-ergodic-process":{},"Chap_7.html":{},"Chap_7.html#impulse-invariant-sampling":{},"info.html":{}},"title":{"info.html#technical-details":{}}}],["detect",{"_index":3418,"text":{"Chap_7.html":{},"Chap_7.html#problem-711":{},"Chap_9.html":{},"Chap_9.html#the-matched-filter":{}},"title":{}}],["detector",{"_index":2322,"text":{"Chap_4.html":{},"Chap_4.html#problem-42":{}},"title":{}}],["determin",{"_index":240,"text":{"Chap_1.html":{},"Chap_1.html#enhanced-experience":{},"Chap_10.html":{},"Chap_10.html#problem-103":{},"Chap_10.html#using-the-least-mean-square-error-criterion":{},"Chap_10.html#what-is-that-least-mean-square-error":{},"Chap_11.html":{},"Chap_11.html#estimating-the-mean":{},"Chap_11.html#problem-112":{},"Chap_11.html#problem-113":{},"Chap_11.html#problem-114":{},"Chap_11.html#problem-117":{},"Chap_11.html#problem-118":{},"Chap_11.html#problem-119":{},"Chap_12.html":{},"Chap_12.html#problem-121":{},"Chap_12.html#problem-122":{},"Chap_12.html#problem-123":{},"Chap_2.html":{},"Chap_2.html#problem-21":{},"Chap_3.html":{},"Chap_3.html#problem-310":{},"Chap_3.html#problem-33":{},"Chap_3.html#problem-34":{},"Chap_3.html#problem-35":{},"Chap_3.html#problem-36":{},"Chap_3.html#problem-37":{},"Chap_3.html#problem-38":{},"Chap_3.html#problem-39":{},"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#example-is-that-coin-fair":{},"Chap_4.html#problem-41":{},"Chap_4.html#problem-44":{},"Chap_5.html":{},"Chap_5.html#example-pink-noise":{},"Chap_5.html#problem-55":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_6.html":{},"Chap_6.html#problem-61":{},"Chap_6.html#problem-62":{},"Chap_6.html#problem-64":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function_1":{},"Chap_7.html#autocorrelation-function_2":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#impulse-invariant-sampling":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#problem-73":{},"Chap_7.html#problem-77":{},"Chap_7.html#tethered-particle-motion":{},"Chap_8.html":{},"Chap_8.html#characterizing-signal-to-noise-ratios":{},"Chap_8.html#problem-81":{},"Chap_8.html#problem-83":{},"Chap_9.html":{},"Chap_9.html#problem-91":{},"Chap_9.html#problem-92":{},"Chap_9.html#the-matched-filter":{}},"title":{"Chap_10.html#determining-the-wiener-filter":{}}}],["determinist",{"_index":605,"text":{"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#the-more-general-restoration-case-noise-distortion":{},"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_12.html":{},"Chap_12.html#windowed-observations":{},"Chap_2.html":{},"Chap_2.html#prologue":{},"Chap_3.html":{},"Chap_3.html#introduction":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#correlations-simple-and-complex":{},"Chap_5.html#problem-55":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_6.html":{},"Chap_6.html#interpretation-of-the-convolution-result":{},"Chap_6.html#the-autocorrelation-function":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function":{},"Chap_7.html#autocorrelation-function_1":{},"Chap_7.html#power-spectral-density":{},"Chap_7.html#problem-72":{},"Chap_7.html#problem-73":{},"Chap_8.html":{},"Chap_8.html#example-filtering-noise":{},"Chap_8.html#example-not-too-noisy":{},"Chap_8.html#snr-for-deterministic-signals-in-the-presence-of-noise":{},"Chap_8.html#snr-for-random-signals-in-the-presence-of-noise":{},"Chap_9.html":{},"Chap_9.html#setting-up-the-problem":{}},"title":{"Chap_8.html#snr-for-deterministic-signals-in-the-presence-of-noise":{}}}],["deterministic\u2014not",{"_index":2167,"text":{"Chap_4.html":{},"Chap_4.html#problem-44":{},"Chap_4.html#properties-of-averaging":{}},"title":{}}],["develop",{"_index":371,"text":{"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#the-wiener-hopf-equation":{},"Chap_10.html#using-the-least-mean-square-error-criterion":{},"Chap_11.html":{},"Chap_11.html#aspects-of-estimation":{},"Chap_12.html":{},"Chap_12.html#problem-122":{},"Chap_2.html":{},"Chap_2.html#prologue":{},"Chap_3.html":{},"Chap_3.html#what-is-a-random-signal":{},"Chap_4.html":{},"Chap_4.html#example-fair-chance":{},"Chap_5.html":{},"Chap_5.html#example-pink-noise":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{},"Chap_6.html#laboratory-exercise-68":{},"Chap_6.html#the-autocorrelation-function":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function_1":{},"Chap_7.html#the-langevin-equation-a-case-study":{},"Chap_7.html#why-this-case-study":{},"info.html":{},"info.html#technical-details":{}},"title":{}}],["deviat",{"_index":966,"text":{"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_3.html":{},"Chap_3.html#problem-34":{},"Chap_3.html#problem-35":{},"Chap_3.html#problem-37":{},"Chap_4.html":{},"Chap_4.html#problem-49":{},"Chap_4.html#properties-of-averaging":{},"Chap_5.html":{},"Chap_5.html#correlations-simple-and-complex":{},"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#the-langevin-velocity-equation":{},"Chap_8.html":{},"Chap_8.html#snr-for-random-signals-in-the-presence-of-noise":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{},"Chap_9.html":{},"Chap_9.html#problem-91":{}},"title":{"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{}}}],["devic",{"_index":118,"text":{"Chap_1.html":{}},"title":{"Chap_1.html#outside-this-device":{}}}],["dft",{"_index":803,"text":{"Chap_10.html":{},"Chap_10.html#laboratory-exercise-105":{}},"title":{}}],["dice",{"_index":1978,"text":{"Chap_3.html":{},"Chap_3.html#problem-37":{},"Chap_4.html":{},"Chap_4.html#example-dice-money":{}},"title":{"Chap_4.html#example-dice-money":{}}}],["dictionari",{"_index":199,"text":{"Chap_1.html":{},"Chap_1.html#enhanced-experience":{},"Chap_2.html":{},"Chap_2.html#problem-21":{},"Chap_4.html":{},"Chap_4.html#laboratory-exercise-42":{}},"title":{}}],["die",{"_index":1840,"text":{"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#example-average-experience":{},"Chap_4.html#example-dice-money":{},"Chap_4.html#example-fair-chance":{},"Chap_4.html#laboratory-exercise-42":{},"Chap_4.html#other-averages":{},"Chap_4.html#problem-42":{}},"title":{}}],["dietrich",{"_index":3178,"text":{"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#one-step-further":{},"Chap_7.html#problem-711":{},"Chap_7.html#tethered-particle-motion":{}},"title":{}}],["differ",{"_index":323,"text":{"Chap_10.html":{},"Chap_10.html#example-sound-of-distorted-music":{},"Chap_10.html#the-restoration-case-noise":{},"Chap_11.html":{},"Chap_11.html#langevin-redux":{},"Chap_11.html#problem-117":{},"Chap_11.html#trouble-in-paradise":{},"Chap_12.html":{},"Chap_12.html#problem-122":{},"Chap_12.html#the-periodogram-unbiased":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_12.html#windowed-observations":{},"Chap_13.html":{},"Chap_13.html#appendix-i-mean-square-error-minimization":{},"Chap_4.html":{},"Chap_4.html#cross-covariance":{},"Chap_4.html#example-is-that-coin-fair":{},"Chap_4.html#problem-42":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_5.html":{},"Chap_5.html#laboratory-exercise-51":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_6.html":{},"Chap_6.html#problem-64":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function_1":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#expected-value":{},"Chap_7.html#from-t-to-n":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#impulse-invariant-sampling":{},"Chap_7.html#one-step-further":{},"Chap_7.html#power-spectral-density":{},"Chap_7.html#the-langevin-equation-a-case-study":{},"Chap_7.html#the-langevin-position-equation":{},"Chap_7.html#the-langevin-velocity-equation":{},"Chap_9.html":{},"Chap_9.html#problem-92":{}},"title":{}}],["differenti",{"_index":364,"text":{"Chap_10.html":{},"Chap_10.html#using-the-least-mean-square-error-criterion":{},"Chap_11.html":{},"Chap_11.html#langevin-redux":{},"Chap_13.html":{},"Chap_13.html#appendix-i-mean-square-error-minimization":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#from-t-to-n":{},"Chap_7.html#impulse-invariant-sampling":{},"Chap_7.html#tethered-particle-motion":{},"Chap_7.html#the-langevin-equation-a-case-study":{}},"title":{}}],["difficult",{"_index":282,"text":{"Chap_10.html":{},"Chap_10.html#the-wiener-filter":{},"Chap_10.html#the-wiener-hopf-equation":{},"Chap_11.html":{},"Chap_11.html#estimating-the-autocorrelation-function":{},"Chap_11.html#example-estimating-the-poisson-rate":{},"Chap_3.html":{},"Chap_3.html#the-basics":{},"Chap_4.html":{},"Chap_4.html#the-mechanics-of-correlations":{}},"title":{}}],["difficulti",{"_index":1901,"text":{"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_5.html":{},"Chap_5.html#a-digression":{}},"title":{}}],["diffus",{"_index":3379,"text":{"Chap_7.html":{},"Chap_7.html#problem-77":{},"Chap_8.html":{},"Chap_8.html#problem-83":{}},"title":{}}],["digit",{"_index":20,"text":{"Chap_1.html":{},"Chap_1.html#how-to-use-this-ibook":{},"Chap_10.html":{},"Chap_10.html#example-sound-of-distorted-music":{},"Chap_10.html#laboratory-exercise-105":{},"Chap_2.html":{},"Chap_2.html#prologue":{},"Chap_4.html":{},"Chap_4.html#laboratory-exercise-42":{},"Chap_5.html":{},"Chap_5.html#laboratory-exercise-51":{},"Chap_7.html":{},"Chap_7.html#descriptive-statistic-variance":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#one-step-further":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#problem-78":{},"Chap_7.html#the-langevin-equation-a-case-study":{},"Chap_8.html":{},"Chap_8.html#problem-83":{}},"title":{}}],["digress",{"_index":2440,"text":{"Chap_5.html":{}},"title":{"Chap_5.html#a-digression":{}}}],["dimens",{"_index":2808,"text":{"Chap_7.html":{},"Chap_7.html#the-langevin-equation-a-case-study":{}},"title":{}}],["dimension",{"_index":642,"text":{"Chap_10.html":{},"Chap_10.html#example-sound-of-distorted-music":{},"Chap_10.html#laboratory-exercise-103":{},"Chap_4.html":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_7.html":{},"Chap_7.html#tethered-particle-motion":{},"Chap_7.html#the-langevin-velocity-equation":{},"Chap_9.html":{},"Chap_9.html#laboratory-exercise-93":{}},"title":{}}],["direct",{"_index":466,"text":{"Chap_10.html":{},"Chap_10.html#the-wiener-hopf-equation":{},"Chap_2.html":{},"Chap_2.html#prologue":{},"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#how-big-is-big-how-small-is-small":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#tethered-particle-motion":{}},"title":{}}],["directli",{"_index":1079,"text":{"Chap_11.html":{},"Chap_11.html#langevin-redux":{},"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{},"info.html":{},"info.html#tips-short-cuts":{}},"title":{}}],["dirti",{"_index":772,"text":{"Chap_10.html":{},"Chap_10.html#laboratory-exercise-104":{}},"title":{}}],["disadvantag",{"_index":2819,"text":{"Chap_7.html":{},"Chap_7.html#from-t-to-n":{}},"title":{}}],["disappear",{"_index":2655,"text":{"Chap_6.html":{},"Chap_6.html#the-autocorrelation-function":{}},"title":{}}],["disciplin",{"_index":1828,"text":{"Chap_3.html":{},"Chap_3.html#the-basics":{}},"title":{}}],["disclosur",{"_index":1563,"text":{"Chap_12.html":{},"Chap_12.html#problem-123":{},"Chap_3.html":{},"Chap_3.html#problem-310":{}},"title":{}}],["discrep",{"_index":3384,"text":{"Chap_7.html":{},"Chap_7.html#problem-78":{}},"title":{}}],["discret",{"_index":761,"text":{"Chap_10.html":{},"Chap_10.html#laboratory-exercise-105":{},"Chap_10.html#problem-104":{},"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#other-windows":{},"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_13.html#epilogue":{},"Chap_2.html":{},"Chap_2.html#prologue":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_3.html#problem-310":{},"Chap_3.html#problem-32":{},"Chap_3.html#problem-34":{},"Chap_4.html":{},"Chap_4.html#autocorrelation":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#describing-the-time-average":{},"Chap_4.html#example-dice-money":{},"Chap_4.html#example-is-that-coin-fair":{},"Chap_4.html#laboratory-exercise-42":{},"Chap_4.html#other-averages":{},"Chap_4.html#problem-48":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#example-pink-noise":{},"Chap_5.html#laboratory-exercise-51":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_6.html":{},"Chap_6.html#filtering-of-stochastic-signals":{},"Chap_6.html#problem-61":{},"Chap_6.html#problem-62":{},"Chap_6.html#problem-64":{},"Chap_7.html":{},"Chap_7.html#descriptive-statistic-variance":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#expected-value":{},"Chap_7.html#from-t-to-n":{},"Chap_7.html#impulse-invariant-sampling":{},"Chap_7.html#one-step-further":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#problem-71":{},"Chap_7.html#problem-78":{},"Chap_7.html#the-langevin-equation-a-case-study":{},"Chap_7.html#why-this-case-study":{},"Chap_8.html":{},"Chap_8.html#example-cocktail-party-noise":{},"Chap_8.html#problem-83":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{}},"title":{"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{}}}],["discrimin",{"_index":3186,"text":{"Chap_7.html":{},"Chap_7.html#tethered-particle-motion":{},"Chap_8.html":{},"Chap_8.html#problem-83":{}},"title":{}}],["discuss",{"_index":795,"text":{"Chap_10.html":{},"Chap_10.html#laboratory-exercise-105":{},"Chap_11.html":{},"Chap_11.html#problem-118":{},"Chap_12.html":{},"Chap_12.html#problem-122":{},"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_3.html":{},"Chap_3.html#problem-39":{},"Chap_4.html":{},"Chap_4.html#laboratory-exercise-42":{},"Chap_4.html#problem-48":{},"Chap_4.html#problem-49":{},"Chap_4.html#properties-of-averaging":{},"Chap_4.html#the-ergodic-process":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_5.html#problem-53":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_6.html":{},"Chap_6.html#filtering-of-stochastic-signals":{},"Chap_6.html#laboratory-exercise-61":{},"Chap_6.html#laboratory-exercise-62":{},"Chap_6.html#problem-63":{},"Chap_6.html#problem-65":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#expected-value":{},"Chap_7.html#from-t-to-n":{},"Chap_7.html#problem-78":{},"Chap_7.html#why-this-case-study":{},"Chap_8.html":{},"Chap_8.html#snr-for-random-signals-in-the-presence-of-noise":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{},"Chap_9.html":{},"Chap_9.html#setting-up-the-problem":{},"info.html":{},"info.html#acknowledgments":{}},"title":{}}],["dispers",{"_index":3086,"text":{"Chap_7.html":{},"Chap_7.html#descriptive-statistic-variance":{},"Chap_7.html#one-step-further":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#problem-711":{},"Chap_7.html#problem-77":{}},"title":{}}],["displac",{"_index":3091,"text":{"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#tethered-particle-motion":{}},"title":{}}],["display",{"_index":756,"text":{"Chap_10.html":{},"Chap_10.html#laboratory-exercise-105":{},"Chap_10.html#problem-104":{},"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_4.html":{},"Chap_4.html#laboratory-exercise-41":{},"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function_1":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{}},"title":{}}],["distanc",{"_index":1237,"text":{"Chap_11.html":{},"Chap_11.html#laboratory-exercise-113":{},"Chap_12.html":{},"Chap_12.html#problem-121":{}},"title":{}}],["distinct",{"_index":2158,"text":{"Chap_4.html":{},"Chap_4.html#example-dice-money":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function_2":{},"Chap_8.html":{},"Chap_8.html#example-filtering-noise":{}},"title":{}}],["distinguish",{"_index":445,"text":{"Chap_10.html":{},"Chap_10.html#the-wiener-hopf-equation":{},"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_12.html":{},"Chap_12.html#problem-123":{},"Chap_3.html":{},"Chap_3.html#what-is-a-random-signal":{},"Chap_4.html":{},"Chap_4.html#problem-42":{}},"title":{}}],["distort",{"_index":594,"text":{"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#example-cleaning-up-our-act":{},"Chap_10.html#example-sound-of-distorted-music":{},"Chap_10.html#laboratory-exercise-103":{},"Chap_10.html#laboratory-exercise-104":{},"Chap_10.html#the-more-general-restoration-case-noise-distortion":{},"Chap_10.html#why-we-avoid-the-inverse-filter":{},"Chap_12.html":{},"Chap_12.html#problem-122":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{}},"title":{"Chap_10.html#example-sound-of-distorted-music":{},"Chap_10.html#the-more-general-restoration-case-noise-distortion":{}}}],["distribut",{"_index":431,"text":{"Chap_10.html":{},"Chap_10.html#correlation-returns":{},"Chap_11.html":{},"Chap_11.html#example-estimating-the-poisson-rate":{},"Chap_11.html#maximum-likelihood-estimation":{},"Chap_11.html#problem-116":{},"Chap_11.html#problem-117":{},"Chap_2.html":{},"Chap_2.html#problem-21":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#example-fair-chance":{},"Chap_4.html#example-is-that-coin-fair":{},"Chap_4.html#laboratory-exercise-42":{},"Chap_4.html#problem-41":{},"Chap_4.html#problem-45":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_5.html":{},"Chap_5.html#correlations-simple-and-complex":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{},"Chap_6.html#laboratory-exercise-67":{},"Chap_6.html#the-autocorrelation-function":{},"Chap_6.html#the-mean":{},"Chap_7.html":{},"Chap_7.html#expected-value":{},"Chap_7.html#how-big-is-big-how-small-is-small":{},"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{},"info.html":{},"info.html#usage":{}},"title":{}}],["diverg",{"_index":620,"text":{"Chap_10.html":{},"Chap_10.html#why-we-avoid-the-inverse-filter":{},"Chap_11.html":{},"Chap_11.html#trouble-in-paradise":{},"Chap_5.html":{},"Chap_5.html#a-digression":{}},"title":{}}],["dna",{"_index":3129,"text":{"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#one-step-further":{},"Chap_7.html#tethered-particle-motion":{}},"title":{}}],["dof",{"_index":1213,"text":{"Chap_11.html":{},"Chap_11.html#problem-117":{}},"title":{}}],["dollar",{"_index":3383,"text":{"Chap_7.html":{},"Chap_7.html#problem-78":{}},"title":{}}],["domain",{"_index":487,"text":{"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#example-cleaning-up-our-act":{},"Chap_10.html#example-sound-of-distorted-music":{},"Chap_10.html#why-we-avoid-the-inverse-filter":{},"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#other-windows":{},"Chap_12.html#problem-122":{},"Chap_12.html#windowed-observations":{},"Chap_2.html":{},"Chap_2.html#prologue":{},"Chap_3.html":{},"Chap_3.html#introduction":{},"Chap_3.html#the-basics":{},"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_7.html":{},"Chap_7.html#tethered-particle-motion":{},"Chap_9.html":{},"Chap_9.html#setting-up-the-problem":{}},"title":{"Chap_10.html#as-seen-from-the-fourier-domain":{}}}],["domin",{"_index":565,"text":{"Chap_10.html":{},"Chap_10.html#classic-example-classic-result":{},"Chap_5.html":{},"Chap_5.html#example-white-noise":{},"Chap_7.html":{},"Chap_7.html#power-spectral-density_1":{}},"title":{}}],["done",{"_index":3704,"text":{"info.html":{},"info.html#technical-details":{}},"title":{}}],["don\u2019t",{"_index":1838,"text":{"Chap_3.html":{},"Chap_3.html#problem-37":{},"Chap_3.html#what-is-a-random-signal":{}},"title":{"Chap_3.html#example-dont-bet-on-it":{}}}],["dot",{"_index":1841,"text":{"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{}},"title":{}}],["dots)\\rightarrow",{"_index":1884,"text":{"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{}},"title":{}}],["doubl",{"_index":2656,"text":{"Chap_6.html":{},"Chap_6.html#the-autocorrelation-function":{},"Chap_7.html":{},"Chap_7.html#tethered-particle-motion":{}},"title":{}}],["down",{"_index":1174,"text":{"Chap_11.html":{},"Chap_11.html#problem-113":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_9.html":{},"Chap_9.html#performance-in-the-presence-of-noise":{}},"title":{}}],["downarrow",{"_index":2514,"text":{"Chap_5.html":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{}},"title":{}}],["dr",{"_index":1775,"text":{"Chap_2.html":{},"Chap_2.html#prologue":{},"info.html":{},"info.html#acknowledgments":{}},"title":{}}],["draw",{"_index":2769,"text":{"Chap_6.html":{},"Chap_6.html#problem-61":{}},"title":{}}],["drive",{"_index":2357,"text":{"Chap_4.html":{},"Chap_4.html#problem-48":{},"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#expected-value":{},"Chap_7.html#how-big-is-big-how-small-is-small":{},"Chap_7.html#power-spectral-density":{},"Chap_7.html#the-langevin-equation-a-case-study":{},"Chap_7.html#the-langevin-position-equation":{},"Chap_7.html#the-langevin-velocity-equation":{}},"title":{}}],["driven",{"_index":2891,"text":{"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small":{}},"title":{}}],["dsdna",{"_index":3133,"text":{"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#tethered-particle-motion":{}},"title":{}}],["dt",{"_index":1693,"text":{"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{}},"title":{}}],["due",{"_index":602,"text":{"Chap_10.html":{},"Chap_10.html#example-sound-of-distorted-music":{},"Chap_10.html#the-more-general-restoration-case-noise-distortion":{},"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#one-step-further":{},"Chap_7.html#problem-79":{},"Chap_7.html#tethered-particle-motion":{},"Chap_8.html":{},"Chap_8.html#problem-83":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{}},"title":{}}],["dummi",{"_index":529,"text":{"Chap_10.html":{},"Chap_10.html#what-is-that-least-mean-square-error":{},"Chap_6.html":{},"Chap_6.html#the-autocorrelation-function":{}},"title":{}}],["durat",{"_index":894,"text":{"Chap_11.html":{},"Chap_11.html#estimating-the-autocorrelation-function":{},"Chap_11.html#example-estimating-the-poisson-rate":{},"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#other-windows":{},"Chap_12.html#problem-122":{},"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{}},"title":{}}],["dure",{"_index":1023,"text":{"Chap_11.html":{},"Chap_11.html#estimating-the-autocorrelation-function":{},"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{}},"title":{}}],["dutch",{"_index":1565,"text":{"Chap_12.html":{},"Chap_12.html#problem-123":{},"Chap_3.html":{},"Chap_3.html#problem-310":{}},"title":{}}],["dye",{"_index":3199,"text":{"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{}},"title":{}}],["dynam",{"_index":36,"text":{"Chap_1.html":{},"Chap_1.html#how-to-use-this-ibook":{},"Chap_1.html#sound-of-music":{},"Chap_11.html":{},"Chap_11.html#estimating-the-autocorrelation-function":{},"Chap_13.html":{},"Chap_13.html#epilogue":{},"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#how-big-is-big-how-small-is-small":{},"Chap_7.html#one-step-further":{},"Chap_7.html#tethered-particle-motion":{}},"title":{}}],["e",{"_index":332,"text":{"Chap_10.html":{},"Chap_10.html#expressing-the-mean-square-error":{},"Chap_10.html#using-the-least-mean-square-error-criterion":{},"Chap_10.html#what-is-that-least-mean-square-error":{},"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_11.html#langevin-redux":{},"Chap_11.html#problem-112":{},"Chap_11.html#problem-115":{},"Chap_11.html#problem-116":{},"Chap_11.html#problem-117":{},"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#problem-122":{},"Chap_12.html#spectral-estimation":{},"Chap_12.html#the-periodogram-unbiased":{},"Chap_13.html":{},"Chap_13.html#appendix-i-mean-square-error-minimization":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_3.html#problem-39":{},"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#problem-41":{},"Chap_4.html#problem-42":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#impulse-invariant-sampling":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#problem-711":{},"Chap_7.html#the-langevin-position-equation":{},"Chap_7.html#the-langevin-velocity-equation":{},"Chap_8.html":{},"Chap_8.html#example-filtering-noise":{},"Chap_8.html#problem-83":{},"Chap_9.html":{},"Chap_9.html#example-matching-your-filter":{},"Chap_9.html#the-classic-example":{},"Chap_9.html#using-cauchy-schwartz":{},"info.html":{},"info.html#technical-details":{}},"title":{}}],["e.g",{"_index":2219,"text":{"Chap_4.html":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_7.html":{},"Chap_7.html#tethered-particle-motion":{}},"title":{}}],["e[n",{"_index":388,"text":{"Chap_10.html":{},"Chap_10.html#expressing-the-mean-square-error":{},"Chap_11.html":{},"Chap_11.html#problem-118":{}},"title":{}}],["e\\left",{"_index":335,"text":{"Chap_10.html":{},"Chap_10.html#classic-example-classic-result":{},"Chap_10.html#correlation-returns":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#expressing-the-mean-square-error":{},"Chap_10.html#the-more-general-restoration-case-noise-distortion":{},"Chap_10.html#using-the-least-mean-square-error-criterion":{},"Chap_10.html#what-is-that-least-mean-square-error":{},"Chap_11.html":{},"Chap_11.html#aspects-of-estimation":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_11.html#estimating-the-autocorrelation-function":{},"Chap_11.html#estimating-the-mean":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_11.html#problem-115":{},"Chap_11.html#problem-116":{},"Chap_11.html#trouble-in-paradise":{},"Chap_12.html":{},"Chap_12.html#the-periodogram-unbiased":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_12.html#windowed-observations":{},"Chap_13.html":{},"Chap_13.html#appendix-i-mean-square-error-minimization":{},"Chap_4.html":{},"Chap_4.html#auto-covariance":{},"Chap_4.html#autocorrelation":{},"Chap_4.html#cross-correlation":{},"Chap_4.html#cross-covariance":{},"Chap_4.html#describing-the-time-average":{},"Chap_4.html#example-average-experience":{},"Chap_4.html#example-dice-money":{},"Chap_4.html#example-is-that-coin-fair":{},"Chap_4.html#other-averages":{},"Chap_4.html#properties-of-averaging":{},"Chap_5.html":{},"Chap_5.html#correlations-and-memory":{},"Chap_5.html#correlations-simple-and-complex":{},"Chap_5.html#example-delayed-effect":{},"Chap_5.html#example-pink-noise":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_6.html":{},"Chap_6.html#filtering-of-stochastic-signals":{},"Chap_6.html#problem-61":{},"Chap_6.html#problem-62":{},"Chap_6.html#problem-65":{},"Chap_6.html#problem-66":{},"Chap_6.html#the-autocorrelation-function":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_6.html#the-mean":{},"Chap_8.html":{},"Chap_8.html#example-not-too-noisy":{},"Chap_9.html":{},"Chap_9.html#setting-up-the-problem":{}},"title":{}}],["e^{j\\omega",{"_index":2503,"text":{"Chap_5.html":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_7.html":{},"Chap_7.html#expected-value":{},"Chap_9.html":{},"Chap_9.html#setting-up-the-problem":{},"Chap_9.html#using-cauchy-schwartz":{}},"title":{}}],["each",{"_index":983,"text":{"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#problem-121":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_3.html#problem-33":{},"Chap_3.html#problem-34":{},"Chap_3.html#problem-38":{},"Chap_3.html#what-is-a-random-signal":{},"Chap_4.html":{},"Chap_4.html#laboratory-exercise-42":{},"Chap_4.html#problem-42":{},"Chap_4.html#properties-of-averaging":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_6.html":{},"Chap_6.html#problem-61":{},"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#expected-value":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#one-step-further":{},"Chap_7.html#power-spectral-density_1":{},"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{},"Chap_9.html":{},"Chap_9.html#problem-91":{},"Chap_9.html#problem-92":{}},"title":{}}],["ear",{"_index":2787,"text":{"Chap_6.html":{},"Chap_6.html#laboratory-exercise-64":{},"Chap_6.html#laboratory-exercise-65":{},"Chap_6.html#laboratory-exercise-66":{},"Chap_6.html#laboratory-exercise-67":{}},"title":{}}],["earlier",{"_index":443,"text":{"Chap_10.html":{},"Chap_10.html#the-wiener-hopf-equation":{},"Chap_12.html":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_4.html":{},"Chap_4.html#describing-the-time-average":{},"Chap_5.html":{},"Chap_5.html#correlations-and-memory":{},"Chap_6.html":{},"Chap_6.html#the-mean":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#one-step-further":{},"Chap_7.html#power-spectral-density_1":{},"Chap_8.html":{},"Chap_8.html#snr-for-random-signals-in-the-presence-of-noise":{},"Chap_9.html":{},"Chap_9.html#the-matched-filter-as-an-autocorrelation":{}},"title":{}}],["easi",{"_index":533,"text":{"Chap_10.html":{},"Chap_10.html#what-is-that-least-mean-square-error":{},"Chap_4.html":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_6.html":{},"Chap_6.html#interpretation-of-the-convolution-result":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_7.html":{},"Chap_7.html#from-t-to-n":{}},"title":{}}],["easier",{"_index":3065,"text":{"Chap_7.html":{},"Chap_7.html#autocorrelation-function_2":{},"Chap_7.html#expected-value":{},"Chap_9.html":{},"Chap_9.html#laboratory-exercise-93":{}},"title":{}}],["east",{"_index":2739,"text":{"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{}},"title":{}}],["econom",{"_index":854,"text":{"Chap_11.html":{},"Chap_11.html#aspects-of-estimation":{},"Chap_7.html":{},"Chap_7.html#why-this-case-study":{}},"title":{}}],["economi",{"_index":2380,"text":{"Chap_4.html":{},"Chap_4.html#laboratory-exercise-42":{}},"title":{}}],["eddi",{"_index":2347,"text":{"Chap_4.html":{},"Chap_4.html#problem-47":{}},"title":{}}],["eddie\u2019",{"_index":2353,"text":{"Chap_4.html":{},"Chap_4.html#problem-47":{}},"title":{}}],["edg",{"_index":1543,"text":{"Chap_12.html":{},"Chap_12.html#problem-122":{}},"title":{}}],["edit",{"_index":55,"text":{"Chap_1.html":{},"Chap_1.html#how-to-use-this-ibook":{},"info.html":{},"info.html#version":{}},"title":{}}],["educ",{"_index":249,"text":{"Chap_1.html":{},"Chap_1.html#enhanced-experience":{},"Chap_2.html":{},"Chap_2.html#prologue":{},"info.html":{},"info.html#contact":{}},"title":{}}],["effect",{"_index":255,"text":{"Chap_1.html":{},"Chap_1.html#enhanced-experience":{},"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#example-cleaning-up-our-act":{},"Chap_10.html#laboratory-exercise-104":{},"Chap_10.html#the-wiener-filter":{},"Chap_12.html":{},"Chap_12.html#laboratory-exercise-123":{},"Chap_12.html#laboratory-exercise-124":{},"Chap_12.html#other-windows":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_5.html":{},"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{},"Chap_6.html#laboratory-exercise-67":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#descriptive-statistic-variance":{},"Chap_7.html#tethered-particle-motion":{}},"title":{"Chap_5.html#example-delayed-effect":{}}}],["effects\u2014se",{"_index":3011,"text":{"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{}},"title":{}}],["effici",{"_index":2569,"text":{"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{}},"title":{}}],["eight",{"_index":1487,"text":{"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#problem-122":{},"Chap_3.html":{},"Chap_3.html#the-basics":{}},"title":{}}],["einstein",{"_index":3378,"text":{"Chap_7.html":{},"Chap_7.html#problem-77":{}},"title":{}}],["elabor",{"_index":2700,"text":{"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{}},"title":{}}],["elast",{"_index":3219,"text":{"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{}},"title":{}}],["electron",{"_index":17,"text":{"Chap_1.html":{},"Chap_1.html#how-to-use-this-ibook":{},"Chap_10.html":{},"Chap_10.html#example-sound-of-distorted-music":{},"Chap_10.html#the-more-general-restoration-case-noise-distortion":{},"Chap_4.html":{},"Chap_4.html#problem-42":{},"Chap_8.html":{},"Chap_8.html#example-cocktail-party-noise":{},"info.html":{},"info.html#acknowledgments":{}},"title":{}}],["eleg",{"_index":2863,"text":{"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small":{}},"title":{}}],["element",{"_index":2757,"text":{"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{}},"title":{}}],["ell",{"_index":2118,"text":{"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{}},"title":{}}],["email",{"_index":3665,"text":{"info.html":{},"info.html#contact":{}},"title":{}}],["embodi",{"_index":3140,"text":{"Chap_7.html":{},"Chap_7.html#tethered-particle-motion":{}},"title":{}}],["emerson",{"_index":1267,"text":{"Chap_11.html":{},"Chap_11.html#laboratory-exercise-113":{},"Chap_12.html":{},"Chap_12.html#laboratory-exercise-124":{}},"title":{}}],["emiss",{"_index":897,"text":{"Chap_11.html":{},"Chap_11.html#example-estimating-the-poisson-rate":{},"Chap_11.html#problem-114":{},"Chap_4.html":{},"Chap_4.html#problem-42":{},"Chap_5.html":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{}},"title":{}}],["emit",{"_index":2323,"text":{"Chap_4.html":{},"Chap_4.html#problem-42":{},"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{}},"title":{}}],["emphas",{"_index":2234,"text":{"Chap_4.html":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{}},"title":{}}],["emptor",{"_index":1568,"text":{"Chap_12.html":{},"Chap_12.html#problem-123":{},"Chap_3.html":{},"Chap_3.html#problem-310":{},"Chap_4.html":{},"Chap_4.html#example-dice-money":{}},"title":{}}],["enabl",{"_index":475,"text":{"Chap_10.html":{},"Chap_10.html#the-wiener-hopf-equation":{}},"title":{}}],["encount",{"_index":2053,"text":{"Chap_4.html":{},"Chap_4.html#characterization-of-random-signals":{},"Chap_4.html#problem-49":{},"Chap_7.html":{},"Chap_7.html#power-spectral-density":{},"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{}},"title":{}}],["end",{"_index":137,"text":{"Chap_1.html":{},"Chap_1.html#enhanced-experience":{},"Chap_1.html#getting-around":{},"Chap_13.html":{},"Chap_13.html#epilogue":{},"Chap_3.html":{},"Chap_3.html#what-is-a-random-signal":{},"Chap_4.html":{},"Chap_4.html#properties-of-averaging":{},"Chap_7.html":{},"Chap_7.html#problem-79":{},"Chap_7.html#tethered-particle-motion":{},"info.html":{},"info.html#tips-short-cuts":{}},"title":{}}],["endnot",{"_index":131,"text":{"Chap_1.html":{},"Chap_1.html#getting-around":{}},"title":{}}],["end{align",{"_index":103,"text":{"Chap_1.html":{},"Chap_1.html#highlighting":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_3.html#the-basics":{},"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#power-spectral-density_1":{}},"title":{}}],["end{array",{"_index":356,"text":{"Chap_10.html":{},"Chap_10.html#classic-example-classic-result":{},"Chap_10.html#correlation-returns":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#expressing-the-mean-square-error":{},"Chap_10.html#using-the-least-mean-square-error-criterion":{},"Chap_10.html#what-is-that-least-mean-square-error":{},"Chap_11.html":{},"Chap_11.html#example-estimating-the-poisson-rate":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_11.html#langevin-redux":{},"Chap_11.html#problem-119":{},"Chap_11.html#trouble-in-paradise":{},"Chap_12.html":{},"Chap_12.html#problem-123":{},"Chap_12.html#the-periodogram-unbiased":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_12.html#windowed-observations":{},"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_4.html":{},"Chap_4.html#auto-covariance":{},"Chap_4.html#autocorrelation":{},"Chap_4.html#cross-correlation":{},"Chap_4.html#cross-covariance":{},"Chap_4.html#describing-the-time-average":{},"Chap_4.html#example-dice-money":{},"Chap_4.html#example-is-that-coin-fair":{},"Chap_4.html#other-averages":{},"Chap_4.html#problem-41":{},"Chap_4.html#properties-of-averaging":{},"Chap_4.html#the-ergodic-process":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#correlations-and-memory":{},"Chap_5.html#correlations-simple-and-complex":{},"Chap_5.html#example-delayed-effect":{},"Chap_5.html#example-pink-noise":{},"Chap_5.html#problem-56":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{},"Chap_6.html#filtering-of-stochastic-signals":{},"Chap_6.html#problem-61":{},"Chap_6.html#problem-63":{},"Chap_6.html#the-autocorrelation-function":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_6.html#the-mean":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function":{},"Chap_7.html#autocorrelation-function_2":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#descriptive-statistic-variance":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#expected-value":{},"Chap_7.html#expected-value_1":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#impulse-invariant-sampling":{},"Chap_7.html#one-step-further":{},"Chap_7.html#power-spectral-density":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#tethered-particle-motion":{},"Chap_7.html#the-langevin-equation-a-case-study":{},"Chap_7.html#the-langevin-position-equation":{},"Chap_7.html#the-langevin-velocity-equation":{},"Chap_8.html":{},"Chap_8.html#example-cocktail-party-noise":{},"Chap_8.html#example-filtering-noise":{},"Chap_8.html#example-not-too-noisy":{},"Chap_8.html#problem-83":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{},"Chap_9.html":{},"Chap_9.html#example-matching-your-filter":{},"Chap_9.html#setting-up-the-problem":{}},"title":{}}],["end{cas",{"_index":1866,"text":{"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_3.html#problem-310":{}},"title":{}}],["energi",{"_index":1695,"text":{"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_9.html":{},"Chap_9.html#example-matching-your-filter":{}},"title":{}}],["engin",{"_index":1250,"text":{"Chap_11.html":{},"Chap_11.html#laboratory-exercise-113":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_9.html":{},"Chap_9.html#laboratory-exercise-93":{}},"title":{}}],["englewood",{"_index":779,"text":{"Chap_10.html":{},"Chap_10.html#laboratory-exercise-105":{},"Chap_4.html":{},"Chap_4.html#laboratory-exercise-42":{},"Chap_5.html":{},"Chap_5.html#laboratory-exercise-51":{},"Chap_7.html":{},"Chap_7.html#problem-711":{}},"title":{}}],["english",{"_index":1799,"text":{"Chap_2.html":{},"Chap_2.html#problem-21":{}},"title":{}}],["enhanc",{"_index":189,"text":{"Chap_1.html":{}},"title":{"Chap_1.html#enhanced-experience":{}}}],["enorm",{"_index":3258,"text":{"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{}},"title":{}}],["enough",{"_index":2201,"text":{"Chap_4.html":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#problem-77":{}},"title":{}}],["ensembl",{"_index":1889,"text":{"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#describing-the-time-average":{},"Chap_4.html#example-fair-chance":{},"Chap_5.html":{},"Chap_5.html#the-mechanics-of-correlations-redux":{}},"title":{"Chap_4.html#describing-the-ensemble-average":{}}}],["ensur",{"_index":361,"text":{"Chap_10.html":{},"Chap_10.html#using-the-least-mean-square-error-criterion":{}},"title":{}}],["entir",{"_index":3387,"text":{"Chap_7.html":{},"Chap_7.html#problem-78":{}},"title":{}}],["entiti",{"_index":1710,"text":{"Chap_13.html":{},"Chap_13.html#epilogue":{}},"title":{}}],["entitl",{"_index":3735,"text":{"info.html":{},"info.html#musical-data":{}},"title":{}}],["envelop",{"_index":3157,"text":{"Chap_7.html":{},"Chap_7.html#tethered-particle-motion":{}},"title":{}}],["environment",{"_index":665,"text":{"Chap_10.html":{},"Chap_10.html#example-sound-of-distorted-music":{}},"title":{}}],["envis",{"_index":1880,"text":{"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{}},"title":{}}],["epilogu",{"_index":1707,"text":{"Chap_13.html":{}},"title":{"Chap_13.html#epilogue":{}}}],["eq.\\,\\,5.5",{"_index":2513,"text":{"Chap_5.html":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{}},"title":{}}],["equal",{"_index":593,"text":{"Chap_10.html":{},"Chap_10.html#classic-example-classic-result":{},"Chap_13.html":{},"Chap_13.html#appendix-i-mean-square-error-minimization":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_4.html":{},"Chap_4.html#describing-the-time-average":{},"Chap_4.html#example-is-that-coin-fair":{},"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_7.html":{},"Chap_7.html#power-spectral-density_1":{},"Chap_9.html":{},"Chap_9.html#using-cauchy-schwartz":{}},"title":{}}],["equat",{"_index":34,"text":{"Chap_1.html":{},"Chap_1.html#how-to-use-this-ibook":{},"Chap_10.html":{},"Chap_10.html#as-seen-from-the-fourier-domain":{},"Chap_10.html#classic-example-classic-result":{},"Chap_10.html#correlation-returns":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#expressing-the-mean-square-error":{},"Chap_10.html#problem-101":{},"Chap_10.html#problem-102":{},"Chap_10.html#the-wiener-hopf-equation":{},"Chap_10.html#using-the-least-mean-square-error-criterion":{},"Chap_10.html#what-is-that-least-mean-square-error":{},"Chap_11.html":{},"Chap_11.html#aspects-of-estimation":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_11.html#estimating-the-autocorrelation-function":{},"Chap_11.html#estimating-the-mean":{},"Chap_11.html#example-estimating-the-poisson-rate":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_11.html#langevin-redux":{},"Chap_11.html#maximum-likelihood-estimation":{},"Chap_11.html#problem-1110":{},"Chap_11.html#problem-114":{},"Chap_11.html#problem-116":{},"Chap_11.html#problem-117":{},"Chap_11.html#problem-119":{},"Chap_11.html#trouble-in-paradise":{},"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#problem-121":{},"Chap_12.html#problem-122":{},"Chap_12.html#spectral-estimation":{},"Chap_12.html#the-periodogram-unbiased":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_12.html#windowed-observations":{},"Chap_13.html":{},"Chap_13.html#appendix-i-mean-square-error-minimization":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_3.html":{},"Chap_3.html#introduction":{},"Chap_3.html#problem-35":{},"Chap_4.html":{},"Chap_4.html#cross-correlation":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#example-is-that-coin-fair":{},"Chap_4.html#problem-43":{},"Chap_4.html#problem-44":{},"Chap_4.html#problem-46":{},"Chap_4.html#properties-of-averaging":{},"Chap_4.html#the-ergodic-process":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#correlations-simple-and-complex":{},"Chap_5.html#example-pink-noise":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_5.html#problem-51":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{},"Chap_6.html#interpretation-of-the-convolution-result":{},"Chap_6.html#problem-66":{},"Chap_6.html#the-autocorrelation-function":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_6.html#the-mean":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function":{},"Chap_7.html#autocorrelation-function_1":{},"Chap_7.html#autocorrelation-function_2":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#descriptive-statistic-variance":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#expected-value":{},"Chap_7.html#expected-value_1":{},"Chap_7.html#from-t-to-n":{},"Chap_7.html#how-big-is-big-how-small-is-small":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#impulse-invariant-sampling":{},"Chap_7.html#one-step-further":{},"Chap_7.html#power-spectral-density":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#power-spectral-density_2":{},"Chap_7.html#problem-71":{},"Chap_7.html#problem-710":{},"Chap_7.html#problem-711":{},"Chap_7.html#problem-74":{},"Chap_7.html#problem-75":{},"Chap_7.html#problem-76":{},"Chap_7.html#problem-77":{},"Chap_7.html#problem-78":{},"Chap_7.html#problem-79":{},"Chap_7.html#tethered-particle-motion":{},"Chap_7.html#the-langevin-equation-a-case-study":{},"Chap_7.html#the-langevin-position-equation":{},"Chap_7.html#the-langevin-velocity-equation":{},"Chap_7.html#why-this-case-study":{},"Chap_8.html":{},"Chap_8.html#example-cocktail-party-noise":{},"Chap_8.html#problem-81":{},"Chap_8.html#problem-83":{},"Chap_8.html#snr-for-random-signals-in-the-presence-of-noise":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{},"Chap_9.html":{},"Chap_9.html#performance-in-the-presence-of-noise":{},"Chap_9.html#problem-91":{},"Chap_9.html#setting-up-the-problem":{},"Chap_9.html#the-classic-example":{},"Chap_9.html#the-matched-filter-as-an-autocorrelation":{},"Chap_9.html#using-cauchy-schwartz":{},"info.html":{},"info.html#technical-details":{},"info.html#tips-short-cuts":{}},"title":{"Chap_10.html#the-wiener-hopf-equation":{},"Chap_7.html":{},"Chap_7.html#the-langevin-equation-a-case-study":{},"Chap_7.html#the-langevin-position-equation":{},"Chap_7.html#the-langevin-velocity-equation":{}}}],["equation\u2014and",{"_index":1137,"text":{"Chap_11.html":{},"Chap_11.html#langevin-redux":{}},"title":{}}],["equation\u2014ar",{"_index":2952,"text":{"Chap_7.html":{},"Chap_7.html#power-spectral-density":{}},"title":{}}],["equation\u2014wa",{"_index":1139,"text":{"Chap_11.html":{},"Chap_11.html#langevin-redux":{}},"title":{}}],["equilibrium",{"_index":2113,"text":{"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#one-step-further":{}},"title":{}}],["equipartit",{"_index":3008,"text":{"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{}},"title":{}}],["equival",{"_index":534,"text":{"Chap_10.html":{},"Chap_10.html#what-is-that-least-mean-square-error":{},"Chap_11.html":{},"Chap_11.html#laboratory-exercise-113":{},"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_7.html":{},"Chap_7.html#descriptive-statistic-variance":{},"Chap_8.html":{},"Chap_8.html#example-not-too-noisy":{}},"title":{}}],["ergod",{"_index":287,"text":{"Chap_10.html":{},"Chap_10.html#expressing-the-mean-square-error":{},"Chap_10.html#problem-103":{},"Chap_10.html#the-more-general-restoration-case-noise-distortion":{},"Chap_10.html#the-wiener-filter":{},"Chap_11.html":{},"Chap_11.html#maximum-likelihood-estimation":{},"Chap_11.html#problem-117":{},"Chap_11.html#problem-118":{},"Chap_4.html":{},"Chap_4.html#describing-the-time-average":{},"Chap_4.html#laboratory-exercise-42":{},"Chap_4.html#problem-48":{},"Chap_4.html#the-ergodic-process":{},"Chap_5.html":{},"Chap_5.html#correlations-and-spectra":{},"Chap_5.html#fourier-description-of-correlation-functions":{},"Chap_5.html#problem-53":{},"Chap_5.html#problem-54":{},"Chap_5.html#problem-56":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_6.html":{},"Chap_6.html#filtering-of-stochastic-signals":{},"Chap_6.html#laboratory-exercise-63":{},"Chap_6.html#problem-62":{},"Chap_6.html#problem-64":{},"Chap_6.html#problem-65":{},"Chap_6.html#problem-66":{},"Chap_7.html":{},"Chap_7.html#problem-73":{},"Chap_7.html#the-langevin-equation-a-case-study":{},"Chap_8.html":{},"Chap_8.html#example-filtering-noise":{}},"title":{"Chap_4.html#the-ergodic-process":{}}}],["errata",{"_index":3669,"text":{"info.html":{},"info.html#contact":{}},"title":{}}],["errata@socraticsoftware.org",{"_index":3670,"text":{"info.html":{},"info.html#contact":{}},"title":{}}],["erron",{"_index":2853,"text":{"Chap_7.html":{},"Chap_7.html#impulse-invariant-sampling":{}},"title":{}}],["error",{"_index":324,"text":{"Chap_10.html":{},"Chap_10.html#laboratory-exercise-103":{},"Chap_10.html#the-more-general-restoration-case-noise-distortion":{},"Chap_10.html#the-restoration-case-noise":{},"Chap_10.html#using-the-least-mean-square-error-criterion":{},"Chap_10.html#what-is-that-least-mean-square-error":{},"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_11.html#problem-115":{},"Chap_11.html#problem-116":{},"Chap_11.html#problem-117":{},"Chap_11.html#problem-118":{},"Chap_13.html":{},"Chap_13.html#appendix-i-mean-square-error-minimization":{},"Chap_9.html":{},"Chap_9.html#the-matched-filter":{}},"title":{"Chap_10.html#expressing-the-mean-square-error":{},"Chap_10.html#using-the-least-mean-square-error-criterion":{},"Chap_10.html#what-is-that-least-mean-square-error":{},"Chap_13.html#appendix-i-mean-square-error-minimization":{}}}],["essenti",{"_index":1222,"text":{"Chap_11.html":{},"Chap_11.html#problem-118":{},"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_13.html#epilogue":{},"Chap_4.html":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_7.html":{},"Chap_7.html#tethered-particle-motion":{},"info.html":{},"info.html#technical-details":{}},"title":{}}],["estim",{"_index":283,"text":{"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#the-more-general-restoration-case-noise-distortion":{},"Chap_10.html#the-restoration-case-noise":{},"Chap_10.html#the-wiener-filter":{},"Chap_10.html#the-wiener-hopf-equation":{},"Chap_10.html#using-the-least-mean-square-error-criterion":{},"Chap_11.html":{},"Chap_11.html#aspects-of-estimation":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_11.html#estimating-the-autocorrelation-function":{},"Chap_11.html#estimating-the-mean":{},"Chap_11.html#example-estimating-the-poisson-rate":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_11.html#laboratory-exercise-111":{},"Chap_11.html#laboratory-exercise-113":{},"Chap_11.html#langevin-redux":{},"Chap_11.html#maximum-likelihood-estimation":{},"Chap_11.html#problem-112":{},"Chap_11.html#problem-113":{},"Chap_11.html#problem-114":{},"Chap_11.html#problem-115":{},"Chap_11.html#problem-116":{},"Chap_11.html#problem-117":{},"Chap_11.html#problem-119":{},"Chap_11.html#trouble-in-paradise":{},"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#laboratory-exercise-121":{},"Chap_12.html#laboratory-exercise-122":{},"Chap_12.html#laboratory-exercise-123":{},"Chap_12.html#laboratory-exercise-124":{},"Chap_12.html#other-windows":{},"Chap_12.html#problem-122":{},"Chap_12.html#spectral-estimation":{},"Chap_12.html#the-periodogram-unbiased":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_12.html#windowed-observations":{},"Chap_13.html":{},"Chap_13.html#appendix-i-mean-square-error-minimization":{},"Chap_3.html":{},"Chap_3.html#what-is-a-random-signal":{},"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#example-fair-chance":{},"Chap_4.html#the-ergodic-process":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_5.html":{},"Chap_5.html#correlations-and-memory":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{},"Chap_6.html#laboratory-exercise-63":{},"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#one-step-further":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#why-this-case-study":{},"Chap_8.html":{},"Chap_8.html#problem-83":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{},"Chap_9.html":{},"Chap_9.html#performance-in-the-presence-of-noise":{}},"title":{"Chap_11.html":{},"Chap_11.html#aspects-of-estimation":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_11.html#estimating-the-autocorrelation-function":{},"Chap_11.html#estimating-the-mean":{},"Chap_11.html#example-estimating-the-poisson-rate":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_11.html#maximum-likelihood-estimation":{},"Chap_12.html":{},"Chap_12.html#spectral-estimation":{}}}],["estimate\u2014wheth",{"_index":949,"text":{"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{}},"title":{}}],["et",{"_index":3151,"text":{"Chap_7.html":{},"Chap_7.html#tethered-particle-motion":{}},"title":{}}],["eta",{"_index":2879,"text":{"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#problem-77":{}},"title":{}}],["etc.\u2014can",{"_index":1760,"text":{"Chap_2.html":{},"Chap_2.html#prologue":{}},"title":{}}],["etymolog",{"_index":193,"text":{"Chap_1.html":{},"Chap_1.html#enhanced-experience":{}},"title":{}}],["euro",{"_index":1757,"text":{"Chap_2.html":{},"Chap_2.html#prologue":{}},"title":{}}],["evalu",{"_index":2456,"text":{"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_8.html":{},"Chap_8.html#snr-for-random-signals-in-the-presence-of-noise":{}},"title":{}}],["even",{"_index":661,"text":{"Chap_10.html":{},"Chap_10.html#example-sound-of-distorted-music":{},"Chap_11.html":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_11.html#langevin-redux":{},"Chap_11.html#problem-1110":{},"Chap_11.html#problem-119":{},"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_3.html#problem-38":{},"Chap_3.html#problem-39":{},"Chap_4.html":{},"Chap_4.html#correlation-the-workhorse":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#the-ergodic-process":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#problem-54":{},"Chap_5.html#problem-55":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_6.html":{},"Chap_6.html#interpretation-of-the-convolution-result":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function":{},"Chap_7.html#autocorrelation-function_2":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#how-big-is-big-how-small-is-small":{},"Chap_7.html#power-spectral-density":{},"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{},"Chap_9.html":{},"Chap_9.html#performance-in-the-presence-of-noise":{},"Chap_9.html#problem-92":{}},"title":{}}],["event",{"_index":891,"text":{"Chap_11.html":{},"Chap_11.html#example-estimating-the-poisson-rate":{},"Chap_2.html":{},"Chap_2.html#prologue":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_4.html":{},"Chap_4.html#example-dice-money":{},"Chap_4.html#laboratory-exercise-41":{},"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{},"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{}},"title":{"Chap_6.html#example-a-world-of-random-events-a-case-study":{}}}],["events/(unit",{"_index":3484,"text":{"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{}},"title":{}}],["eventu",{"_index":2461,"text":{"Chap_5.html":{},"Chap_5.html#a-digression":{}},"title":{}}],["everyth",{"_index":1584,"text":{"Chap_12.html":{},"Chap_12.html#laboratory-exercise-122":{}},"title":{}}],["everywher",{"_index":2026,"text":{"Chap_3.html":{},"Chap_3.html#problem-310":{},"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{}},"title":{}}],["evolut",{"_index":1423,"text":{"Chap_12.html":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{}},"title":{}}],["exacerb",{"_index":680,"text":{"Chap_10.html":{},"Chap_10.html#example-cleaning-up-our-act":{}},"title":{}}],["exact",{"_index":958,"text":{"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_12.html":{},"Chap_12.html#windowed-observations":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{}},"title":{}}],["exactli",{"_index":2207,"text":{"Chap_4.html":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_7.html":{},"Chap_7.html#one-step-further":{}},"title":{}}],["examin",{"_index":1280,"text":{"Chap_12.html":{},"Chap_12.html#laboratory-exercise-121":{},"Chap_12.html#problem-122":{},"Chap_12.html#spectral-estimation":{},"Chap_12.html#the-periodogram-unbiased":{},"Chap_4.html":{},"Chap_4.html#correlation-the-workhorse":{},"Chap_4.html#example-fair-chance":{},"Chap_7.html":{},"Chap_7.html#descriptive-statistic-variance":{},"Chap_7.html#how-big-is-big-how-small-is-small":{},"Chap_7.html#power-spectral-density_1":{},"info.html":{},"info.html#tips-short-cuts":{}},"title":{}}],["exampl",{"_index":105,"text":{"Chap_1.html":{},"Chap_1.html#at-the-movies":{},"Chap_1.html#highlighting":{},"Chap_1.html#outside-this-device":{},"Chap_1.html#sound-of-music":{},"Chap_10.html":{},"Chap_10.html#classic-example-classic-result":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#example-sound-of-distorted-music":{},"Chap_10.html#laboratory-exercise-105":{},"Chap_10.html#the-more-general-restoration-case-noise-distortion":{},"Chap_10.html#the-wiener-hopf-equation":{},"Chap_10.html#why-we-avoid-the-inverse-filter":{},"Chap_11.html":{},"Chap_11.html#aspects-of-estimation":{},"Chap_11.html#estimating-the-mean":{},"Chap_11.html#example-estimating-the-poisson-rate":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_11.html#langevin-redux":{},"Chap_11.html#maximum-likelihood-estimation":{},"Chap_11.html#problem-115":{},"Chap_11.html#trouble-in-paradise":{},"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#problem-122":{},"Chap_12.html#spectral-estimation":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_12.html#windowed-observations":{},"Chap_13.html":{},"Chap_13.html#epilogue":{},"Chap_2.html":{},"Chap_2.html#prologue":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_3.html#problem-33":{},"Chap_3.html#problem-37":{},"Chap_3.html#what-is-a-random-signal":{},"Chap_4.html":{},"Chap_4.html#characterization-of-random-signals":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#example-dice-money":{},"Chap_4.html#example-fair-chance":{},"Chap_4.html#example-is-that-coin-fair":{},"Chap_4.html#laboratory-exercise-42":{},"Chap_4.html#other-averages":{},"Chap_4.html#problem-44":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#correlations-and-memory":{},"Chap_5.html#example-delayed-effect":{},"Chap_5.html#example-pink-noise":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_5.html#problem-52":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function_1":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#expected-value":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#power-spectral-density":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#tethered-particle-motion":{},"Chap_7.html#why-this-case-study":{},"Chap_8.html":{},"Chap_8.html#characterizing-signal-to-noise-ratios":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{},"Chap_9.html":{},"Chap_9.html#the-classic-example":{},"info.html":{},"info.html#technical-details":{},"info.html#weather-data":{}},"title":{"Chap_10.html#classic-example-classic-result":{},"Chap_10.html#example-cleaning-up-our-act":{},"Chap_10.html#example-sound-of-distorted-music":{},"Chap_11.html#example-estimating-the-poisson-rate":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_4.html#example-average-experience":{},"Chap_4.html#example-dice-money":{},"Chap_4.html#example-fair-chance":{},"Chap_4.html#example-is-that-coin-fair":{},"Chap_5.html#example-delayed-effect":{},"Chap_5.html#example-pink-noise":{},"Chap_5.html#example-white-noise":{},"Chap_5.html#examples-of-power-spectra":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{},"Chap_8.html#example-cocktail-party-noise":{},"Chap_8.html#example-filtering-noise":{},"Chap_8.html#example-not-too-noisy":{},"Chap_9.html#example-matching-your-filter":{},"Chap_9.html#the-classic-example":{}}}],["exceed",{"_index":2549,"text":{"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{}},"title":{}}],["excel",{"_index":2077,"text":{"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_9.html":{},"Chap_9.html#problem-92":{}},"title":{}}],["except",{"_index":1779,"text":{"Chap_2.html":{},"Chap_2.html#prologue":{},"Chap_8.html":{},"Chap_8.html#snr-for-random-signals-in-the-presence-of-noise":{}},"title":{}}],["exception",{"_index":3486,"text":{"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{}},"title":{}}],["excerpt",{"_index":3724,"text":{"info.html":{},"info.html#musical-data":{}},"title":{}}],["exchang",{"_index":518,"text":{"Chap_10.html":{},"Chap_10.html#what-is-that-least-mean-square-error":{},"Chap_12.html":{},"Chap_12.html#the-periodogram-unbiased":{},"Chap_13.html":{},"Chap_13.html#appendix-i-mean-square-error-minimization":{},"Chap_5.html":{},"Chap_5.html#the-mechanics-of-correlations-redux":{}},"title":{}}],["exclus",{"_index":3161,"text":{"Chap_7.html":{},"Chap_7.html#tethered-particle-motion":{},"info.html":{},"info.html#usage":{}},"title":{}}],["exemplifi",{"_index":1619,"text":{"Chap_13.html":{},"Chap_13.html#appendix-i-mean-square-error-minimization":{}},"title":{}}],["exercis",{"_index":143,"text":{"Chap_1.html":{},"Chap_1.html#at-the-movies":{},"Chap_1.html#getting-around":{},"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#laboratory-exercise-101":{},"Chap_10.html#laboratory-exercise-102":{},"Chap_10.html#laboratory-exercise-103":{},"Chap_10.html#laboratory-exercise-104":{},"Chap_10.html#laboratory-exercise-105":{},"Chap_10.html#problem-104":{},"Chap_11.html":{},"Chap_11.html#laboratory-exercise-111":{},"Chap_11.html#laboratory-exercise-112":{},"Chap_11.html#laboratory-exercise-113":{},"Chap_12.html":{},"Chap_12.html#laboratory-exercise-122":{},"Chap_12.html#laboratory-exercise-123":{},"Chap_12.html#laboratory-exercise-124":{},"Chap_12.html#problem-122":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_3.html#problem-32":{},"Chap_3.html#the-basics":{},"Chap_3.html#what-is-a-random-signal":{},"Chap_4.html":{},"Chap_4.html#example-fair-chance":{},"Chap_4.html#laboratory-exercise-41":{},"Chap_4.html#laboratory-exercise-42":{},"Chap_5.html":{},"Chap_5.html#laboratory-exercise-51":{},"Chap_6.html":{},"Chap_6.html#laboratory-exercise-61":{},"Chap_6.html#laboratory-exercise-62":{},"Chap_6.html#laboratory-exercise-63":{},"Chap_6.html#laboratory-exercise-64":{},"Chap_6.html#laboratory-exercise-65":{},"Chap_6.html#laboratory-exercise-66":{},"Chap_6.html#laboratory-exercise-67":{},"Chap_6.html#laboratory-exercise-68":{},"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_9.html":{},"Chap_9.html#laboratory-exercise-91":{},"info.html":{},"info.html#tips-short-cuts":{}},"title":{"Chap_10.html#laboratory-exercise-101":{},"Chap_10.html#laboratory-exercise-102":{},"Chap_10.html#laboratory-exercise-103":{},"Chap_10.html#laboratory-exercise-104":{},"Chap_10.html#laboratory-exercise-105":{},"Chap_10.html#laboratory-exercises":{},"Chap_11.html#laboratory-exercise-111":{},"Chap_11.html#laboratory-exercise-112":{},"Chap_11.html#laboratory-exercise-113":{},"Chap_11.html#laboratory-exercises":{},"Chap_12.html#laboratory-exercise-121":{},"Chap_12.html#laboratory-exercise-122":{},"Chap_12.html#laboratory-exercise-123":{},"Chap_12.html#laboratory-exercise-124":{},"Chap_12.html#laboratory-exercises":{},"Chap_4.html#laboratory-exercise-41":{},"Chap_4.html#laboratory-exercise-42":{},"Chap_4.html#laboratory-exercises":{},"Chap_5.html#laboratory-exercise-51":{},"Chap_5.html#laboratory-exercises":{},"Chap_6.html#laboratory-exercise-61":{},"Chap_6.html#laboratory-exercise-62":{},"Chap_6.html#laboratory-exercise-63":{},"Chap_6.html#laboratory-exercise-64":{},"Chap_6.html#laboratory-exercise-65":{},"Chap_6.html#laboratory-exercise-66":{},"Chap_6.html#laboratory-exercise-67":{},"Chap_6.html#laboratory-exercise-68":{},"Chap_6.html#laboratory-exercises":{},"Chap_9.html#laboratory-exercise-91":{},"Chap_9.html#laboratory-exercise-92":{},"Chap_9.html#laboratory-exercise-93":{},"Chap_9.html#laboratory-exercises":{}}}],["exert",{"_index":3167,"text":{"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#tethered-particle-motion":{}},"title":{}}],["exhibit",{"_index":618,"text":{"Chap_10.html":{},"Chap_10.html#why-we-avoid-the-inverse-filter":{},"Chap_5.html":{},"Chap_5.html#correlations-and-memory":{},"Chap_7.html":{},"Chap_7.html#tethered-particle-motion":{}},"title":{}}],["exist",{"_index":1191,"text":{"Chap_11.html":{},"Chap_11.html#problem-116":{},"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_4.html":{},"Chap_4.html#problem-44":{},"Chap_4.html#problem-48":{},"Chap_5.html":{},"Chap_5.html#fourier-description-of-correlation-functions":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_7.html":{},"Chap_7.html#problem-72":{}},"title":{}}],["exists\u2014i",{"_index":2438,"text":{"Chap_5.html":{},"Chap_5.html#fourier-description-of-correlation-functions":{}},"title":{}}],["exot",{"_index":3367,"text":{"Chap_7.html":{},"Chap_7.html#why-this-case-study":{}},"title":{}}],["expand",{"_index":3622,"text":{"Chap_9.html":{},"Chap_9.html#problem-92":{}},"title":{}}],["expans",{"_index":1550,"text":{"Chap_12.html":{},"Chap_12.html#problem-122":{},"Chap_7.html":{},"Chap_7.html#descriptive-statistic-variance":{}},"title":{}}],["expect",{"_index":330,"text":{"Chap_10.html":{},"Chap_10.html#correlation-returns":{},"Chap_10.html#expressing-the-mean-square-error":{},"Chap_10.html#the-more-general-restoration-case-noise-distortion":{},"Chap_10.html#using-the-least-mean-square-error-criterion":{},"Chap_10.html#what-is-that-least-mean-square-error":{},"Chap_11.html":{},"Chap_11.html#aspects-of-estimation":{},"Chap_11.html#langevin-redux":{},"Chap_12.html":{},"Chap_12.html#the-periodogram-unbiased":{},"Chap_13.html":{},"Chap_13.html#appendix-i-mean-square-error-minimization":{},"Chap_3.html":{},"Chap_3.html#problem-38":{},"Chap_3.html#problem-39":{},"Chap_4.html":{},"Chap_4.html#autocorrelation":{},"Chap_4.html#example-fair-chance":{},"Chap_4.html#laboratory-exercise-41":{},"Chap_4.html#problem-41":{},"Chap_4.html#problem-47":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_5.html":{},"Chap_5.html#problem-52":{},"Chap_6.html":{},"Chap_6.html#problem-66":{},"Chap_6.html#the-autocorrelation-function":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_6.html#the-mean":{},"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#expected-value":{},"Chap_7.html#one-step-further":{},"Chap_7.html#problem-79":{},"Chap_7.html#the-langevin-position-equation":{},"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{}},"title":{"Chap_7.html#expected-value":{},"Chap_7.html#expected-value_1":{}}}],["experi",{"_index":48,"text":{"Chap_1.html":{},"Chap_1.html#how-to-use-this-ibook":{},"Chap_10.html":{},"Chap_10.html#example-sound-of-distorted-music":{},"Chap_11.html":{},"Chap_11.html#aspects-of-estimation":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_11.html#problem-113":{},"Chap_11.html#problem-119":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#example-average-experience":{},"Chap_4.html#example-dice-money":{},"Chap_4.html#example-fair-chance":{},"Chap_4.html#example-is-that-coin-fair":{},"Chap_4.html#laboratory-exercise-41":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#one-step-further":{},"Chap_7.html#problem-77":{},"Chap_7.html#tethered-particle-motion":{},"Chap_9.html":{},"Chap_9.html#laboratory-exercise-91":{},"Chap_9.html#problem-91":{},"info.html":{},"info.html#musical-data":{},"info.html#tips-short-cuts":{}},"title":{"Chap_1.html#enhanced-experience":{},"Chap_4.html#example-average-experience":{}}}],["experiment",{"_index":812,"text":{"Chap_11.html":{},"Chap_11.html#aspects-of-estimation":{},"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{}},"title":{}}],["explain",{"_index":304,"text":{"Chap_10.html":{},"Chap_10.html#the-restoration-case-noise":{},"Chap_11.html":{},"Chap_11.html#langevin-redux":{},"Chap_11.html#problem-119":{},"Chap_12.html":{},"Chap_12.html#problem-123":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_3.html":{},"Chap_3.html#problem-39":{},"Chap_4.html":{},"Chap_4.html#example-is-that-coin-fair":{},"Chap_4.html#problem-44":{},"Chap_5.html":{},"Chap_5.html#fourier-description-of-correlation-functions":{},"Chap_5.html#problem-55":{},"Chap_5.html#problem-56":{},"Chap_7.html":{},"Chap_7.html#problem-710":{},"Chap_7.html#problem-72":{}},"title":{}}],["explan",{"_index":1534,"text":{"Chap_12.html":{},"Chap_12.html#problem-122":{}},"title":{}}],["explicitli",{"_index":115,"text":{"Chap_1.html":{},"Chap_1.html#highlighting":{},"Chap_10.html":{},"Chap_10.html#example-sound-of-distorted-music":{},"Chap_4.html":{},"Chap_4.html#example-dice-money":{},"Chap_4.html#the-ergodic-process":{}},"title":{}}],["exploit",{"_index":2570,"text":{"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{}},"title":{}}],["explor",{"_index":709,"text":{"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#laboratory-exercise-102":{},"Chap_11.html":{},"Chap_11.html#problem-117":{},"Chap_12.html":{},"Chap_12.html#laboratory-exercise-124":{},"Chap_12.html#problem-122":{},"Chap_4.html":{},"Chap_4.html#example-fair-chance":{},"Chap_5.html":{},"Chap_5.html#correlations-and-memory":{},"Chap_6.html":{},"Chap_6.html#laboratory-exercise-67":{},"Chap_7.html":{},"Chap_7.html#impulse-invariant-sampling":{},"Chap_7.html#power-spectral-density_1":{},"Chap_9.html":{},"Chap_9.html#example-matching-your-filter":{}},"title":{}}],["exponenti",{"_index":1105,"text":{"Chap_11.html":{},"Chap_11.html#langevin-redux":{},"Chap_2.html":{},"Chap_2.html#prologue":{},"Chap_7.html":{},"Chap_7.html#tethered-particle-motion":{},"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{}},"title":{}}],["expos",{"_index":3351,"text":{"Chap_7.html":{},"Chap_7.html#one-step-further":{}},"title":{}}],["express",{"_index":378,"text":{"Chap_10.html":{},"Chap_10.html#correlation-returns":{},"Chap_10.html#problem-103":{},"Chap_10.html#the-wiener-hopf-equation":{},"Chap_10.html#what-is-that-least-mean-square-error":{},"Chap_12.html":{},"Chap_12.html#windowed-observations":{},"Chap_3.html":{},"Chap_3.html#problem-38":{},"Chap_4.html":{},"Chap_4.html#laboratory-exercise-42":{},"Chap_4.html#problem-49":{},"Chap_5.html":{},"Chap_5.html#problem-55":{},"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{},"Chap_6.html#interpretation-of-the-convolution-result":{},"Chap_6.html#problem-66":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_6.html#the-mean":{},"Chap_7.html":{},"Chap_7.html#descriptive-statistic-variance":{},"Chap_7.html#from-t-to-n":{},"Chap_7.html#problem-711":{},"Chap_7.html#problem-73":{},"Chap_7.html#problem-78":{},"Chap_8.html":{},"Chap_8.html#snr-for-random-signals-in-the-presence-of-noise":{},"info.html":{},"info.html#usage":{}},"title":{"Chap_10.html#expressing-the-mean-square-error":{}}}],["expression\u2014se",{"_index":3340,"text":{"Chap_7.html":{},"Chap_7.html#descriptive-statistic-variance":{}},"title":{}}],["extend",{"_index":76,"text":{"Chap_1.html":{},"Chap_1.html#how-to-use-this-ibook":{},"Chap_12.html":{},"Chap_12.html#windowed-observations":{},"Chap_2.html":{},"Chap_2.html#prologue":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#tethered-particle-motion":{},"Chap_7.html#why-this-case-study":{},"info.html":{},"info.html#tips-short-cuts":{}},"title":{}}],["extens",{"_index":49,"text":{"Chap_1.html":{},"Chap_1.html#how-to-use-this-ibook":{},"Chap_4.html":{},"Chap_4.html#the-ergodic-process":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_7.html":{},"Chap_7.html#expected-value":{},"Chap_7.html#impulse-invariant-sampling":{}},"title":{}}],["extent",{"_index":1444,"text":{"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#other-windows":{}},"title":{}}],["extern",{"_index":42,"text":{"Chap_1.html":{},"Chap_1.html#how-to-use-this-ibook":{},"Chap_1.html#outside-this-device":{},"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{}},"title":{}}],["extrem",{"_index":459,"text":{"Chap_10.html":{},"Chap_10.html#the-wiener-hopf-equation":{},"Chap_11.html":{},"Chap_11.html#problem-118":{}},"title":{}}],["extremum",{"_index":370,"text":{"Chap_10.html":{},"Chap_10.html#problem-101":{},"Chap_10.html#using-the-least-mean-square-error-criterion":{},"Chap_11.html":{},"Chap_11.html#example-estimating-the-poisson-rate":{},"Chap_11.html#problem-111":{}},"title":{}}],["ey",{"_index":2786,"text":{"Chap_6.html":{},"Chap_6.html#laboratory-exercise-64":{},"Chap_6.html#laboratory-exercise-65":{},"Chap_6.html#laboratory-exercise-66":{},"Chap_6.html#laboratory-exercise-67":{},"Chap_9.html":{},"Chap_9.html#laboratory-exercise-92":{}},"title":{}}],["e}}{{\\parti",{"_index":350,"text":{"Chap_10.html":{},"Chap_10.html#using-the-least-mean-square-error-criterion":{},"Chap_13.html":{},"Chap_13.html#appendix-i-mean-square-error-minimization":{}},"title":{}}],["e}}{{{n_0",{"_index":3585,"text":{"Chap_9.html":{},"Chap_9.html#example-matching-your-filter":{}},"title":{}}],["f",{"_index":763,"text":{"Chap_10.html":{},"Chap_10.html#problem-104":{},"Chap_5.html":{},"Chap_5.html#laboratory-exercise-51":{},"Chap_5.html#problem-56":{},"Chap_7.html":{},"Chap_7.html#problem-711":{}},"title":{}}],["f(\\omega",{"_index":807,"text":{"Chap_10.html":{},"Chap_10.html#laboratory-exercise-105":{}},"title":{}}],["f(t",{"_index":2793,"text":{"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#from-t-to-n":{},"Chap_7.html#how-big-is-big-how-small-is-small":{},"Chap_7.html#the-langevin-equation-a-case-study":{},"Chap_7.html#the-langevin-position-equation":{},"Chap_7.html#the-langevin-velocity-equation":{}},"title":{}}],["f(t)\\,\\,\\,\\underbrac",{"_index":3170,"text":{"Chap_7.html":{},"Chap_7.html#tethered-particle-motion":{}},"title":{}}],["f(x",{"_index":1167,"text":{"Chap_11.html":{},"Chap_11.html#problem-111":{}},"title":{}}],["f5",{"_index":3648,"text":{"info.html":{},"info.html#tips-short-cuts":{}},"title":{}}],["f[k",{"_index":2777,"text":{"Chap_6.html":{},"Chap_6.html#problem-63":{},"Chap_7.html":{},"Chap_7.html#expected-value":{}},"title":{}}],["f[k]u[n",{"_index":3059,"text":{"Chap_7.html":{},"Chap_7.html#expected-value":{}},"title":{}}],["f[n",{"_index":806,"text":{"Chap_10.html":{},"Chap_10.html#laboratory-exercise-105":{},"Chap_7.html":{},"Chap_7.html#expected-value":{},"Chap_7.html#from-t-to-n":{},"Chap_7.html#impulse-invariant-sampling":{},"Chap_7.html#the-langevin-position-equation":{},"Chap_7.html#the-langevin-velocity-equation":{}},"title":{}}],["f_",{"_index":2360,"text":{"Chap_4.html":{},"Chap_4.html#problem-48":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period_1":{}},"title":{}}],["f_0",{"_index":1570,"text":{"Chap_12.html":{},"Chap_12.html#problem-123":{},"Chap_7.html":{},"Chap_7.html#power-spectral-density_1":{}},"title":{}}],["f_1",{"_index":1575,"text":{"Chap_12.html":{},"Chap_12.html#problem-123":{}},"title":{}}],["f_o",{"_index":2928,"text":{"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#expected-value":{},"Chap_7.html#one-step-further":{},"Chap_7.html#the-langevin-velocity-equation":{}},"title":{}}],["f_o}/\\left",{"_index":3318,"text":{"Chap_7.html":{},"Chap_7.html#autocorrelation-function_2":{}},"title":{}}],["f_o}/{\\lambda",{"_index":3076,"text":{"Chap_7.html":{},"Chap_7.html#autocorrelation-function_1":{}},"title":{}}],["f_o}/{m^2",{"_index":1077,"text":{"Chap_11.html":{},"Chap_11.html#langevin-redux":{}},"title":{}}],["f_o}\\delta",{"_index":2795,"text":{"Chap_7.html":{},"Chap_7.html#autocorrelation-function_2":{},"Chap_7.html#power-spectral-density":{},"Chap_7.html#the-langevin-equation-a-case-study":{},"Chap_7.html#the-langevin-velocity-equation":{}},"title":{}}],["f_o}\\sum\\limits_{n",{"_index":3301,"text":{"Chap_7.html":{},"Chap_7.html#autocorrelation-function_2":{}},"title":{}}],["f_o}{\\varphi",{"_index":2949,"text":{"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#power-spectral-density":{},"Chap_7.html#power-spectral-density_1":{}},"title":{}}],["f_o}{s_{hh}}(\\omega",{"_index":2950,"text":{"Chap_7.html":{},"Chap_7.html#power-spectral-density":{}},"title":{}}],["f_{mol",{"_index":3165,"text":{"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#tethered-particle-motion":{}},"title":{}}],["face",{"_index":1160,"text":{"Chap_11.html":{},"Chap_11.html#trouble-in-paradise":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_9.html":{},"Chap_9.html#laboratory-exercise-92":{}},"title":{}}],["facilit",{"_index":3623,"text":{"Chap_9.html":{},"Chap_9.html#problem-92":{}},"title":{}}],["fact",{"_index":260,"text":{"Chap_1.html":{},"Chap_1.html#enhanced-experience":{},"Chap_11.html":{},"Chap_11.html#aspects-of-estimation":{},"Chap_11.html#estimating-the-autocorrelation-function":{},"Chap_12.html":{},"Chap_12.html#the-periodogram-unbiased":{},"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_3.html":{},"Chap_3.html#the-basics":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_7.html":{},"Chap_7.html#power-spectral-density_1":{},"Chap_9.html":{},"Chap_9.html#setting-up-the-problem":{}},"title":{}}],["factor",{"_index":243,"text":{"Chap_1.html":{},"Chap_1.html#enhanced-experience":{},"Chap_6.html":{},"Chap_6.html#interpretation-of-the-convolution-result":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#how-big-is-big-how-small-is-small":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{}},"title":{}}],["factor\u2014albeit",{"_index":2432,"text":{"Chap_5.html":{},"Chap_5.html#the-mechanics-of-correlations-redux":{}},"title":{}}],["factor\u2014th",{"_index":2642,"text":{"Chap_6.html":{},"Chap_6.html#the-mean":{}},"title":{}}],["fair",{"_index":185,"text":{"Chap_1.html":{},"Chap_1.html#at-the-movies":{},"Chap_1.html#enhanced-experience":{},"Chap_11.html":{},"Chap_11.html#problem-113":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_3.html#problem-37":{},"Chap_4.html":{},"Chap_4.html#example-dice-money":{},"Chap_4.html#example-fair-chance":{},"Chap_4.html#example-is-that-coin-fair":{},"Chap_4.html#laboratory-exercise-41":{},"Chap_4.html#problem-47":{}},"title":{"Chap_4.html#example-fair-chance":{},"Chap_4.html#example-is-that-coin-fair":{}}}],["faith",{"_index":768,"text":{"Chap_10.html":{},"Chap_10.html#laboratory-exercise-103":{}},"title":{}}],["fall",{"_index":192,"text":{"Chap_1.html":{},"Chap_1.html#enhanced-experience":{},"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{}},"title":{}}],["famili",{"_index":1446,"text":{"Chap_12.html":{}},"title":{"Chap_12.html#a-family-of-windows":{}}}],["familiar",{"_index":1827,"text":{"Chap_3.html":{},"Chap_3.html#the-basics":{},"Chap_3.html#what-is-a-random-signal":{},"Chap_5.html":{},"Chap_5.html#correlations-simple-and-complex":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_7.html":{},"Chap_7.html#tethered-particle-motion":{}},"title":{}}],["famou",{"_index":172,"text":{"Chap_1.html":{},"Chap_1.html#at-the-movies":{},"Chap_10.html":{},"Chap_10.html#the-wiener-hopf-equation":{}},"title":{}}],["far",{"_index":460,"text":{"Chap_10.html":{},"Chap_10.html#the-wiener-hopf-equation":{},"Chap_12.html":{},"Chap_12.html#spectral-estimation":{}},"title":{}}],["fast",{"_index":2346,"text":{"Chap_4.html":{},"Chap_4.html#problem-47":{}},"title":{}}],["faster",{"_index":3361,"text":{"Chap_7.html":{},"Chap_7.html#one-step-further":{}},"title":{}}],["feat",{"_index":1236,"text":{"Chap_11.html":{},"Chap_11.html#laboratory-exercise-111":{}},"title":{}}],["februari",{"_index":2227,"text":{"Chap_4.html":{},"Chap_4.html#the-mechanics-of-correlations":{}},"title":{}}],["fechner",{"_index":3523,"text":{"Chap_8.html":{},"Chap_8.html#problem-82":{},"Chap_8.html#problem-83":{}},"title":{}}],["feedback",{"_index":1771,"text":{"Chap_2.html":{},"Chap_2.html#prologue":{},"info.html":{},"info.html#acknowledgments":{}},"title":{}}],["few",{"_index":826,"text":{"Chap_11.html":{},"Chap_11.html#aspects-of-estimation":{},"Chap_11.html#trouble-in-paradise":{},"Chap_12.html":{},"Chap_12.html#laboratory-exercise-122":{},"Chap_12.html#problem-122":{},"Chap_2.html":{},"Chap_2.html#prologue":{},"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{}},"title":{}}],["feynman",{"_index":2099,"text":{"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#laboratory-exercise-42":{},"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#problem-711":{}},"title":{}}],["fft",{"_index":804,"text":{"Chap_10.html":{},"Chap_10.html#laboratory-exercise-105":{},"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{}},"title":{}}],["fg",{"_index":3211,"text":{"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#power-spectral-density_2":{}},"title":{}}],["field",{"_index":3202,"text":{"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#problem-711":{}},"title":{}}],["figur",{"_index":35,"text":{"Chap_1.html":{},"Chap_1.html#how-to-use-this-ibook":{},"Chap_10.html":{},"Chap_10.html#classic-example-classic-result":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#example-cleaning-up-our-act":{},"Chap_10.html#example-sound-of-distorted-music":{},"Chap_10.html#problem-104":{},"Chap_10.html#the-more-general-restoration-case-noise-distortion":{},"Chap_10.html#the-restoration-case-noise":{},"Chap_10.html#why-we-avoid-the-inverse-filter":{},"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_11.html#estimating-the-autocorrelation-function":{},"Chap_11.html#estimating-the-mean":{},"Chap_11.html#langevin-redux":{},"Chap_12.html":{},"Chap_12.html#problem-121":{},"Chap_12.html#problem-122":{},"Chap_12.html#problem-123":{},"Chap_12.html#spectral-estimation":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_12.html#windowed-observations":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_3.html#problem-310":{},"Chap_3.html#problem-36":{},"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#example-dice-money":{},"Chap_4.html#example-fair-chance":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#example-pink-noise":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{},"Chap_6.html#interpretation-of-the-convolution-result":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function_1":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#one-step-further":{},"Chap_7.html#power-spectral-density":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#power-spectral-density_2":{},"Chap_7.html#problem-79":{},"Chap_7.html#tethered-particle-motion":{},"Chap_8.html":{},"Chap_8.html#example-cocktail-party-noise":{},"Chap_8.html#problem-82":{},"Chap_8.html#problem-83":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{},"Chap_9.html":{},"Chap_9.html#example-matching-your-filter":{},"Chap_9.html#performance-in-the-presence-of-noise":{},"Chap_9.html#problem-91":{},"Chap_9.html#problem-92":{},"Chap_9.html#the-matched-filter-as-an-autocorrelation":{},"info.html":{},"info.html#technical-details":{},"info.html#tips-short-cuts":{}},"title":{}}],["fill",{"_index":1420,"text":{"Chap_12.html":{},"Chap_12.html#the-periodogram-what-about-convergence":{}},"title":{}}],["film",{"_index":173,"text":{"Chap_1.html":{},"Chap_1.html#at-the-movies":{},"info.html":{},"info.html#musical-data":{}},"title":{}}],["filter",{"_index":269,"text":{"Chap_10.html":{},"Chap_10.html#as-seen-from-the-fourier-domain":{},"Chap_10.html#classic-example-classic-result":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#example-cleaning-up-our-act":{},"Chap_10.html#example-sound-of-distorted-music":{},"Chap_10.html#laboratory-exercise-101":{},"Chap_10.html#laboratory-exercise-103":{},"Chap_10.html#laboratory-exercise-105":{},"Chap_10.html#the-more-general-restoration-case-noise-distortion":{},"Chap_10.html#the-restoration-case-noise":{},"Chap_10.html#the-wiener-filter":{},"Chap_10.html#the-wiener-hopf-equation":{},"Chap_10.html#using-the-least-mean-square-error-criterion":{},"Chap_10.html#what-is-that-least-mean-square-error":{},"Chap_10.html#why-we-avoid-the-inverse-filter":{},"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#problem-122":{},"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_2.html":{},"Chap_2.html#prologue":{},"Chap_3.html":{},"Chap_3.html#what-is-a-random-signal":{},"Chap_6.html":{},"Chap_6.html#interpretation-of-the-convolution-result":{},"Chap_6.html#laboratory-exercise-67":{},"Chap_6.html#problem-64":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_6.html#the-mean":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#expected-value":{},"Chap_7.html#power-spectral-density":{},"Chap_8.html":{},"Chap_8.html#characterizing-signal-to-noise-ratios":{},"Chap_8.html#problem-83":{},"Chap_9.html":{},"Chap_9.html#example-matching-your-filter":{},"Chap_9.html#laboratory-exercise-92":{},"Chap_9.html#laboratory-exercise-93":{},"Chap_9.html#performance-in-the-presence-of-noise":{},"Chap_9.html#problem-91":{},"Chap_9.html#setting-up-the-problem":{},"Chap_9.html#the-classic-example":{},"Chap_9.html#the-matched-filter":{},"Chap_9.html#the-matched-filter-as-an-autocorrelation":{},"Chap_9.html#using-cauchy-schwartz":{}},"title":{"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#the-wiener-filter":{},"Chap_10.html#why-we-avoid-the-inverse-filter":{},"Chap_6.html":{},"Chap_6.html#filtering-of-stochastic-signals":{},"Chap_8.html#example-filtering-noise":{},"Chap_9.html":{},"Chap_9.html#example-matching-your-filter":{},"Chap_9.html#the-matched-filter":{},"Chap_9.html#the-matched-filter-as-an-autocorrelation":{}}}],["final",{"_index":724,"text":{"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_11.html":{},"Chap_11.html#estimating-the-mean":{},"Chap_11.html#langevin-redux":{},"Chap_2.html":{},"Chap_2.html#prologue":{},"Chap_5.html":{},"Chap_5.html#correlations-and-memory":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function_2":{},"Chap_9.html":{},"Chap_9.html#the-matched-filter-as-an-autocorrelation":{}},"title":{}}],["financ",{"_index":853,"text":{"Chap_11.html":{},"Chap_11.html#aspects-of-estimation":{}},"title":{}}],["find",{"_index":264,"text":{"Chap_1.html":{},"Chap_1.html#enhanced-experience":{},"Chap_10.html":{},"Chap_10.html#what-is-that-least-mean-square-error":{},"Chap_11.html":{},"Chap_11.html#example-estimating-the-poisson-rate":{},"Chap_11.html#langevin-redux":{},"Chap_11.html#problem-118":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_3.html#the-basics":{},"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{},"Chap_9.html":{},"Chap_9.html#laboratory-exercise-92":{},"Chap_9.html#laboratory-exercise-93":{},"Chap_9.html#problem-91":{},"Chap_9.html#the-matched-filter":{},"info.html":{},"info.html#tips-short-cuts":{}},"title":{}}],["finish",{"_index":124,"text":{"Chap_1.html":{},"Chap_1.html#outside-this-device":{},"Chap_7.html":{},"Chap_7.html#why-this-case-study":{}},"title":{}}],["finit",{"_index":1024,"text":{"Chap_11.html":{},"Chap_11.html#estimating-the-autocorrelation-function":{},"Chap_11.html#problem-116":{},"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#laboratory-exercise-123":{},"Chap_12.html#other-windows":{},"Chap_12.html#the-periodogram-unbiased":{},"Chap_12.html#windowed-observations":{},"Chap_4.html":{},"Chap_4.html#problem-44":{},"Chap_4.html#problem-48":{},"Chap_4.html#the-ergodic-process":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#impulse-invariant-sampling":{},"Chap_7.html#problem-72":{},"Chap_7.html#problem-73":{}},"title":{}}],["firefox",{"_index":61,"text":{"Chap_1.html":{},"Chap_1.html#how-to-use-this-ibook":{}},"title":{}}],["first",{"_index":450,"text":{"Chap_10.html":{},"Chap_10.html#classic-example-classic-result":{},"Chap_10.html#laboratory-exercise-103":{},"Chap_10.html#the-more-general-restoration-case-noise-distortion":{},"Chap_10.html#the-wiener-hopf-equation":{},"Chap_10.html#why-we-avoid-the-inverse-filter":{},"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_11.html#example-estimating-the-poisson-rate":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_11.html#langevin-redux":{},"Chap_11.html#problem-114":{},"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#other-windows":{},"Chap_12.html#problem-121":{},"Chap_12.html#problem-122":{},"Chap_12.html#the-periodogram-unbiased":{},"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_13.html#epilogue":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_3.html#the-basics":{},"Chap_3.html#what-is-a-random-signal":{},"Chap_4.html":{},"Chap_4.html#auto-covariance":{},"Chap_4.html#cross-covariance":{},"Chap_4.html#problem-42":{},"Chap_4.html#properties-of-averaging":{},"Chap_4.html#the-ergodic-process":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#correlations-simple-and-complex":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_6.html":{},"Chap_6.html#interpretation-of-the-convolution-result":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_7.html":{},"Chap_7.html#expected-value":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#one-step-further":{},"Chap_7.html#problem-77":{},"Chap_7.html#tethered-particle-motion":{},"Chap_7.html#the-langevin-equation-a-case-study":{},"Chap_7.html#the-langevin-position-equation":{},"Chap_8.html":{},"Chap_8.html#problem-83":{},"Chap_9.html":{},"Chap_9.html#the-matched-filter-as-an-autocorrelation":{},"info.html":{},"info.html#acknowledgments":{}},"title":{}}],["fit",{"_index":3126,"text":{"Chap_7.html":{},"Chap_7.html#power-spectral-density_1":{}},"title":{}}],["five",{"_index":989,"text":{"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_12.html":{},"Chap_12.html#other-windows":{},"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{}},"title":{}}],["fix",{"_index":1219,"text":{"Chap_11.html":{},"Chap_11.html#problem-118":{},"Chap_12.html":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{},"Chap_9.html":{},"Chap_9.html#using-cauchy-schwartz":{}},"title":{}}],["fk",{"_index":2604,"text":{"Chap_5.html":{},"Chap_5.html#problem-56":{}},"title":{}}],["flat",{"_index":1101,"text":{"Chap_11.html":{},"Chap_11.html#langevin-redux":{},"Chap_12.html":{},"Chap_12.html#problem-122":{},"Chap_5.html":{},"Chap_5.html#example-pink-noise":{},"Chap_5.html#example-white-noise":{},"Chap_5.html#laboratory-exercise-51":{}},"title":{}}],["flaw",{"_index":2218,"text":{"Chap_4.html":{},"Chap_4.html#the-mechanics-of-correlations":{}},"title":{}}],["flip",{"_index":862,"text":{"Chap_11.html":{},"Chap_11.html#maximum-likelihood-estimation":{},"Chap_11.html#problem-113":{},"Chap_4.html":{},"Chap_4.html#characterization-of-random-signals":{},"Chap_4.html#example-dice-money":{},"Chap_4.html#example-fair-chance":{},"Chap_4.html#example-is-that-coin-fair":{},"Chap_4.html#laboratory-exercise-41":{},"Chap_4.html#problem-47":{},"Chap_4.html#the-ergodic-process":{},"Chap_6.html":{},"Chap_6.html#laboratory-exercise-62":{},"Chap_9.html":{},"Chap_9.html#example-matching-your-filter":{}},"title":{}}],["fluctuat",{"_index":1377,"text":{"Chap_12.html":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_4.html":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_6.html":{},"Chap_6.html#the-mean":{},"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{}},"title":{}}],["fluid",{"_index":2881,"text":{"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small":{},"Chap_7.html#one-step-further":{},"Chap_7.html#tethered-particle-motion":{}},"title":{}}],["fluoresc",{"_index":1177,"text":{"Chap_11.html":{},"Chap_11.html#problem-114":{},"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{}},"title":{}}],["focu",{"_index":1780,"text":{"Chap_2.html":{},"Chap_2.html#prologue":{},"Chap_4.html":{},"Chap_4.html#characterization-of-random-signals":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small":{},"Chap_7.html#tethered-particle-motion":{},"Chap_8.html":{},"Chap_8.html#example-filtering-noise":{},"Chap_8.html#snr-for-random-signals-in-the-presence-of-noise":{},"Chap_9.html":{},"Chap_9.html#the-matched-filter":{}},"title":{}}],["folland",{"_index":1629,"text":{"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_13.html#epilogue":{}},"title":{}}],["folland\u2019",{"_index":1738,"text":{"Chap_13.html":{},"Chap_13.html#epilogue":{}},"title":{}}],["follow",{"_index":373,"text":{"Chap_10.html":{},"Chap_10.html#problem-104":{},"Chap_10.html#using-the-least-mean-square-error-criterion":{},"Chap_10.html#what-is-that-least-mean-square-error":{},"Chap_11.html":{},"Chap_11.html#aspects-of-estimation":{},"Chap_11.html#estimating-the-mean":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_11.html#langevin-redux":{},"Chap_12.html":{},"Chap_12.html#problem-121":{},"Chap_12.html#problem-122":{},"Chap_12.html#the-periodogram-unbiased":{},"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_2.html":{},"Chap_2.html#problem-21":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_3.html#problem-31":{},"Chap_3.html#problem-32":{},"Chap_3.html#problem-38":{},"Chap_4.html":{},"Chap_4.html#cross-correlation":{},"Chap_4.html#cross-covariance":{},"Chap_4.html#describing-the-time-average":{},"Chap_4.html#example-is-that-coin-fair":{},"Chap_4.html#problem-41":{},"Chap_4.html#problem-48":{},"Chap_4.html#the-ergodic-process":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#problem-53":{},"Chap_5.html#problem-56":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{},"Chap_6.html#problem-63":{},"Chap_6.html#problem-65":{},"Chap_6.html#problem-66":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function":{},"Chap_7.html#one-step-further":{},"Chap_7.html#the-langevin-position-equation":{},"Chap_7.html#the-langevin-velocity-equation":{},"Chap_8.html":{},"Chap_8.html#example-cocktail-party-noise":{},"Chap_8.html#example-filtering-noise":{}},"title":{}}],["font",{"_index":3715,"text":{"info.html":{},"info.html#technical-details":{}},"title":{}}],["forc",{"_index":733,"text":{"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#expected-value":{},"Chap_7.html#how-big-is-big-how-small-is-small":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#power-spectral-density":{},"Chap_7.html#tethered-particle-motion":{},"Chap_7.html#the-langevin-equation-a-case-study":{},"Chap_7.html#the-langevin-position-equation":{},"Chap_7.html#the-langevin-velocity-equation":{}},"title":{}}],["forecast",{"_index":3366,"text":{"Chap_7.html":{},"Chap_7.html#why-this-case-study":{}},"title":{}}],["foremost",{"_index":1785,"text":{"Chap_2.html":{},"Chap_2.html#prologue":{}},"title":{}}],["forget",{"_index":5,"text":{"Chap_1.html":{},"Chap_5.html":{},"Chap_5.html#correlations-and-memory":{}},"title":{}}],["form",{"_index":706,"text":{"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#laboratory-exercise-105":{},"Chap_10.html#problem-102":{},"Chap_11.html":{},"Chap_11.html#aspects-of-estimation":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_11.html#problem-117":{},"Chap_11.html#problem-119":{},"Chap_12.html":{},"Chap_12.html#spectral-estimation":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_12.html#windowed-observations":{},"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_3.html#problem-310":{},"Chap_4.html":{},"Chap_4.html#example-is-that-coin-fair":{},"Chap_4.html#laboratory-exercise-42":{},"Chap_4.html#problem-45":{},"Chap_4.html#properties-of-averaging":{},"Chap_5.html":{},"Chap_5.html#correlations-and-memory":{},"Chap_5.html#example-white-noise":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_6.html":{},"Chap_6.html#interpretation-of-the-convolution-result":{},"Chap_6.html#the-autocorrelation-function":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function_1":{},"Chap_7.html#autocorrelation-function_2":{},"Chap_7.html#expected-value":{},"Chap_7.html#impulse-invariant-sampling":{},"Chap_7.html#problem-711":{},"Chap_7.html#problem-78":{},"Chap_7.html#the-langevin-equation-a-case-study":{},"Chap_7.html#the-langevin-velocity-equation":{},"Chap_9.html":{},"Chap_9.html#example-matching-your-filter":{}},"title":{}}],["formal",{"_index":817,"text":{"Chap_11.html":{},"Chap_11.html#aspects-of-estimation":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_11.html#estimating-the-autocorrelation-function":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_12.html":{},"Chap_12.html#the-periodogram-unbiased":{},"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_9.html":{},"Chap_9.html#the-matched-filter-as-an-autocorrelation":{}},"title":{}}],["former",{"_index":1090,"text":{"Chap_11.html":{},"Chap_11.html#langevin-redux":{},"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{}},"title":{}}],["formul",{"_index":595,"text":{"Chap_10.html":{},"Chap_10.html#the-more-general-restoration-case-noise-distortion":{},"Chap_13.html":{},"Chap_13.html#appendix-i-mean-square-error-minimization":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#laboratory-exercise-42":{},"Chap_5.html":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_8.html":{},"Chap_8.html#snr-for-random-signals-in-the-presence-of-noise":{}},"title":{}}],["formula",{"_index":928,"text":{"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_3.html":{},"Chap_3.html#problem-36":{},"Chap_3.html#problem-38":{},"Chap_4.html":{},"Chap_4.html#describing-the-time-average":{},"Chap_5.html":{},"Chap_5.html#the-mechanics-of-correlations-redux":{}},"title":{}}],["forth",{"_index":660,"text":{"Chap_10.html":{},"Chap_10.html#example-sound-of-distorted-music":{}},"title":{}}],["found",{"_index":84,"text":{"Chap_1.html":{},"Chap_1.html#how-to-use-this-ibook":{},"Chap_10.html":{},"Chap_10.html#using-the-least-mean-square-error-criterion":{},"Chap_11.html":{},"Chap_11.html#aspects-of-estimation":{},"Chap_11.html#example-estimating-the-poisson-rate":{},"Chap_11.html#langevin-redux":{},"Chap_11.html#problem-117":{},"Chap_12.html":{},"Chap_12.html#problem-121":{},"Chap_12.html#the-periodogram-unbiased":{},"Chap_3.html":{},"Chap_3.html#introduction":{},"Chap_5.html":{},"Chap_5.html#problem-56":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function_1":{},"Chap_7.html#expected-value":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#problem-79":{},"Chap_8.html":{},"Chap_8.html#example-cocktail-party-noise":{},"Chap_8.html#problem-82":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{},"Chap_9.html":{},"Chap_9.html#setting-up-the-problem":{},"Chap_9.html#the-matched-filter":{},"info.html":{},"info.html#tips-short-cuts":{},"info.html#venue":{}},"title":{}}],["four",{"_index":2415,"text":{"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#correlations-and-memory":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_7.html":{},"Chap_7.html#one-step-further":{},"Chap_9.html":{},"Chap_9.html#problem-91":{},"Chap_9.html#problem-92":{}},"title":{}}],["fourier",{"_index":468,"text":{"Chap_10.html":{},"Chap_10.html#as-seen-from-the-fourier-domain":{},"Chap_10.html#classic-example-classic-result":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#laboratory-exercise-105":{},"Chap_10.html#problem-102":{},"Chap_10.html#the-wiener-hopf-equation":{},"Chap_12.html":{},"Chap_12.html#spectral-estimation":{},"Chap_12.html#windowed-observations":{},"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_13.html#epilogue":{},"Chap_2.html":{},"Chap_2.html#prologue":{},"Chap_3.html":{},"Chap_3.html#problem-31":{},"Chap_3.html#problem-310":{},"Chap_3.html#problem-32":{},"Chap_3.html#problem-33":{},"Chap_3.html#problem-38":{},"Chap_3.html#problem-39":{},"Chap_3.html#the-basics":{},"Chap_3.html#what-is-a-random-signal":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#example-pink-noise":{},"Chap_5.html#fourier-description-of-correlation-functions":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_6.html":{},"Chap_6.html#problem-65":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_6.html#the-mean":{},"Chap_7.html":{},"Chap_7.html#expected-value":{},"Chap_7.html#problem-73":{},"Chap_8.html":{},"Chap_8.html#problem-81":{},"Chap_8.html#problem-83":{},"Chap_9.html":{},"Chap_9.html#laboratory-exercise-93":{},"Chap_9.html#setting-up-the-problem":{},"Chap_9.html#the-classic-example":{}},"title":{"Chap_10.html#as-seen-from-the-fourier-domain":{},"Chap_5.html#fourier-description-of-correlation-functions":{}}}],["frac{1}{",{"_index":3030,"text":{"Chap_7.html":{},"Chap_7.html#the-langevin-position-equation":{}},"title":{}}],["frac{1}{0",{"_index":3045,"text":{"Chap_7.html":{},"Chap_7.html#expected-value":{}},"title":{}}],["frac{1}{2",{"_index":1637,"text":{"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_4.html":{},"Chap_4.html#example-dice-money":{},"Chap_4.html#problem-41":{},"Chap_4.html#problem-47":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#example-pink-noise":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function_1":{}},"title":{}}],["frac{1}{2a",{"_index":1863,"text":{"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{}},"title":{}}],["frac{1}{2}",{"_index":1924,"text":{"Chap_3.html":{},"Chap_3.html#problem-32":{}},"title":{}}],["frac{1}{2}\\left",{"_index":2349,"text":{"Chap_4.html":{},"Chap_4.html#problem-47":{}},"title":{}}],["frac{1}{2}{",{"_index":2485,"text":{"Chap_5.html":{},"Chap_5.html#a-digression":{}},"title":{}}],["frac{1}{2}{\\left",{"_index":1450,"text":{"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{}},"title":{}}],["frac{1}{3",{"_index":2774,"text":{"Chap_6.html":{},"Chap_6.html#problem-62":{}},"title":{}}],["frac{1}{3}",{"_index":1926,"text":{"Chap_3.html":{},"Chap_3.html#problem-32":{}},"title":{}}],["frac{1}{4",{"_index":1636,"text":{"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_6.html":{},"Chap_6.html#problem-61":{}},"title":{}}],["frac{1}{6",{"_index":2122,"text":{"Chap_4.html":{},"Chap_4.html#example-average-experience":{},"Chap_4.html#example-dice-money":{},"Chap_4.html#laboratory-exercise-42":{}},"title":{}}],["frac{1}{7}\\delta[n",{"_index":1946,"text":{"Chap_3.html":{},"Chap_3.html#problem-33":{}},"title":{}}],["frac{1}{\\lambda",{"_index":3029,"text":{"Chap_7.html":{},"Chap_7.html#autocorrelation-function_1":{},"Chap_7.html#expected-value":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#the-langevin-position-equation":{}},"title":{}}],["frac{1}{\\theta",{"_index":923,"text":{"Chap_11.html":{},"Chap_11.html#example-estimating-the-poisson-rate":{}},"title":{}}],["frac{1}{k}\\sum\\limits_{k",{"_index":1406,"text":{"Chap_12.html":{},"Chap_12.html#the-periodogram-what-about-convergence":{}},"title":{}}],["frac{1}{k}\\sum\\limits_{n",{"_index":1205,"text":{"Chap_11.html":{},"Chap_11.html#problem-117":{}},"title":{}}],["frac{1}{k}var\\left",{"_index":1415,"text":{"Chap_12.html":{},"Chap_12.html#the-periodogram-what-about-convergence":{}},"title":{}}],["frac{1}{m",{"_index":1068,"text":{"Chap_11.html":{},"Chap_11.html#langevin-redux":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#impulse-invariant-sampling":{},"Chap_7.html#power-spectral-density":{},"Chap_7.html#the-langevin-velocity-equation":{}},"title":{}}],["frac{1}{m}\\left",{"_index":2975,"text":{"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{}},"title":{}}],["frac{1}{m}\\sqrt",{"_index":2966,"text":{"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{}},"title":{}}],["frac{1}{m}{",{"_index":2971,"text":{"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{}},"title":{}}],["frac{1}{m}{\\rho",{"_index":2973,"text":{"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{}},"title":{}}],["frac{1}{n}\\phi",{"_index":1159,"text":{"Chap_11.html":{},"Chap_11.html#trouble-in-paradise":{}},"title":{}}],["frac{1}{n}\\sum\\limits_{i",{"_index":926,"text":{"Chap_11.html":{},"Chap_11.html#example-estimating-the-poisson-rate":{}},"title":{}}],["frac{1}{n}\\sum\\limits_{n",{"_index":832,"text":{"Chap_11.html":{},"Chap_11.html#aspects-of-estimation":{},"Chap_11.html#estimating-the-mean":{},"Chap_11.html#trouble-in-paradise":{}},"title":{}}],["frac{1}{n}{\\left",{"_index":1296,"text":{"Chap_12.html":{},"Chap_12.html#spectral-estimation":{}},"title":{}}],["frac{1}{t}\\int\\limits_",{"_index":1702,"text":{"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{}},"title":{}}],["frac{1}{{",{"_index":3031,"text":{"Chap_7.html":{},"Chap_7.html#the-langevin-position-equation":{}},"title":{}}],["frac{1}{{(1",{"_index":3322,"text":{"Chap_7.html":{},"Chap_7.html#power-spectral-density_2":{}},"title":{}}],["frac{1}{{1",{"_index":2484,"text":{"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#power-spectral-density":{},"Chap_8.html":{},"Chap_8.html#example-filtering-noise":{}},"title":{}}],["frac{1}{{12",{"_index":2157,"text":{"Chap_4.html":{},"Chap_4.html#example-dice-money":{}},"title":{}}],["frac{1}{{2\\pi",{"_index":499,"text":{"Chap_10.html":{},"Chap_10.html#problem-102":{},"Chap_10.html#what-is-that-least-mean-square-error":{},"Chap_12.html":{},"Chap_12.html#windowed-observations":{},"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_5.html":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_8.html":{},"Chap_8.html#example-cocktail-party-noise":{},"Chap_9.html":{},"Chap_9.html#setting-up-the-problem":{},"Chap_9.html#using-cauchy-schwartz":{}},"title":{}}],["frac{1}{{2m\\lambda",{"_index":2977,"text":{"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{}},"title":{}}],["frac{1}{{2n",{"_index":2059,"text":{"Chap_4.html":{},"Chap_4.html#describing-the-time-average":{},"Chap_4.html#example-fair-chance":{},"Chap_4.html#the-ergodic-process":{},"Chap_5.html":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_6.html":{},"Chap_6.html#filtering-of-stochastic-signals":{}},"title":{}}],["frac{1}{{\\sigma",{"_index":1208,"text":{"Chap_11.html":{},"Chap_11.html#problem-117":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{}},"title":{}}],["frac{1}{{\\sqrt",{"_index":1169,"text":{"Chap_11.html":{},"Chap_11.html#problem-112":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#expected-value_1":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{}},"title":{}}],["frac{1}{{m",{"_index":2974,"text":{"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{}},"title":{}}],["frac{1}{{m{s^2",{"_index":3026,"text":{"Chap_7.html":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#tethered-particle-motion":{},"Chap_7.html#the-langevin-position-equation":{}},"title":{}}],["frac{1}{{n",{"_index":1027,"text":{"Chap_11.html":{},"Chap_11.html#estimating-the-autocorrelation-function":{},"Chap_11.html#how-good-is-our-estimator":{}},"title":{}}],["frac{1}{{x[n",{"_index":844,"text":{"Chap_11.html":{},"Chap_11.html#aspects-of-estimation":{}},"title":{}}],["frac{1}{{{\\lambda",{"_index":3108,"text":{"Chap_7.html":{},"Chap_7.html#power-spectral-density_1":{}},"title":{}}],["frac{1}{{{\\omega",{"_index":3112,"text":{"Chap_7.html":{},"Chap_7.html#power-spectral-density_1":{}},"title":{}}],["frac{1}{{{h_0}(\\omega",{"_index":715,"text":{"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{}},"title":{}}],["frac{1}{{{m^2",{"_index":3111,"text":{"Chap_7.html":{},"Chap_7.html#power-spectral-density_1":{}},"title":{}}],["frac{1}{{{m^2}}}\\left",{"_index":2996,"text":{"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{}},"title":{}}],["frac{1}{{{n^2}}}\\sum\\limits_{n",{"_index":1002,"text":{"Chap_11.html":{},"Chap_11.html#estimating-the-mean":{}},"title":{}}],["frac{1}{{{n^2}}}n\\sigma",{"_index":1006,"text":{"Chap_11.html":{},"Chap_11.html#estimating-the-mean":{}},"title":{}}],["frac{1}{{{n_0}}}\\int\\limits_",{"_index":3583,"text":{"Chap_9.html":{},"Chap_9.html#example-matching-your-filter":{}},"title":{}}],["frac{1}{{{n_0}}}h_0^*(\\omega",{"_index":723,"text":{"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{}},"title":{}}],["frac{1}{{{t_s}}}\\sigma",{"_index":3001,"text":{"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{}},"title":{}}],["frac{2}{3",{"_index":2465,"text":{"Chap_5.html":{},"Chap_5.html#a-digression":{}},"title":{}}],["frac{3}{2}\\left",{"_index":3097,"text":{"Chap_7.html":{},"Chap_7.html#power-spectral-density_1":{}},"title":{}}],["frac{3}{2}\\theta",{"_index":3103,"text":{"Chap_7.html":{},"Chap_7.html#power-spectral-density_1":{}},"title":{}}],["frac{3}{{5",{"_index":2536,"text":{"Chap_5.html":{},"Chap_5.html#example-pink-noise":{}},"title":{}}],["frac{7}{2",{"_index":2124,"text":{"Chap_4.html":{},"Chap_4.html#example-average-experience":{}},"title":{}}],["frac{9}{{13",{"_index":2778,"text":{"Chap_6.html":{},"Chap_6.html#problem-64":{}},"title":{}}],["frac{\\lambda",{"_index":3254,"text":{"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{}},"title":{}}],["frac{\\mu",{"_index":3499,"text":{"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{}},"title":{}}],["frac{\\parti",{"_index":351,"text":{"Chap_10.html":{},"Chap_10.html#using-the-least-mean-square-error-criterion":{},"Chap_11.html":{},"Chap_11.html#example-estimating-the-poisson-rate":{}},"title":{}}],["frac{a}{{1",{"_index":1073,"text":{"Chap_11.html":{},"Chap_11.html#langevin-redux":{},"Chap_11.html#problem-1110":{}},"title":{}}],["frac{c}{{{n_0",{"_index":3589,"text":{"Chap_9.html":{},"Chap_9.html#the-matched-filter-as-an-autocorrelation":{}},"title":{}}],["frac{c}{{{n_0}}}x[{n_0",{"_index":3580,"text":{"Chap_9.html":{},"Chap_9.html#example-matching-your-filter":{},"Chap_9.html#the-classic-example":{}},"title":{}}],["frac{c}{{{n_0}}}{x^*}(\\omega",{"_index":3578,"text":{"Chap_9.html":{},"Chap_9.html#the-classic-example":{}},"title":{}}],["frac{k}{m",{"_index":3255,"text":{"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{}},"title":{}}],["frac{m}{\\lambda",{"_index":3102,"text":{"Chap_7.html":{},"Chap_7.html#power-spectral-density_1":{}},"title":{}}],["frac{m}{{\\lambda",{"_index":3098,"text":{"Chap_7.html":{},"Chap_7.html#power-spectral-density_1":{}},"title":{}}],["frac{n}{n",{"_index":1448,"text":{"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{}},"title":{}}],["frac{n}{{\\sigma",{"_index":1451,"text":{"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{}},"title":{}}],["frac{n}{{{{\\left",{"_index":1036,"text":{"Chap_11.html":{},"Chap_11.html#how-good-is-our-estimator":{}},"title":{}}],["frac{s}{n",{"_index":3427,"text":{"Chap_8.html":{},"Chap_8.html#snr-for-deterministic-signals-in-the-presence-of-noise":{},"Chap_8.html#snr-for-random-signals-in-the-presence-of-noise":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{},"Chap_9.html":{},"Chap_9.html#setting-up-the-problem":{},"Chap_9.html#using-cauchy-schwartz":{}},"title":{}}],["frac{{({\\rho",{"_index":3290,"text":{"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#expected-value_1":{}},"title":{}}],["frac{{1",{"_index":3040,"text":{"Chap_7.html":{},"Chap_7.html#expected-value":{},"Chap_7.html#the-langevin-position-equation":{},"Chap_8.html":{},"Chap_8.html#example-cocktail-party-noise":{}},"title":{}}],["frac{{1/m}}{{1",{"_index":2843,"text":{"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#impulse-invariant-sampling":{}},"title":{}}],["frac{{150}}{\\pi",{"_index":3099,"text":{"Chap_7.html":{},"Chap_7.html#power-spectral-density_1":{}},"title":{}}],["frac{{1{\\rm{/}}\\lambda",{"_index":3036,"text":{"Chap_7.html":{},"Chap_7.html#the-langevin-position-equation":{}},"title":{}}],["frac{{2\\,k{e_x}}}{m",{"_index":3020,"text":{"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{}},"title":{}}],["frac{{2\\lambda",{"_index":3346,"text":{"Chap_7.html":{},"Chap_7.html#one-step-further":{}},"title":{}}],["frac{{2\\pi",{"_index":3584,"text":{"Chap_9.html":{},"Chap_9.html#example-matching-your-filter":{}},"title":{}}],["frac{{2\\rho",{"_index":3089,"text":{"Chap_7.html":{},"Chap_7.html#power-spectral-density_1":{}},"title":{}}],["frac{{3m}}{\\lambda",{"_index":3117,"text":{"Chap_7.html":{},"Chap_7.html#power-spectral-density_1":{}},"title":{}}],["frac{{3m}}{{2\\lambda",{"_index":3095,"text":{"Chap_7.html":{},"Chap_7.html#power-spectral-density_1":{}},"title":{}}],["frac{{3{k_b}\\psi",{"_index":3224,"text":{"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{}},"title":{}}],["frac{{49}}{{65",{"_index":1290,"text":{"Chap_12.html":{},"Chap_12.html#spectral-estimation":{}},"title":{}}],["frac{{\\lambda",{"_index":3505,"text":{"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{}},"title":{}}],["frac{{\\left",{"_index":1307,"text":{"Chap_12.html":{},"Chap_12.html#the-periodogram-unbiased":{},"Chap_9.html":{},"Chap_9.html#setting-up-the-problem":{}},"title":{}}],["frac{{\\max",{"_index":3428,"text":{"Chap_8.html":{},"Chap_8.html#snr-for-deterministic-signals-in-the-presence-of-noise":{},"Chap_8.html#snr-for-random-signals-in-the-presence-of-noise":{}},"title":{}}],["frac{{\\parti",{"_index":349,"text":{"Chap_10.html":{},"Chap_10.html#using-the-least-mean-square-error-criterion":{},"Chap_11.html":{},"Chap_11.html#example-estimating-the-poisson-rate":{},"Chap_13.html":{},"Chap_13.html#appendix-i-mean-square-error-minimization":{}},"title":{}}],["frac{{\\pi",{"_index":1458,"text":{"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{}},"title":{}}],["frac{{\\rho",{"_index":3073,"text":{"Chap_7.html":{},"Chap_7.html#autocorrelation-function_1":{},"Chap_7.html#power-spectral-density_1":{}},"title":{}}],["frac{{\\sigma",{"_index":1007,"text":{"Chap_11.html":{},"Chap_11.html#estimating-the-mean":{}},"title":{}}],["frac{{\\sin",{"_index":1368,"text":{"Chap_12.html":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_12.html#windowed-observations":{},"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{}},"title":{}}],["frac{{\\sqrt",{"_index":3265,"text":{"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period_1":{}},"title":{}}],["frac{{de}}{{d{h_i",{"_index":401,"text":{"Chap_10.html":{},"Chap_10.html#expressing-the-mean-square-error":{}},"title":{}}],["frac{{dx(t)}}{{dt",{"_index":2804,"text":{"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#the-langevin-equation-a-case-study":{},"Chap_7.html#the-langevin-position-equation":{}},"title":{}}],["frac{{dx(t)}}{{dt}}}_{frictional\\,force}\\,\\,\\,\\underbrac",{"_index":3171,"text":{"Chap_7.html":{},"Chap_7.html#tethered-particle-motion":{}},"title":{}}],["frac{{h_0^*(\\omega",{"_index":705,"text":{"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{}},"title":{}}],["frac{{n",{"_index":1150,"text":{"Chap_11.html":{},"Chap_11.html#trouble-in-paradise":{},"Chap_12.html":{},"Chap_12.html#the-periodogram-unbiased":{},"Chap_12.html#windowed-observations":{}},"title":{}}],["frac{{v(z)}}{{f(z",{"_index":2839,"text":{"Chap_7.html":{},"Chap_7.html#impulse-invariant-sampling":{}},"title":{}}],["frac{{x(\\omega",{"_index":3569,"text":{"Chap_9.html":{},"Chap_9.html#using-cauchy-schwartz":{}},"title":{}}],["frac{{{\\lambda",{"_index":3263,"text":{"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period_1":{}},"title":{}}],["frac{{{\\sigma",{"_index":3438,"text":{"Chap_8.html":{},"Chap_8.html#snr-for-random-signals-in-the-presence-of-noise":{}},"title":{}}],["frac{{{\\theta",{"_index":903,"text":{"Chap_11.html":{},"Chap_11.html#example-estimating-the-poisson-rate":{}},"title":{}}],["frac{{{\\varphi",{"_index":3453,"text":{"Chap_8.html":{},"Chap_8.html#snr-for-random-signals-in-the-presence-of-noise":{}},"title":{}}],["frac{{{a^2}(1",{"_index":1081,"text":{"Chap_11.html":{},"Chap_11.html#langevin-redux":{}},"title":{}}],["frac{{{a^2}}}{{{{(1",{"_index":1127,"text":{"Chap_11.html":{},"Chap_11.html#langevin-redux":{}},"title":{}}],["frac{{{a_k}}}{{",{"_index":3373,"text":{"Chap_7.html":{},"Chap_7.html#problem-72":{}},"title":{}}],["frac{{{f_o}{{(1",{"_index":3080,"text":{"Chap_7.html":{},"Chap_7.html#power-spectral-density_1":{}},"title":{}}],["frac{{{f_o}{{({\\rho",{"_index":3320,"text":{"Chap_7.html":{},"Chap_7.html#power-spectral-density_2":{}},"title":{}}],["frac{{{f_o}}}{{1",{"_index":1070,"text":{"Chap_11.html":{},"Chap_11.html#langevin-redux":{},"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#power-spectral-density":{}},"title":{}}],["frac{{{f_o}}}{{2k\\lambda",{"_index":3339,"text":{"Chap_7.html":{},"Chap_7.html#descriptive-statistic-variance":{}},"title":{}}],["frac{{{f_o}}}{{2m\\lambda",{"_index":2991,"text":{"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{}},"title":{}}],["frac{{{f_o}}}{{{\\lambda",{"_index":3071,"text":{"Chap_7.html":{},"Chap_7.html#autocorrelation-function_1":{},"Chap_7.html#descriptive-statistic-variance":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#problem-77":{}},"title":{}}],["frac{{{f_o}}}{{{m^2}}}\\left",{"_index":3000,"text":{"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{}},"title":{}}],["frac{{{k_b}\\psi",{"_index":3021,"text":{"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#one-step-further":{},"Chap_7.html#problem-77":{}},"title":{}}],["frac{{{n_0}}}{{1",{"_index":3423,"text":{"Chap_8.html":{},"Chap_8.html#example-cocktail-party-noise":{},"Chap_8.html#example-filtering-noise":{}},"title":{}}],["frac{{{q^2}}}{2",{"_index":1453,"text":{"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{}},"title":{}}],["frac{{{s_0}}}{{1",{"_index":3469,"text":{"Chap_8.html":{},"Chap_8.html#example-cocktail-party-noise":{}},"title":{}}],["frac{{{s_0}}}{{{n_0}}}\\,\\left",{"_index":3478,"text":{"Chap_8.html":{},"Chap_8.html#example-cocktail-party-noise":{}},"title":{}}],["frac{{{s_o}/\\left",{"_index":3476,"text":{"Chap_8.html":{},"Chap_8.html#example-cocktail-party-noise":{}},"title":{}}],["frac{{{s_o}}}{{1",{"_index":1287,"text":{"Chap_12.html":{},"Chap_12.html#spectral-estimation":{}},"title":{}}],["frac{{{s_{nn}}(\\omega",{"_index":712,"text":{"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{}},"title":{}}],["frac{{{s_{rx}}(\\omega",{"_index":495,"text":{"Chap_10.html":{},"Chap_10.html#as-seen-from-the-fourier-domain":{}},"title":{}}],["frac{{{s_{xx}}(\\omega",{"_index":558,"text":{"Chap_10.html":{},"Chap_10.html#classic-example-classic-result":{}},"title":{}}],["frac{{{z",{"_index":3037,"text":{"Chap_7.html":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#the-langevin-position-equation":{}},"title":{}}],["frac{{{{(1",{"_index":3114,"text":{"Chap_7.html":{},"Chap_7.html#power-spectral-density_1":{}},"title":{}}],["frac{{{{\\left",{"_index":887,"text":{"Chap_11.html":{},"Chap_11.html#example-estimating-the-poisson-rate":{},"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_8.html":{},"Chap_8.html#example-not-too-noisy":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{},"Chap_9.html":{},"Chap_9.html#example-matching-your-filter":{},"Chap_9.html#using-cauchy-schwartz":{}},"title":{}}],["frac{{{{\\left\\langl",{"_index":3343,"text":{"Chap_7.html":{},"Chap_7.html#descriptive-statistic-variance":{}},"title":{}}],["free",{"_index":87,"text":{"Chap_1.html":{},"Chap_1.html#how-to-use-this-ibook":{},"Chap_10.html":{},"Chap_10.html#why-we-avoid-the-inverse-filter":{},"Chap_12.html":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#tethered-particle-motion":{},"info.html":{},"info.html#tips-short-cuts":{}},"title":{}}],["freedom",{"_index":1212,"text":{"Chap_11.html":{},"Chap_11.html#problem-117":{},"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{}},"title":{}}],["freeli",{"_index":759,"text":{"Chap_10.html":{},"Chap_10.html#problem-104":{}},"title":{}}],["frequenc",{"_index":561,"text":{"Chap_10.html":{},"Chap_10.html#classic-example-classic-result":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#example-cleaning-up-our-act":{},"Chap_10.html#problem-104":{},"Chap_10.html#why-we-avoid-the-inverse-filter":{},"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#other-windows":{},"Chap_12.html#problem-121":{},"Chap_12.html#problem-122":{},"Chap_12.html#problem-123":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_12.html#windowed-observations":{},"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_3.html":{},"Chap_3.html#introduction":{},"Chap_3.html#problem-38":{},"Chap_3.html#the-basics":{},"Chap_4.html":{},"Chap_4.html#problem-48":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#example-white-noise":{},"Chap_5.html#laboratory-exercise-51":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#impulse-invariant-sampling":{},"Chap_7.html#problem-79":{}},"title":{}}],["frequency\u2014also",{"_index":3272,"text":{"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period_1":{}},"title":{}}],["frequent",{"_index":295,"text":{"Chap_10.html":{},"Chap_10.html#the-restoration-case-noise":{},"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_2.html":{},"Chap_2.html#prologue":{},"Chap_4.html":{},"Chap_4.html#problem-49":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_5.html":{},"Chap_5.html#correlations-and-memory":{},"Chap_7.html":{},"Chap_7.html#the-langevin-equation-a-case-study":{},"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{},"info.html":{},"info.html#tips-short-cuts":{}},"title":{}}],["friction",{"_index":2800,"text":{"Chap_7.html":{},"Chap_7.html#the-langevin-equation-a-case-study":{}},"title":{}}],["fs",{"_index":2890,"text":{"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small":{}},"title":{}}],["fulfil",{"_index":1445,"text":{"Chap_12.html":{},"Chap_12.html#other-windows":{},"Chap_4.html":{},"Chap_4.html#the-ergodic-process":{}},"title":{}}],["full",{"_index":758,"text":{"Chap_10.html":{},"Chap_10.html#problem-104":{},"Chap_12.html":{},"Chap_12.html#problem-123":{},"Chap_3.html":{},"Chap_3.html#problem-310":{},"Chap_4.html":{},"Chap_4.html#problem-47":{}},"title":{}}],["function",{"_index":412,"text":{"Chap_10.html":{},"Chap_10.html#correlation-returns":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#problem-103":{},"Chap_10.html#what-is-that-least-mean-square-error":{},"Chap_10.html#why-we-avoid-the-inverse-filter":{},"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_11.html#estimating-the-autocorrelation-function":{},"Chap_11.html#example-estimating-the-poisson-rate":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_11.html#langevin-redux":{},"Chap_11.html#problem-111":{},"Chap_11.html#problem-112":{},"Chap_11.html#problem-114":{},"Chap_11.html#problem-119":{},"Chap_11.html#trouble-in-paradise":{},"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#spectral-estimation":{},"Chap_12.html#windowed-observations":{},"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_2.html":{},"Chap_2.html#prologue":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_3.html#introduction":{},"Chap_3.html#problem-34":{},"Chap_3.html#problem-35":{},"Chap_3.html#problem-36":{},"Chap_3.html#problem-37":{},"Chap_3.html#problem-38":{},"Chap_3.html#problem-39":{},"Chap_4.html":{},"Chap_4.html#cross-covariance":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#example-dice-money":{},"Chap_4.html#example-is-that-coin-fair":{},"Chap_4.html#laboratory-exercise-42":{},"Chap_4.html#problem-44":{},"Chap_4.html#the-ergodic-process":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#correlations-simple-and-complex":{},"Chap_5.html#example-pink-noise":{},"Chap_5.html#example-white-noise":{},"Chap_5.html#fourier-description-of-correlation-functions":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_5.html#problem-54":{},"Chap_5.html#problem-55":{},"Chap_5.html#problem-56":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{},"Chap_6.html#filtering-of-stochastic-signals":{},"Chap_6.html#interpretation-of-the-convolution-result":{},"Chap_6.html#laboratory-exercise-63":{},"Chap_6.html#laboratory-exercise-67":{},"Chap_6.html#problem-63":{},"Chap_6.html#problem-64":{},"Chap_6.html#the-autocorrelation-function":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function":{},"Chap_7.html#autocorrelation-function_1":{},"Chap_7.html#autocorrelation-function_2":{},"Chap_7.html#descriptive-statistic-variance":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#expected-value":{},"Chap_7.html#impulse-invariant-sampling":{},"Chap_7.html#power-spectral-density":{},"Chap_7.html#power-spectral-density_2":{},"Chap_7.html#problem-73":{},"Chap_7.html#problem-74":{},"Chap_7.html#problem-79":{},"Chap_7.html#tethered-particle-motion":{},"Chap_7.html#the-langevin-equation-a-case-study":{},"Chap_7.html#why-this-case-study":{},"Chap_8.html":{},"Chap_8.html#example-filtering-noise":{},"Chap_8.html#problem-81":{},"Chap_8.html#problem-82":{},"Chap_8.html#problem-83":{},"Chap_8.html#snr-for-random-signals-in-the-presence-of-noise":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{},"Chap_9.html":{},"Chap_9.html#the-matched-filter-as-an-autocorrelation":{},"info.html":{},"info.html#cover":{},"info.html#tips-short-cuts":{}},"title":{"Chap_11.html#estimating-the-autocorrelation-function":{},"Chap_5.html#fourier-description-of-correlation-functions":{},"Chap_6.html#the-autocorrelation-function":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_7.html#autocorrelation-function":{},"Chap_7.html#autocorrelation-function_1":{},"Chap_7.html#autocorrelation-function_2":{}}}],["function\u2014if",{"_index":2437,"text":{"Chap_5.html":{},"Chap_5.html#fourier-description-of-correlation-functions":{}},"title":{}}],["function\u2014then",{"_index":914,"text":{"Chap_11.html":{},"Chap_11.html#example-estimating-the-poisson-rate":{}},"title":{}}],["fundament",{"_index":3392,"text":{"Chap_7.html":{},"Chap_7.html#problem-711":{}},"title":{}}],["further",{"_index":537,"text":{"Chap_10.html":{},"Chap_10.html#classic-example-classic-result":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_11.html":{},"Chap_11.html#estimating-the-mean":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#problem-122":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_12.html#windowed-observations":{},"Chap_2.html":{},"Chap_2.html#prologue":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_4.html":{},"Chap_4.html#the-ergodic-process":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_5.html":{},"Chap_5.html#correlations-simple-and-complex":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_6.html":{},"Chap_6.html#filtering-of-stochastic-signals":{},"Chap_6.html#the-autocorrelation-function":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#descriptive-statistic-variance":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#tethered-particle-motion":{},"Chap_7.html#the-langevin-equation-a-case-study":{},"Chap_8.html":{},"Chap_8.html#example-filtering-noise":{},"Chap_9.html":{},"Chap_9.html#example-matching-your-filter":{},"Chap_9.html#setting-up-the-problem":{},"Chap_9.html#using-cauchy-schwartz":{}},"title":{"Chap_7.html#one-step-further":{}}}],["futur",{"_index":2293,"text":{"Chap_4.html":{},"Chap_4.html#describing-the-time-average":{}},"title":{}}],["g",{"_index":1263,"text":{"Chap_11.html":{},"Chap_11.html#laboratory-exercise-113":{},"Chap_12.html":{},"Chap_12.html#laboratory-exercise-124":{},"Chap_13.html":{},"Chap_13.html#epilogue":{},"Chap_4.html":{},"Chap_4.html#example-dice-money":{},"Chap_7.html":{},"Chap_7.html#problem-711":{},"Chap_8.html":{},"Chap_8.html#problem-83":{}},"title":{}}],["g(x",{"_index":2135,"text":{"Chap_4.html":{},"Chap_4.html#example-dice-money":{},"Chap_4.html#other-averages":{}},"title":{}}],["g(x)p(x)dx",{"_index":2136,"text":{"Chap_4.html":{},"Chap_4.html#other-averages":{}},"title":{}}],["g(x)p(x[n])dx",{"_index":2131,"text":{"Chap_4.html":{},"Chap_4.html#other-averages":{}},"title":{}}],["g(x,y)p(x[n],y[k])dxdi",{"_index":2154,"text":{"Chap_4.html":{},"Chap_4.html#example-dice-money":{}},"title":{}}],["g/",{"_index":2887,"text":{"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small":{}},"title":{}}],["g[n",{"_index":2726,"text":{"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{}},"title":{}}],["g[n\\rbrack",{"_index":2732,"text":{"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{}},"title":{}}],["g\\left",{"_index":2130,"text":{"Chap_4.html":{},"Chap_4.html#example-dice-money":{},"Chap_4.html#other-averages":{}},"title":{}}],["ga",{"_index":2326,"text":{"Chap_4.html":{},"Chap_4.html#problem-42":{}},"title":{}}],["gain",{"_index":1085,"text":{"Chap_11.html":{},"Chap_11.html#langevin-redux":{},"Chap_4.html":{},"Chap_4.html#example-dice-money":{},"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_6.html#the-mean":{}},"title":{}}],["game",{"_index":979,"text":{"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{}},"title":{}}],["gamma",{"_index":2244,"text":{"Chap_4.html":{},"Chap_4.html#auto-covariance":{},"Chap_4.html#cross-covariance":{},"Chap_5.html":{},"Chap_5.html#correlations-and-memory":{},"Chap_5.html#correlations-simple-and-complex":{},"Chap_5.html#problem-52":{},"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#the-langevin-velocity-equation":{},"Chap_8.html":{},"Chap_8.html#snr-for-random-signals-in-the-presence-of-noise":{}},"title":{}}],["garini",{"_index":3150,"text":{"Chap_7.html":{},"Chap_7.html#problem-711":{},"Chap_7.html#tethered-particle-motion":{}},"title":{}}],["gasolin",{"_index":2723,"text":{"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{}},"title":{}}],["gather",{"_index":455,"text":{"Chap_10.html":{},"Chap_10.html#the-wiener-hopf-equation":{}},"title":{}}],["gauss",{"_index":1430,"text":{"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#other-windows":{}},"title":{}}],["gaussian",{"_index":676,"text":{"Chap_10.html":{},"Chap_10.html#example-cleaning-up-our-act":{},"Chap_11.html":{},"Chap_11.html#problem-112":{},"Chap_11.html#problem-117":{},"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#laboratory-exercise-124":{},"Chap_12.html#other-windows":{},"Chap_12.html#problem-122":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_4.html":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_7.html":{},"Chap_7.html#expected-value":{},"Chap_7.html#how-big-is-big-how-small-is-small":{},"Chap_7.html#impulse-invariant-sampling":{},"Chap_7.html#power-spectral-density":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#the-langevin-equation-a-case-study":{},"Chap_7.html#the-langevin-velocity-equation":{},"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{},"Chap_9.html":{},"Chap_9.html#problem-91":{}},"title":{}}],["ge",{"_index":1056,"text":{"Chap_11.html":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_11.html#langevin-redux":{},"Chap_11.html#problem-111":{},"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#windowed-observations":{},"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#correlations-simple-and-complex":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_7.html":{},"Chap_7.html#impulse-invariant-sampling":{}},"title":{}}],["gener",{"_index":110,"text":{"Chap_1.html":{},"Chap_1.html#highlighting":{},"Chap_10.html":{},"Chap_10.html#classic-example-classic-result":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#problem-102":{},"Chap_10.html#the-more-general-restoration-case-noise-distortion":{},"Chap_11.html":{},"Chap_11.html#estimating-the-mean":{},"Chap_11.html#problem-117":{},"Chap_11.html#trouble-in-paradise":{},"Chap_12.html":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_2.html":{},"Chap_2.html#prologue":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_3.html#problem-310":{},"Chap_3.html#what-is-a-random-signal":{},"Chap_4.html":{},"Chap_4.html#correlation-the-workhorse":{},"Chap_4.html#cross-covariance":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#example-dice-money":{},"Chap_4.html#example-is-that-coin-fair":{},"Chap_4.html#laboratory-exercise-41":{},"Chap_4.html#other-averages":{},"Chap_4.html#problem-49":{},"Chap_4.html#properties-of-averaging":{},"Chap_5.html":{},"Chap_5.html#correlations-simple-and-complex":{},"Chap_5.html#problem-55":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_6.html":{},"Chap_6.html#laboratory-exercise-62":{},"Chap_8.html":{},"Chap_8.html#example-not-too-noisy":{},"Chap_8.html#problem-83":{},"Chap_9.html":{},"Chap_9.html#the-matched-filter":{},"info.html":{},"info.html#acknowledgments":{},"info.html#usage":{}},"title":{"Chap_10.html#the-more-general-restoration-case-noise-distortion":{}}}],["generos",{"_index":3723,"text":{"info.html":{},"info.html#weather-data":{}},"title":{}}],["geometr",{"_index":834,"text":{"Chap_11.html":{},"Chap_11.html#aspects-of-estimation":{}},"title":{}}],["geometri",{"_index":3544,"text":{"Chap_8.html":{},"Chap_8.html#problem-83":{}},"title":{}}],["geqslant",{"_index":878,"text":{"Chap_11.html":{},"Chap_11.html#maximum-likelihood-estimation":{},"Chap_11.html#problem-114":{},"Chap_6.html":{},"Chap_6.html#problem-66":{}},"title":{}}],["gestur",{"_index":3656,"text":{"info.html":{},"info.html#tips-short-cuts":{}},"title":{}}],["get",{"_index":129,"text":{"Chap_1.html":{}},"title":{"Chap_1.html#getting-around":{}}}],["giant",{"_index":478,"text":{"Chap_10.html":{},"Chap_10.html#the-wiener-hopf-equation":{}},"title":{}}],["give",{"_index":359,"text":{"Chap_10.html":{},"Chap_10.html#correlation-returns":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#using-the-least-mean-square-error-criterion":{},"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_11.html#example-estimating-the-poisson-rate":{},"Chap_11.html#langevin-redux":{},"Chap_11.html#maximum-likelihood-estimation":{},"Chap_11.html#trouble-in-paradise":{},"Chap_12.html":{},"Chap_12.html#other-windows":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_13.html":{},"Chap_13.html#appendix-i-mean-square-error-minimization":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_2.html":{},"Chap_2.html#prologue":{},"Chap_3.html":{},"Chap_3.html#problem-310":{},"Chap_3.html#problem-38":{},"Chap_4.html":{},"Chap_4.html#cross-covariance":{},"Chap_4.html#example-fair-chance":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#correlations-and-memory":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#how-big-is-big-how-small-is-small":{},"Chap_7.html#one-step-further":{},"Chap_8.html":{},"Chap_8.html#snr-for-random-signals-in-the-presence-of-noise":{},"Chap_9.html":{},"Chap_9.html#performance-in-the-presence-of-noise":{},"Chap_9.html#problem-91":{},"Chap_9.html#the-matched-filter-as-an-autocorrelation":{},"Chap_9.html#using-cauchy-schwartz":{}},"title":{}}],["given",{"_index":493,"text":{"Chap_10.html":{},"Chap_10.html#as-seen-from-the-fourier-domain":{},"Chap_10.html#classic-example-classic-result":{},"Chap_10.html#example-sound-of-distorted-music":{},"Chap_11.html":{},"Chap_11.html#aspects-of-estimation":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_11.html#estimating-the-mean":{},"Chap_11.html#example-estimating-the-poisson-rate":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_11.html#langevin-redux":{},"Chap_11.html#maximum-likelihood-estimation":{},"Chap_11.html#problem-111":{},"Chap_11.html#problem-112":{},"Chap_11.html#problem-114":{},"Chap_11.html#problem-115":{},"Chap_11.html#problem-118":{},"Chap_11.html#trouble-in-paradise":{},"Chap_12.html":{},"Chap_12.html#problem-122":{},"Chap_12.html#spectral-estimation":{},"Chap_12.html#the-periodogram-unbiased":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_12.html#windowed-observations":{},"Chap_13.html":{},"Chap_13.html#appendix-i-mean-square-error-minimization":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_13.html#epilogue":{},"Chap_2.html":{},"Chap_2.html#prologue":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_3.html#problem-310":{},"Chap_3.html#problem-33":{},"Chap_3.html#problem-34":{},"Chap_3.html#problem-39":{},"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#example-dice-money":{},"Chap_4.html#example-is-that-coin-fair":{},"Chap_4.html#laboratory-exercise-42":{},"Chap_4.html#problem-41":{},"Chap_4.html#problem-42":{},"Chap_4.html#problem-44":{},"Chap_4.html#problem-47":{},"Chap_4.html#problem-48":{},"Chap_4.html#properties-of-averaging":{},"Chap_4.html#the-ergodic-process":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#correlations-simple-and-complex":{},"Chap_5.html#example-pink-noise":{},"Chap_5.html#example-white-noise":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_5.html#problem-55":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{},"Chap_6.html#interpretation-of-the-convolution-result":{},"Chap_6.html#problem-62":{},"Chap_6.html#problem-63":{},"Chap_6.html#problem-64":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#descriptive-statistic-variance":{},"Chap_7.html#how-big-is-big-how-small-is-small":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#impulse-invariant-sampling":{},"Chap_7.html#one-step-further":{},"Chap_7.html#power-spectral-density":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#power-spectral-density_2":{},"Chap_7.html#problem-711":{},"Chap_7.html#problem-74":{},"Chap_7.html#problem-75":{},"Chap_7.html#problem-76":{},"Chap_7.html#the-langevin-position-equation":{},"Chap_8.html":{},"Chap_8.html#example-cocktail-party-noise":{},"Chap_8.html#example-filtering-noise":{},"Chap_8.html#problem-81":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{},"Chap_9.html":{},"Chap_9.html#laboratory-exercise-93":{},"Chap_9.html#the-matched-filter":{},"Chap_9.html#the-matched-filter-as-an-autocorrelation":{}},"title":{}}],["glanc",{"_index":906,"text":{"Chap_11.html":{},"Chap_11.html#example-estimating-the-poisson-rate":{},"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_7.html":{},"Chap_7.html#the-langevin-position-equation":{}},"title":{}}],["glean",{"_index":2788,"text":{"Chap_6.html":{},"Chap_6.html#laboratory-exercise-68":{}},"title":{}}],["go",{"_index":962,"text":{"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_12.html":{},"Chap_12.html#the-periodogram-unbiased":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_6.html":{},"Chap_6.html#the-autocorrelation-function":{},"Chap_8.html":{},"Chap_8.html#problem-83":{}},"title":{}}],["goal",{"_index":981,"text":{"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_11.html#problem-115":{},"Chap_12.html":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_13.html":{},"Chap_13.html#epilogue":{},"Chap_2.html":{},"Chap_2.html#prologue":{}},"title":{}}],["goe",{"_index":967,"text":{"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_11.html#estimating-the-mean":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_11.html#trouble-in-paradise":{},"Chap_12.html":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_5.html":{},"Chap_5.html#the-mechanics-of-correlations-redux":{}},"title":{}}],["gold",{"_index":2864,"text":{"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#one-step-further":{},"Chap_7.html#problem-711":{},"Chap_7.html#problem-79":{},"Chap_7.html#tethered-particle-motion":{}},"title":{}}],["good",{"_index":157,"text":{"Chap_1.html":{},"Chap_1.html#sound-of-music":{},"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_11.html#problem-116":{},"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#the-periodogram-unbiased":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_4.html":{},"Chap_4.html#characterization-of-random-signals":{},"Chap_4.html#the-ergodic-process":{}},"title":{"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_11.html#how-good-is-our-estimator":{}}}],["googl",{"_index":206,"text":{"Chap_1.html":{},"Chap_1.html#enhanced-experience":{}},"title":{}}],["govern",{"_index":1852,"text":{"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{}},"title":{}}],["graph",{"_index":637,"text":{"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#example-cleaning-up-our-act":{},"Chap_10.html#why-we-avoid-the-inverse-filter":{},"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_4.html":{},"Chap_4.html#problem-44":{},"Chap_5.html":{},"Chap_5.html#example-white-noise":{},"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#power-spectral-density_2":{}},"title":{}}],["graphic",{"_index":72,"text":{"Chap_1.html":{},"Chap_1.html#how-to-use-this-ibook":{},"Chap_11.html":{},"Chap_11.html#estimating-the-autocorrelation-function":{},"info.html":{},"info.html#technical-details":{}},"title":{}}],["gratefulli",{"_index":3722,"text":{"info.html":{},"info.html#weather-data":{}},"title":{}}],["graviti",{"_index":2028,"text":{"Chap_3.html":{},"Chap_3.html#problem-310":{},"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small":{}},"title":{}}],["greater",{"_index":1598,"text":{"Chap_13.html":{},"Chap_13.html#appendix-i-mean-square-error-minimization":{},"Chap_4.html":{},"Chap_4.html#the-ergodic-process":{},"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_7.html":{},"Chap_7.html#problem-710":{},"Chap_7.html#the-langevin-equation-a-case-study":{},"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{}},"title":{}}],["greek",{"_index":1804,"text":{"Chap_2.html":{},"Chap_2.html#problem-21":{},"info.html":{},"info.html#technical-details":{}},"title":{}}],["green",{"_index":590,"text":{"Chap_10.html":{},"Chap_10.html#classic-example-classic-result":{},"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_11.html#langevin-redux":{},"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_7.html":{},"Chap_7.html#tethered-particle-motion":{},"Chap_8.html":{},"Chap_8.html#example-cocktail-party-noise":{}},"title":{}}],["grey",{"_index":1130,"text":{"Chap_11.html":{},"Chap_11.html#langevin-redux":{},"Chap_4.html":{},"Chap_4.html#laboratory-exercise-42":{}},"title":{}}],["groot",{"_index":3405,"text":{"Chap_7.html":{},"Chap_7.html#problem-711":{}},"title":{}}],["grove",{"_index":1734,"text":{"Chap_13.html":{},"Chap_13.html#epilogue":{}},"title":{}}],["grow",{"_index":1376,"text":{"Chap_12.html":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function_1":{},"Chap_7.html#power-spectral-density_1":{}},"title":{}}],["guarante",{"_index":1652,"text":{"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{}},"title":{}}],["guess",{"_index":1806,"text":{"Chap_2.html":{},"Chap_2.html#problem-21":{}},"title":{}}],["gui",{"_index":75,"text":{"Chap_1.html":{},"Chap_1.html#how-to-use-this-ibook":{}},"title":{}}],["guid",{"_index":52,"text":{"Chap_1.html":{},"Chap_1.html#how-to-use-this-ibook":{},"Chap_13.html":{},"Chap_13.html#epilogue":{}},"title":{}}],["h",{"_index":100,"text":{"Chap_1.html":{},"Chap_1.html#highlighting":{},"Chap_10.html":{},"Chap_10.html#example-cleaning-up-our-act":{},"Chap_10.html#using-the-least-mean-square-error-criterion":{},"Chap_11.html":{},"Chap_11.html#laboratory-exercise-113":{},"Chap_13.html":{},"Chap_13.html#appendix-i-mean-square-error-minimization":{},"Chap_3.html":{},"Chap_3.html#problem-310":{},"Chap_4.html":{},"Chap_4.html#laboratory-exercise-41":{},"Chap_4.html#laboratory-exercise-42":{},"Chap_4.html#problem-47":{},"Chap_5.html":{},"Chap_5.html#laboratory-exercise-51":{},"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_7.html":{},"Chap_7.html#problem-711":{},"Chap_7.html#problem-72":{},"Chap_8.html":{},"Chap_8.html#example-filtering-noise":{},"Chap_9.html":{},"Chap_9.html#setting-up-the-problem":{}},"title":{}}],["h(",{"_index":3372,"text":{"Chap_7.html":{},"Chap_7.html#problem-72":{}},"title":{}}],["h(\\omega",{"_index":104,"text":{"Chap_1.html":{},"Chap_1.html#highlighting":{},"Chap_10.html":{},"Chap_10.html#as-seen-from-the-fourier-domain":{},"Chap_10.html#classic-example-classic-result":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#example-sound-of-distorted-music":{},"Chap_10.html#what-is-that-least-mean-square-error":{},"Chap_10.html#why-we-avoid-the-inverse-filter":{},"Chap_3.html":{},"Chap_3.html#problem-310":{},"Chap_3.html#problem-33":{},"Chap_6.html":{},"Chap_6.html#problem-65":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_6.html#the-mean":{},"Chap_7.html":{},"Chap_7.html#problem-73":{},"Chap_8.html":{},"Chap_8.html#example-filtering-noise":{},"Chap_8.html#problem-83":{},"Chap_9.html":{},"Chap_9.html#setting-up-the-problem":{},"Chap_9.html#the-classic-example":{},"Chap_9.html#using-cauchy-schwartz":{}},"title":{}}],["h(\\omega)=\\left(\\frac{\\sin(3\\omega/2)}{\\sin(\\omega/2)}\\right",{"_index":1948,"text":{"Chap_3.html":{},"Chap_3.html#problem-33":{}},"title":{}}],["h(n{t_s}){z",{"_index":2825,"text":{"Chap_7.html":{},"Chap_7.html#impulse-invariant-sampling":{}},"title":{}}],["h(t",{"_index":2010,"text":{"Chap_3.html":{},"Chap_3.html#problem-310":{},"Chap_7.html":{},"Chap_7.html#impulse-invariant-sampling":{},"Chap_7.html#problem-73":{}},"title":{}}],["h(t)=\\begin{cases}\\frac{1}{2\\sqrt{3}}&\\lvert",{"_index":2014,"text":{"Chap_3.html":{},"Chap_3.html#problem-310":{}},"title":{}}],["h(z",{"_index":2823,"text":{"Chap_7.html":{},"Chap_7.html#impulse-invariant-sampling":{}},"title":{}}],["h[i",{"_index":516,"text":{"Chap_10.html":{},"Chap_10.html#what-is-that-least-mean-square-error":{}},"title":{}}],["h[k",{"_index":410,"text":{"Chap_10.html":{},"Chap_10.html#correlation-returns":{},"Chap_10.html#the-wiener-hopf-equation":{}},"title":{}}],["h[k]{\\varphi",{"_index":527,"text":{"Chap_10.html":{},"Chap_10.html#what-is-that-least-mean-square-error":{}},"title":{}}],["h[m",{"_index":320,"text":{"Chap_10.html":{},"Chap_10.html#the-restoration-case-noise":{},"Chap_10.html#the-wiener-hopf-equation":{},"Chap_10.html#using-the-least-mean-square-error-criterion":{},"Chap_10.html#what-is-that-least-mean-square-error":{},"Chap_6.html":{},"Chap_6.html#the-autocorrelation-function":{}},"title":{}}],["h[m]\\sum\\limits_{i",{"_index":520,"text":{"Chap_10.html":{},"Chap_10.html#what-is-that-least-mean-square-error":{}},"title":{}}],["h[m]{h^*}[m",{"_index":2660,"text":{"Chap_6.html":{},"Chap_6.html#the-autocorrelation-function":{},"Chap_6.html#the-cross-correlation-function":{}},"title":{}}],["h[n",{"_index":340,"text":{"Chap_10.html":{},"Chap_10.html#expressing-the-mean-square-error":{},"Chap_10.html#the-more-general-restoration-case-noise-distortion":{},"Chap_10.html#the-wiener-hopf-equation":{},"Chap_10.html#using-the-least-mean-square-error-criterion":{},"Chap_2.html":{},"Chap_2.html#problem-21":{},"Chap_3.html":{},"Chap_3.html#introduction":{},"Chap_3.html#problem-33":{},"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{},"Chap_6.html#interpretation-of-the-convolution-result":{},"Chap_6.html#problem-61":{},"Chap_6.html#problem-62":{},"Chap_6.html#problem-65":{},"Chap_6.html#the-autocorrelation-function":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_6.html#the-mean":{},"Chap_7.html":{},"Chap_7.html#impulse-invariant-sampling":{},"Chap_7.html#power-spectral-density":{},"Chap_8.html":{},"Chap_8.html#example-filtering-noise":{},"Chap_8.html#problem-83":{},"Chap_9.html":{},"Chap_9.html#example-matching-your-filter":{},"Chap_9.html#setting-up-the-problem":{},"Chap_9.html#the-classic-example":{},"Chap_9.html#the-matched-filter":{},"Chap_9.html#the-matched-filter-as-an-autocorrelation":{}},"title":{}}],["h[n\\rbrack",{"_index":314,"text":{"Chap_10.html":{},"Chap_10.html#the-more-general-restoration-case-noise-distortion":{},"Chap_10.html#the-restoration-case-noise":{}},"title":{}}],["h[n]=\\delta[n",{"_index":1945,"text":{"Chap_3.html":{},"Chap_3.html#problem-33":{}},"title":{}}],["h[n]=\\delta[n+3",{"_index":1933,"text":{"Chap_3.html":{},"Chap_3.html#problem-33":{}},"title":{}}],["h[n]=\\frac{\\sin(2n)}{(\\pi",{"_index":1940,"text":{"Chap_3.html":{},"Chap_3.html#problem-33":{}},"title":{}}],["h[n]=\\frac{\\sin(\\omega_0n)}{(\\pi",{"_index":1931,"text":{"Chap_3.html":{},"Chap_3.html#problem-33":{}},"title":{}}],["h[n]{z",{"_index":2824,"text":{"Chap_7.html":{},"Chap_7.html#impulse-invariant-sampling":{}},"title":{}}],["h\\lbrack",{"_index":2629,"text":{"Chap_6.html":{},"Chap_6.html#interpretation-of-the-convolution-result":{},"Chap_9.html":{},"Chap_9.html#example-matching-your-filter":{}},"title":{}}],["h\\left",{"_index":2820,"text":{"Chap_7.html":{},"Chap_7.html#impulse-invariant-sampling":{}},"title":{}}],["h^*}[k",{"_index":2671,"text":{"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{},"Chap_6.html#the-cross-correlation-function":{}},"title":{}}],["h^*}[m",{"_index":2669,"text":{"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{}},"title":{}}],["h^*}[n",{"_index":2674,"text":{"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{}},"title":{}}],["h^*}[r]e\\left",{"_index":2652,"text":{"Chap_6.html":{},"Chap_6.html#the-autocorrelation-function":{}},"title":{}}],["h^*}[r]x[n",{"_index":2650,"text":{"Chap_6.html":{},"Chap_6.html#the-autocorrelation-function":{}},"title":{}}],["h^*}[r]{\\varphi",{"_index":2654,"text":{"Chap_6.html":{},"Chap_6.html#the-autocorrelation-function":{}},"title":{}}],["h^*}[r]{x^*}[n",{"_index":2649,"text":{"Chap_6.html":{},"Chap_6.html#the-autocorrelation-function":{}},"title":{}}],["h^*}\\left",{"_index":2675,"text":{"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{}},"title":{}}],["h_0",{"_index":716,"text":{"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{}},"title":{}}],["h_0^*(\\omega",{"_index":696,"text":{"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{}},"title":{}}],["h_0}(\\omega",{"_index":702,"text":{"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{}},"title":{}}],["h_1}[n",{"_index":3054,"text":{"Chap_7.html":{},"Chap_7.html#expected-value":{}},"title":{}}],["h_1}\\left",{"_index":2780,"text":{"Chap_6.html":{},"Chap_6.html#problem-64":{}},"title":{}}],["h_2}\\left",{"_index":2781,"text":{"Chap_6.html":{},"Chap_6.html#problem-64":{}},"title":{}}],["h_i",{"_index":1602,"text":{"Chap_13.html":{},"Chap_13.html#appendix-i-mean-square-error-minimization":{}},"title":{}}],["h_i}[n",{"_index":3598,"text":{"Chap_9.html":{},"Chap_9.html#problem-91":{}},"title":{}}],["h_k}{r_k",{"_index":1597,"text":{"Chap_13.html":{},"Chap_13.html#appendix-i-mean-square-error-minimization":{}},"title":{}}],["h_o}(\\omega",{"_index":615,"text":{"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#example-cleaning-up-our-act":{},"Chap_10.html#example-sound-of-distorted-music":{},"Chap_10.html#why-we-avoid-the-inverse-filter":{}},"title":{}}],["h_o}[n",{"_index":598,"text":{"Chap_10.html":{},"Chap_10.html#example-sound-of-distorted-music":{},"Chap_10.html#the-more-general-restoration-case-noise-distortion":{},"Chap_10.html#why-we-avoid-the-inverse-filter":{}},"title":{}}],["h_o}[n\\rbrack",{"_index":606,"text":{"Chap_10.html":{},"Chap_10.html#the-more-general-restoration-case-noise-distortion":{},"Chap_10.html#why-we-avoid-the-inverse-filter":{}},"title":{}}],["h_v",{"_index":2970,"text":{"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{}},"title":{}}],["h_v}(\\omega",{"_index":2897,"text":{"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{}},"title":{}}],["h_v}(t",{"_index":2830,"text":{"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#impulse-invariant-sampling":{}},"title":{}}],["h_v}(z",{"_index":2838,"text":{"Chap_7.html":{},"Chap_7.html#impulse-invariant-sampling":{}},"title":{}}],["h_v}[n",{"_index":2836,"text":{"Chap_7.html":{},"Chap_7.html#autocorrelation-function":{},"Chap_7.html#impulse-invariant-sampling":{}},"title":{}}],["h_v}\\left",{"_index":2910,"text":{"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{}},"title":{}}],["h_x",{"_index":3107,"text":{"Chap_7.html":{},"Chap_7.html#power-spectral-density_1":{}},"title":{}}],["h_x}(",{"_index":3025,"text":{"Chap_7.html":{},"Chap_7.html#tethered-particle-motion":{},"Chap_7.html#the-langevin-position-equation":{}},"title":{}}],["h_x}(\\omega",{"_index":3046,"text":{"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#expected-value":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#power-spectral-density_1":{}},"title":{}}],["h_x}(n{t_",{"_index":3276,"text":{"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period_1":{}},"title":{}}],["h_x}(t",{"_index":3027,"text":{"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#the-langevin-position-equation":{}},"title":{}}],["h_x}(z",{"_index":3035,"text":{"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#the-langevin-position-equation":{}},"title":{}}],["h_x}[n",{"_index":3033,"text":{"Chap_7.html":{},"Chap_7.html#autocorrelation-function_1":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#expected-value":{},"Chap_7.html#the-langevin-position-equation":{}},"title":{}}],["h_x}[n]{h_x}[n",{"_index":3302,"text":{"Chap_7.html":{},"Chap_7.html#autocorrelation-function_2":{}},"title":{}}],["half",{"_index":2313,"text":{"Chap_4.html":{},"Chap_4.html#problem-42":{},"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{}},"title":{}}],["hall",{"_index":658,"text":{"Chap_10.html":{},"Chap_10.html#example-sound-of-distorted-music":{},"Chap_10.html#laboratory-exercise-105":{},"Chap_3.html":{},"Chap_3.html#problem-310":{},"Chap_4.html":{},"Chap_4.html#laboratory-exercise-42":{},"Chap_5.html":{},"Chap_5.html#laboratory-exercise-51":{},"Chap_7.html":{},"Chap_7.html#problem-711":{}},"title":{}}],["ham",{"_index":1432,"text":{"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#other-windows":{}},"title":{}}],["hand",{"_index":386,"text":{"Chap_10.html":{},"Chap_10.html#expressing-the-mean-square-error":{},"Chap_7.html":{},"Chap_7.html#problem-78":{},"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{},"Chap_9.html":{},"Chap_9.html#laboratory-exercise-92":{}},"title":{}}],["hann",{"_index":1433,"text":{"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#other-windows":{},"Chap_12.html#problem-121":{}},"title":{}}],["happen",{"_index":672,"text":{"Chap_10.html":{},"Chap_10.html#example-sound-of-distorted-music":{},"Chap_3.html":{},"Chap_3.html#what-is-a-random-signal":{},"Chap_4.html":{},"Chap_4.html#correlation-the-workhorse":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_5.html":{},"Chap_5.html#correlations-and-memory":{},"Chap_6.html":{},"Chap_6.html#filtering-of-stochastic-signals":{},"Chap_7.html":{},"Chap_7.html#expected-value":{},"Chap_7.html#power-spectral-density_1":{},"Chap_9.html":{},"Chap_9.html#laboratory-exercise-93":{}},"title":{}}],["hard",{"_index":3386,"text":{"Chap_7.html":{},"Chap_7.html#problem-78":{}},"title":{}}],["hardli",{"_index":2574,"text":{"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{}},"title":{}}],["harmon",{"_index":839,"text":{"Chap_11.html":{},"Chap_11.html#aspects-of-estimation":{},"Chap_11.html#problem-114":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period_1":{}},"title":{}}],["harri",{"_index":1776,"text":{"Chap_2.html":{},"Chap_2.html#prologue":{}},"title":{}}],["hat",{"_index":938,"text":{"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_11.html#problem-115":{},"Chap_11.html#trouble-in-paradise":{},"Chap_12.html":{},"Chap_12.html#spectral-estimation":{},"Chap_12.html#the-periodogram-unbiased":{}},"title":{}}],["have",{"_index":112,"text":{"Chap_1.html":{},"Chap_1.html#highlighting":{},"Chap_10.html":{},"Chap_10.html#laboratory-exercise-105":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#how-big-is-big-how-small-is-small":{}},"title":{}}],["haystack",{"_index":3548,"text":{"Chap_9.html":{},"Chap_9.html#laboratory-exercise-92":{},"Chap_9.html#the-matched-filter":{}},"title":{}}],["head",{"_index":1175,"text":{"Chap_11.html":{},"Chap_11.html#problem-113":{},"Chap_4.html":{},"Chap_4.html#example-fair-chance":{},"Chap_4.html#example-is-that-coin-fair":{},"Chap_4.html#laboratory-exercise-41":{},"Chap_4.html#problem-47":{}},"title":{}}],["hear",{"_index":4,"text":{"Chap_1.html":{},"Chap_1.html#sound-of-music":{},"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#example-sound-of-distorted-music":{},"Chap_13.html":{},"Chap_13.html#epilogue":{}},"title":{}}],["heard",{"_index":3730,"text":{"info.html":{},"info.html#musical-data":{}},"title":{}}],["heat",{"_index":2376,"text":{"Chap_4.html":{},"Chap_4.html#laboratory-exercise-42":{},"Chap_7.html":{},"Chap_7.html#problem-711":{}},"title":{}}],["hecht",{"_index":3527,"text":{"Chap_8.html":{},"Chap_8.html#problem-82":{},"Chap_8.html#problem-83":{}},"title":{}}],["heer",{"_index":3406,"text":{"Chap_7.html":{},"Chap_7.html#problem-711":{}},"title":{}}],["height",{"_index":1361,"text":{"Chap_12.html":{},"Chap_12.html#windowed-observations":{}},"title":{}}],["held",{"_index":2797,"text":{"Chap_7.html":{},"Chap_7.html#the-langevin-equation-a-case-study":{}},"title":{}}],["help",{"_index":2186,"text":{"Chap_4.html":{},"Chap_4.html#correlation-the-workhorse":{},"Chap_5.html":{},"Chap_5.html#correlations-and-memory":{},"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{},"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{},"info.html":{},"info.html#acknowledgments":{},"info.html#musical-data":{},"info.html#tips-short-cuts":{}},"title":{}}],["hemispher",{"_index":3158,"text":{"Chap_7.html":{},"Chap_7.html#tethered-particle-motion":{}},"title":{}}],["henc",{"_index":1138,"text":{"Chap_11.html":{},"Chap_11.html#langevin-redux":{}},"title":{}}],["here",{"_index":88,"text":{"Chap_1.html":{},"Chap_1.html#how-to-use-this-ibook":{},"Chap_1.html#outside-this-device":{},"Chap_10.html":{},"Chap_10.html#the-wiener-hopf-equation":{},"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_11.html#langevin-redux":{},"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#laboratory-exercise-42":{},"Chap_4.html#properties-of-averaging":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_5.html":{},"Chap_5.html#laboratory-exercise-51":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_7.html":{},"Chap_7.html#expected-value":{},"Chap_7.html#power-spectral-density":{},"Chap_9.html":{},"Chap_9.html#the-matched-filter":{},"info.html":{},"info.html#tips-short-cuts":{},"info.html#venue":{}},"title":{}}],["high",{"_index":570,"text":{"Chap_10.html":{},"Chap_10.html#classic-example-classic-result":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_7.html":{},"Chap_7.html#descriptive-statistic-variance":{},"Chap_7.html#impulse-invariant-sampling":{},"Chap_7.html#problem-79":{}},"title":{}}],["higher",{"_index":1699,"text":{"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#one-step-further":{},"Chap_7.html#problem-79":{}},"title":{}}],["highest",{"_index":2901,"text":{"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#choosing-the-sampling-period_1":{}},"title":{}}],["highlight",{"_index":89,"text":{"Chap_1.html":{},"Chap_1.html#highlighting":{}},"title":{"Chap_1.html#highlighting":{}}}],["hill",{"_index":794,"text":{"Chap_10.html":{},"Chap_10.html#laboratory-exercise-105":{},"Chap_13.html":{},"Chap_13.html#epilogue":{},"Chap_3.html":{},"Chap_3.html#problem-310":{},"Chap_5.html":{},"Chap_5.html#laboratory-exercise-51":{},"Chap_7.html":{},"Chap_7.html#problem-711":{}},"title":{}}],["hint",{"_index":1189,"text":{"Chap_11.html":{},"Chap_11.html#problem-1110":{},"Chap_11.html#problem-115":{},"Chap_11.html#problem-116":{},"Chap_12.html":{},"Chap_12.html#problem-122":{},"Chap_4.html":{},"Chap_4.html#problem-42":{},"Chap_9.html":{},"Chap_9.html#problem-91":{},"Chap_9.html#problem-92":{}},"title":{}}],["histogram",{"_index":2217,"text":{"Chap_4.html":{},"Chap_4.html#laboratory-exercise-41":{},"Chap_4.html#the-mechanics-of-correlations":{}},"title":{}}],["hoboken",{"_index":1251,"text":{"Chap_11.html":{},"Chap_11.html#laboratory-exercise-113":{}},"title":{}}],["hold",{"_index":1483,"text":{"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_4.html":{},"Chap_4.html#describing-the-time-average":{},"Chap_5.html":{},"Chap_5.html#correlations-and-memory":{},"Chap_5.html#fourier-description-of-correlation-functions":{},"Chap_5.html#problem-56":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_6.html":{},"Chap_6.html#interpretation-of-the-convolution-result":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_7.html":{},"Chap_7.html#power-spectral-density_1":{}},"title":{}}],["homework",{"_index":141,"text":{"Chap_1.html":{},"Chap_1.html#getting-around":{}},"title":{}}],["hookean",{"_index":3164,"text":{"Chap_7.html":{},"Chap_7.html#tethered-particle-motion":{}},"title":{}}],["hope",{"_index":960,"text":{"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{}},"title":{}}],["hopf",{"_index":434,"text":{"Chap_10.html":{},"Chap_10.html#classic-example-classic-result":{},"Chap_10.html#the-wiener-hopf-equation":{}},"title":{"Chap_10.html#the-wiener-hopf-equation":{}}}],["humphrey",{"_index":180,"text":{"Chap_1.html":{},"Chap_1.html#at-the-movies":{}},"title":{}}],["hydrodynam",{"_index":2882,"text":{"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small":{}},"title":{}}],["hypothes",{"_index":851,"text":{"Chap_11.html":{},"Chap_11.html#aspects-of-estimation":{}},"title":{}}],["hypothet",{"_index":978,"text":{"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{}},"title":{}}],["hz",{"_index":2916,"text":{"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#choosing-the-sampling-period_1":{}},"title":{}}],["h}}e\\left",{"_index":353,"text":{"Chap_10.html":{},"Chap_10.html#using-the-least-mean-square-error-criterion":{}},"title":{}}],["i+j=11",{"_index":1980,"text":{"Chap_3.html":{},"Chap_3.html#problem-37":{}},"title":{}}],["i,j=1,\\dots,6",{"_index":1896,"text":{"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{}},"title":{}}],["i.",{"_index":1762,"text":{"Chap_2.html":{},"Chap_2.html#prologue":{},"Chap_7.html":{},"Chap_7.html#tethered-particle-motion":{}},"title":{}}],["i\\,\\delta",{"_index":2526,"text":{"Chap_5.html":{},"Chap_5.html#example-white-noise":{}},"title":{}}],["i\\sum\\limits_{k",{"_index":2528,"text":{"Chap_5.html":{},"Chap_5.html#example-white-noise":{}},"title":{}}],["i]\\sum\\limits_{k",{"_index":408,"text":{"Chap_10.html":{},"Chap_10.html#correlation-returns":{}},"title":{}}],["i]h[i",{"_index":522,"text":{"Chap_10.html":{},"Chap_10.html#what-is-that-least-mean-square-error":{}},"title":{}}],["i_n^{(k)}(\\omega",{"_index":1407,"text":{"Chap_12.html":{},"Chap_12.html#the-periodogram-what-about-convergence":{}},"title":{}}],["i_n^{(k)}\\left",{"_index":1403,"text":{"Chap_12.html":{},"Chap_12.html#the-periodogram-what-about-convergence":{}},"title":{}}],["i_n}(\\omega",{"_index":1281,"text":{"Chap_12.html":{},"Chap_12.html#spectral-estimation":{},"Chap_12.html#the-periodogram-unbiased":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_12.html#windowed-observations":{}},"title":{}}],["i_n}\\left",{"_index":1383,"text":{"Chap_12.html":{},"Chap_12.html#the-periodogram-what-about-convergence":{}},"title":{}}],["ian",{"_index":3660,"text":{"info.html":{},"info.html#authors":{}},"title":{}}],["ibook",{"_index":3,"text":{"Chap_1.html":{},"Chap_1.html#getting-around":{},"Chap_1.html#how-to-use-this-ibook":{},"Chap_1.html#outside-this-device":{},"Chap_1.html#sound-of-music":{},"Chap_13.html":{},"Chap_13.html#epilogue":{},"Chap_2.html":{},"Chap_2.html#prologue":{},"Chap_3.html":{},"Chap_3.html#what-is-a-random-signal":{},"Chap_4.html":{},"Chap_4.html#example-is-that-coin-fair":{},"Chap_4.html#laboratory-exercise-42":{},"Chap_4.html#properties-of-averaging":{},"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"info.html":{},"info.html#acknowledgments":{},"info.html#contact":{},"info.html#musical-data":{},"info.html#technical-details":{},"info.html#tips-short-cuts":{},"info.html#venue":{},"info.html#weather-data":{}},"title":{"Chap_1.html":{},"Chap_1.html#how-to-use-this-ibook":{}}}],["icon",{"_index":155,"text":{"Chap_1.html":{},"Chap_1.html#sound-of-music":{},"Chap_10.html":{},"Chap_10.html#laboratory-exercise-101":{},"Chap_10.html#laboratory-exercise-102":{},"Chap_10.html#laboratory-exercise-103":{},"Chap_10.html#laboratory-exercise-104":{},"Chap_10.html#laboratory-exercise-105":{},"Chap_11.html":{},"Chap_11.html#laboratory-exercise-111":{},"Chap_11.html#laboratory-exercise-112":{},"Chap_11.html#laboratory-exercise-113":{},"Chap_12.html":{},"Chap_12.html#laboratory-exercise-121":{},"Chap_12.html#laboratory-exercise-122":{},"Chap_12.html#laboratory-exercise-123":{},"Chap_12.html#laboratory-exercise-124":{},"Chap_4.html":{},"Chap_4.html#laboratory-exercise-41":{},"Chap_4.html#laboratory-exercise-42":{},"Chap_5.html":{},"Chap_5.html#laboratory-exercise-51":{},"Chap_6.html":{},"Chap_6.html#laboratory-exercise-61":{},"Chap_6.html#laboratory-exercise-62":{},"Chap_6.html#laboratory-exercise-63":{},"Chap_6.html#laboratory-exercise-64":{},"Chap_6.html#laboratory-exercise-65":{},"Chap_6.html#laboratory-exercise-66":{},"Chap_6.html#laboratory-exercise-67":{},"Chap_6.html#laboratory-exercise-68":{},"Chap_9.html":{},"Chap_9.html#laboratory-exercise-91":{},"Chap_9.html#laboratory-exercise-92":{},"Chap_9.html#laboratory-exercise-93":{}},"title":{}}],["idea",{"_index":1353,"text":{"Chap_12.html":{},"Chap_12.html#other-windows":{},"Chap_12.html#windowed-observations":{},"Chap_13.html":{},"Chap_13.html#epilogue":{},"Chap_4.html":{},"Chap_4.html#cross-correlation":{},"Chap_7.html":{},"Chap_7.html#why-this-case-study":{},"Chap_8.html":{},"Chap_8.html#example-filtering-noise":{}},"title":{}}],["ideal",{"_index":1342,"text":{"Chap_12.html":{},"Chap_12.html#other-windows":{},"Chap_12.html#windowed-observations":{},"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_8.html":{},"Chap_8.html#problem-83":{}},"title":{}}],["ident",{"_index":668,"text":{"Chap_10.html":{},"Chap_10.html#example-sound-of-distorted-music":{},"Chap_11.html":{},"Chap_11.html#problem-114":{},"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_3.html":{},"Chap_3.html#problem-310":{},"Chap_4.html":{},"Chap_4.html#example-is-that-coin-fair":{},"Chap_7.html":{},"Chap_7.html#expected-value":{},"Chap_7.html#tethered-particle-motion":{},"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{}},"title":{}}],["identifi",{"_index":2572,"text":{"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_7.html":{},"Chap_7.html#expected-value":{},"Chap_9.html":{},"Chap_9.html#performance-in-the-presence-of-noise":{}},"title":{}}],["ignor",{"_index":2441,"text":{"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_7.html":{},"Chap_7.html#tethered-particle-motion":{},"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{}},"title":{}}],["ii",{"_index":1486,"text":{"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#problem-122":{},"Chap_13.html":{},"Chap_7.html":{},"Chap_7.html#problem-711":{}},"title":{"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{}}}],["iii",{"_index":1525,"text":{"Chap_12.html":{},"Chap_12.html#problem-122":{}},"title":{}}],["ilan",{"_index":3153,"text":{"Chap_7.html":{},"Chap_7.html#tethered-particle-motion":{}},"title":{}}],["ill",{"_index":3092,"text":{"Chap_7.html":{},"Chap_7.html#power-spectral-density_1":{}},"title":{}}],["illustr",{"_index":37,"text":{"Chap_1.html":{},"Chap_1.html#at-the-movies":{},"Chap_1.html#how-to-use-this-ibook":{},"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#example-sound-of-distorted-music":{},"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_11.html#estimating-the-autocorrelation-function":{},"Chap_11.html#estimating-the-mean":{},"Chap_11.html#langevin-redux":{},"Chap_12.html":{},"Chap_12.html#problem-121":{},"Chap_12.html#problem-122":{},"Chap_12.html#problem-123":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_5.html":{},"Chap_5.html#example-pink-noise":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#one-step-further":{},"Chap_7.html#power-spectral-density":{},"Chap_7.html#tethered-particle-motion":{},"Chap_7.html#the-langevin-equation-a-case-study":{},"Chap_8.html":{},"Chap_8.html#example-cocktail-party-noise":{},"Chap_8.html#example-not-too-noisy":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{},"Chap_9.html":{},"Chap_9.html#laboratory-exercise-91":{},"Chap_9.html#the-matched-filter-as-an-autocorrelation":{}},"title":{}}],["imac",{"_index":3700,"text":{"info.html":{},"info.html#technical-details":{}},"title":{}}],["imag",{"_index":601,"text":{"Chap_10.html":{},"Chap_10.html#laboratory-exercise-102":{},"Chap_10.html#laboratory-exercise-103":{},"Chap_10.html#laboratory-exercise-104":{},"Chap_10.html#laboratory-exercise-105":{},"Chap_10.html#the-more-general-restoration-case-noise-distortion":{},"Chap_12.html":{},"Chap_12.html#laboratory-exercise-124":{},"Chap_4.html":{},"Chap_4.html#laboratory-exercise-42":{},"Chap_7.html":{},"Chap_7.html#one-step-further":{},"Chap_7.html#tethered-particle-motion":{},"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{},"Chap_9.html":{},"Chap_9.html#the-matched-filter":{}},"title":{}}],["imageri",{"_index":3357,"text":{"Chap_7.html":{},"Chap_7.html#one-step-further":{}},"title":{}}],["imagin",{"_index":2057,"text":{"Chap_4.html":{},"Chap_4.html#example-fair-chance":{}},"title":{}}],["imaginari",{"_index":113,"text":{"Chap_1.html":{},"Chap_1.html#highlighting":{}},"title":{}}],["imbal",{"_index":3331,"text":{"Chap_7.html":{},"Chap_7.html#power-spectral-density_2":{}},"title":{}}],["immedi",{"_index":2257,"text":{"Chap_4.html":{},"Chap_4.html#cross-covariance":{},"Chap_4.html#example-is-that-coin-fair":{},"Chap_4.html#problem-42":{},"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_9.html":{},"Chap_9.html#the-classic-example":{}},"title":{}}],["immun",{"_index":688,"text":{"Chap_10.html":{},"Chap_10.html#example-cleaning-up-our-act":{}},"title":{}}],["impati",{"_index":1583,"text":{"Chap_12.html":{},"Chap_12.html#laboratory-exercise-122":{}},"title":{}}],["implement",{"_index":86,"text":{"Chap_1.html":{},"Chap_1.html#how-to-use-this-ibook":{},"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_7.html":{},"Chap_7.html#why-this-case-study":{},"info.html":{},"info.html#tips-short-cuts":{}},"title":{}}],["impli",{"_index":567,"text":{"Chap_10.html":{},"Chap_10.html#classic-example-classic-result":{},"Chap_11.html":{},"Chap_11.html#trouble-in-paradise":{},"Chap_12.html":{},"Chap_12.html#other-windows":{},"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#example-is-that-coin-fair":{},"Chap_4.html#the-ergodic-process":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_7.html":{},"Chap_7.html#expected-value":{},"Chap_7.html#impulse-invariant-sampling":{},"Chap_7.html#power-spectral-density_1":{}},"title":{}}],["implic",{"_index":1528,"text":{"Chap_12.html":{},"Chap_12.html#problem-122":{},"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{}},"title":{}}],["implicit",{"_index":435,"text":{"Chap_10.html":{},"Chap_10.html#the-wiener-hopf-equation":{},"Chap_5.html":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{}},"title":{}}],["import",{"_index":728,"text":{"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_11.html":{},"Chap_11.html#langevin-redux":{},"Chap_12.html":{},"Chap_12.html#other-windows":{},"Chap_3.html":{},"Chap_3.html#problem-310":{},"Chap_3.html#the-basics":{},"Chap_3.html#what-is-a-random-signal":{},"Chap_4.html":{},"Chap_4.html#cross-covariance":{},"Chap_4.html#example-dice-money":{},"Chap_4.html#problem-44":{},"Chap_4.html#properties-of-averaging":{},"Chap_4.html#the-ergodic-process":{},"Chap_5.html":{},"Chap_5.html#correlations-and-memory":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_6.html":{},"Chap_6.html#filtering-of-stochastic-signals":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function_1":{},"Chap_7.html#descriptive-statistic-variance":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#impulse-invariant-sampling":{},"Chap_7.html#problem-78":{},"Chap_7.html#tethered-particle-motion":{},"Chap_7.html#the-langevin-position-equation":{},"Chap_7.html#why-this-case-study":{},"Chap_8.html":{},"Chap_8.html#example-filtering-noise":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{},"Chap_9.html":{},"Chap_9.html#the-matched-filter-as-an-autocorrelation":{},"info.html":{},"info.html#acknowledgments":{}},"title":{}}],["imposs",{"_index":2050,"text":{"Chap_4.html":{},"Chap_4.html#characterization-of-random-signals":{}},"title":{}}],["improv",{"_index":961,"text":{"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_13.html":{},"Chap_13.html#epilogue":{},"Chap_8.html":{},"Chap_8.html#problem-83":{}},"title":{}}],["impuls",{"_index":626,"text":{"Chap_10.html":{},"Chap_10.html#laboratory-exercise-101":{},"Chap_10.html#why-we-avoid-the-inverse-filter":{},"Chap_12.html":{},"Chap_12.html#other-windows":{},"Chap_12.html#problem-122":{},"Chap_12.html#windowed-observations":{},"Chap_3.html":{},"Chap_3.html#introduction":{},"Chap_3.html#problem-310":{},"Chap_3.html#problem-33":{},"Chap_4.html":{},"Chap_4.html#example-is-that-coin-fair":{},"Chap_4.html#laboratory-exercise-42":{},"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_6.html":{},"Chap_6.html#interpretation-of-the-convolution-result":{},"Chap_6.html#problem-62":{},"Chap_6.html#problem-65":{},"Chap_6.html#the-autocorrelation-function":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_6.html#the-mean":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function":{},"Chap_7.html#autocorrelation-function_1":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#expected-value":{},"Chap_7.html#from-t-to-n":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#impulse-invariant-sampling":{},"Chap_7.html#problem-72":{},"Chap_7.html#problem-73":{},"Chap_7.html#tethered-particle-motion":{},"Chap_7.html#the-langevin-position-equation":{},"Chap_7.html#the-langevin-velocity-equation":{},"Chap_9.html":{},"Chap_9.html#the-classic-example":{},"Chap_9.html#the-matched-filter":{}},"title":{"Chap_7.html#impulse-invariant-sampling":{}}}],["inadvis",{"_index":686,"text":{"Chap_10.html":{},"Chap_10.html#example-cleaning-up-our-act":{}},"title":{}}],["inc",{"_index":202,"text":{"Chap_1.html":{},"Chap_1.html#enhanced-experience":{},"Chap_7.html":{},"Chap_7.html#problem-711":{},"Chap_9.html":{},"Chap_9.html#laboratory-exercise-93":{}},"title":{}}],["includ",{"_index":224,"text":{"Chap_1.html":{},"Chap_1.html#enhanced-experience":{},"Chap_2.html":{},"Chap_2.html#prologue":{},"Chap_3.html":{},"Chap_3.html#problem-310":{},"Chap_3.html#what-is-a-random-signal":{},"Chap_4.html":{},"Chap_4.html#characterization-of-random-signals":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#laboratory-exercise-42":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function":{},"Chap_7.html#from-t-to-n":{},"Chap_7.html#power-spectral-density_1":{}},"title":{}}],["increas",{"_index":959,"text":{"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_11.html#estimating-the-mean":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_12.html#windowed-observations":{},"Chap_4.html":{},"Chap_4.html#correlation-the-workhorse":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{},"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#power-spectral-density_1":{},"Chap_8.html":{},"Chap_8.html#problem-83":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{}},"title":{}}],["increases\u2014for",{"_index":3508,"text":{"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{}},"title":{}}],["increment",{"_index":3524,"text":{"Chap_8.html":{},"Chap_8.html#problem-82":{}},"title":{}}],["inde",{"_index":1666,"text":{"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_6.html":{},"Chap_6.html#the-mean":{}},"title":{}}],["independ",{"_index":393,"text":{"Chap_10.html":{},"Chap_10.html#classic-example-classic-result":{},"Chap_10.html#expressing-the-mean-square-error":{},"Chap_10.html#problem-103":{},"Chap_10.html#the-more-general-restoration-case-noise-distortion":{},"Chap_10.html#the-wiener-hopf-equation":{},"Chap_11.html":{},"Chap_11.html#estimating-the-autocorrelation-function":{},"Chap_11.html#estimating-the-mean":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_11.html#langevin-redux":{},"Chap_11.html#maximum-likelihood-estimation":{},"Chap_11.html#problem-114":{},"Chap_11.html#trouble-in-paradise":{},"Chap_12.html":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_3.html#problem-37":{},"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#example-dice-money":{},"Chap_4.html#example-is-that-coin-fair":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_5.html":{},"Chap_5.html#example-delayed-effect":{},"Chap_6.html":{},"Chap_6.html#the-mean":{},"Chap_7.html":{},"Chap_7.html#expected-value":{},"Chap_7.html#how-big-is-big-how-small-is-small":{},"Chap_7.html#power-spectral-density_1":{},"Chap_8.html":{},"Chap_8.html#example-cocktail-party-noise":{},"Chap_8.html#example-filtering-noise":{},"Chap_8.html#problem-83":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{},"Chap_9.html":{},"Chap_9.html#using-cauchy-schwartz":{}},"title":{}}],["indetermin",{"_index":669,"text":{"Chap_10.html":{},"Chap_10.html#example-sound-of-distorted-music":{},"Chap_7.html":{},"Chap_7.html#expected-value":{}},"title":{}}],["index",{"_index":0,"text":{"Chap_4.html":{},"Chap_4.html#cross-covariance":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#example-average-experience":{},"Chap_4.html#example-dice-money":{},"Chap_4.html#problem-41":{},"info.html":{},"info.html#tips-short-cuts":{}},"title":{"index.html":{}}}],["indic",{"_index":133,"text":{"Chap_1.html":{},"Chap_1.html#getting-around":{},"Chap_11.html":{},"Chap_11.html#estimating-the-autocorrelation-function":{},"Chap_11.html#problem-119":{},"Chap_12.html":{},"Chap_12.html#the-periodogram-unbiased":{},"Chap_13.html":{},"Chap_13.html#epilogue":{},"Chap_4.html":{},"Chap_4.html#properties-of-averaging":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{},"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#one-step-further":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#tethered-particle-motion":{},"info.html":{},"info.html#copyright":{},"info.html#tips-short-cuts":{}},"title":{}}],["induc",{"_index":2851,"text":{"Chap_7.html":{},"Chap_7.html#impulse-invariant-sampling":{}},"title":{}}],["industri",{"_index":2746,"text":{"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{}},"title":{}}],["ineleg",{"_index":512,"text":{"Chap_10.html":{},"Chap_10.html#what-is-that-least-mean-square-error":{}},"title":{}}],["inequ",{"_index":1254,"text":{"Chap_11.html":{},"Chap_11.html#laboratory-exercise-113":{},"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_9.html":{},"Chap_9.html#laboratory-exercise-93":{},"Chap_9.html#using-cauchy-schwartz":{}},"title":{}}],["inevit",{"_index":1354,"text":{"Chap_12.html":{},"Chap_12.html#other-windows":{},"Chap_12.html#windowed-observations":{}},"title":{}}],["infer",{"_index":2159,"text":{"Chap_4.html":{},"Chap_4.html#example-dice-money":{},"Chap_7.html":{},"Chap_7.html#one-step-further":{}},"title":{}}],["infin",{"_index":634,"text":{"Chap_10.html":{},"Chap_10.html#example-cleaning-up-our-act":{},"Chap_10.html#example-sound-of-distorted-music":{},"Chap_10.html#why-we-avoid-the-inverse-filter":{},"Chap_5.html":{},"Chap_5.html#the-mechanics-of-correlations-redux":{}},"title":{}}],["infinit",{"_index":1322,"text":{"Chap_12.html":{},"Chap_12.html#other-windows":{},"Chap_12.html#windowed-observations":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_5.html":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_9.html":{},"Chap_9.html#laboratory-exercise-93":{}},"title":{}}],["influenc",{"_index":1059,"text":{"Chap_11.html":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_12.html":{},"Chap_12.html#windowed-observations":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{}},"title":{}}],["info@socraticsoftware.org",{"_index":3668,"text":{"info.html":{},"info.html#contact":{}},"title":{}}],["inform",{"_index":122,"text":{"Chap_1.html":{},"Chap_1.html#outside-this-device":{},"Chap_12.html":{},"Chap_12.html#problem-122":{},"Chap_4.html":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_6.html":{},"Chap_6.html#laboratory-exercise-63":{},"Chap_6.html#laboratory-exercise-68":{},"Chap_7.html":{},"Chap_7.html#descriptive-statistic-variance":{},"Chap_8.html":{},"Chap_8.html#problem-82":{},"Chap_8.html#snr-for-random-signals-in-the-presence-of-noise":{},"Chap_9.html":{},"Chap_9.html#problem-92":{},"info.html":{},"info.html#tips-short-cuts":{}},"title":{"info.html":{}}}],["information\u2014e.g",{"_index":1831,"text":{"Chap_3.html":{},"Chap_3.html#what-is-a-random-signal":{}},"title":{}}],["information\u2014nois",{"_index":1834,"text":{"Chap_3.html":{},"Chap_3.html#what-is-a-random-signal":{}},"title":{}}],["infring",{"_index":239,"text":{"Chap_1.html":{},"Chap_1.html#enhanced-experience":{}},"title":{}}],["infti",{"_index":318,"text":{"Chap_10.html":{},"Chap_10.html#correlation-returns":{},"Chap_10.html#expressing-the-mean-square-error":{},"Chap_10.html#problem-102":{},"Chap_10.html#the-restoration-case-noise":{},"Chap_10.html#the-wiener-hopf-equation":{},"Chap_10.html#using-the-least-mean-square-error-criterion":{},"Chap_10.html#what-is-that-least-mean-square-error":{},"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_11.html#estimating-the-mean":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_11.html#langevin-redux":{},"Chap_11.html#problem-119":{},"Chap_11.html#trouble-in-paradise":{},"Chap_12.html":{},"Chap_12.html#the-periodogram-unbiased":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_12.html#windowed-observations":{},"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_3.html#introduction":{},"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#describing-the-time-average":{},"Chap_4.html#other-averages":{},"Chap_4.html#properties-of-averaging":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#correlations-and-memory":{},"Chap_5.html#example-pink-noise":{},"Chap_5.html#example-white-noise":{},"Chap_5.html#problem-52":{},"Chap_5.html#problem-53":{},"Chap_5.html#problem-55":{},"Chap_5.html#problem-56":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_6.html":{},"Chap_6.html#filtering-of-stochastic-signals":{},"Chap_6.html#interpretation-of-the-convolution-result":{},"Chap_6.html#problem-61":{},"Chap_6.html#the-autocorrelation-function":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_6.html#the-mean":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function":{},"Chap_7.html#autocorrelation-function_1":{},"Chap_7.html#autocorrelation-function_2":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#expected-value":{},"Chap_7.html#impulse-invariant-sampling":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#problem-77":{},"Chap_7.html#the-langevin-velocity-equation":{},"Chap_9.html":{},"Chap_9.html#problem-92":{},"Chap_9.html#the-matched-filter-as-an-autocorrelation":{}},"title":{}}],["infty}\\leq",{"_index":1968,"text":{"Chap_3.html":{},"Chap_3.html#problem-34":{}},"title":{}}],["infty}^{+\\infty}(t",{"_index":2034,"text":{"Chap_3.html":{},"Chap_3.html#problem-310":{}},"title":{}}],["infty}^{+\\infty}ty(t)dt}{\\int\\limits_",{"_index":2030,"text":{"Chap_3.html":{},"Chap_3.html#problem-310":{}},"title":{}}],["infty}^{+\\infty}y(t)dt",{"_index":2031,"text":{"Chap_3.html":{},"Chap_3.html#problem-310":{}},"title":{}}],["infty}}^{+\\infty}\\lvert",{"_index":1993,"text":{"Chap_3.html":{},"Chap_3.html#problem-38":{}},"title":{}}],["infty}}^{+\\infty}x[n]",{"_index":1817,"text":{"Chap_3.html":{},"Chap_3.html#the-basics":{}},"title":{}}],["infty}}^{+\\infty}x_e[n]x_o[n",{"_index":1992,"text":{"Chap_3.html":{},"Chap_3.html#problem-38":{}},"title":{}}],["infty}}^{+\\infty}x_o[n",{"_index":1991,"text":{"Chap_3.html":{},"Chap_3.html#problem-38":{}},"title":{}}],["inher",{"_index":1761,"text":{"Chap_2.html":{},"Chap_2.html#prologue":{}},"title":{}}],["inject",{"_index":3352,"text":{"Chap_7.html":{},"Chap_7.html#one-step-further":{}},"title":{}}],["inlin",{"_index":3716,"text":{"info.html":{},"info.html#technical-details":{}},"title":{}}],["inner",{"_index":1617,"text":{"Chap_13.html":{},"Chap_13.html#appendix-i-mean-square-error-minimization":{},"Chap_9.html":{},"Chap_9.html#laboratory-exercise-93":{}},"title":{}}],["input",{"_index":573,"text":{"Chap_10.html":{},"Chap_10.html#classic-example-classic-result":{},"Chap_10.html#the-more-general-restoration-case-noise-distortion":{},"Chap_10.html#why-we-avoid-the-inverse-filter":{},"Chap_3.html":{},"Chap_3.html#introduction":{},"Chap_3.html#problem-310":{},"Chap_3.html#problem-33":{},"Chap_3.html#what-is-a-random-signal":{},"Chap_4.html":{},"Chap_4.html#problem-48":{},"Chap_6.html":{},"Chap_6.html#interpretation-of-the-convolution-result":{},"Chap_6.html#problem-61":{},"Chap_6.html#problem-62":{},"Chap_6.html#problem-64":{},"Chap_6.html#problem-65":{},"Chap_6.html#the-autocorrelation-function":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_6.html#the-mean":{},"Chap_7.html":{},"Chap_7.html#from-t-to-n":{},"Chap_7.html#impulse-invariant-sampling":{},"Chap_7.html#problem-73":{},"Chap_7.html#the-langevin-equation-a-case-study":{},"Chap_7.html#the-langevin-velocity-equation":{},"Chap_8.html":{},"Chap_8.html#example-filtering-noise":{},"Chap_9.html":{},"Chap_9.html#performance-in-the-presence-of-noise":{},"Chap_9.html#problem-91":{},"Chap_9.html#the-matched-filter":{}},"title":{}}],["insid",{"_index":1303,"text":{"Chap_12.html":{},"Chap_12.html#the-periodogram-unbiased":{},"Chap_4.html":{},"Chap_4.html#problem-42":{}},"title":{}}],["insight",{"_index":476,"text":{"Chap_10.html":{},"Chap_10.html#the-wiener-hopf-equation":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{},"Chap_7.html":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#tethered-particle-motion":{},"Chap_7.html#the-langevin-position-equation":{}},"title":{}}],["insist",{"_index":2855,"text":{"Chap_7.html":{},"Chap_7.html#impulse-invariant-sampling":{}},"title":{}}],["instanc",{"_index":2103,"text":{"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#example-dice-money":{},"Chap_4.html#example-is-that-coin-fair":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{}},"title":{}}],["instant",{"_index":1888,"text":{"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_4.html":{},"Chap_4.html#characterization-of-random-signals":{},"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_8.html":{},"Chap_8.html#snr-for-deterministic-signals-in-the-presence-of-noise":{}},"title":{}}],["instantan",{"_index":2689,"text":{"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{}},"title":{}}],["instead",{"_index":389,"text":{"Chap_10.html":{},"Chap_10.html#expressing-the-mean-square-error":{},"Chap_10.html#the-wiener-hopf-equation":{},"Chap_11.html":{},"Chap_11.html#aspects-of-estimation":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_11.html#trouble-in-paradise":{},"Chap_12.html":{},"Chap_12.html#problem-122":{},"Chap_12.html#the-periodogram-unbiased":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_12.html#windowed-observations":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_3.html#problem-310":{},"Chap_4.html":{},"Chap_4.html#cross-covariance":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#example-fair-chance":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_5.html":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"info.html":{},"info.html#tips-short-cuts":{}},"title":{}}],["institut",{"_index":1718,"text":{"Chap_13.html":{},"Chap_13.html#epilogue":{},"Chap_4.html":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"info.html":{},"info.html#cover":{},"info.html#weather-data":{}},"title":{}}],["instruct",{"_index":2698,"text":{"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#power-spectral-density_1":{},"Chap_9.html":{},"Chap_9.html#performance-in-the-presence-of-noise":{}},"title":{}}],["insuffici",{"_index":2917,"text":{"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{}},"title":{}}],["int",{"_index":1671,"text":{"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_13.html#epilogue":{},"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{}},"title":{}}],["int\\limits_",{"_index":500,"text":{"Chap_10.html":{},"Chap_10.html#problem-102":{},"Chap_10.html#what-is-that-least-mean-square-error":{},"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#example-dice-money":{},"Chap_4.html#other-averages":{},"Chap_4.html#properties-of-averaging":{},"Chap_5.html":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_8.html":{},"Chap_8.html#example-cocktail-party-noise":{},"Chap_9.html":{},"Chap_9.html#example-matching-your-filter":{},"Chap_9.html#setting-up-the-problem":{},"Chap_9.html#using-cauchy-schwartz":{}},"title":{}}],["int\\limits_a^b",{"_index":3565,"text":{"Chap_9.html":{},"Chap_9.html#using-cauchy-schwartz":{}},"title":{}}],["integ",{"_index":1247,"text":{"Chap_11.html":{},"Chap_11.html#laboratory-exercise-113":{},"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#example-dice-money":{},"Chap_4.html#problem-41":{},"Chap_7.html":{},"Chap_7.html#problem-72":{}},"title":{}}],["integr",{"_index":1654,"text":{"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_13.html#epilogue":{},"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#laboratory-exercise-42":{},"Chap_5.html":{},"Chap_5.html#fourier-description-of-correlation-functions":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_6.html":{},"Chap_6.html#problem-61":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{}},"title":{}}],["intend",{"_index":57,"text":{"Chap_1.html":{},"Chap_1.html#how-to-use-this-ibook":{},"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_3.html":{},"Chap_3.html#problem-34":{},"info.html":{},"info.html#musical-data":{}},"title":{}}],["intens",{"_index":3510,"text":{"Chap_8.html":{},"Chap_8.html#problem-83":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{}},"title":{}}],["intent",{"_index":2809,"text":{"Chap_7.html":{},"Chap_7.html#the-langevin-equation-a-case-study":{}},"title":{}}],["intention",{"_index":1477,"text":{"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{}},"title":{}}],["interact",{"_index":46,"text":{"Chap_1.html":{},"Chap_1.html#how-to-use-this-ibook":{},"Chap_7.html":{},"Chap_7.html#one-step-further":{},"Chap_7.html#problem-711":{}},"title":{}}],["interchang",{"_index":2501,"text":{"Chap_5.html":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{}},"title":{}}],["interest",{"_index":647,"text":{"Chap_10.html":{},"Chap_10.html#example-sound-of-distorted-music":{},"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{}},"title":{}}],["interfac",{"_index":74,"text":{"Chap_1.html":{},"Chap_1.html#how-to-use-this-ibook":{}},"title":{}}],["intern",{"_index":41,"text":{"Chap_1.html":{},"Chap_1.html#how-to-use-this-ibook":{},"info.html":{},"info.html#copyright":{}},"title":{}}],["internet",{"_index":22,"text":{"Chap_1.html":{},"Chap_1.html#how-to-use-this-ibook":{},"Chap_5.html":{},"Chap_5.html#the-mechanics-of-correlations-redux":{}},"title":{}}],["interpret",{"_index":2623,"text":{"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_7.html":{},"Chap_7.html#power-spectral-density_1":{},"Chap_9.html":{},"Chap_9.html#example-matching-your-filter":{},"Chap_9.html#laboratory-exercise-93":{}},"title":{"Chap_6.html#interpretation-of-the-convolution-result":{}}}],["intersci",{"_index":1252,"text":{"Chap_11.html":{},"Chap_11.html#laboratory-exercise-113":{}},"title":{}}],["intersect",{"_index":592,"text":{"Chap_10.html":{},"Chap_10.html#classic-example-classic-result":{}},"title":{}}],["interv",{"_index":448,"text":{"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#example-cleaning-up-our-act":{},"Chap_10.html#the-wiener-hopf-equation":{},"Chap_10.html#why-we-avoid-the-inverse-filter":{},"Chap_11.html":{},"Chap_11.html#problem-114":{},"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#problem-122":{},"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_3.html":{},"Chap_3.html#problem-32":{},"Chap_3.html#problem-35":{},"Chap_4.html":{},"Chap_4.html#describing-the-time-average":{},"Chap_4.html#problem-42":{},"Chap_4.html#the-ergodic-process":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#descriptive-statistic-variance":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#how-big-is-big-how-small-is-small":{},"Chap_7.html#impulse-invariant-sampling":{},"Chap_7.html#one-step-further":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#problem-72":{},"Chap_7.html#problem-79":{},"Chap_8.html":{},"Chap_8.html#example-not-too-noisy":{}},"title":{}}],["intract",{"_index":908,"text":{"Chap_11.html":{},"Chap_11.html#example-estimating-the-poisson-rate":{},"Chap_5.html":{},"Chap_5.html#a-digression":{}},"title":{}}],["intrins",{"_index":3496,"text":{"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{}},"title":{}}],["introduc",{"_index":462,"text":{"Chap_10.html":{},"Chap_10.html#the-wiener-hopf-equation":{},"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_12.html":{},"Chap_12.html#windowed-observations":{},"Chap_2.html":{},"Chap_2.html#prologue":{},"Chap_4.html":{},"Chap_4.html#cross-correlation":{},"Chap_4.html#properties-of-averaging":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_7.html":{},"Chap_7.html#impulse-invariant-sampling":{},"Chap_7.html#tethered-particle-motion":{}},"title":{}}],["introduct",{"_index":822,"text":{"Chap_11.html":{},"Chap_11.html#aspects-of-estimation":{},"Chap_3.html":{},"Chap_3.html#introduction":{}},"title":{"Chap_3.html":{},"Chap_3.html#introduction":{}}}],["introductori",{"_index":1807,"text":{"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_3.html#introduction":{},"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{}},"title":{}}],["intuit",{"_index":991,"text":{"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_11.html#problem-119":{},"Chap_7.html":{},"Chap_7.html#expected-value":{}},"title":{}}],["invari",{"_index":1795,"text":{"Chap_2.html":{},"Chap_2.html#problem-21":{},"Chap_3.html":{},"Chap_3.html#introduction":{},"Chap_3.html#problem-310":{},"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_5.html":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_6.html":{},"Chap_6.html#filtering-of-stochastic-signals":{},"Chap_7.html":{},"Chap_7.html#from-t-to-n":{},"Chap_7.html#impulse-invariant-sampling":{},"Chap_7.html#problem-73":{},"Chap_7.html#the-langevin-position-equation":{},"Chap_7.html#the-langevin-velocity-equation":{}},"title":{"Chap_7.html#impulse-invariant-sampling":{}}}],["invers",{"_index":612,"text":{"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#example-cleaning-up-our-act":{},"Chap_10.html#example-sound-of-distorted-music":{},"Chap_10.html#why-we-avoid-the-inverse-filter":{},"Chap_3.html":{},"Chap_3.html#the-basics":{},"Chap_5.html":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_9.html":{},"Chap_9.html#the-classic-example":{}},"title":{"Chap_10.html#why-we-avoid-the-inverse-filter":{}}}],["investig",{"_index":1301,"text":{"Chap_12.html":{},"Chap_12.html#the-periodogram-unbiased":{}},"title":{}}],["invok",{"_index":2235,"text":{"Chap_4.html":{},"Chap_4.html#the-mechanics-of-correlations":{}},"title":{}}],["involv",{"_index":68,"text":{"Chap_1.html":{},"Chap_1.html#how-to-use-this-ibook":{},"Chap_10.html":{},"Chap_10.html#problem-104":{},"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_11.html#laboratory-exercise-113":{},"Chap_11.html#problem-119":{},"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_2.html":{},"Chap_2.html#prologue":{},"Chap_3.html":{},"Chap_3.html#problem-36":{},"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#problem-42":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_7.html":{},"Chap_7.html#expected-value":{},"Chap_7.html#tethered-particle-motion":{},"Chap_9.html":{},"Chap_9.html#the-matched-filter":{},"Chap_9.html#the-matched-filter-as-an-autocorrelation":{}},"title":{}}],["ionic",{"_index":3134,"text":{"Chap_7.html":{},"Chap_7.html#tethered-particle-motion":{}},"title":{}}],["ipad",{"_index":23,"text":{"Chap_1.html":{},"Chap_1.html#enhanced-experience":{},"Chap_1.html#how-to-use-this-ibook":{}},"title":{}}],["irwin",{"_index":1782,"text":{"Chap_2.html":{},"Chap_2.html#prologue":{}},"title":{}}],["is\\,\\,real",{"_index":2515,"text":{"Chap_5.html":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{}},"title":{}}],["isbn",{"_index":3742,"text":{"info.html":{},"info.html#registration":{}},"title":{}}],["isotop",{"_index":2312,"text":{"Chap_4.html":{},"Chap_4.html#problem-42":{}},"title":{}}],["israel",{"_index":3398,"text":{"Chap_7.html":{},"Chap_7.html#problem-711":{}},"title":{}}],["issu",{"_index":819,"text":{"Chap_11.html":{},"Chap_11.html#aspects-of-estimation":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_12.html":{},"Chap_12.html#the-periodogram-unbiased":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_4.html":{},"Chap_4.html#correlation-the-workhorse":{},"Chap_4.html#properties-of-averaging":{},"Chap_4.html#the-ergodic-process":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#laboratory-exercise-51":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#impulse-invariant-sampling":{},"Chap_7.html#power-spectral-density_1":{},"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{}},"title":{}}],["is\u2014on",{"_index":2937,"text":{"Chap_7.html":{},"Chap_7.html#the-langevin-velocity-equation":{}},"title":{}}],["itself",{"_index":262,"text":{"Chap_1.html":{},"Chap_1.html#enhanced-experience":{},"Chap_11.html":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_12.html":{},"Chap_12.html#spectral-estimation":{},"Chap_6.html":{},"Chap_6.html#laboratory-exercise-67":{}},"title":{}}],["iv",{"_index":1526,"text":{"Chap_12.html":{},"Chap_12.html#problem-122":{}},"title":{}}],["j",{"_index":1979,"text":{"Chap_3.html":{},"Chap_3.html#problem-37":{},"Chap_4.html":{},"Chap_4.html#laboratory-exercise-42":{},"Chap_5.html":{},"Chap_5.html#laboratory-exercise-51":{},"Chap_7.html":{},"Chap_7.html#problem-711":{},"Chap_9.html":{},"Chap_9.html#laboratory-exercise-93":{},"Chap_9.html#problem-91":{}},"title":{}}],["j/k",{"_index":3015,"text":{"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{}},"title":{}}],["j\\omega",{"_index":1293,"text":{"Chap_12.html":{},"Chap_12.html#spectral-estimation":{},"Chap_12.html#the-periodogram-unbiased":{},"Chap_12.html#windowed-observations":{},"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#example-pink-noise":{},"Chap_5.html#example-white-noise":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_8.html":{},"Chap_8.html#example-filtering-noise":{},"Chap_9.html":{},"Chap_9.html#the-classic-example":{},"Chap_9.html#using-cauchy-schwartz":{}},"title":{}}],["jacob",{"_index":3625,"text":{"Chap_9.html":{},"Chap_9.html#laboratory-exercise-93":{},"Chap_9.html#problem-92":{}},"title":{}}],["jan",{"_index":2727,"text":{"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{}},"title":{}}],["januari",{"_index":2539,"text":{"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{},"info.html":{},"info.html#cover":{}},"title":{}}],["javascript",{"_index":3699,"text":{"info.html":{},"info.html#technical-details":{}},"title":{}}],["jenkin",{"_index":1044,"text":{"Chap_11.html":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_11.html#laboratory-exercise-113":{},"Chap_12.html":{},"Chap_12.html#laboratory-exercise-124":{},"Chap_12.html#the-periodogram-what-about-convergence":{}},"title":{}}],["jersey",{"_index":781,"text":{"Chap_10.html":{},"Chap_10.html#laboratory-exercise-105":{},"Chap_11.html":{},"Chap_11.html#laboratory-exercise-113":{},"Chap_3.html":{},"Chap_3.html#problem-310":{},"Chap_4.html":{},"Chap_4.html#laboratory-exercise-42":{},"Chap_5.html":{},"Chap_5.html#laboratory-exercise-51":{},"Chap_7.html":{},"Chap_7.html#problem-711":{}},"title":{}}],["jo",{"_index":3683,"text":{"info.html":{},"info.html#acknowledgments":{}},"title":{}}],["john",{"_index":788,"text":{"Chap_10.html":{},"Chap_10.html#laboratory-exercise-105":{},"Chap_13.html":{},"Chap_13.html#epilogue":{},"Chap_7.html":{},"Chap_7.html#problem-711":{},"Chap_9.html":{},"Chap_9.html#laboratory-exercise-93":{}},"title":{}}],["joint",{"_index":865,"text":{"Chap_11.html":{},"Chap_11.html#maximum-likelihood-estimation":{},"Chap_4.html":{},"Chap_4.html#autocorrelation":{},"Chap_4.html#correlation-the-workhorse":{},"Chap_4.html#example-dice-money":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_5.html":{},"Chap_5.html#the-mechanics-of-correlations-redux":{}},"title":{}}],["journal",{"_index":1257,"text":{"Chap_11.html":{},"Chap_11.html#laboratory-exercise-113":{},"Chap_7.html":{},"Chap_7.html#problem-711":{},"Chap_8.html":{},"Chap_8.html#problem-83":{}},"title":{}}],["juli",{"_index":1730,"text":{"Chap_13.html":{},"Chap_13.html#epilogue":{}},"title":{}}],["jump",{"_index":140,"text":{"Chap_1.html":{},"Chap_1.html#getting-around":{}},"title":{}}],["junctur",{"_index":3232,"text":{"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{}},"title":{}}],["justif",{"_index":3447,"text":{"Chap_8.html":{},"Chap_8.html#snr-for-random-signals-in-the-presence-of-noise":{}},"title":{}}],["justifi",{"_index":757,"text":{"Chap_10.html":{},"Chap_10.html#laboratory-exercise-105":{},"Chap_10.html#problem-104":{},"Chap_4.html":{},"Chap_4.html#problem-49":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#problem-71":{}},"title":{}}],["j}3n}\\qquad",{"_index":1939,"text":{"Chap_3.html":{},"Chap_3.html#problem-33":{}},"title":{}}],["j}\\omega",{"_index":1818,"text":{"Chap_3.html":{},"Chap_3.html#the-basics":{}},"title":{}}],["j}\\omega_{0}n",{"_index":1906,"text":{"Chap_3.html":{},"Chap_3.html#problem-31":{}},"title":{}}],["j}\\omega_{0}n}\\sin(\\omega_{0}n",{"_index":1908,"text":{"Chap_3.html":{},"Chap_3.html#problem-31":{}},"title":{}}],["j}\\omega}\\right",{"_index":1927,"text":{"Chap_3.html":{},"Chap_3.html#problem-32":{}},"title":{}}],["j}\\omega}\\right)\\left(1",{"_index":1925,"text":{"Chap_3.html":{},"Chap_3.html#problem-32":{}},"title":{}}],["j}\\omega}}\\right",{"_index":2003,"text":{"Chap_3.html":{},"Chap_3.html#problem-39":{}},"title":{}}],["k",{"_index":409,"text":{"Chap_10.html":{},"Chap_10.html#classic-example-classic-result":{},"Chap_10.html#correlation-returns":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#laboratory-exercise-105":{},"Chap_10.html#the-more-general-restoration-case-noise-distortion":{},"Chap_10.html#the-wiener-hopf-equation":{},"Chap_10.html#what-is-that-least-mean-square-error":{},"Chap_11.html":{},"Chap_11.html#aspects-of-estimation":{},"Chap_11.html#estimating-the-autocorrelation-function":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_11.html#langevin-redux":{},"Chap_11.html#problem-1110":{},"Chap_11.html#problem-117":{},"Chap_11.html#problem-118":{},"Chap_11.html#problem-119":{},"Chap_11.html#trouble-in-paradise":{},"Chap_12.html":{},"Chap_12.html#spectral-estimation":{},"Chap_12.html#the-periodogram-unbiased":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_12.html#windowed-observations":{},"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_3.html":{},"Chap_3.html#introduction":{},"Chap_4.html":{},"Chap_4.html#autocorrelation":{},"Chap_4.html#cross-covariance":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#describing-the-time-average":{},"Chap_4.html#example-dice-money":{},"Chap_4.html#example-is-that-coin-fair":{},"Chap_4.html#the-ergodic-process":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#correlations-and-memory":{},"Chap_5.html#correlations-simple-and-complex":{},"Chap_5.html#example-delayed-effect":{},"Chap_5.html#example-pink-noise":{},"Chap_5.html#example-white-noise":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_5.html#problem-52":{},"Chap_5.html#problem-55":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{},"Chap_6.html#filtering-of-stochastic-signals":{},"Chap_6.html#interpretation-of-the-convolution-result":{},"Chap_6.html#laboratory-exercise-63":{},"Chap_6.html#problem-61":{},"Chap_6.html#problem-62":{},"Chap_6.html#problem-63":{},"Chap_6.html#problem-64":{},"Chap_6.html#problem-66":{},"Chap_6.html#the-autocorrelation-function":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_6.html#the-mean":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function":{},"Chap_7.html#autocorrelation-function_1":{},"Chap_7.html#autocorrelation-function_2":{},"Chap_7.html#descriptive-statistic-variance":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#expected-value":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#one-step-further":{},"Chap_7.html#power-spectral-density":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#power-spectral-density_2":{},"Chap_7.html#problem-72":{},"Chap_7.html#problem-78":{},"Chap_7.html#tethered-particle-motion":{},"Chap_7.html#the-langevin-velocity-equation":{},"Chap_7.html#why-this-case-study":{},"Chap_8.html":{},"Chap_8.html#example-filtering-noise":{},"Chap_8.html#problem-81":{},"Chap_8.html#problem-82":{},"Chap_8.html#problem-83":{},"Chap_8.html#snr-for-random-signals-in-the-presence-of-noise":{},"Chap_9.html":{},"Chap_9.html#the-matched-filter-as-an-autocorrelation":{}},"title":{}}],["k)dt",{"_index":1663,"text":{"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{}},"title":{}}],["k/\\lambda",{"_index":3328,"text":{"Chap_7.html":{},"Chap_7.html#power-spectral-density_2":{},"Chap_7.html#problem-710":{}},"title":{}}],["k/m",{"_index":3187,"text":{"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#tethered-particle-motion":{}},"title":{}}],["k\\frac{{\\delta",{"_index":3519,"text":{"Chap_8.html":{},"Chap_8.html#problem-82":{}},"title":{}}],["k\\left",{"_index":2557,"text":{"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{}},"title":{}}],["k\\rbrack",{"_index":1018,"text":{"Chap_11.html":{},"Chap_11.html#estimating-the-autocorrelation-function":{},"Chap_11.html#langevin-redux":{},"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{}},"title":{}}],["k\\rbrack{\\varphi",{"_index":1087,"text":{"Chap_11.html":{},"Chap_11.html#langevin-redux":{}},"title":{}}],["k]\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\left",{"_index":1057,"text":{"Chap_11.html":{},"Chap_11.html#how-good-is-our-estimator":{}},"title":{}}],["k]\\,{y^*}[m",{"_index":2407,"text":{"Chap_5.html":{},"Chap_5.html#correlations-simple-and-complex":{}},"title":{}}],["k]h[k",{"_index":385,"text":{"Chap_10.html":{},"Chap_10.html#expressing-the-mean-square-error":{}},"title":{}}],["k]h[n",{"_index":610,"text":{"Chap_10.html":{},"Chap_10.html#the-more-general-restoration-case-noise-distortion":{},"Chap_3.html":{},"Chap_3.html#introduction":{}},"title":{}}],["k]r[n",{"_index":428,"text":{"Chap_10.html":{},"Chap_10.html#correlation-returns":{}},"title":{}}],["k]{\\varphi",{"_index":1039,"text":{"Chap_11.html":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_11.html#langevin-redux":{},"Chap_11.html#problem-1110":{},"Chap_11.html#problem-119":{}},"title":{}}],["k]{e",{"_index":2496,"text":{"Chap_5.html":{},"Chap_5.html#example-white-noise":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{}},"title":{}}],["k]}&{\\left",{"_index":2512,"text":{"Chap_5.html":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{}},"title":{}}],["k_b",{"_index":3012,"text":{"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#one-step-further":{}},"title":{}}],["k_b}\\psi",{"_index":3010,"text":{"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#one-step-further":{}},"title":{}}],["keep",{"_index":1229,"text":{"Chap_11.html":{},"Chap_11.html#problem-119":{}},"title":{}}],["kern",{"_index":1876,"text":{"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_4.html":{},"Chap_4.html#the-ergodic-process":{}},"title":{}}],["key",{"_index":396,"text":{"Chap_10.html":{},"Chap_10.html#expressing-the-mean-square-error":{}},"title":{}}],["keyboard",{"_index":71,"text":{"Chap_1.html":{},"Chap_1.html#how-to-use-this-ibook":{},"Chap_12.html":{},"Chap_12.html#problem-123":{},"info.html":{},"info.html#tips-short-cuts":{}},"title":{}}],["kg",{"_index":3382,"text":{"Chap_7.html":{},"Chap_7.html#problem-78":{}},"title":{}}],["kg/",{"_index":3213,"text":{"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{}},"title":{}}],["khinchin",{"_index":2492,"text":{"Chap_5.html":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{}},"title":{}}],["khz",{"_index":755,"text":{"Chap_10.html":{},"Chap_10.html#problem-104":{},"Chap_12.html":{},"Chap_12.html#problem-122":{}},"title":{}}],["kilogram",{"_index":1758,"text":{"Chap_2.html":{},"Chap_2.html#prologue":{},"Chap_7.html":{},"Chap_7.html#problem-78":{}},"title":{}}],["kinet",{"_index":3009,"text":{"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{}},"title":{}}],["knmi",{"_index":2198,"text":{"Chap_4.html":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"info.html":{},"info.html#cover":{},"info.html#weather-data":{}},"title":{}}],["know",{"_index":1034,"text":{"Chap_11.html":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_11.html#problem-116":{},"Chap_12.html":{},"Chap_12.html#problem-122":{},"Chap_12.html#windowed-observations":{},"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_4.html":{},"Chap_4.html#correlation-the-workhorse":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#tethered-particle-motion":{},"Chap_8.html":{},"Chap_8.html#characterizing-signal-to-noise-ratios":{},"Chap_8.html#problem-82":{},"Chap_8.html#snr-for-random-signals-in-the-presence-of-noise":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{},"Chap_9.html":{},"Chap_9.html#the-matched-filter":{}},"title":{}}],["knowledg",{"_index":731,"text":{"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#laboratory-exercise-105":{},"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_3.html":{},"Chap_3.html#introduction":{},"Chap_4.html":{},"Chap_4.html#correlation-the-workhorse":{},"Chap_4.html#example-fair-chance":{},"Chap_6.html":{},"Chap_6.html#the-mean":{},"Chap_7.html":{},"Chap_7.html#power-spectral-density_1":{}},"title":{}}],["known",{"_index":288,"text":{"Chap_10.html":{},"Chap_10.html#the-more-general-restoration-case-noise-distortion":{},"Chap_10.html#the-wiener-filter":{},"Chap_10.html#the-wiener-hopf-equation":{},"Chap_11.html":{},"Chap_11.html#problem-112":{},"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#other-windows":{},"Chap_12.html#problem-123":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_2.html":{},"Chap_2.html#problem-21":{},"Chap_2.html#prologue":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_3.html#introduction":{},"Chap_3.html#what-is-a-random-signal":{},"Chap_4.html":{},"Chap_4.html#describing-the-time-average":{},"Chap_4.html#laboratory-exercise-41":{},"Chap_4.html#properties-of-averaging":{},"Chap_4.html#the-ergodic-process":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_6.html":{},"Chap_6.html#problem-65":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_7.html":{},"Chap_7.html#tethered-particle-motion":{},"Chap_8.html":{},"Chap_8.html#example-filtering-noise":{},"Chap_8.html#example-not-too-noisy":{},"Chap_8.html#snr-for-deterministic-signals-in-the-presence-of-noise":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{},"Chap_9.html":{},"Chap_9.html#the-matched-filter":{}},"title":{}}],["kx",{"_index":3166,"text":{"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#tethered-particle-motion":{}},"title":{}}],["kx(t",{"_index":3275,"text":{"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period_1":{}},"title":{}}],["kx}_{hookean\\,forc",{"_index":3172,"text":{"Chap_7.html":{},"Chap_7.html#tethered-particle-motion":{}},"title":{}}],["k{e_x",{"_index":3017,"text":{"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{}},"title":{}}],["k{t_",{"_index":3348,"text":{"Chap_7.html":{},"Chap_7.html#one-step-further":{}},"title":{}}],["k})u[n]u[n",{"_index":3307,"text":{"Chap_7.html":{},"Chap_7.html#autocorrelation-function_2":{}},"title":{}}],["k}}d\\omega",{"_index":2490,"text":{"Chap_5.html":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{}},"title":{}}],["k}}{\\rho",{"_index":1099,"text":{"Chap_11.html":{},"Chap_11.html#langevin-redux":{}},"title":{}}],["k}}{e",{"_index":2534,"text":{"Chap_5.html":{},"Chap_5.html#example-pink-noise":{}},"title":{}}],["l",{"_index":2475,"text":{"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#problem-711":{},"Chap_7.html#tethered-particle-motion":{}},"title":{}}],["l(\\theta",{"_index":900,"text":{"Chap_11.html":{},"Chap_11.html#example-estimating-the-poisson-rate":{}},"title":{}}],["l^2",{"_index":1655,"text":{"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{}},"title":{}}],["label",{"_index":2018,"text":{"Chap_3.html":{},"Chap_3.html#problem-310":{},"Chap_6.html":{},"Chap_6.html#problem-61":{},"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{}},"title":{}}],["laboratori",{"_index":47,"text":{"Chap_1.html":{},"Chap_1.html#at-the-movies":{},"Chap_1.html#getting-around":{},"Chap_1.html#how-to-use-this-ibook":{},"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#problem-104":{},"Chap_11.html":{},"Chap_12.html":{},"Chap_12.html#problem-122":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_4.html":{},"Chap_4.html#example-fair-chance":{},"Chap_5.html":{},"Chap_6.html":{},"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_9.html":{},"Chap_9.html#problem-91":{},"info.html":{},"info.html#tips-short-cuts":{}},"title":{"Chap_10.html#laboratory-exercise-101":{},"Chap_10.html#laboratory-exercise-102":{},"Chap_10.html#laboratory-exercise-103":{},"Chap_10.html#laboratory-exercise-104":{},"Chap_10.html#laboratory-exercise-105":{},"Chap_10.html#laboratory-exercises":{},"Chap_11.html#laboratory-exercise-111":{},"Chap_11.html#laboratory-exercise-112":{},"Chap_11.html#laboratory-exercise-113":{},"Chap_11.html#laboratory-exercises":{},"Chap_12.html#laboratory-exercise-121":{},"Chap_12.html#laboratory-exercise-122":{},"Chap_12.html#laboratory-exercise-123":{},"Chap_12.html#laboratory-exercise-124":{},"Chap_12.html#laboratory-exercises":{},"Chap_4.html#laboratory-exercise-41":{},"Chap_4.html#laboratory-exercise-42":{},"Chap_4.html#laboratory-exercises":{},"Chap_5.html#laboratory-exercise-51":{},"Chap_5.html#laboratory-exercises":{},"Chap_6.html#laboratory-exercise-61":{},"Chap_6.html#laboratory-exercise-62":{},"Chap_6.html#laboratory-exercise-63":{},"Chap_6.html#laboratory-exercise-64":{},"Chap_6.html#laboratory-exercise-65":{},"Chap_6.html#laboratory-exercise-66":{},"Chap_6.html#laboratory-exercise-67":{},"Chap_6.html#laboratory-exercise-68":{},"Chap_6.html#laboratory-exercises":{},"Chap_9.html#laboratory-exercise-91":{},"Chap_9.html#laboratory-exercise-92":{},"Chap_9.html#laboratory-exercise-93":{},"Chap_9.html#laboratory-exercises":{}}}],["lack",{"_index":1375,"text":{"Chap_12.html":{},"Chap_12.html#the-periodogram-what-about-convergence":{}},"title":{}}],["lacuna",{"_index":194,"text":{"Chap_1.html":{},"Chap_1.html#enhanced-experience":{}},"title":{}}],["lambda",{"_index":888,"text":{"Chap_11.html":{},"Chap_11.html#example-estimating-the-poisson-rate":{},"Chap_11.html#langevin-redux":{},"Chap_11.html#problem-114":{},"Chap_5.html":{},"Chap_5.html#laboratory-exercise-51":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function":{},"Chap_7.html#autocorrelation-function_2":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#expected-value":{},"Chap_7.html#expected-value_1":{},"Chap_7.html#how-big-is-big-how-small-is-small":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#impulse-invariant-sampling":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#power-spectral-density_2":{},"Chap_7.html#problem-710":{},"Chap_7.html#tethered-particle-motion":{},"Chap_7.html#the-langevin-equation-a-case-study":{},"Chap_7.html#the-langevin-position-equation":{},"Chap_7.html#the-langevin-velocity-equation":{},"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{}},"title":{}}],["lambda}}}{n!}\\qquad",{"_index":1964,"text":{"Chap_3.html":{},"Chap_3.html#problem-34":{}},"title":{}}],["land",{"_index":984,"text":{"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{}},"title":{}}],["langevin",{"_index":1060,"text":{"Chap_11.html":{},"Chap_11.html#langevin-redux":{},"Chap_11.html#problem-119":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function":{},"Chap_7.html#autocorrelation-function_1":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#descriptive-statistic-variance":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#expected-value":{},"Chap_7.html#how-big-is-big-how-small-is-small":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#impulse-invariant-sampling":{},"Chap_7.html#power-spectral-density":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#power-spectral-density_2":{},"Chap_7.html#problem-79":{},"Chap_7.html#tethered-particle-motion":{},"Chap_7.html#the-langevin-equation-a-case-study":{},"Chap_7.html#the-langevin-position-equation":{},"Chap_7.html#why-this-case-study":{}},"title":{"Chap_11.html#langevin-redux":{},"Chap_7.html":{},"Chap_7.html#the-langevin-equation-a-case-study":{},"Chap_7.html#the-langevin-position-equation":{},"Chap_7.html#the-langevin-velocity-equation":{}}}],["langl",{"_index":2988,"text":{"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#power-spectral-density_1":{}},"title":{}}],["laplac",{"_index":3371,"text":{"Chap_7.html":{},"Chap_7.html#problem-72":{}},"title":{}}],["laptop",{"_index":28,"text":{"Chap_1.html":{},"Chap_1.html#how-to-use-this-ibook":{}},"title":{}}],["larg",{"_index":932,"text":{"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_11.html#estimating-the-mean":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_11.html#trouble-in-paradise":{},"Chap_12.html":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_4.html":{},"Chap_4.html#example-fair-chance":{},"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#tethered-particle-motion":{}},"title":{}}],["larger",{"_index":1351,"text":{"Chap_12.html":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_12.html#windowed-observations":{},"Chap_5.html":{},"Chap_5.html#correlations-and-memory":{},"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#problem-710":{}},"title":{}}],["largest",{"_index":3573,"text":{"Chap_9.html":{},"Chap_9.html#using-cauchy-schwartz":{}},"title":{}}],["last",{"_index":1315,"text":{"Chap_12.html":{},"Chap_12.html#other-windows":{},"Chap_12.html#the-periodogram-unbiased":{},"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_4.html":{},"Chap_4.html#example-is-that-coin-fair":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_6.html":{},"Chap_6.html#the-mean":{}},"title":{}}],["later",{"_index":1669,"text":{"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_4.html":{},"Chap_4.html#example-is-that-coin-fair":{},"Chap_4.html#properties-of-averaging":{},"Chap_5.html":{},"Chap_5.html#fourier-description-of-correlation-functions":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#one-step-further":{},"Chap_7.html#power-spectral-density":{}},"title":{}}],["later\u2014becom",{"_index":2487,"text":{"Chap_5.html":{},"Chap_5.html#a-digression":{}},"title":{}}],["latter",{"_index":1092,"text":{"Chap_11.html":{},"Chap_11.html#langevin-redux":{},"Chap_12.html":{},"Chap_12.html#other-windows":{},"Chap_7.html":{},"Chap_7.html#power-spectral-density":{},"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{}},"title":{}}],["launch",{"_index":3731,"text":{"info.html":{},"info.html#musical-data":{}},"title":{}}],["lauren",{"_index":182,"text":{"Chap_1.html":{},"Chap_1.html#at-the-movies":{}},"title":{}}],["law",{"_index":2877,"text":{"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small":{},"Chap_8.html":{},"Chap_8.html#problem-82":{},"Chap_8.html#problem-83":{},"info.html":{},"info.html#copyright":{}},"title":{}}],["ldot",{"_index":2109,"text":{"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#example-average-experience":{},"Chap_4.html#example-dice-money":{}},"title":{}}],["le",{"_index":464,"text":{"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#example-cleaning-up-our-act":{},"Chap_10.html#problem-104":{},"Chap_10.html#the-wiener-hopf-equation":{},"Chap_10.html#why-we-avoid-the-inverse-filter":{},"Chap_11.html":{},"Chap_11.html#langevin-redux":{},"Chap_11.html#problem-1110":{},"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#the-periodogram-unbiased":{},"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_3.html":{},"Chap_3.html#problem-32":{},"Chap_3.html#problem-39":{},"Chap_4.html":{},"Chap_4.html#problem-41":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#example-pink-noise":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_6.html":{},"Chap_6.html#problem-63":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_7.html":{},"Chap_7.html#power-spectral-density":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#power-spectral-density_2":{},"Chap_8.html":{},"Chap_8.html#problem-83":{},"Chap_9.html":{},"Chap_9.html#laboratory-exercise-93":{},"Chap_9.html#using-cauchy-schwartz":{}},"title":{}}],["lead",{"_index":608,"text":{"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#example-cleaning-up-our-act":{},"Chap_10.html#example-sound-of-distorted-music":{},"Chap_10.html#the-more-general-restoration-case-noise-distortion":{},"Chap_11.html":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_13.html":{},"Chap_13.html#appendix-i-mean-square-error-minimization":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#example-dice-money":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#problem-53":{},"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{},"Chap_6.html#problem-64":{},"Chap_7.html":{},"Chap_7.html#from-t-to-n":{},"Chap_7.html#impulse-invariant-sampling":{},"Chap_7.html#one-step-further":{},"Chap_7.html#power-spectral-density_2":{},"Chap_7.html#tethered-particle-motion":{},"Chap_8.html":{},"Chap_8.html#snr-for-random-signals-in-the-presence-of-noise":{},"Chap_9.html":{},"Chap_9.html#the-matched-filter":{}},"title":{}}],["learn",{"_index":8,"text":{"Chap_1.html":{},"Chap_1.html#at-the-movies":{},"Chap_13.html":{},"Chap_13.html#epilogue":{},"Chap_4.html":{},"Chap_4.html#problem-47":{},"Chap_9.html":{},"Chap_9.html#the-matched-filter":{}},"title":{}}],["leav",{"_index":1533,"text":{"Chap_12.html":{},"Chap_12.html#problem-122":{},"Chap_4.html":{},"Chap_4.html#auto-covariance":{},"Chap_4.html#properties-of-averaging":{}},"title":{}}],["lectur",{"_index":2373,"text":{"Chap_4.html":{},"Chap_4.html#laboratory-exercise-42":{},"Chap_7.html":{},"Chap_7.html#problem-711":{},"info.html":{},"info.html#acknowledgments":{}},"title":{}}],["led",{"_index":2948,"text":{"Chap_7.html":{},"Chap_7.html#power-spectral-density":{}},"title":{}}],["lee",{"_index":376,"text":{"Chap_10.html":{},"Chap_10.html#laboratory-exercise-105":{},"Chap_10.html#using-the-least-mean-square-error-criterion":{},"Chap_13.html":{},"Chap_13.html#epilogue":{}},"title":{}}],["left",{"_index":99,"text":{"Chap_1.html":{},"Chap_1.html#highlighting":{},"Chap_1.html#outside-this-device":{},"Chap_10.html":{},"Chap_10.html#classic-example-classic-result":{},"Chap_10.html#correlation-returns":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#example-cleaning-up-our-act":{},"Chap_10.html#expressing-the-mean-square-error":{},"Chap_10.html#laboratory-exercise-101":{},"Chap_10.html#laboratory-exercise-102":{},"Chap_10.html#laboratory-exercise-103":{},"Chap_10.html#laboratory-exercise-104":{},"Chap_10.html#laboratory-exercise-105":{},"Chap_10.html#using-the-least-mean-square-error-criterion":{},"Chap_10.html#what-is-that-least-mean-square-error":{},"Chap_11.html":{},"Chap_11.html#aspects-of-estimation":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_11.html#estimating-the-autocorrelation-function":{},"Chap_11.html#example-estimating-the-poisson-rate":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_11.html#laboratory-exercise-111":{},"Chap_11.html#laboratory-exercise-112":{},"Chap_11.html#laboratory-exercise-113":{},"Chap_11.html#langevin-redux":{},"Chap_11.html#problem-111":{},"Chap_11.html#problem-1110":{},"Chap_11.html#problem-112":{},"Chap_11.html#problem-114":{},"Chap_11.html#problem-115":{},"Chap_11.html#problem-116":{},"Chap_11.html#problem-117":{},"Chap_11.html#problem-119":{},"Chap_11.html#trouble-in-paradise":{},"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#laboratory-exercise-121":{},"Chap_12.html#laboratory-exercise-122":{},"Chap_12.html#laboratory-exercise-123":{},"Chap_12.html#laboratory-exercise-124":{},"Chap_12.html#problem-123":{},"Chap_12.html#the-periodogram-unbiased":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_12.html#windowed-observations":{},"Chap_13.html":{},"Chap_13.html#appendix-i-mean-square-error-minimization":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_13.html#epilogue":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_3.html#problem-35":{},"Chap_3.html#problem-37":{},"Chap_4.html":{},"Chap_4.html#auto-covariance":{},"Chap_4.html#cross-covariance":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#example-dice-money":{},"Chap_4.html#example-fair-chance":{},"Chap_4.html#example-is-that-coin-fair":{},"Chap_4.html#laboratory-exercise-41":{},"Chap_4.html#laboratory-exercise-42":{},"Chap_4.html#problem-41":{},"Chap_4.html#problem-42":{},"Chap_4.html#problem-45":{},"Chap_4.html#problem-47":{},"Chap_4.html#problem-49":{},"Chap_4.html#properties-of-averaging":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#correlations-and-memory":{},"Chap_5.html#correlations-simple-and-complex":{},"Chap_5.html#example-pink-noise":{},"Chap_5.html#laboratory-exercise-51":{},"Chap_5.html#problem-55":{},"Chap_5.html#problem-56":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_6.html":{},"Chap_6.html#interpretation-of-the-convolution-result":{},"Chap_6.html#laboratory-exercise-61":{},"Chap_6.html#laboratory-exercise-62":{},"Chap_6.html#laboratory-exercise-63":{},"Chap_6.html#laboratory-exercise-64":{},"Chap_6.html#laboratory-exercise-65":{},"Chap_6.html#laboratory-exercise-66":{},"Chap_6.html#laboratory-exercise-67":{},"Chap_6.html#laboratory-exercise-68":{},"Chap_6.html#problem-61":{},"Chap_6.html#problem-62":{},"Chap_6.html#problem-63":{},"Chap_6.html#problem-66":{},"Chap_6.html#the-autocorrelation-function":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_6.html#the-mean":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function":{},"Chap_7.html#autocorrelation-function_1":{},"Chap_7.html#autocorrelation-function_2":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#descriptive-statistic-variance":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#expected-value":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#impulse-invariant-sampling":{},"Chap_7.html#one-step-further":{},"Chap_7.html#power-spectral-density":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#power-spectral-density_2":{},"Chap_7.html#problem-78":{},"Chap_7.html#tethered-particle-motion":{},"Chap_7.html#the-langevin-position-equation":{},"Chap_7.html#the-langevin-velocity-equation":{},"Chap_8.html":{},"Chap_8.html#example-filtering-noise":{},"Chap_8.html#example-not-too-noisy":{},"Chap_8.html#problem-83":{},"Chap_8.html#snr-for-deterministic-signals-in-the-presence-of-noise":{},"Chap_8.html#snr-for-random-signals-in-the-presence-of-noise":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{},"Chap_9.html":{},"Chap_9.html#example-matching-your-filter":{},"Chap_9.html#laboratory-exercise-91":{},"Chap_9.html#laboratory-exercise-92":{},"Chap_9.html#laboratory-exercise-93":{},"Chap_9.html#problem-91":{},"Chap_9.html#problem-92":{},"Chap_9.html#setting-up-the-problem":{},"Chap_9.html#the-matched-filter":{},"Chap_9.html#the-matched-filter-as-an-autocorrelation":{},"Chap_9.html#using-cauchy-schwartz":{},"info.html":{},"info.html#tips-short-cuts":{}},"title":{}}],["left\\langl",{"_index":2934,"text":{"Chap_7.html":{},"Chap_7.html#autocorrelation-function_1":{},"Chap_7.html#descriptive-statistic-variance":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#expected-value":{},"Chap_7.html#one-step-further":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#problem-711":{},"Chap_7.html#the-langevin-velocity-equation":{}},"title":{}}],["leftrightarrow",{"_index":3605,"text":{"Chap_9.html":{},"Chap_9.html#problem-92":{}},"title":{}}],["legend",{"_index":3358,"text":{"Chap_7.html":{},"Chap_7.html#one-step-further":{}},"title":{}}],["leighton",{"_index":2370,"text":{"Chap_4.html":{},"Chap_4.html#laboratory-exercise-42":{},"Chap_7.html":{},"Chap_7.html#problem-711":{}},"title":{}}],["len",{"_index":3179,"text":{"Chap_7.html":{},"Chap_7.html#tethered-particle-motion":{}},"title":{}}],["lend",{"_index":3364,"text":{"Chap_7.html":{},"Chap_7.html#why-this-case-study":{},"Chap_9.html":{},"Chap_9.html#laboratory-exercise-92":{}},"title":{}}],["length",{"_index":1242,"text":{"Chap_11.html":{},"Chap_11.html#laboratory-exercise-113":{},"Chap_12.html":{},"Chap_12.html#problem-123":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_12.html#windowed-observations":{},"Chap_4.html":{},"Chap_4.html#the-ergodic-process":{},"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#one-step-further":{},"Chap_7.html#tethered-particle-motion":{},"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{}},"title":{}}],["lengths\u2014w",{"_index":2433,"text":{"Chap_5.html":{},"Chap_5.html#the-mechanics-of-correlations-redux":{}},"title":{}}],["lengthy\u2014somewhat",{"_index":511,"text":{"Chap_10.html":{},"Chap_10.html#what-is-that-least-mean-square-error":{}},"title":{}}],["leq",{"_index":1557,"text":{"Chap_12.html":{},"Chap_12.html#problem-122":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_4.html":{},"Chap_4.html#describing-the-time-average":{}},"title":{}}],["leqslant",{"_index":1751,"text":{"Chap_13.html":{},"Chap_13.html#epilogue":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_4.html":{},"Chap_4.html#problem-42":{},"Chap_9.html":{},"Chap_9.html#the-matched-filter-as-an-autocorrelation":{}},"title":{}}],["less",{"_index":471,"text":{"Chap_10.html":{},"Chap_10.html#the-wiener-hopf-equation":{},"Chap_11.html":{},"Chap_11.html#laboratory-exercise-113":{},"Chap_12.html":{},"Chap_12.html#problem-122":{},"Chap_13.html":{},"Chap_13.html#appendix-i-mean-square-error-minimization":{},"Chap_5.html":{},"Chap_5.html#correlations-and-memory":{},"Chap_5.html#problem-52":{},"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{}},"title":{}}],["letter",{"_index":3719,"text":{"info.html":{},"info.html#technical-details":{}},"title":{}}],["level",{"_index":161,"text":{"Chap_1.html":{},"Chap_1.html#sound-of-music":{},"Chap_10.html":{},"Chap_10.html#laboratory-exercise-101":{},"Chap_3.html":{},"Chap_3.html#introduction":{},"Chap_4.html":{},"Chap_4.html#laboratory-exercise-42":{},"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#why-this-case-study":{},"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{}},"title":{}}],["li",{"_index":616,"text":{"Chap_10.html":{},"Chap_10.html#why-we-avoid-the-inverse-filter":{},"Chap_12.html":{},"Chap_12.html#the-periodogram-unbiased":{}},"title":{}}],["lie",{"_index":1973,"text":{"Chap_3.html":{},"Chap_3.html#problem-35":{}},"title":{}}],["life",{"_index":1419,"text":{"Chap_12.html":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_4.html":{},"Chap_4.html#problem-42":{}},"title":{}}],["light",{"_index":3528,"text":{"Chap_8.html":{},"Chap_8.html#problem-83":{}},"title":{}}],["ligteringen",{"_index":1728,"text":{"Chap_13.html":{},"Chap_13.html#epilogue":{},"info.html":{},"info.html#authors":{}},"title":{}}],["likelihood",{"_index":850,"text":{"Chap_11.html":{},"Chap_11.html#aspects-of-estimation":{},"Chap_11.html#example-estimating-the-poisson-rate":{},"Chap_11.html#maximum-likelihood-estimation":{},"Chap_11.html#problem-112":{}},"title":{"Chap_11.html#maximum-likelihood-estimation":{}}}],["likewis",{"_index":3064,"text":{"Chap_7.html":{},"Chap_7.html#expected-value":{}},"title":{}}],["lim",{"_index":2286,"text":{"Chap_4.html":{},"Chap_4.html#describing-the-time-average":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#correlations-and-memory":{},"Chap_5.html#problem-52":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_6.html":{},"Chap_6.html#filtering-of-stochastic-signals":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function_1":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#problem-77":{},"Chap_7.html#the-langevin-velocity-equation":{}},"title":{}}],["limit",{"_index":968,"text":{"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_11.html#estimating-the-autocorrelation-function":{},"Chap_12.html":{},"Chap_12.html#problem-122":{},"Chap_12.html#the-periodogram-unbiased":{},"Chap_4.html":{},"Chap_4.html#the-ergodic-process":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function_1":{},"Chap_7.html#how-big-is-big-how-small-is-small":{}},"title":{}}],["limits^{m",{"_index":2405,"text":{"Chap_5.html":{},"Chap_5.html#correlations-simple-and-complex":{}},"title":{}}],["limits_{\\tau",{"_index":2984,"text":{"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#power-spectral-density_1":{}},"title":{}}],["limits_{k",{"_index":2418,"text":{"Chap_5.html":{},"Chap_5.html#correlations-and-memory":{},"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#the-langevin-velocity-equation":{}},"title":{}}],["limits_{n",{"_index":2287,"text":{"Chap_4.html":{},"Chap_4.html#describing-the-time-average":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_6.html":{},"Chap_6.html#filtering-of-stochastic-signals":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function_1":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#problem-77":{}},"title":{}}],["limits_{t",{"_index":3110,"text":{"Chap_7.html":{},"Chap_7.html#power-spectral-density_1":{}},"title":{}}],["limits_{x",{"_index":2594,"text":{"Chap_5.html":{},"Chap_5.html#problem-52":{}},"title":{}}],["limits_{{t_",{"_index":2999,"text":{"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{}},"title":{}}],["lindner",{"_index":3148,"text":{"Chap_7.html":{},"Chap_7.html#problem-711":{},"Chap_7.html#tethered-particle-motion":{}},"title":{}}],["line",{"_index":801,"text":{"Chap_10.html":{},"Chap_10.html#laboratory-exercise-105":{},"Chap_12.html":{},"Chap_12.html#problem-121":{},"Chap_12.html#the-periodogram-unbiased":{},"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_4.html":{},"Chap_4.html#auto-covariance":{},"Chap_4.html#example-is-that-coin-fair":{},"Chap_5.html":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_6.html":{},"Chap_6.html#the-autocorrelation-function":{},"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{}},"title":{}}],["linear",{"_index":277,"text":{"Chap_10.html":{},"Chap_10.html#classic-example-classic-result":{},"Chap_10.html#the-more-general-restoration-case-noise-distortion":{},"Chap_10.html#the-restoration-case-noise":{},"Chap_10.html#the-wiener-filter":{},"Chap_13.html":{},"Chap_13.html#appendix-i-mean-square-error-minimization":{},"Chap_2.html":{},"Chap_2.html#problem-21":{},"Chap_3.html":{},"Chap_3.html#introduction":{},"Chap_3.html#problem-310":{},"Chap_3.html#the-basics":{},"Chap_3.html#what-is-a-random-signal":{},"Chap_4.html":{},"Chap_4.html#properties-of-averaging":{},"Chap_5.html":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_6.html":{},"Chap_6.html#filtering-of-stochastic-signals":{},"Chap_6.html#interpretation-of-the-convolution-result":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_6.html#the-mean":{},"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#from-t-to-n":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#problem-73":{},"Chap_7.html#tethered-particle-motion":{},"Chap_8.html":{},"Chap_8.html#characterizing-signal-to-noise-ratios":{}},"title":{}}],["linearli",{"_index":3075,"text":{"Chap_7.html":{},"Chap_7.html#autocorrelation-function_1":{}},"title":{}}],["link",{"_index":43,"text":{"Chap_1.html":{},"Chap_1.html#getting-around":{},"Chap_1.html#how-to-use-this-ibook":{},"Chap_1.html#outside-this-device":{},"Chap_13.html":{},"Chap_13.html#epilogue":{},"Chap_3.html":{},"Chap_3.html#problem-310":{},"Chap_7.html":{},"Chap_7.html#problem-78":{}},"title":{}}],["liquid",{"_index":3530,"text":{"Chap_8.html":{},"Chap_8.html#problem-83":{}},"title":{}}],["list",{"_index":1829,"text":{"Chap_3.html":{},"Chap_3.html#the-basics":{},"info.html":{},"info.html#tips-short-cuts":{}},"title":{}}],["listen",{"_index":662,"text":{"Chap_10.html":{},"Chap_10.html#example-sound-of-distorted-music":{},"Chap_10.html#laboratory-exercise-101":{}},"title":{}}],["liter",{"_index":2721,"text":{"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{}},"title":{}}],["literatur",{"_index":1298,"text":{"Chap_12.html":{},"Chap_12.html#other-windows":{},"Chap_12.html#the-periodogram-unbiased":{}},"title":{}}],["littl",{"_index":1440,"text":{"Chap_12.html":{},"Chap_12.html#laboratory-exercise-124":{},"Chap_12.html#other-windows":{}},"title":{}}],["live",{"_index":2328,"text":{"Chap_4.html":{},"Chap_4.html#problem-42":{}},"title":{}}],["llc",{"_index":207,"text":{"Chap_1.html":{},"Chap_1.html#enhanced-experience":{}},"title":{}}],["ln",{"_index":912,"text":{"Chap_11.html":{},"Chap_11.html#example-estimating-the-poisson-rate":{},"Chap_11.html#problem-111":{}},"title":{}}],["lobe",{"_index":1346,"text":{"Chap_12.html":{},"Chap_12.html#problem-121":{},"Chap_12.html#problem-122":{},"Chap_12.html#windowed-observations":{}},"title":{}}],["locat",{"_index":2233,"text":{"Chap_4.html":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_7.html":{},"Chap_7.html#problem-710":{},"Chap_9.html":{},"Chap_9.html#laboratory-exercise-91":{},"Chap_9.html#performance-in-the-presence-of-noise":{},"info.html":{},"info.html#tips-short-cuts":{}},"title":{}}],["log",{"_index":2563,"text":{"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{}},"title":{}}],["logarithm",{"_index":913,"text":{"Chap_11.html":{},"Chap_11.html#example-estimating-the-poisson-rate":{},"Chap_8.html":{},"Chap_8.html#snr-for-deterministic-signals-in-the-presence-of-noise":{}},"title":{}}],["long",{"_index":1245,"text":{"Chap_11.html":{},"Chap_11.html#laboratory-exercise-113":{},"Chap_2.html":{},"Chap_2.html#prologue":{},"Chap_5.html":{},"Chap_5.html#correlations-and-memory":{},"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small":{},"Chap_7.html#problem-77":{}},"title":{}}],["longer",{"_index":3147,"text":{"Chap_7.html":{},"Chap_7.html#problem-79":{},"Chap_7.html#tethered-particle-motion":{},"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{}},"title":{}}],["look",{"_index":329,"text":{"Chap_10.html":{},"Chap_10.html#classic-example-classic-result":{},"Chap_10.html#example-sound-of-distorted-music":{},"Chap_10.html#laboratory-exercise-101":{},"Chap_10.html#using-the-least-mean-square-error-criterion":{},"Chap_11.html":{},"Chap_11.html#aspects-of-estimation":{},"Chap_11.html#estimating-the-autocorrelation-function":{},"Chap_11.html#estimating-the-mean":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_11.html#maximum-likelihood-estimation":{},"Chap_11.html#trouble-in-paradise":{},"Chap_12.html":{},"Chap_12.html#other-windows":{},"Chap_12.html#problem-122":{},"Chap_12.html#spectral-estimation":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_3.html":{},"Chap_3.html#introduction":{},"Chap_4.html":{},"Chap_4.html#problem-44":{},"Chap_4.html#properties-of-averaging":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_5.html":{},"Chap_5.html#fourier-description-of-correlation-functions":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function_1":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#expected-value":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#tethered-particle-motion":{},"Chap_8.html":{},"Chap_8.html#example-filtering-noise":{},"Chap_9.html":{},"Chap_9.html#the-matched-filter":{}},"title":{}}],["loss",{"_index":1200,"text":{"Chap_11.html":{},"Chap_11.html#problem-117":{},"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_4.html":{},"Chap_4.html#problem-49":{},"Chap_5.html":{},"Chap_5.html#correlations-and-memory":{}},"title":{}}],["lot",{"_index":2366,"text":{"Chap_4.html":{},"Chap_4.html#laboratory-exercise-41":{},"Chap_9.html":{},"Chap_9.html#problem-91":{},"Chap_9.html#problem-92":{}},"title":{}}],["love",{"_index":3736,"text":{"info.html":{},"info.html#musical-data":{}},"title":{}}],["low",{"_index":718,"text":{"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_8.html":{},"Chap_8.html#problem-83":{},"Chap_9.html":{},"Chap_9.html#performance-in-the-presence-of-noise":{}},"title":{}}],["lower",{"_index":1232,"text":{"Chap_11.html":{},"Chap_11.html#problem-119":{},"Chap_12.html":{},"Chap_12.html#problem-122":{},"Chap_7.html":{},"Chap_7.html#problem-79":{}},"title":{}}],["lowpass",{"_index":1647,"text":{"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{}},"title":{}}],["lt",{"_index":1922,"text":{"Chap_3.html":{},"Chap_3.html#problem-32":{},"Chap_3.html#problem-39":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#example-pink-noise":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_7.html":{},"Chap_7.html#power-spectral-density":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#power-spectral-density_2":{},"Chap_8.html":{},"Chap_8.html#problem-83":{}},"title":{}}],["lti",{"_index":313,"text":{"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#the-more-general-restoration-case-noise-distortion":{},"Chap_10.html#the-restoration-case-noise":{},"Chap_3.html":{},"Chap_3.html#introduction":{},"Chap_3.html#problem-310":{},"Chap_3.html#problem-33":{},"Chap_3.html#what-is-a-random-signal":{},"Chap_5.html":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_6.html":{},"Chap_6.html#filtering-of-stochastic-signals":{},"Chap_6.html#interpretation-of-the-convolution-result":{},"Chap_6.html#problem-61":{},"Chap_6.html#problem-62":{},"Chap_6.html#problem-64":{},"Chap_6.html#problem-65":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_6.html#the-mean":{},"Chap_7.html":{},"Chap_7.html#from-t-to-n":{},"Chap_8.html":{},"Chap_8.html#characterizing-signal-to-noise-ratios":{},"Chap_8.html#example-filtering-noise":{},"Chap_8.html#problem-83":{},"Chap_9.html":{},"Chap_9.html#the-matched-filter":{}},"title":{}}],["luca",{"_index":3676,"text":{"info.html":{},"info.html#acknowledgments":{}},"title":{}}],["lucid",{"_index":3062,"text":{"Chap_7.html":{},"Chap_7.html#expected-value":{},"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{}},"title":{}}],["lvert",{"_index":1869,"text":{"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#power-spectral-density_1":{}},"title":{}}],["lvert\\alpha\\rvert",{"_index":1865,"text":{"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{}},"title":{}}],["lvert\\alpha\\rvert>1\\\\h[n]&=\\beta^n",{"_index":1950,"text":{"Chap_3.html":{},"Chap_3.html#problem-33":{}},"title":{}}],["lvert\\alpha\\rvert\\leq",{"_index":1864,"text":{"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{}},"title":{}}],["lvert\\beta\\rvert>1\\end{aligned}\\qquad",{"_index":1951,"text":{"Chap_3.html":{},"Chap_3.html#problem-33":{}},"title":{}}],["m",{"_index":319,"text":{"Chap_10.html":{},"Chap_10.html#the-restoration-case-noise":{},"Chap_10.html#the-wiener-hopf-equation":{},"Chap_10.html#using-the-least-mean-square-error-criterion":{},"Chap_10.html#what-is-that-least-mean-square-error":{},"Chap_11.html":{},"Chap_11.html#laboratory-exercise-113":{},"Chap_11.html#langevin-redux":{},"Chap_11.html#problem-1110":{},"Chap_11.html#problem-113":{},"Chap_11.html#problem-119":{},"Chap_12.html":{},"Chap_12.html#laboratory-exercise-124":{},"Chap_12.html#problem-122":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_4.html":{},"Chap_4.html#auto-covariance":{},"Chap_4.html#autocorrelation":{},"Chap_4.html#cross-correlation":{},"Chap_4.html#cross-covariance":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#laboratory-exercise-42":{},"Chap_4.html#problem-47":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_5.html":{},"Chap_5.html#correlations-simple-and-complex":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{},"Chap_6.html#the-autocorrelation-function":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#expected-value":{},"Chap_7.html#how-big-is-big-how-small-is-small":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#impulse-invariant-sampling":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#power-spectral-density_2":{},"Chap_7.html#problem-710":{},"Chap_7.html#problem-711":{},"Chap_7.html#problem-78":{},"Chap_7.html#the-langevin-equation-a-case-study":{},"Chap_7.html#the-langevin-position-equation":{},"Chap_9.html":{},"Chap_9.html#laboratory-exercise-93":{}},"title":{}}],["m(\\vec",{"_index":2083,"text":{"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{}},"title":{}}],["m({\\vec",{"_index":2095,"text":{"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{}},"title":{}}],["m,\\lambda",{"_index":3173,"text":{"Chap_7.html":{},"Chap_7.html#descriptive-statistic-variance":{},"Chap_7.html#tethered-particle-motion":{}},"title":{}}],["m/",{"_index":3124,"text":{"Chap_7.html":{},"Chap_7.html#power-spectral-density_1":{}},"title":{}}],["m/100\\lambda",{"_index":2921,"text":{"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#power-spectral-density_1":{}},"title":{}}],["m/2\\lambda",{"_index":3002,"text":{"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{}},"title":{}}],["m/\\lambda",{"_index":2834,"text":{"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#impulse-invariant-sampling":{}},"title":{}}],["m;\\quad",{"_index":1895,"text":{"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{}},"title":{}}],["m\\frac{{dv(t)}}{{dt",{"_index":2802,"text":{"Chap_7.html":{},"Chap_7.html#the-langevin-equation-a-case-study":{},"Chap_7.html#the-langevin-velocity-equation":{}},"title":{}}],["m\\frac{{{d^2}x(t)}}{{d{t^2",{"_index":2803,"text":{"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#tethered-particle-motion":{},"Chap_7.html#the-langevin-equation-a-case-study":{},"Chap_7.html#the-langevin-position-equation":{}},"title":{}}],["m^2",{"_index":3125,"text":{"Chap_7.html":{},"Chap_7.html#power-spectral-density_1":{}},"title":{}}],["m_\\alpha",{"_index":1975,"text":{"Chap_3.html":{},"Chap_3.html#problem-35":{}},"title":{}}],["m_f",{"_index":2931,"text":{"Chap_7.html":{},"Chap_7.html#expected-value":{},"Chap_7.html#the-langevin-velocity-equation":{}},"title":{}}],["m_f}\\,{h_v}(\\omega",{"_index":2958,"text":{"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{}},"title":{}}],["m_f}\\,{h_v}(z",{"_index":2959,"text":{"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{}},"title":{}}],["m_f}\\,{h_x}(\\omega",{"_index":3043,"text":{"Chap_7.html":{},"Chap_7.html#expected-value":{}},"title":{}}],["m_f}\\,{h_x}(z",{"_index":3044,"text":{"Chap_7.html":{},"Chap_7.html#expected-value":{}},"title":{}}],["m_f}{h_x}(\\omega",{"_index":3297,"text":{"Chap_7.html":{},"Chap_7.html#expected-value_1":{}},"title":{}}],["m_f}{h_x}(z",{"_index":3298,"text":{"Chap_7.html":{},"Chap_7.html#expected-value_1":{}},"title":{}}],["m_i",{"_index":2632,"text":{"Chap_6.html":{},"Chap_6.html#interpretation-of-the-convolution-result":{},"Chap_6.html#problem-61":{},"Chap_6.html#problem-62":{},"Chap_6.html#problem-65":{},"Chap_6.html#the-mean":{},"Chap_7.html":{},"Chap_7.html#problem-73":{},"Chap_8.html":{},"Chap_8.html#snr-for-random-signals-in-the-presence-of-noise":{}},"title":{}}],["m_n",{"_index":753,"text":{"Chap_10.html":{},"Chap_10.html#problem-103":{},"Chap_8.html":{},"Chap_8.html#snr-for-random-signals-in-the-presence-of-noise":{}},"title":{}}],["m_r",{"_index":1984,"text":{"Chap_3.html":{},"Chap_3.html#problem-37":{}},"title":{}}],["m_v",{"_index":2956,"text":{"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{}},"title":{}}],["m_x",{"_index":752,"text":{"Chap_10.html":{},"Chap_10.html#problem-103":{},"Chap_11.html":{},"Chap_11.html#aspects-of-estimation":{},"Chap_11.html#estimating-the-mean":{},"Chap_11.html#problem-118":{},"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#describing-the-time-average":{},"Chap_4.html#example-average-experience":{},"Chap_4.html#example-is-that-coin-fair":{},"Chap_4.html#properties-of-averaging":{},"Chap_4.html#the-ergodic-process":{},"Chap_5.html":{},"Chap_5.html#correlations-and-memory":{},"Chap_5.html#correlations-simple-and-complex":{},"Chap_5.html#example-pink-noise":{},"Chap_5.html#problem-53":{},"Chap_6.html":{},"Chap_6.html#filtering-of-stochastic-signals":{},"Chap_6.html#interpretation-of-the-convolution-result":{},"Chap_6.html#problem-65":{},"Chap_6.html#the-mean":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function_1":{},"Chap_7.html#descriptive-statistic-variance":{},"Chap_7.html#expected-value":{},"Chap_7.html#expected-value_1":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#problem-73":{},"Chap_8.html":{},"Chap_8.html#problem-81":{}},"title":{}}],["m_x^2",{"_index":2182,"text":{"Chap_4.html":{},"Chap_4.html#example-is-that-coin-fair":{},"Chap_4.html#properties-of-averaging":{}},"title":{}}],["m_x}\\sum\\limits_{k",{"_index":2638,"text":{"Chap_6.html":{},"Chap_6.html#the-mean":{}},"title":{}}],["m_x}\\sum\\limits_{n",{"_index":2640,"text":{"Chap_6.html":{},"Chap_6.html#the-mean":{}},"title":{}}],["m_x}h(\\omega",{"_index":2641,"text":{"Chap_6.html":{},"Chap_6.html#the-mean":{}},"title":{}}],["m_x}h[n",{"_index":2637,"text":{"Chap_6.html":{},"Chap_6.html#the-mean":{}},"title":{}}],["m_x}m_i",{"_index":2395,"text":{"Chap_5.html":{},"Chap_5.html#correlations-and-memory":{},"Chap_5.html#correlations-simple-and-complex":{}},"title":{}}],["m_{x[\\ell",{"_index":2117,"text":{"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{}},"title":{}}],["m_{x[k",{"_index":2245,"text":{"Chap_4.html":{},"Chap_4.html#auto-covariance":{}},"title":{}}],["m_{x[n",{"_index":2102,"text":{"Chap_4.html":{},"Chap_4.html#auto-covariance":{},"Chap_4.html#cross-covariance":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#properties-of-averaging":{}},"title":{}}],["m_{x[n]}}m_{x[k",{"_index":2246,"text":{"Chap_4.html":{},"Chap_4.html#auto-covariance":{}},"title":{}}],["m_{x[n]}}m_{x[n",{"_index":2247,"text":{"Chap_4.html":{},"Chap_4.html#auto-covariance":{}},"title":{}}],["m_{x[n]}}m_{y[k",{"_index":2255,"text":{"Chap_4.html":{},"Chap_4.html#cross-covariance":{}},"title":{}}],["m_{x[n]}}m_{y[n",{"_index":2256,"text":{"Chap_4.html":{},"Chap_4.html#cross-covariance":{}},"title":{}}],["m_{y[k",{"_index":2254,"text":{"Chap_4.html":{},"Chap_4.html#cross-covariance":{}},"title":{}}],["m_{{x_n",{"_index":2259,"text":{"Chap_4.html":{},"Chap_4.html#cross-covariance":{}},"title":{}}],["mac",{"_index":3702,"text":{"info.html":{},"info.html#technical-details":{}},"title":{}}],["macromolecul",{"_index":3143,"text":{"Chap_7.html":{},"Chap_7.html#one-step-further":{},"Chap_7.html#tethered-particle-motion":{}},"title":{}}],["macromolecular",{"_index":3174,"text":{"Chap_7.html":{},"Chap_7.html#tethered-particle-motion":{}},"title":{}}],["made",{"_index":50,"text":{"Chap_1.html":{},"Chap_1.html#enhanced-experience":{},"Chap_1.html#how-to-use-this-ibook":{},"Chap_1.html#outside-this-device":{},"Chap_10.html":{},"Chap_10.html#correlation-returns":{},"Chap_11.html":{},"Chap_11.html#aspects-of-estimation":{},"Chap_11.html#maximum-likelihood-estimation":{},"Chap_7.html":{},"Chap_7.html#problem-78":{},"Chap_7.html#the-langevin-equation-a-case-study":{},"Chap_9.html":{},"Chap_9.html#the-matched-filter":{}},"title":{}}],["magnet",{"_index":3201,"text":{"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_9.html":{},"Chap_9.html#the-matched-filter":{}},"title":{}}],["magnitud",{"_index":2909,"text":{"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#choosing-the-sampling-period_1":{}},"title":{}}],["main",{"_index":90,"text":{"Chap_1.html":{},"Chap_1.html#highlighting":{},"Chap_12.html":{},"Chap_12.html#problem-121":{},"Chap_12.html#problem-122":{},"Chap_12.html#windowed-observations":{}},"title":{}}],["mainli",{"_index":2374,"text":{"Chap_4.html":{},"Chap_4.html#laboratory-exercise-42":{},"Chap_7.html":{},"Chap_7.html#problem-711":{}},"title":{}}],["maintain",{"_index":1546,"text":{"Chap_12.html":{},"Chap_12.html#problem-122":{}},"title":{}}],["mainten",{"_index":3137,"text":{"Chap_7.html":{},"Chap_7.html#tethered-particle-motion":{}},"title":{}}],["major",{"_index":2749,"text":{"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{},"Chap_7.html":{},"Chap_7.html#power-spectral-density_2":{}},"title":{}}],["make",{"_index":54,"text":{"Chap_1.html":{},"Chap_1.html#how-to-use-this-ibook":{},"Chap_10.html":{},"Chap_10.html#example-sound-of-distorted-music":{},"Chap_10.html#laboratory-exercise-105":{},"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_13.html#epilogue":{},"Chap_4.html":{},"Chap_4.html#cross-covariance":{},"Chap_4.html#the-ergodic-process":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_6.html#the-mean":{},"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_8.html":{},"Chap_8.html#example-filtering-noise":{},"Chap_9.html":{},"Chap_9.html#laboratory-exercise-93":{},"Chap_9.html#problem-92":{},"info.html":{},"info.html#tips-short-cuts":{}},"title":{}}],["mani",{"_index":685,"text":{"Chap_10.html":{},"Chap_10.html#example-cleaning-up-our-act":{},"Chap_11.html":{},"Chap_11.html#aspects-of-estimation":{},"Chap_12.html":{},"Chap_12.html#problem-122":{},"Chap_2.html":{},"Chap_2.html#prologue":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#example-fair-chance":{},"Chap_4.html#laboratory-exercise-41":{},"Chap_4.html#problem-49":{},"Chap_5.html":{},"Chap_5.html#correlations-and-memory":{},"Chap_5.html#problem-52":{},"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{},"Chap_7.html":{},"Chap_7.html#the-langevin-equation-a-case-study":{},"Chap_7.html#why-this-case-study":{},"Chap_8.html":{},"Chap_8.html#problem-82":{},"info.html":{},"info.html#acknowledgments":{}},"title":{}}],["manipul",{"_index":497,"text":{"Chap_10.html":{},"Chap_10.html#what-is-that-least-mean-square-error":{},"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{}},"title":{}}],["manner",{"_index":652,"text":{"Chap_10.html":{},"Chap_10.html#example-sound-of-distorted-music":{}},"title":{}}],["manuscript",{"_index":3686,"text":{"info.html":{},"info.html#acknowledgments":{}},"title":{}}],["man\u2019",{"_index":777,"text":{"Chap_10.html":{},"Chap_10.html#laboratory-exercise-105":{}},"title":{}}],["map",{"_index":2055,"text":{"Chap_4.html":{},"Chap_4.html#example-fair-chance":{}},"title":{}}],["mark",{"_index":1240,"text":{"Chap_11.html":{},"Chap_11.html#laboratory-exercise-113":{},"Chap_2.html":{},"Chap_2.html#problem-21":{}},"title":{}}],["markdown",{"_index":3706,"text":{"info.html":{},"info.html#technical-details":{}},"title":{}}],["market",{"_index":258,"text":{"Chap_1.html":{},"Chap_1.html#enhanced-experience":{}},"title":{}}],["marketplac",{"_index":2747,"text":{"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{}},"title":{}}],["mass",{"_index":1953,"text":{"Chap_3.html":{},"Chap_3.html#problem-34":{},"Chap_3.html#problem-37":{},"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#expected-value":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#tethered-particle-motion":{},"Chap_7.html#the-langevin-equation-a-case-study":{}},"title":{}}],["massachusett",{"_index":1717,"text":{"Chap_13.html":{},"Chap_13.html#epilogue":{},"Chap_4.html":{},"Chap_4.html#laboratory-exercise-42":{},"Chap_7.html":{},"Chap_7.html#problem-711":{},"Chap_8.html":{},"Chap_8.html#problem-83":{}},"title":{}}],["match",{"_index":278,"text":{"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#the-wiener-filter":{},"Chap_9.html":{},"Chap_9.html#example-matching-your-filter":{},"Chap_9.html#laboratory-exercise-92":{},"Chap_9.html#laboratory-exercise-93":{},"Chap_9.html#performance-in-the-presence-of-noise":{},"Chap_9.html#problem-91":{},"Chap_9.html#the-classic-example":{},"Chap_9.html#the-matched-filter":{},"Chap_9.html#the-matched-filter-as-an-autocorrelation":{}},"title":{"Chap_9.html":{},"Chap_9.html#example-matching-your-filter":{},"Chap_9.html#the-matched-filter":{},"Chap_9.html#the-matched-filter-as-an-autocorrelation":{}}}],["materi",{"_index":45,"text":{"Chap_1.html":{},"Chap_1.html#how-to-use-this-ibook":{},"Chap_1.html#outside-this-device":{},"Chap_3.html":{},"Chap_3.html#the-basics":{},"Chap_3.html#what-is-a-random-signal":{},"info.html":{},"info.html#copyright":{},"info.html#technical-details":{},"info.html#usage":{}},"title":{}}],["mathemat",{"_index":477,"text":{"Chap_10.html":{},"Chap_10.html#the-wiener-hopf-equation":{},"Chap_11.html":{},"Chap_11.html#laboratory-exercise-113":{},"Chap_11.html#problem-119":{},"Chap_12.html":{},"Chap_12.html#problem-122":{},"Chap_3.html":{},"Chap_3.html#problem-310":{},"Chap_3.html#problem-36":{},"Chap_3.html#what-is-a-random-signal":{},"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#laboratory-exercise-42":{},"Chap_4.html#problem-49":{},"Chap_6.html":{},"Chap_6.html#laboratory-exercise-64":{},"Chap_6.html#laboratory-exercise-65":{},"Chap_6.html#laboratory-exercise-66":{},"Chap_6.html#laboratory-exercise-68":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#problem-78":{},"Chap_7.html#the-langevin-equation-a-case-study":{},"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{}},"title":{}}],["mathematica",{"_index":3696,"text":{"info.html":{},"info.html#technical-details":{}},"title":{}}],["mathjax",{"_index":3707,"text":{"info.html":{},"info.html#technical-details":{}},"title":{}}],["mathop",{"_index":2285,"text":{"Chap_4.html":{},"Chap_4.html#describing-the-time-average":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#correlations-and-memory":{},"Chap_5.html#problem-52":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_6.html":{},"Chap_6.html#filtering-of-stochastic-signals":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function_1":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#problem-77":{},"Chap_7.html#the-langevin-velocity-equation":{}},"title":{}}],["mathop{\\rm",{"_index":3634,"text":{"Chap_9.html":{},"Chap_9.html#laboratory-exercise-93":{}},"title":{}}],["mathscr{f",{"_index":1687,"text":{"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_5.html":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{}},"title":{}}],["mathscr{f}\\left\\{\u2022\\right",{"_index":1826,"text":{"Chap_3.html":{},"Chap_3.html#the-basics":{}},"title":{}}],["mathscr{f}}\\left",{"_index":576,"text":{"Chap_10.html":{},"Chap_10.html#classic-example-classic-result":{},"Chap_10.html#why-we-avoid-the-inverse-filter":{},"Chap_11.html":{},"Chap_11.html#aspects-of-estimation":{},"Chap_11.html#problem-119":{},"Chap_12.html":{},"Chap_12.html#problem-122":{},"Chap_12.html#spectral-estimation":{},"Chap_12.html#the-periodogram-unbiased":{},"Chap_12.html#windowed-observations":{},"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#example-white-noise":{},"Chap_5.html#problem-55":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_6.html#the-mean":{},"Chap_7.html":{},"Chap_7.html#power-spectral-density":{},"Chap_7.html#power-spectral-density_2":{},"Chap_8.html":{},"Chap_8.html#problem-83":{}},"title":{}}],["mathtyp",{"_index":3709,"text":{"info.html":{},"info.html#technical-details":{}},"title":{}}],["matter",{"_index":670,"text":{"Chap_10.html":{},"Chap_10.html#example-sound-of-distorted-music":{},"Chap_4.html":{},"Chap_4.html#example-dice-money":{},"Chap_4.html#the-ergodic-process":{},"Chap_5.html":{},"Chap_5.html#fourier-description-of-correlation-functions":{},"Chap_8.html":{},"Chap_8.html#snr-for-random-signals-in-the-presence-of-noise":{},"info.html":{},"info.html#contact":{}},"title":{}}],["max",{"_index":2455,"text":{"Chap_5.html":{},"Chap_5.html#a-digression":{}},"title":{}}],["maxim",{"_index":272,"text":{"Chap_10.html":{},"Chap_10.html#the-wiener-filter":{},"Chap_11.html":{},"Chap_11.html#example-estimating-the-poisson-rate":{},"Chap_9.html":{},"Chap_9.html#setting-up-the-problem":{},"Chap_9.html#the-matched-filter":{},"Chap_9.html#the-matched-filter-as-an-autocorrelation":{}},"title":{}}],["maxima",{"_index":2712,"text":{"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{}},"title":{}}],["maximum",{"_index":739,"text":{"Chap_10.html":{},"Chap_10.html#problem-101":{},"Chap_11.html":{},"Chap_11.html#aspects-of-estimation":{},"Chap_11.html#example-estimating-the-poisson-rate":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_11.html#maximum-likelihood-estimation":{},"Chap_11.html#problem-112":{},"Chap_11.html#problem-119":{},"Chap_4.html":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_9.html":{},"Chap_9.html#laboratory-exercise-93":{},"Chap_9.html#the-matched-filter-as-an-autocorrelation":{},"Chap_9.html#using-cauchy-schwartz":{}},"title":{"Chap_11.html#maximum-likelihood-estimation":{}}}],["may}},{t_{16",{"_index":2209,"text":{"Chap_4.html":{},"Chap_4.html#the-mechanics-of-correlations":{}},"title":{}}],["mcgraw",{"_index":793,"text":{"Chap_10.html":{},"Chap_10.html#laboratory-exercise-105":{},"Chap_13.html":{},"Chap_13.html#epilogue":{},"Chap_3.html":{},"Chap_3.html#problem-310":{},"Chap_5.html":{},"Chap_5.html#laboratory-exercise-51":{},"Chap_7.html":{},"Chap_7.html#problem-711":{}},"title":{}}],["mean",{"_index":19,"text":{"Chap_1.html":{},"Chap_1.html#enhanced-experience":{},"Chap_1.html#how-to-use-this-ibook":{},"Chap_10.html":{},"Chap_10.html#classic-example-classic-result":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#example-sound-of-distorted-music":{},"Chap_10.html#laboratory-exercise-103":{},"Chap_10.html#laboratory-exercise-105":{},"Chap_10.html#problem-103":{},"Chap_10.html#the-more-general-restoration-case-noise-distortion":{},"Chap_10.html#using-the-least-mean-square-error-criterion":{},"Chap_10.html#what-is-that-least-mean-square-error":{},"Chap_11.html":{},"Chap_11.html#aspects-of-estimation":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_11.html#estimating-the-autocorrelation-function":{},"Chap_11.html#estimating-the-mean":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_11.html#laboratory-exercise-111":{},"Chap_11.html#problem-114":{},"Chap_11.html#problem-115":{},"Chap_11.html#problem-116":{},"Chap_11.html#problem-117":{},"Chap_11.html#problem-118":{},"Chap_11.html#trouble-in-paradise":{},"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#laboratory-exercise-122":{},"Chap_12.html#other-windows":{},"Chap_12.html#spectral-estimation":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_13.html":{},"Chap_13.html#appendix-i-mean-square-error-minimization":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_2.html":{},"Chap_2.html#problem-21":{},"Chap_2.html#prologue":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_3.html#problem-310":{},"Chap_3.html#problem-34":{},"Chap_3.html#problem-35":{},"Chap_3.html#problem-37":{},"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#example-fair-chance":{},"Chap_4.html#example-is-that-coin-fair":{},"Chap_4.html#laboratory-exercise-42":{},"Chap_4.html#problem-44":{},"Chap_4.html#problem-45":{},"Chap_4.html#problem-49":{},"Chap_4.html#properties-of-averaging":{},"Chap_4.html#the-ergodic-process":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#correlations-and-spectra":{},"Chap_5.html#correlations-simple-and-complex":{},"Chap_5.html#example-delayed-effect":{},"Chap_5.html#example-pink-noise":{},"Chap_5.html#problem-53":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{},"Chap_6.html#filtering-of-stochastic-signals":{},"Chap_6.html#interpretation-of-the-convolution-result":{},"Chap_6.html#problem-65":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_6.html#the-mean":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function_1":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#descriptive-statistic-variance":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#expected-value":{},"Chap_7.html#expected-value_1":{},"Chap_7.html#how-big-is-big-how-small-is-small":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#one-step-further":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#power-spectral-density_2":{},"Chap_7.html#problem-710":{},"Chap_7.html#problem-711":{},"Chap_7.html#problem-73":{},"Chap_7.html#problem-77":{},"Chap_7.html#why-this-case-study":{},"Chap_8.html":{},"Chap_8.html#example-not-too-noisy":{},"Chap_8.html#snr-for-random-signals-in-the-presence-of-noise":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{},"Chap_9.html":{},"Chap_9.html#problem-91":{},"Chap_9.html#problem-92":{},"Chap_9.html#setting-up-the-problem":{},"info.html":{},"info.html#usage":{}},"title":{"Chap_10.html#expressing-the-mean-square-error":{},"Chap_10.html#using-the-least-mean-square-error-criterion":{},"Chap_10.html#what-is-that-least-mean-square-error":{},"Chap_11.html#estimating-the-mean":{},"Chap_13.html#appendix-i-mean-square-error-minimization":{},"Chap_6.html#the-mean":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{}}}],["mean\\;squar",{"_index":2127,"text":{"Chap_4.html":{},"Chap_4.html#other-averages":{}},"title":{}}],["mean\\text",{"_index":333,"text":{"Chap_10.html":{},"Chap_10.html#using-the-least-mean-square-error-criterion":{}},"title":{}}],["mean{\\text",{"_index":2397,"text":{"Chap_5.html":{},"Chap_5.html#correlations-simple-and-complex":{}},"title":{}}],["measur",{"_index":322,"text":{"Chap_10.html":{},"Chap_10.html#the-restoration-case-noise":{},"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_11.html#example-estimating-the-poisson-rate":{},"Chap_11.html#laboratory-exercise-113":{},"Chap_11.html#maximum-likelihood-estimation":{},"Chap_11.html#problem-114":{},"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#problem-123":{},"Chap_4.html":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_6.html":{},"Chap_6.html#filtering-of-stochastic-signals":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_7.html":{},"Chap_7.html#descriptive-statistic-variance":{},"Chap_7.html#how-big-is-big-how-small-is-small":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#one-step-further":{},"Chap_7.html#the-langevin-equation-a-case-study":{},"Chap_7.html#why-this-case-study":{},"Chap_8.html":{},"Chap_8.html#example-filtering-noise":{},"Chap_8.html#problem-83":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{},"Chap_9.html":{},"Chap_9.html#problem-92":{},"info.html":{},"info.html#cover":{}},"title":{}}],["mechan",{"_index":2193,"text":{"Chap_4.html":{},"Chap_4.html#laboratory-exercise-42":{},"Chap_5.html":{},"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#problem-711":{},"Chap_7.html#tethered-particle-motion":{}},"title":{"Chap_4.html#the-mechanics-of-correlations":{},"Chap_5.html#the-mechanics-of-correlations-redux":{}}}],["mediat",{"_index":3407,"text":{"Chap_7.html":{},"Chap_7.html#problem-711":{}},"title":{}}],["meet",{"_index":3284,"text":{"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period_1":{}},"title":{}}],["memori",{"_index":2414,"text":{"Chap_5.html":{},"Chap_5.html#correlations-and-memory":{}},"title":{"Chap_5.html#correlations-and-memory":{}}}],["mention",{"_index":1429,"text":{"Chap_12.html":{},"Chap_12.html#other-windows":{},"Chap_4.html":{},"Chap_4.html#describing-the-time-average":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_7.html":{},"Chap_7.html#power-spectral-density_1":{}},"title":{}}],["messag",{"_index":3616,"text":{"Chap_9.html":{},"Chap_9.html#problem-92":{}},"title":{}}],["met",{"_index":3003,"text":{"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{}},"title":{}}],["meteorolog",{"_index":2197,"text":{"Chap_4.html":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"info.html":{},"info.html#cover":{},"info.html#weather-data":{}},"title":{}}],["meter",{"_index":1756,"text":{"Chap_2.html":{},"Chap_2.html#prologue":{},"Chap_4.html":{},"Chap_4.html#properties-of-averaging":{},"Chap_7.html":{},"Chap_7.html#problem-78":{}},"title":{}}],["method",{"_index":1270,"text":{"Chap_11.html":{},"Chap_11.html#laboratory-exercise-113":{},"Chap_3.html":{},"Chap_3.html#problem-310":{},"Chap_3.html#what-is-a-random-signal":{},"Chap_4.html":{},"Chap_4.html#example-fair-chance":{},"Chap_4.html#laboratory-exercise-42":{},"Chap_5.html":{},"Chap_5.html#laboratory-exercise-51":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#problem-711":{},"Chap_9.html":{},"Chap_9.html#performance-in-the-presence-of-noise":{},"Chap_9.html#problem-91":{},"Chap_9.html#the-matched-filter":{}},"title":{}}],["methodolog",{"_index":3067,"text":{"Chap_7.html":{},"Chap_7.html#autocorrelation-function_1":{}},"title":{}}],["microphon",{"_index":82,"text":{"Chap_1.html":{},"Chap_1.html#how-to-use-this-ibook":{},"Chap_8.html":{},"Chap_8.html#example-cocktail-party-noise":{},"info.html":{},"info.html#tips-short-cuts":{}},"title":{}}],["microscop",{"_index":3177,"text":{"Chap_7.html":{},"Chap_7.html#tethered-particle-motion":{}},"title":{}}],["microscopi",{"_index":3200,"text":{"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#problem-711":{}},"title":{}}],["microsoft",{"_index":3705,"text":{"info.html":{},"info.html#technical-details":{}},"title":{}}],["middl",{"_index":1389,"text":{"Chap_12.html":{},"Chap_12.html#problem-123":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{},"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{}},"title":{}}],["midst",{"_index":2760,"text":{"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{}},"title":{}}],["mile",{"_index":1244,"text":{"Chap_11.html":{},"Chap_11.html#laboratory-exercise-113":{}},"title":{}}],["miller",{"_index":3393,"text":{"Chap_7.html":{},"Chap_7.html#problem-711":{}},"title":{}}],["minim",{"_index":342,"text":{"Chap_10.html":{},"Chap_10.html#laboratory-exercise-103":{},"Chap_10.html#the-more-general-restoration-case-noise-distortion":{},"Chap_10.html#using-the-least-mean-square-error-criterion":{},"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_11.html#problem-115":{},"Chap_11.html#problem-118":{},"Chap_12.html":{},"Chap_12.html#problem-122":{},"Chap_13.html":{},"Chap_13.html#appendix-i-mean-square-error-minimization":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_9.html":{},"Chap_9.html#the-matched-filter":{}},"title":{"Chap_13.html#appendix-i-mean-square-error-minimization":{}}}],["minimum",{"_index":346,"text":{"Chap_10.html":{},"Chap_10.html#problem-101":{},"Chap_10.html#using-the-least-mean-square-error-criterion":{},"Chap_10.html#what-is-that-least-mean-square-error":{},"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_11.html#example-estimating-the-poisson-rate":{},"Chap_11.html#problem-117":{},"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#problem-123":{},"Chap_13.html":{},"Chap_13.html#appendix-i-mean-square-error-minimization":{}},"title":{}}],["minut",{"_index":3363,"text":{"Chap_7.html":{},"Chap_7.html#one-step-further":{}},"title":{}}],["mistak",{"_index":3385,"text":{"Chap_7.html":{},"Chap_7.html#problem-78":{}},"title":{}}],["mix",{"_index":2104,"text":{"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{}},"title":{}}],["mkdoc",{"_index":3713,"text":{"info.html":{},"info.html#technical-details":{}},"title":{}}],["ml",{"_index":874,"text":{"Chap_11.html":{},"Chap_11.html#example-estimating-the-poisson-rate":{},"Chap_11.html#maximum-likelihood-estimation":{},"Chap_11.html#problem-113":{},"Chap_11.html#problem-114":{}},"title":{}}],["mm",{"_index":1238,"text":{"Chap_11.html":{},"Chap_11.html#laboratory-exercise-113":{}},"title":{}}],["mm/",{"_index":2874,"text":{"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small":{}},"title":{}}],["modal",{"_index":3196,"text":{"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{}},"title":{}}],["model",{"_index":310,"text":{"Chap_10.html":{},"Chap_10.html#example-sound-of-distorted-music":{},"Chap_10.html#the-more-general-restoration-case-noise-distortion":{},"Chap_10.html#the-restoration-case-noise":{},"Chap_12.html":{},"Chap_12.html#spectral-estimation":{},"Chap_3.html":{},"Chap_3.html#what-is-a-random-signal":{},"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#example-dice-money":{},"Chap_4.html#example-fair-chance":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{},"Chap_6.html#interpretation-of-the-convolution-result":{},"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#one-step-further":{},"Chap_7.html#problem-79":{},"Chap_7.html#tethered-particle-motion":{},"Chap_7.html#the-langevin-equation-a-case-study":{},"Chap_8.html":{},"Chap_8.html#example-cocktail-party-noise":{},"Chap_8.html#example-filtering-noise":{},"Chap_8.html#problem-83":{},"Chap_9.html":{},"Chap_9.html#the-matched-filter":{}},"title":{}}],["modern",{"_index":16,"text":{"Chap_1.html":{},"Chap_1.html#how-to-use-this-ibook":{},"Chap_12.html":{},"Chap_12.html#laboratory-exercise-122":{},"Chap_13.html":{},"Chap_13.html#epilogue":{},"Chap_2.html":{},"Chap_2.html#prologue":{},"Chap_7.html":{},"Chap_7.html#tethered-particle-motion":{}},"title":{}}],["modif",{"_index":3168,"text":{"Chap_7.html":{},"Chap_7.html#tethered-particle-motion":{}},"title":{}}],["modifi",{"_index":1215,"text":{"Chap_11.html":{},"Chap_11.html#problem-117":{},"Chap_12.html":{},"Chap_12.html#laboratory-exercise-124":{},"Chap_12.html#problem-122":{},"Chap_7.html":{},"Chap_7.html#tethered-particle-motion":{}},"title":{}}],["modul",{"_index":1770,"text":{"Chap_2.html":{},"Chap_2.html#prologue":{}},"title":{}}],["molecul",{"_index":1182,"text":{"Chap_11.html":{},"Chap_11.html#problem-114":{},"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#how-big-is-big-how-small-is-small":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#one-step-further":{},"Chap_7.html#problem-711":{},"Chap_7.html#tethered-particle-motion":{},"Chap_7.html#the-langevin-equation-a-case-study":{},"Chap_7.html#why-this-case-study":{}},"title":{}}],["molecular",{"_index":3195,"text":{"Chap_7.html":{},"Chap_7.html#tethered-particle-motion":{},"Chap_7.html#why-this-case-study":{}},"title":{}}],["money",{"_index":2137,"text":{"Chap_4.html":{},"Chap_4.html#example-dice-money":{}},"title":{"Chap_4.html#example-dice-money":{}}}],["monologu",{"_index":1787,"text":{"Chap_2.html":{},"Chap_2.html#prologue":{}},"title":{}}],["montag",{"_index":3737,"text":{"info.html":{},"info.html#musical-data":{}},"title":{}}],["month",{"_index":2580,"text":{"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{}},"title":{}}],["more",{"_index":281,"text":{"Chap_10.html":{},"Chap_10.html#example-sound-of-distorted-music":{},"Chap_10.html#the-more-general-restoration-case-noise-distortion":{},"Chap_10.html#the-wiener-filter":{},"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_11.html#estimating-the-autocorrelation-function":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_11.html#laboratory-exercise-111":{},"Chap_3.html":{},"Chap_3.html#problem-310":{},"Chap_4.html":{},"Chap_4.html#correlation-the-workhorse":{},"Chap_4.html#example-dice-money":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_5.html":{},"Chap_5.html#correlations-and-memory":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#tethered-particle-motion":{},"Chap_7.html#the-langevin-position-equation":{},"Chap_7.html#why-this-case-study":{},"Chap_8.html":{},"Chap_8.html#problem-82":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{},"Chap_9.html":{},"Chap_9.html#the-matched-filter":{}},"title":{"Chap_10.html#the-more-general-restoration-case-noise-distortion":{}}}],["morn",{"_index":1173,"text":{"Chap_11.html":{},"Chap_11.html#problem-113":{}},"title":{}}],["motion",{"_index":603,"text":{"Chap_10.html":{},"Chap_10.html#the-more-general-restoration-case-noise-distortion":{},"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#how-big-is-big-how-small-is-small":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#one-step-further":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#problem-711":{},"Chap_7.html#tethered-particle-motion":{},"Chap_7.html#the-langevin-equation-a-case-study":{},"Chap_7.html#the-langevin-position-equation":{},"Chap_7.html#why-this-case-study":{},"Chap_8.html":{},"Chap_8.html#problem-83":{}},"title":{"Chap_7.html#tethered-particle-motion":{}}}],["motiv",{"_index":2185,"text":{"Chap_4.html":{},"Chap_4.html#correlation-the-workhorse":{}},"title":{}}],["move",{"_index":3141,"text":{"Chap_7.html":{},"Chap_7.html#tethered-particle-motion":{},"Chap_9.html":{},"Chap_9.html#setting-up-the-problem":{}},"title":{}}],["movi",{"_index":167,"text":{"Chap_1.html":{},"Chap_1.html#at-the-movies":{},"Chap_11.html":{},"Chap_11.html#estimating-the-autocorrelation-function":{},"Chap_11.html#estimating-the-mean":{},"Chap_11.html#trouble-in-paradise":{},"Chap_12.html":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_12.html#windowed-observations":{},"Chap_7.html":{},"Chap_7.html#one-step-further":{},"Chap_7.html#tethered-particle-motion":{},"Chap_9.html":{},"Chap_9.html#laboratory-exercise-91":{},"Chap_9.html#performance-in-the-presence-of-noise":{},"Chap_9.html#problem-91":{},"Chap_9.html#the-matched-filter-as-an-autocorrelation":{},"info.html":{},"info.html#technical-details":{}},"title":{"Chap_1.html#at-the-movies":{}}}],["ms",{"_index":3257,"text":{"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{}},"title":{}}],["mu",{"_index":830,"text":{"Chap_11.html":{},"Chap_11.html#aspects-of-estimation":{},"Chap_11.html#example-estimating-the-poisson-rate":{},"Chap_11.html#problem-112":{},"Chap_11.html#problem-117":{},"Chap_3.html":{},"Chap_3.html#problem-34":{},"Chap_4.html":{},"Chap_4.html#problem-44":{},"Chap_4.html#problem-45":{},"Chap_4.html#problem-49":{},"Chap_5.html":{},"Chap_5.html#correlations-simple-and-complex":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#expected-value":{},"Chap_7.html#how-big-is-big-how-small-is-small":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#power-spectral-density_2":{},"Chap_7.html#problem-79":{},"Chap_7.html#why-this-case-study":{},"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{}},"title":{}}],["mu=1.0",{"_index":1878,"text":{"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{}},"title":{}}],["much",{"_index":1515,"text":{"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#problem-122":{},"Chap_3.html":{},"Chap_3.html#problem-38":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_6.html":{},"Chap_6.html#laboratory-exercise-68":{},"Chap_7.html":{},"Chap_7.html#problem-710":{},"Chap_7.html#problem-79":{},"Chap_7.html#the-langevin-velocity-equation":{},"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{}},"title":{}}],["multipl",{"_index":235,"text":{"Chap_1.html":{},"Chap_1.html#enhanced-experience":{},"Chap_12.html":{},"Chap_12.html#windowed-observations":{},"Chap_3.html":{},"Chap_3.html#introduction":{},"Chap_6.html":{},"Chap_6.html#interpretation-of-the-convolution-result":{}},"title":{}}],["multipli",{"_index":678,"text":{"Chap_10.html":{},"Chap_10.html#example-cleaning-up-our-act":{},"Chap_12.html":{},"Chap_12.html#problem-122":{},"Chap_4.html":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_6.html":{},"Chap_6.html#the-mean":{},"Chap_9.html":{},"Chap_9.html#the-matched-filter-as-an-autocorrelation":{}},"title":{}}],["music",{"_index":147,"text":{"Chap_1.html":{},"Chap_1.html#sound-of-music":{},"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#example-sound-of-distorted-music":{},"Chap_10.html#problem-104":{},"Chap_12.html":{},"Chap_12.html#problem-123":{},"Chap_3.html":{},"Chap_3.html#what-is-a-random-signal":{},"info.html":{},"info.html#musical-data":{}},"title":{"Chap_1.html#sound-of-music":{},"Chap_10.html#example-sound-of-distorted-music":{},"info.html#musical-data":{}}}],["mv",{"_index":3456,"text":{"Chap_8.html":{},"Chap_8.html#example-not-too-noisy":{}},"title":{}}],["mvue",{"_index":948,"text":{"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_11.html#problem-117":{}},"title":{}}],["m}}{\\rho",{"_index":1103,"text":{"Chap_11.html":{},"Chap_11.html#langevin-redux":{}},"title":{}}],["n",{"_index":394,"text":{"Chap_10.html":{},"Chap_10.html#example-cleaning-up-our-act":{},"Chap_10.html#expressing-the-mean-square-error":{},"Chap_10.html#laboratory-exercise-105":{},"Chap_11.html":{},"Chap_11.html#aspects-of-estimation":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_11.html#estimating-the-autocorrelation-function":{},"Chap_11.html#estimating-the-mean":{},"Chap_11.html#example-estimating-the-poisson-rate":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_11.html#maximum-likelihood-estimation":{},"Chap_11.html#problem-112":{},"Chap_11.html#problem-113":{},"Chap_11.html#problem-117":{},"Chap_11.html#problem-118":{},"Chap_11.html#problem-119":{},"Chap_11.html#trouble-in-paradise":{},"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#the-periodogram-unbiased":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_12.html#windowed-observations":{},"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_3.html#problem-31":{},"Chap_3.html#problem-33":{},"Chap_3.html#problem-34":{},"Chap_3.html#problem-38":{},"Chap_3.html#the-basics":{},"Chap_4.html":{},"Chap_4.html#autocorrelation":{},"Chap_4.html#characterization-of-random-signals":{},"Chap_4.html#cross-covariance":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#describing-the-time-average":{},"Chap_4.html#example-dice-money":{},"Chap_4.html#example-fair-chance":{},"Chap_4.html#laboratory-exercise-41":{},"Chap_4.html#laboratory-exercise-42":{},"Chap_4.html#other-averages":{},"Chap_4.html#problem-45":{},"Chap_4.html#the-ergodic-process":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#correlations-and-memory":{},"Chap_5.html#correlations-simple-and-complex":{},"Chap_5.html#problem-52":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{},"Chap_6.html#filtering-of-stochastic-signals":{},"Chap_6.html#interpretation-of-the-convolution-result":{},"Chap_6.html#laboratory-exercise-63":{},"Chap_6.html#problem-61":{},"Chap_6.html#problem-62":{},"Chap_6.html#the-autocorrelation-function":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_6.html#the-mean":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function_1":{},"Chap_7.html#expected-value":{},"Chap_7.html#impulse-invariant-sampling":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#problem-77":{},"Chap_7.html#problem-79":{},"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{},"Chap_9.html":{},"Chap_9.html#example-matching-your-filter":{},"Chap_9.html#problem-91":{},"Chap_9.html#setting-up-the-problem":{},"Chap_9.html#the-classic-example":{},"Chap_9.html#the-matched-filter":{},"Chap_9.html#the-matched-filter-as-an-autocorrelation":{}},"title":{"Chap_7.html#from-t-to-n":{}}}],["n){\\rm{sinc}}(t",{"_index":1662,"text":{"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{}},"title":{}}],["n,k",{"_index":2237,"text":{"Chap_4.html":{},"Chap_4.html#the-mechanics-of-correlations":{}},"title":{}}],["n,n",{"_index":2238,"text":{"Chap_4.html":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_5.html":{},"Chap_5.html#the-mechanics-of-correlations-redux":{}},"title":{}}],["n,q\\in\\mathbb{r",{"_index":1958,"text":{"Chap_3.html":{},"Chap_3.html#problem-34":{}},"title":{}}],["n=100",{"_index":2025,"text":{"Chap_3.html":{},"Chap_3.html#problem-310":{}},"title":{}}],["n=\\dot",{"_index":1883,"text":{"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{}},"title":{}}],["n=n_0",{"_index":1842,"text":{"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{}},"title":{}}],["n[n",{"_index":306,"text":{"Chap_10.html":{},"Chap_10.html#classic-example-classic-result":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#problem-103":{},"Chap_10.html#the-restoration-case-noise":{},"Chap_8.html":{},"Chap_8.html#example-cocktail-party-noise":{},"Chap_8.html#example-not-too-noisy":{},"Chap_8.html#problem-83":{},"Chap_9.html":{},"Chap_9.html#the-matched-filter":{}},"title":{}}],["n[n\\rbrack",{"_index":681,"text":{"Chap_10.html":{},"Chap_10.html#example-cleaning-up-our-act":{},"Chap_8.html":{},"Chap_8.html#example-cocktail-party-noise":{}},"title":{}}],["n[n]x[n",{"_index":543,"text":{"Chap_10.html":{},"Chap_10.html#classic-example-classic-result":{}},"title":{}}],["n\\\\0&\\lvert",{"_index":1914,"text":{"Chap_3.html":{},"Chap_3.html#problem-31":{}},"title":{}}],["n\\end{cas",{"_index":1916,"text":{"Chap_3.html":{},"Chap_3.html#problem-31":{}},"title":{}}],["n\\geq0\\text",{"_index":1965,"text":{"Chap_3.html":{},"Chap_3.html#problem-34":{}},"title":{}}],["n\\in\\mathbb{z",{"_index":1966,"text":{"Chap_3.html":{},"Chap_3.html#problem-34":{}},"title":{}}],["n\\left",{"_index":3051,"text":{"Chap_7.html":{},"Chap_7.html#expected-value":{}},"title":{}}],["n\\neq",{"_index":1894,"text":{"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{}},"title":{}}],["n\\omega",{"_index":1381,"text":{"Chap_12.html":{},"Chap_12.html#the-periodogram-what-about-convergence":{}},"title":{}}],["n\\rbrack",{"_index":2448,"text":{"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_6.html":{},"Chap_6.html#interpretation-of-the-convolution-result":{},"Chap_9.html":{},"Chap_9.html#example-matching-your-filter":{}},"title":{}}],["n\\rvert",{"_index":1915,"text":{"Chap_3.html":{},"Chap_3.html#problem-31":{}},"title":{}}],["n\\rvert\\leq",{"_index":1913,"text":{"Chap_3.html":{},"Chap_3.html#problem-31":{}},"title":{}}],["n\\sin",{"_index":1382,"text":{"Chap_12.html":{},"Chap_12.html#the-periodogram-what-about-convergence":{}},"title":{}}],["n\\text",{"_index":1882,"text":{"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{}},"title":{}}],["n]{\\varphi",{"_index":2661,"text":{"Chap_6.html":{},"Chap_6.html#the-autocorrelation-function":{}},"title":{}}],["n^2}{w^2}[n",{"_index":1471,"text":{"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{}},"title":{}}],["n^2}{{\\left",{"_index":1632,"text":{"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{}},"title":{}}],["n_0",{"_index":720,"text":{"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_5.html":{},"Chap_5.html#example-delayed-effect":{},"Chap_8.html":{},"Chap_8.html#example-cocktail-party-noise":{},"Chap_8.html#example-filtering-noise":{},"Chap_9.html":{},"Chap_9.html#example-matching-your-filter":{},"Chap_9.html#setting-up-the-problem":{},"Chap_9.html#the-classic-example":{},"Chap_9.html#the-matched-filter":{},"Chap_9.html#the-matched-filter-as-an-autocorrelation":{},"Chap_9.html#using-cauchy-schwartz":{}},"title":{}}],["n_0}]\\,{x^*}[n",{"_index":2413,"text":{"Chap_5.html":{},"Chap_5.html#example-delayed-effect":{}},"title":{}}],["n_0}{\\left",{"_index":3422,"text":{"Chap_8.html":{},"Chap_8.html#example-filtering-noise":{}},"title":{}}],["n_0}}}d\\omega",{"_index":3563,"text":{"Chap_9.html":{},"Chap_9.html#setting-up-the-problem":{},"Chap_9.html#using-cauchy-schwartz":{}},"title":{}}],["n_1",{"_index":975,"text":{"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{}},"title":{}}],["n_1},{n_2},\\,...\\,,{n_n}|\\theta",{"_index":898,"text":{"Chap_11.html":{},"Chap_11.html#example-estimating-the-poisson-rate":{}},"title":{}}],["n_2",{"_index":974,"text":{"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{}},"title":{}}],["n_3",{"_index":973,"text":{"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{}},"title":{}}],["n_h",{"_index":2068,"text":{"Chap_4.html":{},"Chap_4.html#example-fair-chance":{}},"title":{}}],["n_h}/n",{"_index":2071,"text":{"Chap_4.html":{},"Chap_4.html#example-fair-chance":{}},"title":{}}],["n_i",{"_index":905,"text":{"Chap_11.html":{},"Chap_11.html#example-estimating-the-poisson-rate":{}},"title":{}}],["n_i}\\ln",{"_index":916,"text":{"Chap_11.html":{},"Chap_11.html#example-estimating-the-poisson-rate":{}},"title":{}}],["n_i}}}{",{"_index":904,"text":{"Chap_11.html":{},"Chap_11.html#example-estimating-the-poisson-rate":{}},"title":{}}],["n_o",{"_index":2410,"text":{"Chap_5.html":{},"Chap_5.html#example-delayed-effect":{},"Chap_9.html":{},"Chap_9.html#problem-91":{},"Chap_9.html#the-classic-example":{}},"title":{}}],["n_o}\\delta",{"_index":3420,"text":{"Chap_8.html":{},"Chap_8.html#example-filtering-noise":{}},"title":{}}],["n_p",{"_index":2545,"text":{"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{}},"title":{}}],["n_t",{"_index":2069,"text":{"Chap_4.html":{},"Chap_4.html#example-fair-chance":{},"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{}},"title":{}}],["n_t}/k",{"_index":2559,"text":{"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{}},"title":{}}],["n_t}/n",{"_index":2073,"text":{"Chap_4.html":{},"Chap_4.html#example-fair-chance":{}},"title":{}}],["n_{rm",{"_index":1467,"text":{"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{}},"title":{}}],["n_{rms}}\\delta",{"_index":1485,"text":{"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{}},"title":{}}],["na",{"_index":3180,"text":{"Chap_7.html":{},"Chap_7.html#tethered-particle-motion":{}},"title":{}}],["name",{"_index":441,"text":{"Chap_10.html":{},"Chap_10.html#the-wiener-hopf-equation":{},"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_5.html":{},"Chap_5.html#fourier-description-of-correlation-functions":{}},"title":{}}],["nanoparticl",{"_index":3409,"text":{"Chap_7.html":{},"Chap_7.html#problem-711":{}},"title":{}}],["nanophoton",{"_index":3410,"text":{"Chap_7.html":{},"Chap_7.html#problem-711":{}},"title":{}}],["narrow",{"_index":1350,"text":{"Chap_12.html":{},"Chap_12.html#other-windows":{},"Chap_12.html#problem-122":{},"Chap_12.html#windowed-observations":{}},"title":{}}],["natur",{"_index":247,"text":{"Chap_1.html":{},"Chap_1.html#enhanced-experience":{},"Chap_11.html":{},"Chap_11.html#example-estimating-the-poisson-rate":{},"Chap_11.html#laboratory-exercise-111":{},"Chap_4.html":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_5.html":{},"Chap_7.html":{},"Chap_7.html#problem-711":{}},"title":{"Chap_5.html#predicting-the-natural-climate-a-case-study":{}}}],["nawab",{"_index":2046,"text":{"Chap_3.html":{},"Chap_3.html#problem-310":{},"Chap_5.html":{},"Chap_5.html#laboratory-exercise-51":{},"Chap_7.html":{},"Chap_7.html#problem-711":{}},"title":{}}],["ne",{"_index":880,"text":{"Chap_11.html":{},"Chap_11.html#maximum-likelihood-estimation":{},"Chap_4.html":{},"Chap_4.html#example-dice-money":{},"Chap_4.html#example-is-that-coin-fair":{},"Chap_4.html#problem-44":{},"Chap_5.html":{},"Chap_5.html#problem-52":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_6.html":{},"Chap_6.html#problem-65":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period_1":{}},"title":{}}],["necessari",{"_index":2618,"text":{"Chap_6.html":{},"Chap_6.html#filtering-of-stochastic-signals":{},"Chap_7.html":{},"Chap_7.html#tethered-particle-motion":{},"info.html":{},"info.html#tips-short-cuts":{}},"title":{}}],["need",{"_index":170,"text":{"Chap_1.html":{},"Chap_1.html#at-the-movies":{},"Chap_10.html":{},"Chap_10.html#using-the-least-mean-square-error-criterion":{},"Chap_11.html":{},"Chap_11.html#langevin-redux":{},"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_5.html":{},"Chap_5.html#fourier-description-of-correlation-functions":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function":{},"Chap_7.html#tethered-particle-motion":{},"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{},"Chap_9.html":{},"Chap_9.html#the-matched-filter":{},"info.html":{},"info.html#acknowledgments":{}},"title":{}}],["needl",{"_index":956,"text":{"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_9.html":{},"Chap_9.html#laboratory-exercise-92":{},"Chap_9.html#the-matched-filter":{}},"title":{}}],["neg",{"_index":1029,"text":{"Chap_11.html":{},"Chap_11.html#estimating-the-autocorrelation-function":{},"Chap_11.html#problem-111":{},"Chap_3.html":{},"Chap_3.html#problem-310":{},"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#laboratory-exercise-42":{},"Chap_6.html":{},"Chap_6.html#problem-66":{},"Chap_7.html":{},"Chap_7.html#expected-value":{}},"title":{}}],["neglect",{"_index":2847,"text":{"Chap_7.html":{},"Chap_7.html#impulse-invariant-sampling":{}},"title":{}}],["neglig",{"_index":2852,"text":{"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#impulse-invariant-sampling":{}},"title":{}}],["neq",{"_index":1937,"text":{"Chap_3.html":{},"Chap_3.html#problem-33":{}},"title":{}}],["netherland",{"_index":1729,"text":{"Chap_13.html":{},"Chap_13.html#epilogue":{},"Chap_4.html":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"info.html":{},"info.html#cover":{},"info.html#weather-data":{}},"title":{}}],["never",{"_index":2426,"text":{"Chap_5.html":{},"Chap_5.html#the-mechanics-of-correlations-redux":{}},"title":{}}],["nevertheless",{"_index":653,"text":{"Chap_10.html":{},"Chap_10.html#example-sound-of-distorted-music":{},"Chap_10.html#laboratory-exercise-105":{},"Chap_2.html":{},"Chap_2.html#prologue":{},"Chap_3.html":{},"Chap_3.html#problem-310":{},"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{},"Chap_7.html":{},"Chap_7.html#expected-value":{},"Chap_7.html#tethered-particle-motion":{}},"title":{}}],["new",{"_index":232,"text":{"Chap_1.html":{},"Chap_1.html#enhanced-experience":{},"Chap_10.html":{},"Chap_10.html#laboratory-exercise-105":{},"Chap_11.html":{},"Chap_11.html#laboratory-exercise-113":{},"Chap_12.html":{},"Chap_12.html#problem-122":{},"Chap_13.html":{},"Chap_13.html#epilogue":{},"Chap_3.html":{},"Chap_3.html#problem-310":{},"Chap_4.html":{},"Chap_4.html#laboratory-exercise-42":{},"Chap_5.html":{},"Chap_5.html#laboratory-exercise-51":{},"Chap_7.html":{},"Chap_7.html#problem-71":{},"Chap_7.html#problem-711":{},"Chap_9.html":{},"Chap_9.html#laboratory-exercise-93":{}},"title":{}}],["next",{"_index":735,"text":{"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_11.html":{},"Chap_11.html#aspects-of-estimation":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_11.html#trouble-in-paradise":{},"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_7.html":{},"Chap_7.html#power-spectral-density":{},"Chap_7.html#power-spectral-density_1":{},"info.html":{},"info.html#tips-short-cuts":{}},"title":{}}],["ng",{"_index":2885,"text":{"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small":{}},"title":{}}],["ng/",{"_index":3215,"text":{"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#power-spectral-density_2":{}},"title":{}}],["nice",{"_index":1163,"text":{"Chap_11.html":{},"Chap_11.html#trouble-in-paradise":{}},"title":{}}],["nir",{"_index":3394,"text":{"Chap_7.html":{},"Chap_7.html#problem-711":{}},"title":{}}],["nm",{"_index":2613,"text":{"Chap_5.html":{},"Chap_5.html#laboratory-exercise-51":{},"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#one-step-further":{},"Chap_7.html#tethered-particle-motion":{}},"title":{}}],["nm/",{"_index":3209,"text":{"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{}},"title":{}}],["no.1",{"_index":3725,"text":{"info.html":{},"info.html#musical-data":{}},"title":{}}],["nois",{"_index":285,"text":{"Chap_10.html":{},"Chap_10.html#classic-example-classic-result":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#example-cleaning-up-our-act":{},"Chap_10.html#example-sound-of-distorted-music":{},"Chap_10.html#laboratory-exercise-101":{},"Chap_10.html#laboratory-exercise-102":{},"Chap_10.html#laboratory-exercise-103":{},"Chap_10.html#laboratory-exercise-105":{},"Chap_10.html#problem-103":{},"Chap_10.html#the-more-general-restoration-case-noise-distortion":{},"Chap_10.html#the-restoration-case-noise":{},"Chap_10.html#the-wiener-filter":{},"Chap_10.html#why-we-avoid-the-inverse-filter":{},"Chap_12.html":{},"Chap_12.html#laboratory-exercise-124":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_3.html":{},"Chap_3.html#what-is-a-random-signal":{},"Chap_4.html":{},"Chap_4.html#example-is-that-coin-fair":{},"Chap_4.html#problem-48":{},"Chap_4.html#properties-of-averaging":{},"Chap_5.html":{},"Chap_5.html#example-pink-noise":{},"Chap_5.html#example-white-noise":{},"Chap_5.html#laboratory-exercise-51":{},"Chap_6.html":{},"Chap_6.html#laboratory-exercise-61":{},"Chap_6.html#laboratory-exercise-62":{},"Chap_6.html#laboratory-exercise-63":{},"Chap_6.html#laboratory-exercise-67":{},"Chap_6.html#problem-64":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#impulse-invariant-sampling":{},"Chap_7.html#power-spectral-density":{},"Chap_7.html#the-langevin-equation-a-case-study":{},"Chap_7.html#the-langevin-velocity-equation":{},"Chap_8.html":{},"Chap_8.html#example-cocktail-party-noise":{},"Chap_8.html#example-filtering-noise":{},"Chap_8.html#example-not-too-noisy":{},"Chap_8.html#problem-82":{},"Chap_8.html#problem-83":{},"Chap_8.html#snr-for-deterministic-signals-in-the-presence-of-noise":{},"Chap_8.html#snr-for-random-signals-in-the-presence-of-noise":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{},"Chap_9.html":{},"Chap_9.html#laboratory-exercise-91":{},"Chap_9.html#performance-in-the-presence-of-noise":{},"Chap_9.html#problem-91":{},"Chap_9.html#problem-92":{},"Chap_9.html#setting-up-the-problem":{},"Chap_9.html#the-classic-example":{},"Chap_9.html#the-matched-filter":{},"Chap_9.html#using-cauchy-schwartz":{}},"title":{"Chap_10.html#the-more-general-restoration-case-noise-distortion":{},"Chap_10.html#the-restoration-case-noise":{},"Chap_5.html#example-pink-noise":{},"Chap_5.html#example-white-noise":{},"Chap_8.html":{},"Chap_8.html#characterizing-signal-to-noise-ratios":{},"Chap_8.html#example-cocktail-party-noise":{},"Chap_8.html#example-filtering-noise":{},"Chap_8.html#snr-for-deterministic-signals-in-the-presence-of-noise":{},"Chap_8.html#snr-for-random-signals-in-the-presence-of-noise":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{},"Chap_9.html#performance-in-the-presence-of-noise":{}}}],["noisi",{"_index":302,"text":{"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#laboratory-exercise-104":{},"Chap_10.html#the-restoration-case-noise":{},"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{},"Chap_9.html":{},"Chap_9.html#performance-in-the-presence-of-noise":{}},"title":{"Chap_8.html#example-not-too-noisy":{}}}],["non",{"_index":363,"text":{"Chap_10.html":{},"Chap_10.html#example-cleaning-up-our-act":{},"Chap_10.html#using-the-least-mean-square-error-criterion":{},"Chap_11.html":{},"Chap_11.html#problem-111":{},"Chap_11.html#problem-115":{},"Chap_12.html":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_3.html":{},"Chap_3.html#problem-310":{},"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#laboratory-exercise-42":{},"Chap_6.html":{},"Chap_6.html#problem-66":{},"Chap_6.html#the-mean":{},"Chap_7.html":{},"Chap_7.html#the-langevin-equation-a-case-study":{},"Chap_8.html":{},"Chap_8.html#example-filtering-noise":{},"Chap_8.html#snr-for-random-signals-in-the-presence-of-noise":{},"info.html":{},"info.html#acknowledgments":{}},"title":{}}],["nonprofit",{"_index":248,"text":{"Chap_1.html":{},"Chap_1.html#enhanced-experience":{}},"title":{}}],["norbert",{"_index":483,"text":{"Chap_10.html":{},"Chap_10.html#the-wiener-hopf-equation":{}},"title":{}}],["norm",{"_index":2476,"text":{"Chap_5.html":{},"Chap_5.html#a-digression":{}},"title":{}}],["normal",{"_index":639,"text":{"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#example-cleaning-up-our-act":{},"Chap_10.html#why-we-avoid-the-inverse-filter":{},"Chap_11.html":{},"Chap_11.html#problem-112":{},"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#problem-123":{},"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_4.html":{},"Chap_4.html#problem-49":{},"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#power-spectral-density":{},"Chap_7.html#power-spectral-density_2":{}},"title":{}}],["notat",{"_index":444,"text":{"Chap_10.html":{},"Chap_10.html#the-wiener-hopf-equation":{},"Chap_3.html":{},"Chap_3.html#the-basics":{},"Chap_4.html":{},"Chap_4.html#laboratory-exercise-42":{},"Chap_4.html#properties-of-averaging":{},"Chap_4.html#the-mechanics-of-correlations":{}},"title":{}}],["note",{"_index":136,"text":{"Chap_1.html":{},"Chap_1.html#getting-around":{},"Chap_10.html":{},"Chap_10.html#example-sound-of-distorted-music":{},"Chap_10.html#problem-102":{},"Chap_10.html#problem-104":{},"Chap_10.html#the-wiener-hopf-equation":{},"Chap_10.html#using-the-least-mean-square-error-criterion":{},"Chap_11.html":{},"Chap_11.html#estimating-the-mean":{},"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#problem-123":{},"Chap_12.html#windowed-observations":{},"Chap_13.html":{},"Chap_13.html#appendix-i-mean-square-error-minimization":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_3.html":{},"Chap_3.html#problem-32":{},"Chap_4.html":{},"Chap_4.html#example-is-that-coin-fair":{},"Chap_4.html#properties-of-averaging":{},"Chap_4.html#the-ergodic-process":{},"Chap_5.html":{},"Chap_5.html#example-pink-noise":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_6.html":{},"Chap_6.html#the-mean":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#power-spectral-density":{},"Chap_9.html":{},"Chap_9.html#example-matching-your-filter":{},"Chap_9.html#performance-in-the-presence-of-noise":{},"info.html":{},"info.html#acknowledgments":{}},"title":{}}],["noth",{"_index":2161,"text":{"Chap_4.html":{},"Chap_4.html#example-dice-money":{},"Chap_5.html":{},"Chap_5.html#a-digression":{}},"title":{}}],["notic",{"_index":729,"text":{"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_12.html":{},"Chap_12.html#windowed-observations":{},"Chap_4.html":{},"Chap_4.html#cross-covariance":{},"Chap_4.html#example-is-that-coin-fair":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function":{},"Chap_7.html#autocorrelation-function_2":{},"Chap_9.html":{},"Chap_9.html#laboratory-exercise-92":{}},"title":{}}],["notwithstand",{"_index":218,"text":{"Chap_1.html":{},"Chap_1.html#enhanced-experience":{}},"title":{}}],["not\u2014i",{"_index":950,"text":{"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{}},"title":{}}],["novemb",{"_index":2226,"text":{"Chap_4.html":{},"Chap_4.html#the-mechanics-of-correlations":{}},"title":{}}],["now",{"_index":279,"text":{"Chap_10.html":{},"Chap_10.html#example-cleaning-up-our-act":{},"Chap_10.html#example-sound-of-distorted-music":{},"Chap_10.html#expressing-the-mean-square-error":{},"Chap_10.html#the-wiener-filter":{},"Chap_11.html":{},"Chap_11.html#estimating-the-autocorrelation-function":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_11.html#laboratory-exercise-112":{},"Chap_12.html":{},"Chap_12.html#laboratory-exercise-122":{},"Chap_12.html#laboratory-exercise-124":{},"Chap_12.html#the-periodogram-unbiased":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_3.html":{},"Chap_3.html#problem-310":{},"Chap_4.html":{},"Chap_4.html#correlation-the-workhorse":{},"Chap_4.html#example-is-that-coin-fair":{},"Chap_5.html":{},"Chap_5.html#correlations-and-memory":{},"Chap_5.html#fourier-description-of-correlation-functions":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_6.html":{},"Chap_6.html#filtering-of-stochastic-signals":{},"Chap_6.html#interpretation-of-the-convolution-result":{},"Chap_6.html#laboratory-exercise-61":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function_1":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#descriptive-statistic-variance":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#problem-78":{},"Chap_7.html#the-langevin-velocity-equation":{},"Chap_8.html":{},"Chap_8.html#characterizing-signal-to-noise-ratios":{},"Chap_8.html#snr-for-random-signals-in-the-presence-of-noise":{},"Chap_9.html":{},"Chap_9.html#using-cauchy-schwartz":{},"info.html":{},"info.html#tips-short-cuts":{}},"title":{}}],["nr",{"_index":3572,"text":{"Chap_9.html":{},"Chap_9.html#using-cauchy-schwartz":{}},"title":{}}],["ns",{"_index":3217,"text":{"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{}},"title":{}}],["number",{"_index":211,"text":{"Chap_1.html":{},"Chap_1.html#enhanced-experience":{},"Chap_10.html":{},"Chap_10.html#why-we-avoid-the-inverse-filter":{},"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_11.html#estimating-the-autocorrelation-function":{},"Chap_11.html#estimating-the-mean":{},"Chap_11.html#example-estimating-the-poisson-rate":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_11.html#problem-113":{},"Chap_12.html":{},"Chap_12.html#problem-122":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_13.html":{},"Chap_13.html#epilogue":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_3.html#problem-37":{},"Chap_4.html":{},"Chap_4.html#characterization-of-random-signals":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#example-average-experience":{},"Chap_4.html#example-fair-chance":{},"Chap_4.html#example-is-that-coin-fair":{},"Chap_4.html#laboratory-exercise-41":{},"Chap_4.html#properties-of-averaging":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_6.html":{},"Chap_6.html#laboratory-exercise-63":{},"Chap_7.html":{},"Chap_7.html#expected-value":{},"Chap_7.html#how-big-is-big-how-small-is-small":{},"Chap_7.html#impulse-invariant-sampling":{},"Chap_7.html#power-spectral-density_1":{},"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{},"info.html":{},"info.html#acknowledgments":{}},"title":{}}],["numer",{"_index":852,"text":{"Chap_11.html":{},"Chap_11.html#aspects-of-estimation":{},"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_3.html":{},"Chap_3.html#problem-310":{},"Chap_3.html#problem-36":{},"Chap_4.html":{},"Chap_4.html#example-fair-chance":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#power-spectral-density_2":{}},"title":{}}],["nyquist",{"_index":1774,"text":{"Chap_2.html":{},"Chap_2.html#prologue":{},"Chap_4.html":{},"Chap_4.html#problem-48":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#impulse-invariant-sampling":{},"Chap_7.html#problem-72":{}},"title":{}}],["n{\\left",{"_index":842,"text":{"Chap_11.html":{},"Chap_11.html#aspects-of-estimation":{}},"title":{}}],["n{r_d",{"_index":3426,"text":{"Chap_8.html":{},"Chap_8.html#snr-for-deterministic-signals-in-the-presence-of-noise":{},"Chap_9.html":{},"Chap_9.html#example-matching-your-filter":{},"Chap_9.html#setting-up-the-problem":{},"Chap_9.html#using-cauchy-schwartz":{}},"title":{}}],["n{r_p",{"_index":3498,"text":{"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{}},"title":{}}],["n{r_r",{"_index":3437,"text":{"Chap_8.html":{},"Chap_8.html#snr-for-random-signals-in-the-presence-of-noise":{}},"title":{}}],["n{t_",{"_index":2821,"text":{"Chap_7.html":{},"Chap_7.html#impulse-invariant-sampling":{}},"title":{}}],["n{{\\left",{"_index":1626,"text":{"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{}},"title":{}}],["n}\\otimes\\frac{\\sin(2n)}{\\pi",{"_index":1918,"text":{"Chap_3.html":{},"Chap_3.html#problem-31":{}},"title":{}}],["n}\\text",{"_index":1919,"text":{"Chap_3.html":{},"Chap_3.html#problem-31":{}},"title":{}}],["n}]\\qquad",{"_index":1949,"text":{"Chap_3.html":{},"Chap_3.html#problem-33":{}},"title":{}}],["n}]\\qquad\\lvert\\beta\\rvert>1\\end{aligned}\\qquad",{"_index":1942,"text":{"Chap_3.html":{},"Chap_3.html#problem-33":{}},"title":{}}],["n}d\\omega",{"_index":1821,"text":{"Chap_3.html":{},"Chap_3.html#the-basics":{}},"title":{}}],["n}u[n",{"_index":2942,"text":{"Chap_7.html":{},"Chap_7.html#autocorrelation-function":{},"Chap_7.html#autocorrelation-function_1":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#expected-value":{},"Chap_7.html#the-langevin-position-equation":{},"Chap_8.html":{},"Chap_8.html#example-filtering-noise":{}},"title":{}}],["n}u[n]+2^{n}u",{"_index":1910,"text":{"Chap_3.html":{},"Chap_3.html#problem-31":{}},"title":{}}],["n}}\\sum\\limits_m",{"_index":2498,"text":{"Chap_5.html":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{}},"title":{}}],["n}}{2n",{"_index":1462,"text":{"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{}},"title":{}}],["n}}{n",{"_index":1459,"text":{"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{}},"title":{}}],["o",{"_index":683,"text":{"Chap_10.html":{},"Chap_10.html#example-cleaning-up-our-act":{}},"title":{}}],["object",{"_index":2088,"text":{"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_5.html":{},"Chap_5.html#laboratory-exercise-51":{},"Chap_7.html":{},"Chap_7.html#tethered-particle-motion":{}},"title":{}}],["objection",{"_index":1599,"text":{"Chap_13.html":{},"Chap_13.html#appendix-i-mean-square-error-minimization":{}},"title":{}}],["observ",{"_index":449,"text":{"Chap_10.html":{},"Chap_10.html#the-wiener-hopf-equation":{},"Chap_11.html":{},"Chap_11.html#example-estimating-the-poisson-rate":{},"Chap_11.html#langevin-redux":{},"Chap_12.html":{},"Chap_12.html#laboratory-exercise-123":{},"Chap_12.html#windowed-observations":{},"Chap_13.html":{},"Chap_13.html#epilogue":{},"Chap_4.html":{},"Chap_4.html#cross-covariance":{},"Chap_5.html":{},"Chap_5.html#laboratory-exercise-51":{},"Chap_6.html":{},"Chap_6.html#the-mean":{},"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#power-spectral-density_1":{},"Chap_8.html":{},"Chap_8.html#problem-82":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{},"Chap_9.html":{},"Chap_9.html#problem-92":{}},"title":{"Chap_12.html#windowed-observations":{}}}],["obtain",{"_index":936,"text":{"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_12.html":{},"Chap_12.html#problem-122":{},"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function_2":{}},"title":{}}],["obviou",{"_index":953,"text":{"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_4.html":{},"Chap_4.html#problem-44":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_7.html":{},"Chap_7.html#one-step-further":{}},"title":{}}],["obvious",{"_index":2225,"text":{"Chap_4.html":{},"Chap_4.html#the-mechanics-of-correlations":{}},"title":{}}],["occasion",{"_index":119,"text":{"Chap_1.html":{},"Chap_1.html#outside-this-device":{},"Chap_2.html":{},"Chap_2.html#prologue":{}},"title":{}}],["occur",{"_index":1022,"text":{"Chap_11.html":{},"Chap_11.html#estimating-the-autocorrelation-function":{},"Chap_11.html#trouble-in-paradise":{},"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#example-is-that-coin-fair":{},"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#one-step-further":{},"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{},"Chap_9.html":{},"Chap_9.html#the-matched-filter-as-an-autocorrelation":{}},"title":{}}],["occurr",{"_index":2264,"text":{"Chap_4.html":{},"Chap_4.html#example-is-that-coin-fair":{},"Chap_4.html#laboratory-exercise-41":{},"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{}},"title":{}}],["octob",{"_index":2733,"text":{"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{}},"title":{}}],["odd",{"_index":1886,"text":{"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_3.html#problem-38":{},"Chap_3.html#problem-39":{},"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{}},"title":{}}],["odditi",{"_index":2472,"text":{"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{}},"title":{}}],["odomet",{"_index":1246,"text":{"Chap_11.html":{},"Chap_11.html#laboratory-exercise-113":{}},"title":{}}],["offer",{"_index":197,"text":{"Chap_1.html":{},"Chap_1.html#enhanced-experience":{},"Chap_7.html":{},"Chap_7.html#the-langevin-position-equation":{},"Chap_7.html#why-this-case-study":{}},"title":{}}],["offer\u2014without",{"_index":2967,"text":{"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{}},"title":{}}],["oil",{"_index":2717,"text":{"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{}},"title":{}}],["old",{"_index":2600,"text":{"Chap_5.html":{},"Chap_5.html#problem-56":{}},"title":{}}],["olympiad",{"_index":1566,"text":{"Chap_12.html":{},"Chap_12.html#problem-123":{},"Chap_3.html":{},"Chap_3.html#problem-310":{}},"title":{}}],["omega",{"_index":101,"text":{"Chap_1.html":{},"Chap_1.html#highlighting":{},"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#example-cleaning-up-our-act":{},"Chap_10.html#problem-104":{},"Chap_10.html#why-we-avoid-the-inverse-filter":{},"Chap_11.html":{},"Chap_11.html#problem-119":{},"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#problem-121":{},"Chap_12.html#problem-122":{},"Chap_12.html#spectral-estimation":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_12.html#windowed-observations":{},"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_3.html":{},"Chap_3.html#problem-32":{},"Chap_3.html#problem-38":{},"Chap_3.html#problem-39":{},"Chap_3.html#the-basics":{},"Chap_4.html":{},"Chap_4.html#problem-45":{},"Chap_4.html#problem-48":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#example-pink-noise":{},"Chap_5.html#example-white-noise":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_5.html#problem-56":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_6.html":{},"Chap_6.html#laboratory-exercise-63":{},"Chap_6.html#problem-64":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_6.html#the-mean":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#expected-value":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#impulse-invariant-sampling":{},"Chap_7.html#power-spectral-density":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#power-spectral-density_2":{},"Chap_8.html":{},"Chap_8.html#example-cocktail-party-noise":{},"Chap_8.html#example-filtering-noise":{},"Chap_8.html#problem-83":{},"Chap_9.html":{},"Chap_9.html#setting-up-the-problem":{}},"title":{}}],["on",{"_index":358,"text":{"Chap_10.html":{},"Chap_10.html#classic-example-classic-result":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#example-sound-of-distorted-music":{},"Chap_10.html#using-the-least-mean-square-error-criterion":{},"Chap_11.html":{},"Chap_11.html#aspects-of-estimation":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_11.html#estimating-the-mean":{},"Chap_11.html#example-estimating-the-poisson-rate":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_11.html#laboratory-exercise-111":{},"Chap_11.html#maximum-likelihood-estimation":{},"Chap_12.html":{},"Chap_12.html#other-windows":{},"Chap_12.html#problem-122":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_13.html":{},"Chap_13.html#appendix-i-mean-square-error-minimization":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_13.html#epilogue":{},"Chap_2.html":{},"Chap_2.html#prologue":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_3.html#problem-310":{},"Chap_3.html#problem-39":{},"Chap_4.html":{},"Chap_4.html#characterization-of-random-signals":{},"Chap_4.html#correlation-the-workhorse":{},"Chap_4.html#example-dice-money":{},"Chap_4.html#example-fair-chance":{},"Chap_4.html#problem-47":{},"Chap_4.html#properties-of-averaging":{},"Chap_4.html#the-ergodic-process":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_5.html":{},"Chap_5.html#correlations-and-memory":{},"Chap_5.html#example-pink-noise":{},"Chap_5.html#laboratory-exercise-51":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{},"Chap_6.html#problem-61":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#from-t-to-n":{},"Chap_7.html#how-big-is-big-how-small-is-small":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#impulse-invariant-sampling":{},"Chap_7.html#power-spectral-density":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#power-spectral-density_2":{},"Chap_7.html#problem-710":{},"Chap_7.html#problem-79":{},"Chap_7.html#tethered-particle-motion":{},"Chap_7.html#the-langevin-equation-a-case-study":{},"Chap_7.html#the-langevin-position-equation":{},"Chap_7.html#the-langevin-velocity-equation":{},"Chap_7.html#why-this-case-study":{},"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{},"Chap_9.html":{},"Chap_9.html#problem-91":{},"Chap_9.html#problem-92":{},"Chap_9.html#the-matched-filter":{},"Chap_9.html#the-matched-filter-as-an-autocorrelation":{},"info.html":{},"info.html#acknowledgments":{},"info.html#tips-short-cuts":{}},"title":{"Chap_7.html#one-step-further":{}}}],["onc",{"_index":528,"text":{"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#the-more-general-restoration-case-noise-distortion":{},"Chap_10.html#what-is-that-least-mean-square-error":{},"Chap_12.html":{},"Chap_12.html#other-windows":{},"Chap_12.html#the-periodogram-unbiased":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_12.html#windowed-observations":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_3.html#problem-310":{},"Chap_3.html#problem-39":{},"Chap_4.html":{},"Chap_4.html#example-fair-chance":{},"Chap_4.html#example-is-that-coin-fair":{},"Chap_4.html#the-ergodic-process":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_6.html":{},"Chap_6.html#the-autocorrelation-function":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period_1":{}},"title":{}}],["oper",{"_index":152,"text":{"Chap_1.html":{},"Chap_1.html#sound-of-music":{},"Chap_10.html":{},"Chap_10.html#correlation-returns":{},"Chap_10.html#expressing-the-mean-square-error":{},"Chap_10.html#using-the-least-mean-square-error-criterion":{},"Chap_2.html":{},"Chap_2.html#problem-21":{},"Chap_3.html":{},"Chap_3.html#the-basics":{},"Chap_4.html":{},"Chap_4.html#properties-of-averaging":{},"Chap_6.html":{},"Chap_6.html#the-mean":{},"Chap_9.html":{},"Chap_9.html#laboratory-exercise-93":{}},"title":{}}],["opera",{"_index":63,"text":{"Chap_1.html":{},"Chap_1.html#how-to-use-this-ibook":{}},"title":{}}],["operatorname{r",{"_index":1750,"text":{"Chap_13.html":{},"Chap_13.html#epilogue":{}},"title":{}}],["oppenheim",{"_index":2043,"text":{"Chap_3.html":{},"Chap_3.html#problem-310":{},"Chap_4.html":{},"Chap_4.html#example-is-that-coin-fair":{},"Chap_4.html#laboratory-exercise-42":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#example-white-noise":{},"Chap_5.html#fourier-description-of-correlation-functions":{},"Chap_5.html#laboratory-exercise-51":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_7.html":{},"Chap_7.html#from-t-to-n":{},"Chap_7.html#problem-711":{},"Chap_7.html#tethered-particle-motion":{}},"title":{}}],["opportun",{"_index":1797,"text":{"Chap_2.html":{},"Chap_2.html#problem-21":{},"Chap_7.html":{},"Chap_7.html#why-this-case-study":{},"Chap_9.html":{},"Chap_9.html#problem-91":{}},"title":{}}],["oppos",{"_index":738,"text":{"Chap_10.html":{},"Chap_10.html#problem-101":{},"Chap_10.html#problem-104":{},"Chap_11.html":{},"Chap_11.html#example-estimating-the-poisson-rate":{},"Chap_3.html":{},"Chap_3.html#problem-38":{},"Chap_5.html":{},"Chap_5.html#laboratory-exercise-51":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small":{},"Chap_9.html":{},"Chap_9.html#the-matched-filter":{}},"title":{}}],["optic",{"_index":3183,"text":{"Chap_7.html":{},"Chap_7.html#problem-711":{},"Chap_7.html#tethered-particle-motion":{}},"title":{}}],["optimum",{"_index":436,"text":{"Chap_10.html":{},"Chap_10.html#the-wiener-hopf-equation":{},"Chap_10.html#what-is-that-least-mean-square-error":{},"Chap_12.html":{},"Chap_12.html#other-windows":{}},"title":{}}],["orang",{"_index":1020,"text":{"Chap_11.html":{},"Chap_11.html#estimating-the-autocorrelation-function":{},"Chap_12.html":{},"Chap_12.html#problem-122":{}},"title":{}}],["order",{"_index":341,"text":{"Chap_10.html":{},"Chap_10.html#correlation-returns":{},"Chap_10.html#the-wiener-hopf-equation":{},"Chap_10.html#using-the-least-mean-square-error-criterion":{},"Chap_10.html#what-is-that-least-mean-square-error":{},"Chap_11.html":{},"Chap_11.html#langevin-redux":{},"Chap_12.html":{},"Chap_12.html#problem-122":{},"Chap_12.html#the-periodogram-unbiased":{},"Chap_13.html":{},"Chap_13.html#appendix-i-mean-square-error-minimization":{},"Chap_4.html":{},"Chap_4.html#the-ergodic-process":{},"Chap_5.html":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function_1":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#one-step-further":{},"Chap_7.html#tethered-particle-motion":{},"Chap_7.html#the-langevin-equation-a-case-study":{},"Chap_9.html":{},"Chap_9.html#problem-92":{}},"title":{}}],["ordinari",{"_index":2391,"text":{"Chap_5.html":{},"Chap_5.html#correlations-simple-and-complex":{},"Chap_6.html":{},"Chap_6.html#the-autocorrelation-function":{}},"title":{}}],["origin",{"_index":309,"text":{"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#example-sound-of-distorted-music":{},"Chap_10.html#the-restoration-case-noise":{},"Chap_11.html":{},"Chap_11.html#estimating-the-autocorrelation-function":{},"Chap_12.html":{},"Chap_12.html#problem-122":{},"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#laboratory-exercise-42":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#example-white-noise":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_7.html":{},"Chap_7.html#problem-78":{},"Chap_7.html#tethered-particle-motion":{},"Chap_7.html#the-langevin-velocity-equation":{},"info.html":{},"info.html#acknowledgments":{}},"title":{}}],["orthogon",{"_index":1613,"text":{"Chap_13.html":{},"Chap_13.html#appendix-i-mean-square-error-minimization":{}},"title":{}}],["orthonorm",{"_index":1664,"text":{"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{}},"title":{}}],["os",{"_index":3703,"text":{"info.html":{},"info.html#technical-details":{}},"title":{}}],["oscillatori",{"_index":3193,"text":{"Chap_7.html":{},"Chap_7.html#tethered-particle-motion":{}},"title":{}}],["otherwis",{"_index":2240,"text":{"Chap_4.html":{},"Chap_4.html#the-mechanics-of-correlations":{},"info.html":{},"info.html#copyright":{}},"title":{}}],["otim",{"_index":383,"text":{"Chap_10.html":{},"Chap_10.html#expressing-the-mean-square-error":{},"Chap_10.html#the-wiener-hopf-equation":{},"Chap_10.html#why-we-avoid-the-inverse-filter":{},"Chap_12.html":{},"Chap_12.html#windowed-observations":{},"Chap_2.html":{},"Chap_2.html#problem-21":{},"Chap_3.html":{},"Chap_3.html#introduction":{},"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{},"Chap_6.html#interpretation-of-the-convolution-result":{},"Chap_6.html#the-autocorrelation-function":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function":{},"Chap_7.html#autocorrelation-function_2":{},"Chap_7.html#expected-value":{},"Chap_7.html#power-spectral-density":{},"Chap_9.html":{},"Chap_9.html#example-matching-your-filter":{},"Chap_9.html#the-matched-filter":{}},"title":{}}],["out",{"_index":1041,"text":{"Chap_11.html":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_12.html":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_3.html":{},"Chap_3.html#problem-310":{},"Chap_4.html":{},"Chap_4.html#problem-47":{},"Chap_9.html":{},"Chap_9.html#laboratory-exercise-93":{},"Chap_9.html#the-matched-filter-as-an-autocorrelation":{},"info.html":{},"info.html#tips-short-cuts":{}},"title":{}}],["outcom",{"_index":1890,"text":{"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_4.html":{},"Chap_4.html#example-average-experience":{},"Chap_4.html#laboratory-exercise-41":{}},"title":{}}],["outcomes\u2014in",{"_index":2074,"text":{"Chap_4.html":{},"Chap_4.html#example-fair-chance":{}},"title":{}}],["output",{"_index":632,"text":{"Chap_10.html":{},"Chap_10.html#example-cleaning-up-our-act":{},"Chap_10.html#example-sound-of-distorted-music":{},"Chap_10.html#why-we-avoid-the-inverse-filter":{},"Chap_3.html":{},"Chap_3.html#introduction":{},"Chap_3.html#problem-310":{},"Chap_3.html#problem-33":{},"Chap_3.html#what-is-a-random-signal":{},"Chap_6.html":{},"Chap_6.html#interpretation-of-the-convolution-result":{},"Chap_6.html#problem-61":{},"Chap_6.html#problem-62":{},"Chap_6.html#problem-64":{},"Chap_6.html#problem-65":{},"Chap_6.html#the-autocorrelation-function":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_6.html#the-mean":{},"Chap_7.html":{},"Chap_7.html#expected-value":{},"Chap_7.html#from-t-to-n":{},"Chap_7.html#problem-72":{},"Chap_7.html#problem-73":{},"Chap_8.html":{},"Chap_8.html#example-cocktail-party-noise":{},"Chap_8.html#example-filtering-noise":{},"Chap_8.html#problem-83":{},"Chap_9.html":{},"Chap_9.html#performance-in-the-presence-of-noise":{},"Chap_9.html#problem-91":{},"Chap_9.html#the-matched-filter":{},"info.html":{},"info.html#musical-data":{}},"title":{}}],["outsid",{"_index":117,"text":{"Chap_1.html":{},"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_13.html":{},"Chap_13.html#epilogue":{}},"title":{"Chap_1.html#outside-this-device":{}}}],["over",{"_index":432,"text":{"Chap_10.html":{},"Chap_10.html#correlation-returns":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#example-cleaning-up-our-act":{},"Chap_10.html#the-wiener-hopf-equation":{},"Chap_10.html#why-we-avoid-the-inverse-filter":{},"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#problem-122":{},"Chap_12.html#windowed-observations":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#example-fair-chance":{},"Chap_5.html":{},"Chap_5.html#laboratory-exercise-51":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{},"Chap_6.html#the-mean":{},"Chap_8.html":{},"Chap_8.html#problem-82":{},"Chap_9.html":{},"Chap_9.html#problem-91":{},"info.html":{},"info.html#acknowledgments":{}},"title":{}}],["over)simplif",{"_index":2761,"text":{"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{}},"title":{}}],["overdamp",{"_index":3390,"text":{"Chap_7.html":{},"Chap_7.html#problem-710":{}},"title":{}}],["overdamped\\,system",{"_index":3189,"text":{"Chap_7.html":{},"Chap_7.html#tethered-particle-motion":{}},"title":{}}],["overestim",{"_index":940,"text":{"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_13.html":{},"Chap_13.html#appendix-i-mean-square-error-minimization":{}},"title":{}}],["overestimate\u2014but",{"_index":1011,"text":{"Chap_11.html":{},"Chap_11.html#estimating-the-mean":{}},"title":{}}],["overlap",{"_index":1016,"text":{"Chap_11.html":{},"Chap_11.html#estimating-the-autocorrelation-function":{},"Chap_11.html#trouble-in-paradise":{},"Chap_12.html":{},"Chap_12.html#the-periodogram-what-about-convergence":{}},"title":{}}],["oversampl",{"_index":2895,"text":{"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{}},"title":{}}],["overwhelm",{"_index":622,"text":{"Chap_10.html":{},"Chap_10.html#why-we-avoid-the-inverse-filter":{}},"title":{}}],["oxford",{"_index":1798,"text":{"Chap_2.html":{},"Chap_2.html#problem-21":{},"Chap_7.html":{},"Chap_7.html#problem-711":{}},"title":{}}],["p",{"_index":863,"text":{"Chap_11.html":{},"Chap_11.html#maximum-likelihood-estimation":{},"Chap_11.html#problem-113":{},"Chap_12.html":{},"Chap_12.html#laboratory-exercise-124":{},"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#example-is-that-coin-fair":{},"Chap_4.html#laboratory-exercise-41":{},"Chap_4.html#laboratory-exercise-42":{},"Chap_5.html":{},"Chap_5.html#laboratory-exercise-51":{},"Chap_6.html":{},"Chap_6.html#problem-61":{},"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#one-step-further":{},"Chap_7.html#problem-711":{},"Chap_8.html":{},"Chap_8.html#problem-82":{}},"title":{}}],["p(",{"_index":3525,"text":{"Chap_8.html":{},"Chap_8.html#problem-82":{}},"title":{}}],["p(0",{"_index":2330,"text":{"Chap_4.html":{},"Chap_4.html#problem-42":{}},"title":{}}],["p(1)=p(2)=\\dots=p(6)=\\frac{1}{6",{"_index":1846,"text":{"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{}},"title":{}}],["p(\\alpha",{"_index":1861,"text":{"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{}},"title":{}}],["p(\\omega",{"_index":743,"text":{"Chap_10.html":{},"Chap_10.html#problem-102":{}},"title":{}}],["p(\\sqrt{2}),p(\\sqrt{5}),p(\\sqrt{8}),\\dots,p(6\\sqrt{2",{"_index":1983,"text":{"Chap_3.html":{},"Chap_3.html#problem-37":{}},"title":{}}],["p(h",{"_index":2070,"text":{"Chap_4.html":{},"Chap_4.html#example-fair-chance":{},"Chap_4.html#example-is-that-coin-fair":{},"Chap_4.html#problem-47":{}},"title":{}}],["p(head",{"_index":864,"text":{"Chap_11.html":{},"Chap_11.html#maximum-likelihood-estimation":{},"Chap_11.html#problem-113":{}},"title":{}}],["p(i",{"_index":1845,"text":{"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_4.html":{},"Chap_4.html#problem-41":{}},"title":{}}],["p(i)\\geq",{"_index":1850,"text":{"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{}},"title":{}}],["p(n",{"_index":1954,"text":{"Chap_3.html":{},"Chap_3.html#problem-34":{}},"title":{}}],["p(n)=a\\delta(n",{"_index":1955,"text":{"Chap_3.html":{},"Chap_3.html#problem-34":{}},"title":{}}],["p(n)=a\\frac{\\lambda^{n}",{"_index":1963,"text":{"Chap_3.html":{},"Chap_3.html#problem-34":{}},"title":{}}],["p(n|\\lambda",{"_index":885,"text":{"Chap_11.html":{},"Chap_11.html#example-estimating-the-poisson-rate":{},"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{}},"title":{}}],["p(q",{"_index":1551,"text":{"Chap_12.html":{},"Chap_12.html#problem-122":{}},"title":{}}],["p(r",{"_index":1981,"text":{"Chap_3.html":{},"Chap_3.html#problem-37":{}},"title":{}}],["p(t",{"_index":2072,"text":{"Chap_4.html":{},"Chap_4.html#example-fair-chance":{},"Chap_4.html#example-is-that-coin-fair":{},"Chap_4.html#problem-42":{},"Chap_4.html#problem-47":{}},"title":{}}],["p(x",{"_index":1952,"text":{"Chap_3.html":{},"Chap_3.html#problem-34":{},"Chap_4.html":{},"Chap_4.html#laboratory-exercise-42":{}},"title":{}}],["p(x)=\\begin{cases}a",{"_index":1959,"text":{"Chap_3.html":{},"Chap_3.html#problem-34":{}},"title":{}}],["p(x)=\\begin{cases}ax",{"_index":1970,"text":{"Chap_3.html":{},"Chap_3.html#problem-34":{}},"title":{}}],["p(x)=\\frac{a}{4+x^2}\\qquad",{"_index":1967,"text":{"Chap_3.html":{},"Chap_3.html#problem-34":{}},"title":{}}],["p(x[n",{"_index":2066,"text":{"Chap_4.html":{},"Chap_4.html#example-dice-money":{},"Chap_4.html#example-fair-chance":{},"Chap_4.html#laboratory-exercise-42":{}},"title":{}}],["p(x[n])&=\\text",{"_index":1885,"text":{"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{}},"title":{}}],["p(x[n],y[k",{"_index":2148,"text":{"Chap_4.html":{},"Chap_4.html#example-dice-money":{}},"title":{}}],["p(x[n]=i,x[m]=j)=p(x[n]=i)p(x[m]=j)\\quad",{"_index":1893,"text":{"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{}},"title":{}}],["p({n_i}|\\theta",{"_index":902,"text":{"Chap_11.html":{},"Chap_11.html#example-estimating-the-poisson-rate":{}},"title":{}}],["p({x_1},{x_2},{x_3},...,{x_n}|\\theta",{"_index":870,"text":{"Chap_11.html":{},"Chap_11.html#maximum-likelihood-estimation":{}},"title":{}}],["p({x_i}|\\theta",{"_index":859,"text":{"Chap_11.html":{},"Chap_11.html#maximum-likelihood-estimation":{}},"title":{}}],["p)d\\vec",{"_index":2092,"text":{"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{}},"title":{}}],["p[n",{"_index":741,"text":{"Chap_10.html":{},"Chap_10.html#problem-102":{},"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{}},"title":{}}],["p[n\\rbrack",{"_index":2586,"text":{"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{}},"title":{}}],["p\\left",{"_index":866,"text":{"Chap_11.html":{},"Chap_11.html#maximum-likelihood-estimation":{},"Chap_11.html#problem-112":{},"Chap_11.html#problem-114":{},"Chap_4.html":{},"Chap_4.html#the-mechanics-of-correlations":{}},"title":{}}],["p^*}(\\omega",{"_index":747,"text":{"Chap_10.html":{},"Chap_10.html#problem-102":{}},"title":{}}],["p_2}(q",{"_index":1553,"text":{"Chap_12.html":{},"Chap_12.html#problem-122":{}},"title":{}}],["p_2}(q)\\,{e",{"_index":1555,"text":{"Chap_12.html":{},"Chap_12.html#problem-122":{}},"title":{}}],["p_i",{"_index":2096,"text":{"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{}},"title":{}}],["p_n^{(k)}(\\omega",{"_index":1411,"text":{"Chap_12.html":{},"Chap_12.html#the-periodogram-what-about-convergence":{}},"title":{}}],["p_n^{(k)}\\left",{"_index":1408,"text":{"Chap_12.html":{},"Chap_12.html#the-periodogram-what-about-convergence":{}},"title":{}}],["p_n}(\\omega",{"_index":1313,"text":{"Chap_12.html":{},"Chap_12.html#the-periodogram-unbiased":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_12.html#windowed-observations":{}},"title":{}}],["p_{x,y}(\\alpha",{"_index":1897,"text":{"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{}},"title":{}}],["p_{x[n]}}(x,n",{"_index":2381,"text":{"Chap_4.html":{},"Chap_4.html#laboratory-exercise-42":{}},"title":{}}],["pacif",{"_index":1733,"text":{"Chap_13.html":{},"Chap_13.html#epilogue":{}},"title":{}}],["paganini",{"_index":166,"text":{"Chap_1.html":{},"Chap_1.html#sound-of-music":{},"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#example-sound-of-distorted-music":{},"Chap_10.html#problem-104":{},"info.html":{},"info.html#musical-data":{}},"title":{}}],["paganini\u2019",{"_index":644,"text":{"Chap_10.html":{},"Chap_10.html#example-sound-of-distorted-music":{}},"title":{}}],["page",{"_index":3645,"text":{"info.html":{},"info.html#tips-short-cuts":{}},"title":{}}],["pair",{"_index":1814,"text":{"Chap_3.html":{},"Chap_3.html#the-basics":{},"Chap_4.html":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_5.html":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_9.html":{},"Chap_9.html#problem-92":{}},"title":{}}],["palatino",{"_index":3718,"text":{"info.html":{},"info.html#technical-details":{}},"title":{}}],["panel",{"_index":2741,"text":{"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{},"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{}},"title":{}}],["paper",{"_index":3688,"text":{"info.html":{},"info.html#acknowledgments":{}},"title":{}}],["papouli",{"_index":377,"text":{"Chap_10.html":{},"Chap_10.html#laboratory-exercise-105":{},"Chap_10.html#using-the-least-mean-square-error-criterion":{},"Chap_10.html#what-is-that-least-mean-square-error":{},"Chap_13.html":{},"Chap_13.html#appendix-i-mean-square-error-minimization":{},"Chap_13.html#epilogue":{},"Chap_3.html":{},"Chap_3.html#problem-310":{},"Chap_5.html":{},"Chap_5.html#laboratory-exercise-51":{},"Chap_5.html#the-mechanics-of-correlations-redux":{}},"title":{}}],["parabol",{"_index":1523,"text":{"Chap_12.html":{},"Chap_12.html#problem-121":{}},"title":{}}],["paradis",{"_index":1143,"text":{"Chap_11.html":{}},"title":{"Chap_11.html#trouble-in-paradise":{}}}],["parallel",{"_index":3640,"text":{"Chap_9.html":{},"Chap_9.html#laboratory-exercise-93":{}},"title":{}}],["paramet",{"_index":811,"text":{"Chap_11.html":{},"Chap_11.html#aspects-of-estimation":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_11.html#estimating-the-autocorrelation-function":{},"Chap_11.html#estimating-the-mean":{},"Chap_11.html#example-estimating-the-poisson-rate":{},"Chap_11.html#laboratory-exercise-113":{},"Chap_11.html#langevin-redux":{},"Chap_11.html#maximum-likelihood-estimation":{},"Chap_11.html#problem-116":{},"Chap_11.html#trouble-in-paradise":{},"Chap_3.html":{},"Chap_3.html#problem-36":{},"Chap_4.html":{},"Chap_4.html#problem-44":{},"Chap_5.html":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_6.html":{},"Chap_6.html#laboratory-exercise-63":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function_1":{},"Chap_7.html#descriptive-statistic-variance":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#how-big-is-big-how-small-is-small":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#one-step-further":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#tethered-particle-motion":{},"Chap_7.html#why-this-case-study":{},"Chap_8.html":{},"Chap_8.html#problem-83":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{},"Chap_9.html":{},"Chap_9.html#setting-up-the-problem":{}},"title":{}}],["parameters\u2014characteristics\u2014of",{"_index":2392,"text":{"Chap_5.html":{},"Chap_5.html#correlations-simple-and-complex":{}},"title":{}}],["parameter\u2014for",{"_index":1184,"text":{"Chap_11.html":{},"Chap_11.html#problem-115":{}},"title":{}}],["parenthes",{"_index":2663,"text":{"Chap_6.html":{},"Chap_6.html#the-autocorrelation-function":{}},"title":{}}],["parseval\u2019",{"_index":531,"text":{"Chap_10.html":{},"Chap_10.html#problem-102":{},"Chap_10.html#what-is-that-least-mean-square-error":{},"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{}},"title":{}}],["part",{"_index":114,"text":{"Chap_1.html":{},"Chap_1.html#highlighting":{},"Chap_10.html":{},"Chap_10.html#problem-102":{},"Chap_11.html":{},"Chap_11.html#problem-114":{},"Chap_11.html#problem-117":{},"Chap_11.html#problem-119":{},"Chap_13.html":{},"Chap_13.html#epilogue":{},"Chap_3.html":{},"Chap_3.html#problem-38":{},"Chap_3.html#problem-39":{},"Chap_4.html":{},"Chap_4.html#problem-49":{},"Chap_5.html":{},"Chap_5.html#correlations-simple-and-complex":{},"Chap_5.html#problem-51":{},"Chap_6.html":{},"Chap_6.html#problem-64":{},"Chap_7.html":{},"Chap_7.html#problem-78":{},"Chap_7.html#tethered-particle-motion":{},"Chap_9.html":{},"Chap_9.html#laboratory-exercise-93":{},"Chap_9.html#problem-91":{}},"title":{}}],["parti",{"_index":3465,"text":{"Chap_8.html":{}},"title":{"Chap_8.html#example-cocktail-party-noise":{}}}],["partial",{"_index":352,"text":{"Chap_10.html":{},"Chap_10.html#using-the-least-mean-square-error-criterion":{},"Chap_11.html":{},"Chap_11.html#example-estimating-the-poisson-rate":{},"Chap_13.html":{},"Chap_13.html#appendix-i-mean-square-error-minimization":{}},"title":{}}],["particl",{"_index":2324,"text":{"Chap_4.html":{},"Chap_4.html#problem-42":{},"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#expected-value":{},"Chap_7.html#expected-value_1":{},"Chap_7.html#how-big-is-big-how-small-is-small":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#one-step-further":{},"Chap_7.html#problem-711":{},"Chap_7.html#problem-79":{},"Chap_7.html#tethered-particle-motion":{},"Chap_7.html#the-langevin-equation-a-case-study":{},"Chap_7.html#the-langevin-velocity-equation":{},"Chap_7.html#why-this-case-study":{},"Chap_8.html":{},"Chap_8.html#problem-83":{}},"title":{"Chap_7.html#tethered-particle-motion":{}}}],["particular",{"_index":242,"text":{"Chap_1.html":{},"Chap_1.html#enhanced-experience":{},"Chap_12.html":{},"Chap_12.html#windowed-observations":{},"Chap_2.html":{},"Chap_2.html#prologue":{},"Chap_4.html":{},"Chap_4.html#example-is-that-coin-fair":{},"Chap_4.html#the-ergodic-process":{},"Chap_5.html":{},"Chap_5.html#example-white-noise":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_9.html":{},"Chap_9.html#problem-92":{}},"title":{}}],["parzen",{"_index":1434,"text":{"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#other-windows":{},"Chap_12.html#problem-121":{}},"title":{}}],["pascal",{"_index":1759,"text":{"Chap_2.html":{},"Chap_2.html#prologue":{}},"title":{}}],["pass",{"_index":572,"text":{"Chap_10.html":{},"Chap_10.html#classic-example-classic-result":{},"Chap_10.html#example-sound-of-distorted-music":{},"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_4.html":{},"Chap_4.html#example-is-that-coin-fair":{},"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_7.html":{},"Chap_7.html#power-spectral-density_1":{},"Chap_8.html":{},"Chap_8.html#characterizing-signal-to-noise-ratios":{},"Chap_8.html#problem-83":{}},"title":{}}],["passband",{"_index":2682,"text":{"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{}},"title":{}}],["past",{"_index":2292,"text":{"Chap_4.html":{},"Chap_4.html#describing-the-time-average":{}},"title":{}}],["patholog",{"_index":2471,"text":{"Chap_5.html":{},"Chap_5.html#a-digression":{}},"title":{}}],["patienc",{"_index":3694,"text":{"info.html":{},"info.html#acknowledgments":{}},"title":{}}],["pattern",{"_index":1801,"text":{"Chap_2.html":{},"Chap_2.html#problem-21":{},"Chap_8.html":{},"Chap_8.html#example-not-too-noisy":{}},"title":{}}],["paul",{"_index":2790,"text":{"Chap_7.html":{},"Chap_7.html#the-langevin-equation-a-case-study":{}},"title":{}}],["pay",{"_index":2351,"text":{"Chap_4.html":{},"Chap_4.html#problem-47":{},"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{}},"title":{}}],["pdf",{"_index":1873,"text":{"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{}},"title":{}}],["peak",{"_index":2562,"text":{"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_9.html":{},"Chap_9.html#laboratory-exercise-91":{},"Chap_9.html#performance-in-the-presence-of-noise":{}},"title":{}}],["peak\u2014a",{"_index":2554,"text":{"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{}},"title":{}}],["penetr",{"_index":3159,"text":{"Chap_7.html":{},"Chap_7.html#tethered-particle-motion":{}},"title":{}}],["peopl",{"_index":3674,"text":{"info.html":{},"info.html#acknowledgments":{}},"title":{}}],["per",{"_index":892,"text":{"Chap_11.html":{},"Chap_11.html#example-estimating-the-poisson-rate":{},"Chap_12.html":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{}},"title":{}}],["perceiv",{"_index":2615,"text":{"Chap_5.html":{},"Chap_5.html#laboratory-exercise-51":{}},"title":{}}],["percept",{"_index":3516,"text":{"Chap_8.html":{},"Chap_8.html#problem-82":{}},"title":{}}],["perform",{"_index":654,"text":{"Chap_10.html":{},"Chap_10.html#example-sound-of-distorted-music":{},"Chap_11.html":{},"Chap_11.html#problem-113":{},"Chap_11.html#problem-119":{},"Chap_12.html":{},"Chap_12.html#problem-122":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_5.html":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_6.html":{},"Chap_6.html#the-autocorrelation-function":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function":{},"Chap_7.html#how-big-is-big-how-small-is-small":{},"Chap_8.html":{},"Chap_8.html#example-filtering-noise":{},"Chap_9.html":{}},"title":{"Chap_9.html#performance-in-the-presence-of-noise":{}}}],["perhap",{"_index":774,"text":{"Chap_10.html":{},"Chap_10.html#laboratory-exercise-105":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_9.html":{},"Chap_9.html#problem-91":{}},"title":{}}],["period",{"_index":1620,"text":{"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_3.html#problem-32":{},"Chap_3.html#problem-39":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#example-pink-noise":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#descriptive-statistic-variance":{},"Chap_7.html#how-big-is-big-how-small-is-small":{},"Chap_7.html#impulse-invariant-sampling":{},"Chap_7.html#power-spectral-density_2":{},"Chap_7.html#problem-79":{}},"title":{"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#choosing-the-sampling-period_1":{}}}],["periodogram",{"_index":1297,"text":{"Chap_12.html":{},"Chap_12.html#the-periodogram-unbiased":{},"Chap_12.html#the-periodogram-what-about-convergence":{}},"title":{"Chap_12.html#the-periodogram-unbiased":{},"Chap_12.html#the-periodogram-what-about-convergence":{}}}],["perman",{"_index":993,"text":{"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{}},"title":{}}],["permiss",{"_index":3749,"text":{"info.html":{},"info.html#usage":{}},"title":{}}],["permit",{"_index":2502,"text":{"Chap_5.html":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{}},"title":{}}],["persist",{"_index":3227,"text":{"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#one-step-further":{}},"title":{}}],["phenomena",{"_index":3023,"text":{"Chap_7.html":{},"Chap_7.html#the-langevin-position-equation":{},"Chap_7.html#why-this-case-study":{}},"title":{}}],["phenomenon",{"_index":1276,"text":{"Chap_12.html":{},"Chap_12.html#spectral-estimation":{},"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{}},"title":{}}],["phi",{"_index":1046,"text":{"Chap_11.html":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_11.html#langevin-redux":{},"Chap_11.html#problem-119":{},"Chap_11.html#trouble-in-paradise":{},"info.html":{},"info.html#technical-details":{}},"title":{}}],["phonorecord",{"_index":227,"text":{"Chap_1.html":{},"Chap_1.html#enhanced-experience":{}},"title":{}}],["photoelectron",{"_index":3491,"text":{"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{}},"title":{}}],["photomultipli",{"_index":3531,"text":{"Chap_8.html":{},"Chap_8.html#problem-83":{}},"title":{}}],["photon",{"_index":896,"text":{"Chap_11.html":{},"Chap_11.html#example-estimating-the-poisson-rate":{},"Chap_11.html#problem-114":{},"Chap_2.html":{},"Chap_2.html#prologue":{},"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{}},"title":{}}],["phrase",{"_index":2361,"text":{"Chap_4.html":{},"Chap_4.html#problem-49":{}},"title":{}}],["physic",{"_index":857,"text":{"Chap_11.html":{},"Chap_11.html#aspects-of-estimation":{},"Chap_11.html#problem-119":{},"Chap_12.html":{},"Chap_12.html#problem-123":{},"Chap_2.html":{},"Chap_2.html#prologue":{},"Chap_3.html":{},"Chap_3.html#problem-310":{},"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#laboratory-exercise-42":{},"Chap_4.html#properties-of-averaging":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_7.html":{},"Chap_7.html#descriptive-statistic-variance":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#problem-71":{},"Chap_7.html#problem-711":{},"Chap_7.html#problem-78":{},"Chap_7.html#problem-79":{},"Chap_7.html#the-langevin-equation-a-case-study":{},"Chap_7.html#why-this-case-study":{},"Chap_8.html":{},"Chap_8.html#problem-82":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{}},"title":{}}],["physiolog",{"_index":3546,"text":{"Chap_8.html":{},"Chap_8.html#problem-83":{}},"title":{}}],["pi",{"_index":501,"text":{"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#example-cleaning-up-our-act":{},"Chap_10.html#problem-102":{},"Chap_10.html#problem-104":{},"Chap_10.html#what-is-that-least-mean-square-error":{},"Chap_10.html#why-we-avoid-the-inverse-filter":{},"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_3.html":{},"Chap_3.html#problem-32":{},"Chap_3.html#problem-39":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#example-pink-noise":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_5.html#problem-56":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#how-big-is-big-how-small-is-small":{},"Chap_7.html#power-spectral-density":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#power-spectral-density_2":{},"Chap_8.html":{},"Chap_8.html#example-cocktail-party-noise":{},"Chap_8.html#problem-83":{},"Chap_9.html":{},"Chap_9.html#example-matching-your-filter":{},"Chap_9.html#laboratory-exercise-93":{},"Chap_9.html#setting-up-the-problem":{},"Chap_9.html#using-cauchy-schwartz":{}},"title":{}}],["pi\\delta(\\omega",{"_index":2004,"text":{"Chap_3.html":{},"Chap_3.html#problem-39":{}},"title":{}}],["piano",{"_index":1576,"text":{"Chap_12.html":{},"Chap_12.html#problem-123":{}},"title":{}}],["piecewis",{"_index":1638,"text":{"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{}},"title":{}}],["piet",{"_index":3678,"text":{"info.html":{},"info.html#acknowledgments":{}},"title":{}}],["pillai",{"_index":2049,"text":{"Chap_3.html":{},"Chap_3.html#problem-310":{}},"title":{}}],["pinch",{"_index":3655,"text":{"info.html":{},"info.html#tips-short-cuts":{}},"title":{}}],["pink",{"_index":93,"text":{"Chap_1.html":{},"Chap_1.html#highlighting":{},"Chap_5.html":{},"Chap_5.html#example-pink-noise":{},"Chap_7.html":{},"Chap_7.html#power-spectral-density":{}},"title":{"Chap_5.html#example-pink-noise":{}}}],["pioneer",{"_index":1781,"text":{"Chap_2.html":{},"Chap_2.html#prologue":{}},"title":{}}],["pivot",{"_index":1371,"text":{"Chap_12.html":{},"Chap_12.html#the-periodogram-what-about-convergence":{}},"title":{}}],["pixel",{"_index":2367,"text":{"Chap_4.html":{},"Chap_4.html#laboratory-exercise-42":{}},"title":{}}],["pi}^{+\\pi}x(\\omega)e^{+j\\omega",{"_index":1820,"text":{"Chap_3.html":{},"Chap_3.html#the-basics":{}},"title":{}}],["place",{"_index":128,"text":{"Chap_1.html":{},"Chap_1.html#outside-this-device":{},"info.html":{},"info.html#technical-details":{}},"title":{}}],["placement",{"_index":988,"text":{"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{}},"title":{}}],["plaintiv",{"_index":1788,"text":{"Chap_2.html":{},"Chap_2.html#prologue":{}},"title":{}}],["plan",{"_index":2111,"text":{"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{}},"title":{}}],["plane",{"_index":3240,"text":{"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{}},"title":{}}],["play",{"_index":156,"text":{"Chap_1.html":{},"Chap_1.html#at-the-movies":{},"Chap_1.html#sound-of-music":{},"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#example-sound-of-distorted-music":{},"Chap_4.html":{},"Chap_4.html#problem-47":{},"Chap_8.html":{},"Chap_8.html#example-filtering-noise":{}},"title":{}}],["playback",{"_index":154,"text":{"Chap_1.html":{},"Chap_1.html#sound-of-music":{}},"title":{}}],["player",{"_index":990,"text":{"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_4.html":{},"Chap_4.html#problem-47":{},"info.html":{},"info.html#technical-details":{}},"title":{}}],["pleas",{"_index":748,"text":{"Chap_10.html":{},"Chap_10.html#problem-102":{}},"title":{}}],["plot",{"_index":638,"text":{"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#example-cleaning-up-our-act":{},"Chap_10.html#why-we-avoid-the-inverse-filter":{},"Chap_11.html":{},"Chap_11.html#langevin-redux":{},"Chap_12.html":{},"Chap_12.html#problem-122":{},"Chap_12.html#windowed-observations":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#example-pink-noise":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function_1":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#power-spectral-density":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#power-spectral-density_2":{}},"title":{}}],["plotli",{"_index":3714,"text":{"info.html":{},"info.html#technical-details":{}},"title":{}}],["plu",{"_index":2504,"text":{"Chap_5.html":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{}},"title":{}}],["pm",{"_index":1095,"text":{"Chap_11.html":{},"Chap_11.html#langevin-redux":{},"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_6.html":{},"Chap_6.html#problem-66":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_9.html":{},"Chap_9.html#laboratory-exercise-93":{}},"title":{}}],["pn",{"_index":3235,"text":{"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#power-spectral-density_2":{}},"title":{}}],["point",{"_index":195,"text":{"Chap_1.html":{},"Chap_1.html#enhanced-experience":{},"Chap_10.html":{},"Chap_10.html#problem-101":{},"Chap_11.html":{},"Chap_11.html#example-estimating-the-poisson-rate":{},"Chap_12.html":{},"Chap_12.html#the-periodogram-unbiased":{},"Chap_2.html":{},"Chap_2.html#prologue":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_3.html#introduction":{},"Chap_3.html#what-is-a-random-signal":{},"Chap_4.html":{},"Chap_4.html#correlation-the-workhorse":{},"Chap_4.html#laboratory-exercise-42":{},"Chap_4.html#properties-of-averaging":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_5.html":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function":{},"Chap_7.html#tethered-particle-motion":{},"Chap_9.html":{},"Chap_9.html#the-matched-filter-as-an-autocorrelation":{}},"title":{}}],["poison",{"_index":2325,"text":{"Chap_4.html":{},"Chap_4.html#problem-42":{}},"title":{}}],["poisson",{"_index":882,"text":{"Chap_11.html":{},"Chap_11.html#example-estimating-the-poisson-rate":{},"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{}},"title":{"Chap_11.html#example-estimating-the-poisson-rate":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{}}}],["pole",{"_index":3239,"text":{"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#power-spectral-density_2":{},"Chap_7.html#problem-710":{}},"title":{}}],["polici",{"_index":187,"text":{"Chap_1.html":{},"Chap_1.html#at-the-movies":{},"info.html":{},"info.html#tips-short-cuts":{},"info.html#venue":{}},"title":{}}],["polym",{"_index":3131,"text":{"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#problem-711":{},"Chap_7.html#tethered-particle-motion":{}},"title":{}}],["polynomi",{"_index":1447,"text":{"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#problem-122":{}},"title":{}}],["polystyren",{"_index":3197,"text":{"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{}},"title":{}}],["poor",{"_index":776,"text":{"Chap_10.html":{},"Chap_10.html#laboratory-exercise-105":{},"Chap_12.html":{},"Chap_12.html#the-periodogram-what-about-convergence":{}},"title":{}}],["popul",{"_index":3494,"text":{"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{}},"title":{}}],["porat",{"_index":2283,"text":{"Chap_4.html":{},"Chap_4.html#example-is-that-coin-fair":{},"Chap_4.html#laboratory-exercise-42":{},"Chap_5.html":{},"Chap_5.html#example-white-noise":{},"Chap_5.html#laboratory-exercise-51":{}},"title":{}}],["portion",{"_index":252,"text":{"Chap_1.html":{},"Chap_1.html#enhanced-experience":{},"Chap_12.html":{},"Chap_12.html#problem-123":{}},"title":{}}],["pose",{"_index":2744,"text":{"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{}},"title":{}}],["posit",{"_index":214,"text":{"Chap_1.html":{},"Chap_1.html#enhanced-experience":{},"Chap_10.html":{},"Chap_10.html#example-sound-of-distorted-music":{},"Chap_11.html":{},"Chap_11.html#estimating-the-autocorrelation-function":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_12.html":{},"Chap_12.html#problem-121":{},"Chap_12.html#problem-123":{},"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#example-is-that-coin-fair":{},"Chap_4.html#properties-of-averaging":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function_1":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#descriptive-statistic-variance":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#expected-value":{},"Chap_7.html#expected-value_1":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#power-spectral-density_2":{},"Chap_7.html#problem-72":{},"Chap_7.html#problem-76":{},"Chap_7.html#tethered-particle-motion":{},"Chap_7.html#the-langevin-equation-a-case-study":{},"Chap_7.html#the-langevin-position-equation":{},"Chap_9.html":{},"Chap_9.html#performance-in-the-presence-of-noise":{}},"title":{"Chap_7.html#the-langevin-position-equation":{}}}],["positron",{"_index":2321,"text":{"Chap_4.html":{},"Chap_4.html#problem-42":{}},"title":{}}],["possibl",{"_index":31,"text":{"Chap_1.html":{},"Chap_1.html#enhanced-experience":{},"Chap_1.html#how-to-use-this-ibook":{},"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#the-wiener-hopf-equation":{},"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#laboratory-exercise-122":{},"Chap_12.html#other-windows":{},"Chap_12.html#problem-122":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_12.html#windowed-observations":{},"Chap_13.html":{},"Chap_13.html#epilogue":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_3.html#problem-310":{},"Chap_3.html#problem-38":{},"Chap_4.html":{},"Chap_4.html#correlation-the-workhorse":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#describing-the-time-average":{},"Chap_4.html#example-average-experience":{},"Chap_4.html#example-dice-money":{},"Chap_4.html#example-fair-chance":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_6.html":{},"Chap_6.html#problem-61":{},"Chap_6.html#problem-64":{},"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small":{},"Chap_7.html#problem-79":{},"Chap_7.html#tethered-particle-motion":{},"Chap_9.html":{},"Chap_9.html#problem-92":{},"Chap_9.html#the-matched-filter":{}},"title":{}}],["potenti",{"_index":257,"text":{"Chap_1.html":{},"Chap_1.html#enhanced-experience":{},"Chap_4.html":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period_1":{}},"title":{}}],["power",{"_index":564,"text":{"Chap_10.html":{},"Chap_10.html#classic-example-classic-result":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#example-cleaning-up-our-act":{},"Chap_10.html#example-sound-of-distorted-music":{},"Chap_10.html#problem-103":{},"Chap_10.html#why-we-avoid-the-inverse-filter":{},"Chap_11.html":{},"Chap_11.html#problem-119":{},"Chap_11.html#trouble-in-paradise":{},"Chap_12.html":{},"Chap_12.html#problem-122":{},"Chap_12.html#spectral-estimation":{},"Chap_12.html#the-periodogram-unbiased":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_12.html#windowed-observations":{},"Chap_13.html":{},"Chap_13.html#epilogue":{},"Chap_5.html":{},"Chap_5.html#example-pink-noise":{},"Chap_5.html#example-white-noise":{},"Chap_5.html#fourier-description-of-correlation-functions":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_5.html#problem-56":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_6.html":{},"Chap_6.html#laboratory-exercise-63":{},"Chap_6.html#laboratory-exercise-67":{},"Chap_6.html#problem-64":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#power-spectral-density":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#power-spectral-density_2":{},"Chap_7.html#problem-73":{},"Chap_7.html#problem-75":{},"Chap_7.html#problem-76":{},"Chap_7.html#why-this-case-study":{},"Chap_8.html":{},"Chap_8.html#example-cocktail-party-noise":{},"Chap_8.html#example-filtering-noise":{},"Chap_8.html#problem-81":{},"Chap_8.html#problem-83":{},"Chap_9.html":{},"Chap_9.html#the-classic-example":{},"info.html":{},"info.html#cover":{}},"title":{"Chap_5.html#examples-of-power-spectra":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_7.html#power-spectral-density":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#power-spectral-density_2":{}}}],["powerpoint",{"_index":3710,"text":{"info.html":{},"info.html#technical-details":{}},"title":{}}],["power\u2014at",{"_index":2555,"text":{"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{}},"title":{}}],["practic",{"_index":881,"text":{"Chap_11.html":{},"Chap_11.html#maximum-likelihood-estimation":{},"Chap_12.html":{},"Chap_12.html#laboratory-exercise-121":{},"Chap_4.html":{},"Chap_4.html#problem-47":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{}},"title":{}}],["precis",{"_index":623,"text":{"Chap_10.html":{},"Chap_10.html#why-we-avoid-the-inverse-filter":{},"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_11.html#laboratory-exercise-112":{},"Chap_2.html":{},"Chap_2.html#problem-21":{},"Chap_3.html":{},"Chap_3.html#problem-310":{},"Chap_4.html":{},"Chap_4.html#cross-covariance":{},"Chap_6.html":{},"Chap_6.html#the-autocorrelation-function":{},"Chap_7.html":{},"Chap_7.html#tethered-particle-motion":{}},"title":{}}],["predict",{"_index":1221,"text":{"Chap_11.html":{},"Chap_11.html#problem-118":{},"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_2.html":{},"Chap_2.html#problem-21":{},"Chap_2.html#prologue":{},"Chap_4.html":{},"Chap_4.html#correlation-the-workhorse":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_5.html":{},"Chap_8.html":{},"Chap_8.html#snr-for-random-signals-in-the-presence-of-noise":{}},"title":{"Chap_5.html#predicting-the-natural-climate-a-case-study":{}}}],["predictor",{"_index":1220,"text":{"Chap_11.html":{},"Chap_11.html#problem-118":{}},"title":{}}],["prefer",{"_index":849,"text":{"Chap_11.html":{},"Chap_11.html#aspects-of-estimation":{}},"title":{}}],["prentic",{"_index":782,"text":{"Chap_10.html":{},"Chap_10.html#laboratory-exercise-105":{},"Chap_3.html":{},"Chap_3.html#problem-310":{},"Chap_4.html":{},"Chap_4.html#laboratory-exercise-42":{},"Chap_5.html":{},"Chap_5.html#laboratory-exercise-51":{},"Chap_7.html":{},"Chap_7.html#problem-711":{}},"title":{}}],["prepar",{"_index":14,"text":{"Chap_1.html":{},"Chap_1.html#how-to-use-this-ibook":{},"Chap_10.html":{},"Chap_10.html#laboratory-exercise-105":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"info.html":{},"info.html#technical-details":{}},"title":{}}],["prepend",{"_index":212,"text":{"Chap_1.html":{},"Chap_1.html#enhanced-experience":{}},"title":{}}],["presenc",{"_index":284,"text":{"Chap_10.html":{},"Chap_10.html#laboratory-exercise-102":{},"Chap_10.html#the-restoration-case-noise":{},"Chap_10.html#the-wiener-filter":{},"Chap_8.html":{},"Chap_9.html":{},"Chap_9.html#laboratory-exercise-91":{},"Chap_9.html#problem-92":{}},"title":{"Chap_8.html#snr-for-deterministic-signals-in-the-presence-of-noise":{},"Chap_8.html#snr-for-random-signals-in-the-presence-of-noise":{},"Chap_9.html#performance-in-the-presence-of-noise":{}}}],["present",{"_index":32,"text":{"Chap_1.html":{},"Chap_1.html#how-to-use-this-ibook":{},"Chap_10.html":{},"Chap_10.html#laboratory-exercise-105":{},"Chap_11.html":{},"Chap_11.html#langevin-redux":{},"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#problem-121":{},"Chap_12.html#spectral-estimation":{},"Chap_13.html":{},"Chap_13.html#epilogue":{},"Chap_2.html":{},"Chap_2.html#prologue":{},"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#describing-the-time-average":{},"Chap_4.html#problem-44":{},"Chap_5.html":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_6.html":{},"Chap_6.html#laboratory-exercise-64":{},"Chap_6.html#laboratory-exercise-65":{},"Chap_6.html#laboratory-exercise-66":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#how-big-is-big-how-small-is-small":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#tethered-particle-motion":{},"info.html":{},"info.html#musical-data":{},"info.html#weather-data":{}},"title":{}}],["press",{"_index":1269,"text":{"Chap_11.html":{},"Chap_11.html#laboratory-exercise-113":{},"Chap_12.html":{},"Chap_12.html#laboratory-exercise-124":{},"Chap_3.html":{},"Chap_3.html#problem-310":{},"Chap_4.html":{},"Chap_4.html#laboratory-exercise-42":{},"Chap_7.html":{},"Chap_7.html#problem-711":{}},"title":{}}],["pressur",{"_index":2424,"text":{"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_5.html#the-mechanics-of-correlations-redux":{}},"title":{}}],["presum",{"_index":3617,"text":{"Chap_9.html":{},"Chap_9.html#problem-92":{}},"title":{}}],["pretti",{"_index":769,"text":{"Chap_10.html":{},"Chap_10.html#laboratory-exercise-103":{}},"title":{}}],["prevent",{"_index":190,"text":{"Chap_1.html":{},"Chap_1.html#enhanced-experience":{},"Chap_4.html":{},"Chap_4.html#example-dice-money":{}},"title":{}}],["previou",{"_index":213,"text":{"Chap_1.html":{},"Chap_1.html#enhanced-experience":{},"Chap_10.html":{},"Chap_10.html#the-wiener-filter":{},"Chap_12.html":{},"Chap_12.html#other-windows":{},"Chap_12.html#spectral-estimation":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_3.html":{},"Chap_3.html#problem-38":{},"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"info.html":{},"info.html#tips-short-cuts":{}},"title":{}}],["previous",{"_index":1428,"text":{"Chap_12.html":{},"Chap_12.html#other-windows":{},"Chap_4.html":{},"Chap_4.html#example-is-that-coin-fair":{}},"title":{}}],["price",{"_index":2714,"text":{"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{},"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{}},"title":{}}],["primarili",{"_index":56,"text":{"Chap_1.html":{},"Chap_1.html#how-to-use-this-ibook":{}},"title":{}}],["princeton",{"_index":1271,"text":{"Chap_11.html":{},"Chap_11.html#laboratory-exercise-113":{},"Chap_3.html":{},"Chap_3.html#problem-310":{},"Chap_4.html":{},"Chap_4.html#laboratory-exercise-42":{}},"title":{}}],["principl",{"_index":452,"text":{"Chap_10.html":{},"Chap_10.html#the-wiener-hopf-equation":{},"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#problem-122":{},"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#problem-47":{},"Chap_9.html":{},"Chap_9.html#laboratory-exercise-93":{}},"title":{"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{}}}],["prior",{"_index":730,"text":{"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#laboratory-exercise-105":{}},"title":{}}],["privaci",{"_index":3658,"text":{"info.html":{},"info.html#tips-short-cuts":{},"info.html#venue":{}},"title":{}}],["probabilist",{"_index":2294,"text":{"Chap_4.html":{},"Chap_4.html#describing-the-time-average":{}},"title":{}}],["probability\\,1",{"_index":2767,"text":{"Chap_6.html":{},"Chap_6.html#problem-61":{}},"title":{}}],["probability\\,p",{"_index":2766,"text":{"Chap_6.html":{},"Chap_6.html#problem-61":{}},"title":{}}],["probabl",{"_index":858,"text":{"Chap_11.html":{},"Chap_11.html#example-estimating-the-poisson-rate":{},"Chap_11.html#laboratory-exercise-113":{},"Chap_11.html#maximum-likelihood-estimation":{},"Chap_11.html#problem-112":{},"Chap_11.html#problem-113":{},"Chap_11.html#problem-114":{},"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_2.html":{},"Chap_2.html#problem-21":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_3.html#problem-310":{},"Chap_3.html#problem-34":{},"Chap_3.html#problem-35":{},"Chap_3.html#problem-36":{},"Chap_3.html#problem-37":{},"Chap_3.html#the-basics":{},"Chap_3.html#what-is-a-random-signal":{},"Chap_4.html":{},"Chap_4.html#autocorrelation":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#example-dice-money":{},"Chap_4.html#example-fair-chance":{},"Chap_4.html#example-is-that-coin-fair":{},"Chap_4.html#laboratory-exercise-41":{},"Chap_4.html#laboratory-exercise-42":{},"Chap_4.html#problem-41":{},"Chap_4.html#problem-42":{},"Chap_4.html#problem-44":{},"Chap_4.html#problem-45":{},"Chap_4.html#problem-47":{},"Chap_4.html#the-ergodic-process":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_5.html":{},"Chap_5.html#correlations-simple-and-complex":{},"Chap_5.html#laboratory-exercise-51":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_6.html":{},"Chap_6.html#interpretation-of-the-convolution-result":{},"Chap_6.html#problem-61":{},"Chap_7.html":{},"Chap_7.html#expected-value":{},"Chap_7.html#the-langevin-equation-a-case-study":{},"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{},"Chap_9.html":{},"Chap_9.html#the-matched-filter":{}},"title":{}}],["problem",{"_index":142,"text":{"Chap_1.html":{},"Chap_1.html#getting-around":{},"Chap_10.html":{},"Chap_10.html#classic-example-classic-result":{},"Chap_10.html#example-cleaning-up-our-act":{},"Chap_10.html#laboratory-exercise-105":{},"Chap_10.html#the-more-general-restoration-case-noise-distortion":{},"Chap_10.html#the-wiener-filter":{},"Chap_10.html#using-the-least-mean-square-error-criterion":{},"Chap_10.html#what-is-that-least-mean-square-error":{},"Chap_10.html#why-we-avoid-the-inverse-filter":{},"Chap_11.html":{},"Chap_11.html#aspects-of-estimation":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_11.html#estimating-the-autocorrelation-function":{},"Chap_11.html#example-estimating-the-poisson-rate":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_11.html#laboratory-exercise-111":{},"Chap_11.html#langevin-redux":{},"Chap_11.html#problem-1110":{},"Chap_11.html#problem-116":{},"Chap_11.html#problem-117":{},"Chap_11.html#trouble-in-paradise":{},"Chap_12.html":{},"Chap_12.html#laboratory-exercise-124":{},"Chap_12.html#other-windows":{},"Chap_12.html#problem-122":{},"Chap_12.html#problem-123":{},"Chap_12.html#spectral-estimation":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_2.html":{},"Chap_2.html#prologue":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_3.html#problem-310":{},"Chap_3.html#the-basics":{},"Chap_3.html#what-is-a-random-signal":{},"Chap_4.html":{},"Chap_4.html#auto-covariance":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#example-dice-money":{},"Chap_4.html#example-is-that-coin-fair":{},"Chap_4.html#problem-44":{},"Chap_4.html#properties-of-averaging":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#correlations-and-memory":{},"Chap_5.html#correlations-simple-and-complex":{},"Chap_5.html#problem-53":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function_2":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#descriptive-statistic-variance":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#expected-value":{},"Chap_7.html#impulse-invariant-sampling":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#power-spectral-density_2":{},"Chap_7.html#the-langevin-equation-a-case-study":{},"Chap_8.html":{},"Chap_8.html#example-cocktail-party-noise":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{},"Chap_9.html":{},"Chap_9.html#the-matched-filter-as-an-autocorrelation":{}},"title":{"Chap_10.html#problem-101":{},"Chap_10.html#problem-102":{},"Chap_10.html#problem-103":{},"Chap_10.html#problem-104":{},"Chap_10.html#problems":{},"Chap_11.html#problem-111":{},"Chap_11.html#problem-1110":{},"Chap_11.html#problem-112":{},"Chap_11.html#problem-113":{},"Chap_11.html#problem-114":{},"Chap_11.html#problem-115":{},"Chap_11.html#problem-116":{},"Chap_11.html#problem-117":{},"Chap_11.html#problem-118":{},"Chap_11.html#problem-119":{},"Chap_11.html#problems":{},"Chap_12.html#problem-121":{},"Chap_12.html#problem-122":{},"Chap_12.html#problem-123":{},"Chap_12.html#problems":{},"Chap_2.html#problem-21":{},"Chap_2.html#problems":{},"Chap_3.html#problem-31":{},"Chap_3.html#problem-310":{},"Chap_3.html#problem-32":{},"Chap_3.html#problem-33":{},"Chap_3.html#problem-34":{},"Chap_3.html#problem-35":{},"Chap_3.html#problem-36":{},"Chap_3.html#problem-37":{},"Chap_3.html#problem-38":{},"Chap_3.html#problem-39":{},"Chap_3.html#problems":{},"Chap_4.html#problem-41":{},"Chap_4.html#problem-42":{},"Chap_4.html#problem-43":{},"Chap_4.html#problem-44":{},"Chap_4.html#problem-45":{},"Chap_4.html#problem-46":{},"Chap_4.html#problem-47":{},"Chap_4.html#problem-48":{},"Chap_4.html#problem-49":{},"Chap_4.html#problems":{},"Chap_5.html#problem-51":{},"Chap_5.html#problem-52":{},"Chap_5.html#problem-53":{},"Chap_5.html#problem-54":{},"Chap_5.html#problem-55":{},"Chap_5.html#problem-56":{},"Chap_5.html#problems":{},"Chap_6.html#problem-61":{},"Chap_6.html#problem-62":{},"Chap_6.html#problem-63":{},"Chap_6.html#problem-64":{},"Chap_6.html#problem-65":{},"Chap_6.html#problem-66":{},"Chap_6.html#problems":{},"Chap_7.html#problem-71":{},"Chap_7.html#problem-710":{},"Chap_7.html#problem-711":{},"Chap_7.html#problem-72":{},"Chap_7.html#problem-73":{},"Chap_7.html#problem-74":{},"Chap_7.html#problem-75":{},"Chap_7.html#problem-76":{},"Chap_7.html#problem-77":{},"Chap_7.html#problem-78":{},"Chap_7.html#problem-79":{},"Chap_7.html#problems":{},"Chap_8.html#problem-81":{},"Chap_8.html#problem-82":{},"Chap_8.html#problem-83":{},"Chap_8.html#problems":{},"Chap_9.html#problem-91":{},"Chap_9.html#problem-92":{},"Chap_9.html#problems":{},"Chap_9.html#setting-up-the-problem":{}}}],["proce",{"_index":536,"text":{"Chap_10.html":{},"Chap_10.html#classic-example-classic-result":{},"Chap_6.html":{},"Chap_6.html#the-autocorrelation-function":{},"Chap_8.html":{},"Chap_8.html#problem-82":{}},"title":{}}],["procedur",{"_index":970,"text":{"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_12.html":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_13.html":{},"Chap_13.html#appendix-i-mean-square-error-minimization":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_4.html":{},"Chap_4.html#autocorrelation":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function_2":{},"Chap_7.html#from-t-to-n":{},"Chap_7.html#power-spectral-density_1":{},"info.html":{},"info.html#technical-details":{}},"title":{}}],["procedures\u2014a.k.a",{"_index":909,"text":{"Chap_11.html":{},"Chap_11.html#example-estimating-the-poisson-rate":{}},"title":{}}],["proceed",{"_index":3005,"text":{"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#problem-77":{}},"title":{}}],["process",{"_index":169,"text":{"Chap_1.html":{},"Chap_1.html#at-the-movies":{},"Chap_10.html":{},"Chap_10.html#laboratory-exercise-105":{},"Chap_10.html#the-restoration-case-noise":{},"Chap_10.html#the-wiener-filter":{},"Chap_10.html#the-wiener-hopf-equation":{},"Chap_11.html":{},"Chap_11.html#aspects-of-estimation":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_11.html#estimating-the-autocorrelation-function":{},"Chap_11.html#estimating-the-mean":{},"Chap_11.html#example-estimating-the-poisson-rate":{},"Chap_11.html#langevin-redux":{},"Chap_11.html#maximum-likelihood-estimation":{},"Chap_11.html#problem-113":{},"Chap_11.html#problem-115":{},"Chap_11.html#problem-117":{},"Chap_11.html#problem-119":{},"Chap_12.html":{},"Chap_12.html#spectral-estimation":{},"Chap_12.html#windowed-observations":{},"Chap_13.html":{},"Chap_13.html#epilogue":{},"Chap_2.html":{},"Chap_2.html#problem-21":{},"Chap_2.html#prologue":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_3.html#introduction":{},"Chap_3.html#problem-310":{},"Chap_3.html#what-is-a-random-signal":{},"Chap_4.html":{},"Chap_4.html#correlation-the-workhorse":{},"Chap_4.html#cross-covariance":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#describing-the-time-average":{},"Chap_4.html#example-dice-money":{},"Chap_4.html#example-is-that-coin-fair":{},"Chap_4.html#laboratory-exercise-42":{},"Chap_4.html#other-averages":{},"Chap_4.html#problem-45":{},"Chap_4.html#problem-47":{},"Chap_4.html#problem-48":{},"Chap_4.html#properties-of-averaging":{},"Chap_4.html#the-ergodic-process":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#correlations-and-memory":{},"Chap_5.html#correlations-and-spectra":{},"Chap_5.html#correlations-simple-and-complex":{},"Chap_5.html#example-pink-noise":{},"Chap_5.html#fourier-description-of-correlation-functions":{},"Chap_5.html#laboratory-exercise-51":{},"Chap_5.html#problem-52":{},"Chap_5.html#problem-53":{},"Chap_5.html#problem-54":{},"Chap_5.html#problem-56":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{},"Chap_6.html#filtering-of-stochastic-signals":{},"Chap_6.html#laboratory-exercise-61":{},"Chap_6.html#laboratory-exercise-62":{},"Chap_6.html#laboratory-exercise-63":{},"Chap_6.html#laboratory-exercise-64":{},"Chap_6.html#laboratory-exercise-65":{},"Chap_6.html#laboratory-exercise-66":{},"Chap_6.html#problem-61":{},"Chap_6.html#problem-65":{},"Chap_6.html#the-autocorrelation-function":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_6.html#the-mean":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function_1":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#descriptive-statistic-variance":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#expected-value":{},"Chap_7.html#impulse-invariant-sampling":{},"Chap_7.html#power-spectral-density":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#power-spectral-density_2":{},"Chap_7.html#problem-711":{},"Chap_7.html#problem-72":{},"Chap_7.html#tethered-particle-motion":{},"Chap_7.html#the-langevin-equation-a-case-study":{},"Chap_7.html#the-langevin-velocity-equation":{},"Chap_7.html#why-this-case-study":{},"Chap_8.html":{},"Chap_8.html#example-filtering-noise":{},"Chap_8.html#problem-81":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{},"Chap_9.html":{},"Chap_9.html#setting-up-the-problem":{},"Chap_9.html#the-matched-filter":{},"info.html":{},"info.html#musical-data":{},"info.html#technical-details":{}},"title":{"Chap_4.html#the-ergodic-process":{}}}],["processes\u2014do",{"_index":2473,"text":{"Chap_5.html":{},"Chap_5.html#a-digression":{}},"title":{}}],["process\u2014a",{"_index":2951,"text":{"Chap_7.html":{},"Chap_7.html#power-spectral-density":{}},"title":{}}],["process\u2014involv",{"_index":2318,"text":{"Chap_4.html":{},"Chap_4.html#problem-42":{}},"title":{}}],["process\u2014wheth",{"_index":3502,"text":{"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{}},"title":{}}],["prod\\limits_{i",{"_index":871,"text":{"Chap_11.html":{},"Chap_11.html#example-estimating-the-poisson-rate":{},"Chap_11.html#maximum-likelihood-estimation":{}},"title":{}}],["prod\\limits_{n",{"_index":837,"text":{"Chap_11.html":{},"Chap_11.html#aspects-of-estimation":{}},"title":{}}],["produc",{"_index":292,"text":{"Chap_10.html":{},"Chap_10.html#as-seen-from-the-fourier-domain":{},"Chap_10.html#example-cleaning-up-our-act":{},"Chap_10.html#the-restoration-case-noise":{},"Chap_10.html#what-is-that-least-mean-square-error":{},"Chap_13.html":{},"Chap_13.html#appendix-i-mean-square-error-minimization":{},"Chap_3.html":{},"Chap_3.html#problem-37":{},"Chap_6.html":{},"Chap_6.html#interpretation-of-the-convolution-result":{},"Chap_6.html#the-autocorrelation-function":{},"Chap_7.html":{},"Chap_7.html#impulse-invariant-sampling":{},"Chap_7.html#power-spectral-density_2":{},"Chap_7.html#problem-72":{},"info.html":{},"info.html#technical-details":{}},"title":{}}],["product",{"_index":1014,"text":{"Chap_11.html":{},"Chap_11.html#estimating-the-autocorrelation-function":{},"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#other-windows":{},"Chap_12.html#problem-122":{},"Chap_2.html":{},"Chap_2.html#prologue":{},"Chap_4.html":{},"Chap_4.html#autocorrelation":{},"Chap_4.html#example-is-that-coin-fair":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{},"Chap_9.html":{},"Chap_9.html#laboratory-exercise-93":{},"Chap_9.html#the-matched-filter-as-an-autocorrelation":{},"info.html":{},"info.html#technical-details":{}},"title":{}}],["product\u2014a",{"_index":1618,"text":{"Chap_13.html":{},"Chap_13.html#appendix-i-mean-square-error-minimization":{}},"title":{}}],["prof",{"_index":482,"text":{"Chap_10.html":{},"Chap_10.html#the-wiener-hopf-equation":{},"Chap_7.html":{},"Chap_7.html#the-langevin-equation-a-case-study":{}},"title":{}}],["professor",{"_index":1715,"text":{"Chap_13.html":{},"Chap_13.html#epilogue":{},"Chap_2.html":{},"Chap_2.html#prologue":{},"info.html":{},"info.html#acknowledgments":{}},"title":{}}],["prologu",{"_index":1752,"text":{"Chap_2.html":{}},"title":{"Chap_2.html":{},"Chap_2.html#prologue":{}}}],["proof",{"_index":1484,"text":{"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_4.html":{},"Chap_4.html#properties-of-averaging":{},"Chap_5.html":{},"Chap_5.html#correlations-simple-and-complex":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_8.html":{},"Chap_8.html#example-cocktail-party-noise":{}},"title":{}}],["proofread",{"_index":3691,"text":{"info.html":{},"info.html#acknowledgments":{}},"title":{}}],["proof\u2014that",{"_index":2968,"text":{"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{}},"title":{}}],["proper",{"_index":1425,"text":{"Chap_12.html":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{}},"title":{}}],["properli",{"_index":3369,"text":{"Chap_7.html":{},"Chap_7.html#why-this-case-study":{}},"title":{}}],["properti",{"_index":1165,"text":{"Chap_11.html":{},"Chap_11.html#laboratory-exercise-113":{},"Chap_11.html#problem-1110":{},"Chap_11.html#trouble-in-paradise":{},"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#other-windows":{},"Chap_12.html#windowed-observations":{},"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_2.html":{},"Chap_2.html#problem-21":{},"Chap_3.html":{},"Chap_3.html#problem-38":{},"Chap_3.html#problem-39":{},"Chap_3.html#the-basics":{},"Chap_3.html#what-is-a-random-signal":{},"Chap_4.html":{},"Chap_4.html#characterization-of-random-signals":{},"Chap_4.html#laboratory-exercise-42":{},"Chap_4.html#problem-44":{},"Chap_4.html#properties-of-averaging":{},"Chap_4.html#the-ergodic-process":{},"Chap_5.html":{},"Chap_5.html#example-pink-noise":{},"Chap_5.html#problem-52":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_6.html":{},"Chap_6.html#the-autocorrelation-function":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function_2":{},"Chap_7.html#expected-value":{},"Chap_7.html#one-step-further":{},"Chap_7.html#tethered-particle-motion":{},"Chap_8.html":{},"Chap_8.html#problem-81":{},"Chap_9.html":{},"Chap_9.html#problem-91":{},"info.html":{},"info.html#usage":{}},"title":{"Chap_4.html#properties-of-averaging":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{}}}],["property\\,a",{"_index":2511,"text":{"Chap_5.html":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{}},"title":{}}],["property\\,b",{"_index":2509,"text":{"Chap_5.html":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{}},"title":{}}],["proport",{"_index":2801,"text":{"Chap_7.html":{},"Chap_7.html#the-langevin-equation-a-case-study":{}},"title":{}}],["proportion",{"_index":3521,"text":{"Chap_8.html":{},"Chap_8.html#problem-82":{}},"title":{}}],["propos",{"_index":338,"text":{"Chap_10.html":{},"Chap_10.html#using-the-least-mean-square-error-criterion":{},"Chap_11.html":{},"Chap_11.html#problem-117":{},"Chap_12.html":{},"Chap_12.html#other-windows":{}},"title":{}}],["proposit",{"_index":2358,"text":{"Chap_4.html":{},"Chap_4.html#problem-48":{},"Chap_6.html":{},"Chap_6.html#problem-63":{},"Chap_6.html#problem-65":{}},"title":{}}],["propto",{"_index":3121,"text":{"Chap_7.html":{},"Chap_7.html#power-spectral-density_1":{},"Chap_9.html":{},"Chap_9.html#the-matched-filter-as-an-autocorrelation":{}},"title":{}}],["protect",{"_index":3615,"text":{"Chap_9.html":{},"Chap_9.html#problem-92":{}},"title":{}}],["protein",{"_index":3138,"text":{"Chap_7.html":{},"Chap_7.html#one-step-further":{},"Chap_7.html#tethered-particle-motion":{}},"title":{}}],["prove",{"_index":1225,"text":{"Chap_11.html":{},"Chap_11.html#problem-119":{},"Chap_4.html":{},"Chap_4.html#problem-43":{},"Chap_4.html#problem-46":{},"Chap_4.html#properties-of-averaging":{},"Chap_5.html":{},"Chap_5.html#correlations-simple-and-complex":{},"Chap_5.html#problem-51":{},"Chap_6.html":{},"Chap_6.html#problem-66":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_8.html":{},"Chap_8.html#problem-81":{}},"title":{}}],["proven",{"_index":1091,"text":{"Chap_11.html":{},"Chap_11.html#langevin-redux":{}},"title":{}}],["proverb",{"_index":10,"text":{"Chap_1.html":{}},"title":{}}],["provid",{"_index":1374,"text":{"Chap_12.html":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#laboratory-exercise-42":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#correlations-and-memory":{},"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_7.html":{},"Chap_7.html#descriptive-statistic-variance":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#tethered-particle-motion":{},"info.html":{},"info.html#acknowledgments":{},"info.html#weather-data":{}},"title":{}}],["provis",{"_index":219,"text":{"Chap_1.html":{},"Chap_1.html#enhanced-experience":{}},"title":{}}],["psi",{"_index":1226,"text":{"Chap_11.html":{},"Chap_11.html#problem-119":{},"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#how-big-is-big-how-small-is-small":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#one-step-further":{}},"title":{}}],["publish",{"_index":18,"text":{"Chap_1.html":{},"Chap_1.html#how-to-use-this-ibook":{},"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"info.html":{},"info.html#technical-details":{},"info.html#venue":{}},"title":{}}],["pump",{"_index":2725,"text":{"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{}},"title":{}}],["pure",{"_index":2279,"text":{"Chap_4.html":{},"Chap_4.html#example-is-that-coin-fair":{},"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{}},"title":{}}],["purpos",{"_index":229,"text":{"Chap_1.html":{},"Chap_1.html#enhanced-experience":{},"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_7.html":{},"Chap_7.html#from-t-to-n":{}},"title":{}}],["push",{"_index":2961,"text":{"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{}},"title":{}}],["put",{"_index":1442,"text":{"Chap_12.html":{},"Chap_12.html#other-windows":{},"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{}},"title":{}}],["pythagorean",{"_index":847,"text":{"Chap_11.html":{},"Chap_11.html#aspects-of-estimation":{}},"title":{}}],["p}_i",{"_index":2094,"text":{"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{}},"title":{}}],["q",{"_index":1452,"text":{"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#problem-122":{},"Chap_13.html":{},"Chap_13.html#appendix-i-mean-square-error-minimization":{},"Chap_13.html#epilogue":{},"Chap_8.html":{},"Chap_8.html#problem-83":{}},"title":{}}],["q(\\omega",{"_index":744,"text":{"Chap_10.html":{},"Chap_10.html#problem-102":{}},"title":{}}],["q(t",{"_index":1747,"text":{"Chap_13.html":{},"Chap_13.html#epilogue":{}},"title":{}}],["q)=\\begin{cases}a&n=q\\\\0&n\\neq",{"_index":1956,"text":{"Chap_3.html":{},"Chap_3.html#problem-34":{}},"title":{}}],["q[k]{p^*}[k",{"_index":746,"text":{"Chap_10.html":{},"Chap_10.html#problem-102":{}},"title":{}}],["q[n",{"_index":742,"text":{"Chap_10.html":{},"Chap_10.html#problem-102":{},"Chap_6.html":{},"Chap_6.html#problem-64":{},"Chap_8.html":{},"Chap_8.html#problem-83":{}},"title":{}}],["q\\end{cases}\\quad",{"_index":1957,"text":{"Chap_3.html":{},"Chap_3.html#problem-34":{}},"title":{}}],["q^*}(t",{"_index":1748,"text":{"Chap_13.html":{},"Chap_13.html#epilogue":{}},"title":{}}],["q^2}/2",{"_index":1548,"text":{"Chap_12.html":{},"Chap_12.html#problem-122":{}},"title":{}}],["qiaol",{"_index":3689,"text":{"info.html":{},"info.html#acknowledgments":{}},"title":{}}],["quadrat",{"_index":2477,"text":{"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_9.html":{},"Chap_9.html#problem-92":{}},"title":{}}],["qualifi",{"_index":2900,"text":{"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{}},"title":{}}],["qualiti",{"_index":766,"text":{"Chap_10.html":{},"Chap_10.html#laboratory-exercise-102":{}},"title":{}}],["quantit",{"_index":3389,"text":{"Chap_7.html":{},"Chap_7.html#problem-79":{}},"title":{}}],["quantiti",{"_index":545,"text":{"Chap_10.html":{},"Chap_10.html#classic-example-classic-result":{},"Chap_12.html":{},"Chap_12.html#spectral-estimation":{},"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_9.html":{},"Chap_9.html#laboratory-exercise-93":{}},"title":{}}],["quantum",{"_index":1765,"text":{"Chap_2.html":{},"Chap_2.html#prologue":{}},"title":{}}],["question",{"_index":873,"text":{"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_11.html#laboratory-exercise-112":{},"Chap_11.html#maximum-likelihood-estimation":{},"Chap_12.html":{},"Chap_12.html#problem-122":{},"Chap_12.html#spectral-estimation":{},"Chap_2.html":{},"Chap_2.html#prologue":{},"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{},"Chap_6.html#interpretation-of-the-convolution-result":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#problem-78":{},"info.html":{},"info.html#contact":{}},"title":{}}],["quicktim",{"_index":3697,"text":{"info.html":{},"info.html#technical-details":{}},"title":{}}],["quit",{"_index":820,"text":{"Chap_11.html":{},"Chap_11.html#aspects-of-estimation":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function_1":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#impulse-invariant-sampling":{}},"title":{}}],["q}}\\,\\,\\,\\,\\,\\,\\,\\,q",{"_index":1449,"text":{"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{}},"title":{}}],["q}}{{\\partial",{"_index":1603,"text":{"Chap_13.html":{},"Chap_13.html#appendix-i-mean-square-error-minimization":{}},"title":{}}],["r",{"_index":682,"text":{"Chap_10.html":{},"Chap_10.html#example-cleaning-up-our-act":{},"Chap_10.html#laboratory-exercise-105":{},"Chap_13.html":{},"Chap_13.html#appendix-i-mean-square-error-minimization":{},"Chap_3.html":{},"Chap_3.html#problem-37":{},"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#laboratory-exercise-42":{},"Chap_5.html":{},"Chap_5.html#laboratory-exercise-51":{},"Chap_6.html":{},"Chap_6.html#the-autocorrelation-function":{},"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#one-step-further":{},"Chap_7.html#problem-711":{},"Chap_7.html#problem-77":{},"Chap_7.html#tethered-particle-motion":{},"Chap_8.html":{},"Chap_8.html#example-cocktail-party-noise":{},"Chap_8.html#problem-83":{},"info.html":{},"info.html#tips-short-cuts":{}},"title":{}}],["r(\\omega",{"_index":575,"text":{"Chap_10.html":{},"Chap_10.html#classic-example-classic-result":{},"Chap_10.html#example-cleaning-up-our-act":{}},"title":{}}],["r=\\sqrt{i^2+j^2",{"_index":1982,"text":{"Chap_3.html":{},"Chap_3.html#problem-37":{}},"title":{}}],["r[n",{"_index":307,"text":{"Chap_10.html":{},"Chap_10.html#classic-example-classic-result":{},"Chap_10.html#correlation-returns":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#example-sound-of-distorted-music":{},"Chap_10.html#expressing-the-mean-square-error":{},"Chap_10.html#problem-103":{},"Chap_10.html#the-restoration-case-noise":{},"Chap_10.html#the-wiener-hopf-equation":{},"Chap_10.html#using-the-least-mean-square-error-criterion":{},"Chap_10.html#what-is-that-least-mean-square-error":{},"Chap_8.html":{},"Chap_8.html#example-cocktail-party-noise":{}},"title":{}}],["r[n\\rbrack",{"_index":630,"text":{"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#example-cleaning-up-our-act":{},"Chap_10.html#why-we-avoid-the-inverse-filter":{},"Chap_8.html":{},"Chap_8.html#example-cocktail-party-noise":{}},"title":{}}],["r[n]x[n",{"_index":547,"text":{"Chap_10.html":{},"Chap_10.html#classic-example-classic-result":{},"Chap_10.html#determining-the-wiener-filter":{}},"title":{}}],["r^2",{"_index":3355,"text":{"Chap_7.html":{},"Chap_7.html#one-step-further":{}},"title":{}}],["rad/",{"_index":2914,"text":{"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#power-spectral-density_2":{}},"title":{}}],["radar",{"_index":3365,"text":{"Chap_7.html":{},"Chap_7.html#why-this-case-study":{}},"title":{}}],["radial",{"_index":3354,"text":{"Chap_7.html":{},"Chap_7.html#one-step-further":{}},"title":{}}],["radiat",{"_index":2375,"text":{"Chap_4.html":{},"Chap_4.html#laboratory-exercise-42":{},"Chap_7.html":{},"Chap_7.html#problem-711":{}},"title":{}}],["radio",{"_index":1832,"text":{"Chap_3.html":{},"Chap_3.html#what-is-a-random-signal":{}},"title":{}}],["radioact",{"_index":2316,"text":{"Chap_4.html":{},"Chap_4.html#problem-42":{},"Chap_5.html":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{}},"title":{}}],["radiu",{"_index":2866,"text":{"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#one-step-further":{},"Chap_7.html#problem-79":{},"Chap_7.html#tethered-particle-motion":{}},"title":{}}],["rais",{"_index":1231,"text":{"Chap_11.html":{},"Chap_11.html#problem-119":{}},"title":{}}],["random",{"_index":597,"text":{"Chap_10.html":{},"Chap_10.html#the-more-general-restoration-case-noise-distortion":{},"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_11.html#estimating-the-autocorrelation-function":{},"Chap_11.html#estimating-the-mean":{},"Chap_11.html#example-estimating-the-poisson-rate":{},"Chap_11.html#langevin-redux":{},"Chap_11.html#maximum-likelihood-estimation":{},"Chap_11.html#problem-115":{},"Chap_11.html#problem-116":{},"Chap_11.html#problem-117":{},"Chap_11.html#problem-119":{},"Chap_12.html":{},"Chap_12.html#spectral-estimation":{},"Chap_13.html":{},"Chap_13.html#appendix-i-mean-square-error-minimization":{},"Chap_13.html#epilogue":{},"Chap_2.html":{},"Chap_2.html#problem-21":{},"Chap_2.html#prologue":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_3.html#problem-310":{},"Chap_3.html#problem-35":{},"Chap_3.html#what-is-a-random-signal":{},"Chap_4.html":{},"Chap_4.html#autocorrelation":{},"Chap_4.html#characterization-of-random-signals":{},"Chap_4.html#correlation-the-workhorse":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#describing-the-time-average":{},"Chap_4.html#example-dice-money":{},"Chap_4.html#example-fair-chance":{},"Chap_4.html#example-is-that-coin-fair":{},"Chap_4.html#laboratory-exercise-41":{},"Chap_4.html#laboratory-exercise-42":{},"Chap_4.html#other-averages":{},"Chap_4.html#problem-41":{},"Chap_4.html#problem-44":{},"Chap_4.html#problem-45":{},"Chap_4.html#problem-47":{},"Chap_4.html#problem-48":{},"Chap_4.html#problem-49":{},"Chap_4.html#properties-of-averaging":{},"Chap_4.html#the-ergodic-process":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_5.html":{},"Chap_5.html#correlations-and-memory":{},"Chap_5.html#correlations-and-spectra":{},"Chap_5.html#correlations-simple-and-complex":{},"Chap_5.html#example-pink-noise":{},"Chap_5.html#fourier-description-of-correlation-functions":{},"Chap_5.html#laboratory-exercise-51":{},"Chap_5.html#problem-52":{},"Chap_5.html#problem-53":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_6.html":{},"Chap_6.html#filtering-of-stochastic-signals":{},"Chap_6.html#interpretation-of-the-convolution-result":{},"Chap_6.html#problem-61":{},"Chap_6.html#the-autocorrelation-function":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_6.html#the-mean":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function_1":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#expected-value":{},"Chap_7.html#power-spectral-density":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#the-langevin-equation-a-case-study":{},"Chap_7.html#the-langevin-velocity-equation":{},"Chap_8.html":{},"Chap_8.html#example-cocktail-party-noise":{},"Chap_8.html#example-filtering-noise":{},"Chap_8.html#problem-81":{},"Chap_8.html#snr-for-random-signals-in-the-presence-of-noise":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{}},"title":{"Chap_3.html#what-is-a-random-signal":{},"Chap_4.html":{},"Chap_4.html#characterization-of-random-signals":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{},"Chap_8.html#snr-for-random-signals-in-the-presence-of-noise":{}}}],["randomli",{"_index":1800,"text":{"Chap_2.html":{},"Chap_2.html#problem-21":{}},"title":{}}],["random\u2014vari",{"_index":2334,"text":{"Chap_4.html":{},"Chap_4.html#problem-44":{}},"title":{}}],["rang",{"_index":640,"text":{"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#example-cleaning-up-our-act":{},"Chap_10.html#problem-104":{},"Chap_10.html#why-we-avoid-the-inverse-filter":{},"Chap_4.html":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#laboratory-exercise-51":{},"Chap_9.html":{},"Chap_9.html#the-matched-filter":{}},"title":{}}],["rangl",{"_index":2990,"text":{"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#power-spectral-density_1":{}},"title":{}}],["rapid",{"_index":1386,"text":{"Chap_12.html":{},"Chap_12.html#the-periodogram-what-about-convergence":{}},"title":{}}],["rare",{"_index":732,"text":{"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{}},"title":{}}],["rate",{"_index":764,"text":{"Chap_10.html":{},"Chap_10.html#problem-104":{},"Chap_11.html":{},"Chap_7.html":{},"Chap_7.html#descriptive-statistic-variance":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#impulse-invariant-sampling":{},"Chap_7.html#power-spectral-density_1":{},"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{}},"title":{"Chap_11.html#example-estimating-the-poisson-rate":{}}}],["ratio",{"_index":569,"text":{"Chap_10.html":{},"Chap_10.html#classic-example-classic-result":{},"Chap_3.html":{},"Chap_3.html#what-is-a-random-signal":{},"Chap_4.html":{},"Chap_4.html#properties-of-averaging":{},"Chap_8.html":{},"Chap_8.html#example-filtering-noise":{},"Chap_8.html#problem-83":{},"Chap_8.html#snr-for-deterministic-signals-in-the-presence-of-noise":{},"Chap_8.html#snr-for-random-signals-in-the-presence-of-noise":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{},"Chap_9.html":{},"Chap_9.html#performance-in-the-presence-of-noise":{},"Chap_9.html#the-matched-filter":{},"Chap_9.html#using-cauchy-schwartz":{}},"title":{"Chap_8.html":{},"Chap_8.html#characterizing-signal-to-noise-ratios":{}}}],["ration",{"_index":2356,"text":{"Chap_4.html":{},"Chap_4.html#problem-47":{}},"title":{}}],["ravi",{"_index":3738,"text":{"info.html":{},"info.html#musical-data":{}},"title":{}}],["re",{"_index":3638,"text":{"Chap_9.html":{},"Chap_9.html#laboratory-exercise-93":{},"info.html":{},"info.html#acknowledgments":{}},"title":{}}],["reach",{"_index":1665,"text":{"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_9.html":{},"Chap_9.html#using-cauchy-schwartz":{}},"title":{}}],["read",{"_index":2377,"text":{"Chap_4.html":{},"Chap_4.html#laboratory-exercise-42":{},"Chap_7.html":{},"Chap_7.html#problem-711":{},"Chap_8.html":{},"Chap_8.html#problem-83":{},"info.html":{},"info.html#tips-short-cuts":{}},"title":{}}],["reader",{"_index":191,"text":{"Chap_1.html":{},"Chap_1.html#enhanced-experience":{}},"title":{}}],["readi",{"_index":3273,"text":{"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period_1":{}},"title":{}}],["real",{"_index":107,"text":{"Chap_1.html":{},"Chap_1.html#highlighting":{},"Chap_10.html":{},"Chap_10.html#correlation-returns":{},"Chap_10.html#problem-102":{},"Chap_10.html#the-more-general-restoration-case-noise-distortion":{},"Chap_10.html#the-restoration-case-noise":{},"Chap_10.html#using-the-least-mean-square-error-criterion":{},"Chap_11.html":{},"Chap_11.html#estimating-the-autocorrelation-function":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_11.html#problem-118":{},"Chap_11.html#problem-119":{},"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_3.html#problem-38":{},"Chap_3.html#problem-39":{},"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#example-is-that-coin-fair":{},"Chap_4.html#laboratory-exercise-42":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_5.html#problem-54":{},"Chap_5.html#problem-55":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_6.html":{},"Chap_6.html#laboratory-exercise-63":{},"Chap_6.html#problem-62":{},"Chap_6.html#problem-66":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#power-spectral-density":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#tethered-particle-motion":{},"Chap_8.html":{},"Chap_8.html#example-cocktail-party-noise":{},"Chap_8.html#example-filtering-noise":{},"Chap_9.html":{},"Chap_9.html#laboratory-exercise-93":{},"Chap_9.html#performance-in-the-presence-of-noise":{},"Chap_9.html#setting-up-the-problem":{},"Chap_9.html#the-matched-filter":{},"Chap_9.html#the-matched-filter-as-an-autocorrelation":{},"Chap_9.html#using-cauchy-schwartz":{}},"title":{}}],["realist",{"_index":472,"text":{"Chap_10.html":{},"Chap_10.html#example-sound-of-distorted-music":{},"Chap_10.html#the-wiener-hopf-equation":{},"Chap_6.html":{},"Chap_6.html#the-mean":{},"Chap_7.html":{},"Chap_7.html#tethered-particle-motion":{}},"title":{}}],["realiz",{"_index":1791,"text":{"Chap_2.html":{},"Chap_2.html#prologue":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_4.html":{},"Chap_4.html#example-dice-money":{},"Chap_4.html#example-fair-chance":{},"Chap_4.html#example-is-that-coin-fair":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function_1":{}},"title":{}}],["realli",{"_index":2568,"text":{"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{}},"title":{}}],["rearrang",{"_index":405,"text":{"Chap_10.html":{},"Chap_10.html#correlation-returns":{}},"title":{}}],["reason",{"_index":1234,"text":{"Chap_11.html":{},"Chap_11.html#problem-119":{},"Chap_12.html":{},"Chap_12.html#problem-122":{},"Chap_3.html":{},"Chap_3.html#problem-310":{},"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_5.html":{},"Chap_5.html#example-pink-noise":{},"Chap_5.html#problem-56":{},"Chap_7.html":{},"Chap_7.html#problem-710":{},"Chap_7.html#problem-72":{}},"title":{}}],["reca",{"_index":3139,"text":{"Chap_7.html":{},"Chap_7.html#one-step-further":{},"Chap_7.html#tethered-particle-motion":{}},"title":{}}],["recal",{"_index":2619,"text":{"Chap_6.html":{},"Chap_6.html#filtering-of-stochastic-signals":{}},"title":{}}],["receiv",{"_index":2352,"text":{"Chap_4.html":{},"Chap_4.html#problem-47":{}},"title":{}}],["recogn",{"_index":2662,"text":{"Chap_6.html":{},"Chap_6.html#the-autocorrelation-function":{},"Chap_8.html":{},"Chap_8.html#problem-82":{}},"title":{}}],["recognit",{"_index":1560,"text":{"Chap_12.html":{},"Chap_12.html#problem-123":{}},"title":{}}],["reconstruct",{"_index":1773,"text":{"Chap_2.html":{},"Chap_2.html#prologue":{}},"title":{}}],["record",{"_index":600,"text":{"Chap_10.html":{},"Chap_10.html#example-sound-of-distorted-music":{},"Chap_10.html#the-more-general-restoration-case-noise-distortion":{},"Chap_12.html":{},"Chap_12.html#problem-122":{},"Chap_12.html#problem-123":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_12.html#windowed-observations":{},"Chap_4.html":{},"Chap_4.html#the-ergodic-process":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_5.html":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_7.html":{},"Chap_7.html#tethered-particle-motion":{}},"title":{}}],["records\u2014do",{"_index":1412,"text":{"Chap_12.html":{},"Chap_12.html#the-periodogram-what-about-convergence":{}},"title":{}}],["rectangular",{"_index":1329,"text":{"Chap_12.html":{},"Chap_12.html#other-windows":{},"Chap_12.html#problem-121":{},"Chap_12.html#problem-122":{},"Chap_12.html#windowed-observations":{}},"title":{}}],["red",{"_index":589,"text":{"Chap_10.html":{},"Chap_10.html#classic-example-classic-result":{},"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_11.html#langevin-redux":{},"Chap_12.html":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#power-spectral-density":{},"Chap_7.html#tethered-particle-motion":{},"Chap_8.html":{},"Chap_8.html#example-cocktail-party-noise":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{}},"title":{}}],["reduc",{"_index":713,"text":{"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#problem-103":{},"Chap_3.html":{},"Chap_3.html#problem-310":{},"Chap_4.html":{},"Chap_4.html#other-averages":{},"Chap_5.html":{},"Chap_5.html#the-mechanics-of-correlations-redux":{}},"title":{}}],["reduct",{"_index":1837,"text":{"Chap_3.html":{},"Chap_3.html#what-is-a-random-signal":{}},"title":{}}],["redux",{"_index":1061,"text":{"Chap_11.html":{},"Chap_5.html":{},"Chap_7.html":{}},"title":{"Chap_11.html#langevin-redux":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{}}}],["refer",{"_index":120,"text":{"Chap_1.html":{},"Chap_1.html#outside-this-device":{},"Chap_10.html":{},"Chap_10.html#using-the-least-mean-square-error-criterion":{},"Chap_11.html":{},"Chap_11.html#aspects-of-estimation":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_11.html#example-estimating-the-poisson-rate":{},"Chap_12.html":{},"Chap_12.html#the-periodogram-unbiased":{},"Chap_2.html":{},"Chap_2.html#prologue":{},"Chap_3.html":{},"Chap_3.html#what-is-a-random-signal":{},"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_5.html":{},"Chap_5.html#laboratory-exercise-51":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function_1":{},"Chap_7.html#tethered-particle-motion":{},"info.html":{},"info.html#tips-short-cuts":{}},"title":{}}],["refin",{"_index":2302,"text":{"Chap_4.html":{},"Chap_4.html#the-ergodic-process":{},"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{}},"title":{}}],["reflect",{"_index":2337,"text":{"Chap_4.html":{},"Chap_4.html#problem-44":{},"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{}},"title":{}}],["reformul",{"_index":710,"text":{"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_5.html":{},"Chap_5.html#the-mechanics-of-correlations-redux":{}},"title":{}}],["refresh",{"_index":3644,"text":{"info.html":{},"info.html#tips-short-cuts":{}},"title":{}}],["regard",{"_index":934,"text":{"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{}},"title":{}}],["region",{"_index":562,"text":{"Chap_10.html":{},"Chap_10.html#classic-example-classic-result":{},"Chap_11.html":{},"Chap_11.html#estimating-the-autocorrelation-function":{},"Chap_3.html":{},"Chap_3.html#problem-35":{},"Chap_7.html":{},"Chap_7.html#impulse-invariant-sampling":{},"Chap_7.html#power-spectral-density_1":{}},"title":{}}],["regist",{"_index":203,"text":{"Chap_1.html":{},"Chap_1.html#enhanced-experience":{}},"title":{}}],["registr",{"_index":3741,"text":{"info.html":{}},"title":{"info.html#registration":{}}}],["reif",{"_index":2862,"text":{"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small":{},"Chap_7.html#problem-711":{}},"title":{}}],["rel",{"_index":2338,"text":{"Chap_4.html":{},"Chap_4.html#problem-44":{},"Chap_7.html":{},"Chap_7.html#power-spectral-density_1":{}},"title":{}}],["relat",{"_index":253,"text":{"Chap_1.html":{},"Chap_1.html#enhanced-experience":{},"Chap_11.html":{},"Chap_11.html#problem-114":{},"Chap_11.html#trouble-in-paradise":{},"Chap_12.html":{},"Chap_12.html#the-periodogram-unbiased":{},"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_3.html":{},"Chap_3.html#the-basics":{},"Chap_4.html":{},"Chap_4.html#characterization-of-random-signals":{},"Chap_4.html#describing-the-time-average":{},"Chap_4.html#problem-44":{},"Chap_5.html":{},"Chap_5.html#correlations-and-memory":{},"Chap_5.html#laboratory-exercise-51":{},"Chap_5.html#problem-56":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_6.html":{},"Chap_6.html#filtering-of-stochastic-signals":{},"Chap_6.html#interpretation-of-the-convolution-result":{},"Chap_7.html":{},"Chap_7.html#impulse-invariant-sampling":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#problem-73":{},"Chap_7.html#the-langevin-position-equation":{},"Chap_8.html":{},"Chap_8.html#problem-82":{},"Chap_8.html#problem-83":{},"Chap_9.html":{},"Chap_9.html#problem-92":{},"info.html":{},"info.html#tips-short-cuts":{}},"title":{}}],["relationship",{"_index":848,"text":{"Chap_11.html":{},"Chap_11.html#aspects-of-estimation":{},"Chap_12.html":{},"Chap_12.html#problem-122":{},"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{},"Chap_7.html":{},"Chap_7.html#descriptive-statistic-variance":{},"Chap_7.html#problem-77":{},"Chap_9.html":{},"Chap_9.html#problem-92":{}},"title":{}}],["releas",{"_index":2327,"text":{"Chap_4.html":{},"Chap_4.html#problem-42":{}},"title":{}}],["relev",{"_index":44,"text":{"Chap_1.html":{},"Chap_1.html#how-to-use-this-ibook":{},"Chap_11.html":{},"Chap_11.html#problem-113":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_7.html":{},"Chap_7.html#tethered-particle-motion":{},"Chap_7.html#why-this-case-study":{}},"title":{}}],["remain",{"_index":765,"text":{"Chap_10.html":{},"Chap_10.html#problem-104":{},"Chap_11.html":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_4.html":{},"Chap_4.html#example-dice-money":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_7.html":{},"Chap_7.html#descriptive-statistic-variance":{},"Chap_7.html#expected-value_1":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#why-this-case-study":{},"Chap_9.html":{},"Chap_9.html#the-matched-filter":{}},"title":{}}],["remaind",{"_index":2920,"text":{"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{}},"title":{}}],["remark",{"_index":1050,"text":{"Chap_11.html":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_11.html#trouble-in-paradise":{},"Chap_5.html":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{}},"title":{}}],["rememb",{"_index":7,"text":{"Chap_1.html":{},"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#example-dice-money":{},"Chap_5.html":{},"Chap_5.html#fourier-description-of-correlation-functions":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function_2":{},"Chap_7.html#tethered-particle-motion":{},"Chap_9.html":{},"Chap_9.html#setting-up-the-problem":{},"Chap_9.html#the-matched-filter-as-an-autocorrelation":{}},"title":{}}],["remind",{"_index":994,"text":{"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_6.html":{},"Chap_6.html#interpretation-of-the-convolution-result":{}},"title":{}}],["remov",{"_index":635,"text":{"Chap_10.html":{},"Chap_10.html#why-we-avoid-the-inverse-filter":{}},"title":{}}],["render",{"_index":1021,"text":{"Chap_11.html":{},"Chap_11.html#estimating-the-autocorrelation-function":{}},"title":{}}],["repair",{"_index":3136,"text":{"Chap_7.html":{},"Chap_7.html#tethered-particle-motion":{}},"title":{}}],["repeat",{"_index":883,"text":{"Chap_11.html":{},"Chap_11.html#example-estimating-the-poisson-rate":{},"Chap_11.html#problem-113":{},"Chap_3.html":{},"Chap_3.html#problem-38":{},"Chap_4.html":{},"Chap_4.html#other-averages":{},"Chap_5.html":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#descriptive-statistic-variance":{},"Chap_7.html#one-step-further":{},"Chap_7.html#power-spectral-density_1":{}},"title":{}}],["repeatedli",{"_index":1793,"text":{"Chap_2.html":{},"Chap_2.html#prologue":{}},"title":{}}],["replac",{"_index":362,"text":{"Chap_10.html":{},"Chap_10.html#using-the-least-mean-square-error-criterion":{},"Chap_10.html#what-is-that-least-mean-square-error":{},"Chap_11.html":{},"Chap_11.html#langevin-redux":{},"Chap_11.html#problem-115":{},"Chap_12.html":{},"Chap_12.html#the-periodogram-unbiased":{},"Chap_3.html":{},"Chap_3.html#problem-310":{},"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#the-ergodic-process":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#correlations-simple-and-complex":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function_1":{}},"title":{}}],["report",{"_index":233,"text":{"Chap_1.html":{},"Chap_1.html#enhanced-experience":{},"Chap_11.html":{},"Chap_11.html#laboratory-exercise-113":{}},"title":{}}],["repres",{"_index":447,"text":{"Chap_10.html":{},"Chap_10.html#the-wiener-hopf-equation":{},"Chap_11.html":{},"Chap_11.html#estimating-the-autocorrelation-function":{},"Chap_11.html#langevin-redux":{},"Chap_11.html#problem-118":{},"Chap_12.html":{},"Chap_12.html#the-periodogram-unbiased":{},"Chap_13.html":{},"Chap_13.html#appendix-i-mean-square-error-minimization":{},"Chap_2.html":{},"Chap_2.html#problem-21":{},"Chap_3.html":{},"Chap_3.html#problem-33":{},"Chap_3.html#problem-38":{},"Chap_4.html":{},"Chap_4.html#characterization-of-random-signals":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#expected-value":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#problem-71":{},"Chap_7.html#why-this-case-study":{},"Chap_8.html":{},"Chap_8.html#problem-82":{}},"title":{}}],["represent",{"_index":1813,"text":{"Chap_3.html":{},"Chap_3.html#the-basics":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_7.html":{},"Chap_7.html#problem-71":{}},"title":{}}],["reproduc",{"_index":800,"text":{"Chap_10.html":{},"Chap_10.html#laboratory-exercise-105":{},"info.html":{},"info.html#usage":{}},"title":{}}],["reproduct",{"_index":225,"text":{"Chap_1.html":{},"Chap_1.html#enhanced-experience":{},"Chap_10.html":{},"Chap_10.html#example-sound-of-distorted-music":{}},"title":{}}],["requir",{"_index":689,"text":{"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_11.html":{},"Chap_11.html#problem-119":{},"Chap_12.html":{},"Chap_12.html#other-windows":{},"Chap_12.html#problem-122":{},"Chap_12.html#problem-123":{},"Chap_12.html#the-periodogram-unbiased":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_5.html":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#problem-79":{},"Chap_9.html":{},"Chap_9.html#setting-up-the-problem":{}},"title":{}}],["research",{"_index":238,"text":{"Chap_1.html":{},"Chap_1.html#enhanced-experience":{}},"title":{}}],["resembl",{"_index":1479,"text":{"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#problem-122":{},"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{}},"title":{}}],["resolut",{"_index":2212,"text":{"Chap_4.html":{},"Chap_4.html#the-mechanics-of-correlations":{}},"title":{}}],["respect",{"_index":920,"text":{"Chap_11.html":{},"Chap_11.html#example-estimating-the-poisson-rate":{},"Chap_11.html#problem-117":{},"Chap_13.html":{},"Chap_13.html#appendix-i-mean-square-error-minimization":{},"Chap_4.html":{},"Chap_4.html#problem-49":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_6.html":{},"Chap_6.html#the-mean":{},"Chap_8.html":{},"Chap_8.html#snr-for-random-signals-in-the-presence-of-noise":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{},"Chap_9.html":{},"Chap_9.html#the-matched-filter-as-an-autocorrelation":{}},"title":{}}],["respond",{"_index":2791,"text":{"Chap_7.html":{},"Chap_7.html#the-langevin-equation-a-case-study":{}},"title":{}}],["respons",{"_index":627,"text":{"Chap_10.html":{},"Chap_10.html#why-we-avoid-the-inverse-filter":{},"Chap_3.html":{},"Chap_3.html#introduction":{},"Chap_3.html#problem-310":{},"Chap_3.html#problem-33":{},"Chap_6.html":{},"Chap_6.html#interpretation-of-the-convolution-result":{},"Chap_6.html#problem-62":{},"Chap_6.html#problem-65":{},"Chap_6.html#the-autocorrelation-function":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_6.html#the-mean":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function":{},"Chap_7.html#autocorrelation-function_1":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#expected-value":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#impulse-invariant-sampling":{},"Chap_7.html#problem-72":{},"Chap_7.html#problem-73":{},"Chap_7.html#tethered-particle-motion":{},"Chap_7.html#the-langevin-position-equation":{},"Chap_9.html":{},"Chap_9.html#the-classic-example":{},"Chap_9.html#the-matched-filter":{}},"title":{}}],["rest",{"_index":2457,"text":{"Chap_5.html":{},"Chap_5.html#a-digression":{}},"title":{}}],["restor",{"_index":290,"text":{"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#example-sound-of-distorted-music":{},"Chap_10.html#laboratory-exercise-101":{},"Chap_10.html#laboratory-exercise-102":{},"Chap_10.html#laboratory-exercise-103":{},"Chap_10.html#laboratory-exercise-104":{},"Chap_10.html#the-restoration-case-noise":{}},"title":{"Chap_10.html#the-more-general-restoration-case-noise-distortion":{},"Chap_10.html#the-restoration-case-noise":{}}}],["restrain",{"_index":3162,"text":{"Chap_7.html":{},"Chap_7.html#tethered-particle-motion":{}},"title":{}}],["restrict",{"_index":360,"text":{"Chap_10.html":{},"Chap_10.html#using-the-least-mean-square-error-criterion":{},"info.html":{},"info.html#technical-details":{}},"title":{}}],["result",{"_index":91,"text":{"Chap_1.html":{},"Chap_1.html#highlighting":{},"Chap_1.html#sound-of-music":{},"Chap_10.html":{},"Chap_10.html#classic-example-classic-result":{},"Chap_10.html#expressing-the-mean-square-error":{},"Chap_10.html#problem-102":{},"Chap_10.html#problem-103":{},"Chap_10.html#the-wiener-hopf-equation":{},"Chap_10.html#using-the-least-mean-square-error-criterion":{},"Chap_11.html":{},"Chap_11.html#estimating-the-autocorrelation-function":{},"Chap_11.html#example-estimating-the-poisson-rate":{},"Chap_11.html#langevin-redux":{},"Chap_11.html#problem-118":{},"Chap_11.html#problem-119":{},"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#problem-122":{},"Chap_12.html#the-periodogram-unbiased":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_13.html":{},"Chap_13.html#appendix-i-mean-square-error-minimization":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_13.html#epilogue":{},"Chap_2.html":{},"Chap_2.html#problem-21":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_3.html#introduction":{},"Chap_3.html#problem-310":{},"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#laboratory-exercise-41":{},"Chap_4.html#problem-44":{},"Chap_4.html#problem-47":{},"Chap_4.html#the-ergodic-process":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#correlations-and-memory":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{},"Chap_6.html#the-autocorrelation-function":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_6.html#the-mean":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function_1":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#descriptive-statistic-variance":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#expected-value":{},"Chap_7.html#impulse-invariant-sampling":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#the-langevin-equation-a-case-study":{},"Chap_7.html#the-langevin-velocity-equation":{},"Chap_8.html":{},"Chap_8.html#example-cocktail-party-noise":{},"Chap_8.html#snr-for-random-signals-in-the-presence-of-noise":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{},"Chap_9.html":{},"Chap_9.html#example-matching-your-filter":{},"Chap_9.html#laboratory-exercise-91":{},"Chap_9.html#performance-in-the-presence-of-noise":{},"Chap_9.html#using-cauchy-schwartz":{},"info.html":{},"info.html#technical-details":{}},"title":{"Chap_10.html#classic-example-classic-result":{},"Chap_6.html#interpretation-of-the-convolution-result":{}}}],["result\u2014orthogonality\u2014from",{"_index":397,"text":{"Chap_10.html":{},"Chap_10.html#expressing-the-mean-square-error":{}},"title":{}}],["retail",{"_index":2743,"text":{"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{}},"title":{}}],["retard",{"_index":2798,"text":{"Chap_7.html":{},"Chap_7.html#the-langevin-equation-a-case-study":{}},"title":{}}],["return",{"_index":126,"text":{"Chap_1.html":{},"Chap_1.html#enhanced-experience":{},"Chap_1.html#outside-this-device":{},"Chap_10.html":{},"Chap_11.html":{},"Chap_11.html#trouble-in-paradise":{},"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#example-is-that-coin-fair":{},"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{},"info.html":{},"info.html#tips-short-cuts":{}},"title":{"Chap_10.html#correlation-returns":{}}}],["retyp",{"_index":3685,"text":{"info.html":{},"info.html#acknowledgments":{}},"title":{}}],["reveal",{"_index":1465,"text":{"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_7.html":{},"Chap_7.html#tethered-particle-motion":{}},"title":{}}],["revers",{"_index":424,"text":{"Chap_10.html":{},"Chap_10.html#correlation-returns":{}},"title":{}}],["revert",{"_index":707,"text":{"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{}},"title":{}}],["review",{"_index":1197,"text":{"Chap_11.html":{},"Chap_11.html#problem-116":{},"Chap_11.html#problem-119":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_3.html#the-basics":{},"Chap_3.html#what-is-a-random-signal":{},"Chap_5.html":{},"Chap_5.html#laboratory-exercise-51":{}},"title":{}}],["rewrit",{"_index":399,"text":{"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#expressing-the-mean-square-error":{},"Chap_11.html":{},"Chap_11.html#langevin-redux":{},"Chap_11.html#maximum-likelihood-estimation":{},"Chap_12.html":{},"Chap_12.html#windowed-observations":{},"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{},"Chap_6.html#the-mean":{},"Chap_8.html":{},"Chap_8.html#snr-for-random-signals-in-the-presence-of-noise":{},"Chap_9.html":{},"Chap_9.html#using-cauchy-schwartz":{}},"title":{}}],["rewritten",{"_index":425,"text":{"Chap_10.html":{},"Chap_10.html#correlation-returns":{},"Chap_10.html#problem-102":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_9.html":{},"Chap_9.html#using-cauchy-schwartz":{}},"title":{}}],["re}\\nolimit",{"_index":1675,"text":{"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_9.html":{},"Chap_9.html#laboratory-exercise-93":{}},"title":{}}],["rho",{"_index":1071,"text":{"Chap_11.html":{},"Chap_11.html#langevin-redux":{},"Chap_11.html#problem-1110":{},"Chap_11.html#problem-119":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function":{},"Chap_7.html#autocorrelation-function_1":{},"Chap_7.html#autocorrelation-function_2":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#descriptive-statistic-variance":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#expected-value":{},"Chap_7.html#expected-value_1":{},"Chap_7.html#power-spectral-density":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#power-spectral-density_2":{},"Chap_7.html#problem-710":{},"Chap_7.html#problem-711":{},"Chap_7.html#the-langevin-position-equation":{}},"title":{}}],["rieger",{"_index":3403,"text":{"Chap_7.html":{},"Chap_7.html#problem-711":{}},"title":{}}],["riff",{"_index":3729,"text":{"info.html":{},"info.html#musical-data":{}},"title":{}}],["right",{"_index":337,"text":{"Chap_10.html":{},"Chap_10.html#classic-example-classic-result":{},"Chap_10.html#correlation-returns":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#example-cleaning-up-our-act":{},"Chap_10.html#expressing-the-mean-square-error":{},"Chap_10.html#the-more-general-restoration-case-noise-distortion":{},"Chap_10.html#using-the-least-mean-square-error-criterion":{},"Chap_10.html#what-is-that-least-mean-square-error":{},"Chap_10.html#why-we-avoid-the-inverse-filter":{},"Chap_11.html":{},"Chap_11.html#aspects-of-estimation":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_11.html#estimating-the-autocorrelation-function":{},"Chap_11.html#estimating-the-mean":{},"Chap_11.html#example-estimating-the-poisson-rate":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_11.html#langevin-redux":{},"Chap_11.html#maximum-likelihood-estimation":{},"Chap_11.html#problem-111":{},"Chap_11.html#problem-112":{},"Chap_11.html#problem-114":{},"Chap_11.html#problem-115":{},"Chap_11.html#problem-116":{},"Chap_11.html#problem-119":{},"Chap_11.html#trouble-in-paradise":{},"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#problem-121":{},"Chap_12.html#problem-122":{},"Chap_12.html#problem-123":{},"Chap_12.html#spectral-estimation":{},"Chap_12.html#the-periodogram-unbiased":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_12.html#windowed-observations":{},"Chap_13.html":{},"Chap_13.html#appendix-i-mean-square-error-minimization":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_13.html#epilogue":{},"Chap_3.html":{},"Chap_3.html#problem-35":{},"Chap_3.html#problem-37":{},"Chap_4.html":{},"Chap_4.html#auto-covariance":{},"Chap_4.html#autocorrelation":{},"Chap_4.html#cross-correlation":{},"Chap_4.html#cross-covariance":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#describing-the-time-average":{},"Chap_4.html#example-average-experience":{},"Chap_4.html#example-dice-money":{},"Chap_4.html#example-fair-chance":{},"Chap_4.html#example-is-that-coin-fair":{},"Chap_4.html#laboratory-exercise-42":{},"Chap_4.html#other-averages":{},"Chap_4.html#problem-41":{},"Chap_4.html#problem-42":{},"Chap_4.html#problem-45":{},"Chap_4.html#problem-47":{},"Chap_4.html#properties-of-averaging":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#correlations-and-memory":{},"Chap_5.html#correlations-simple-and-complex":{},"Chap_5.html#example-delayed-effect":{},"Chap_5.html#example-pink-noise":{},"Chap_5.html#example-white-noise":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_5.html#problem-55":{},"Chap_5.html#problem-56":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_6.html":{},"Chap_6.html#filtering-of-stochastic-signals":{},"Chap_6.html#interpretation-of-the-convolution-result":{},"Chap_6.html#problem-61":{},"Chap_6.html#problem-62":{},"Chap_6.html#problem-63":{},"Chap_6.html#problem-64":{},"Chap_6.html#problem-65":{},"Chap_6.html#problem-66":{},"Chap_6.html#the-autocorrelation-function":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_6.html#the-mean":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function":{},"Chap_7.html#autocorrelation-function_1":{},"Chap_7.html#autocorrelation-function_2":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#descriptive-statistic-variance":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#expected-value":{},"Chap_7.html#expected-value_1":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#impulse-invariant-sampling":{},"Chap_7.html#power-spectral-density":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#power-spectral-density_2":{},"Chap_7.html#problem-77":{},"Chap_7.html#problem-78":{},"Chap_7.html#tethered-particle-motion":{},"Chap_7.html#the-langevin-position-equation":{},"Chap_7.html#the-langevin-velocity-equation":{},"Chap_8.html":{},"Chap_8.html#example-cocktail-party-noise":{},"Chap_8.html#example-filtering-noise":{},"Chap_8.html#example-not-too-noisy":{},"Chap_8.html#problem-81":{},"Chap_8.html#problem-83":{},"Chap_8.html#snr-for-deterministic-signals-in-the-presence-of-noise":{},"Chap_8.html#snr-for-random-signals-in-the-presence-of-noise":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{},"Chap_9.html":{},"Chap_9.html#laboratory-exercise-93":{},"Chap_9.html#problem-91":{},"Chap_9.html#problem-92":{},"Chap_9.html#setting-up-the-problem":{},"Chap_9.html#the-matched-filter":{},"Chap_9.html#using-cauchy-schwartz":{},"info.html":{},"info.html#tips-short-cuts":{}},"title":{}}],["right)/2",{"_index":1369,"text":{"Chap_12.html":{},"Chap_12.html#problem-123":{},"Chap_12.html#windowed-observations":{}},"title":{}}],["right)/\\left",{"_index":1472,"text":{"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{}},"title":{}}],["right)/\\parti",{"_index":1608,"text":{"Chap_13.html":{},"Chap_13.html#appendix-i-mean-square-error-minimization":{}},"title":{}}],["right)/\\sum\\limits_{n",{"_index":1633,"text":{"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{}},"title":{}}],["right)/{\\sigma",{"_index":2362,"text":{"Chap_4.html":{},"Chap_4.html#problem-49":{}},"title":{}}],["right)\\frac{1}{{\\sqrt",{"_index":2898,"text":{"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{}},"title":{}}],["right)\\frac{1}{{{{\\left\\langl",{"_index":3349,"text":{"Chap_7.html":{},"Chap_7.html#one-step-further":{}},"title":{}}],["right)\\frac{{{f_o}}}{{{\\omega",{"_index":3113,"text":{"Chap_7.html":{},"Chap_7.html#power-spectral-density_1":{}},"title":{}}],["right)\\frac{{{{({\\rho",{"_index":3335,"text":{"Chap_7.html":{},"Chap_7.html#descriptive-statistic-variance":{}},"title":{}}],["right)\\left",{"_index":514,"text":{"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#what-is-that-least-mean-square-error":{},"Chap_13.html":{},"Chap_13.html#appendix-i-mean-square-error-minimization":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_4.html":{},"Chap_4.html#example-dice-money":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_6.html":{},"Chap_6.html#the-autocorrelation-function":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function_1":{},"Chap_7.html#expected-value":{},"Chap_7.html#expected-value_1":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#power-spectral-density_2":{},"Chap_9.html":{},"Chap_9.html#using-cauchy-schwartz":{}},"title":{}}],["right)\\sum\\limits_{k",{"_index":3058,"text":{"Chap_7.html":{},"Chap_7.html#expected-value":{}},"title":{}}],["right)\\sum\\limits_{m",{"_index":3590,"text":{"Chap_9.html":{},"Chap_9.html#the-matched-filter-as-an-autocorrelation":{}},"title":{}}],["right)\\sum\\limits_{n",{"_index":2841,"text":{"Chap_7.html":{},"Chap_7.html#impulse-invariant-sampling":{}},"title":{}}],["right)^2",{"_index":368,"text":{"Chap_10.html":{},"Chap_10.html#using-the-least-mean-square-error-criterion":{},"Chap_11.html":{},"Chap_11.html#problem-116":{},"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_13.html":{},"Chap_13.html#appendix-i-mean-square-error-minimization":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#tethered-particle-motion":{},"Chap_9.html":{},"Chap_9.html#using-cauchy-schwartz":{}},"title":{}}],["right)^2}\\frac{{{\\rho",{"_index":1119,"text":{"Chap_11.html":{},"Chap_11.html#langevin-redux":{}},"title":{}}],["right)^2}\\frac{{{f_o}}}{{{\\omega",{"_index":2982,"text":{"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{}},"title":{}}],["right)^2}\\left",{"_index":1069,"text":{"Chap_11.html":{},"Chap_11.html#langevin-redux":{},"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{}},"title":{}}],["right)^2}k{\\rho",{"_index":1118,"text":{"Chap_11.html":{},"Chap_11.html#langevin-redux":{}},"title":{}}],["right)^2}var",{"_index":1158,"text":{"Chap_11.html":{},"Chap_11.html#trouble-in-paradise":{}},"title":{}}],["right)^2}{\\left",{"_index":1635,"text":{"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{}},"title":{}}],["right)^2}{\\rho",{"_index":1117,"text":{"Chap_11.html":{},"Chap_11.html#langevin-redux":{},"Chap_11.html#problem-1110":{}},"title":{}}],["right)^n}u[n",{"_index":2768,"text":{"Chap_6.html":{},"Chap_6.html#problem-61":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function_1":{},"Chap_7.html#power-spectral-density_1":{}},"title":{}}],["right)^{1/n",{"_index":838,"text":{"Chap_11.html":{},"Chap_11.html#aspects-of-estimation":{}},"title":{}}],["right)^{\\left",{"_index":2466,"text":{"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#example-pink-noise":{},"Chap_8.html":{},"Chap_8.html#problem-83":{}},"title":{}}],["right)^{n",{"_index":2775,"text":{"Chap_6.html":{},"Chap_6.html#problem-62":{}},"title":{}}],["right)df",{"_index":2606,"text":{"Chap_5.html":{},"Chap_5.html#problem-56":{}},"title":{}}],["right)f[n",{"_index":2846,"text":{"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#impulse-invariant-sampling":{},"Chap_7.html#the-langevin-position-equation":{},"Chap_7.html#the-langevin-velocity-equation":{}},"title":{}}],["right)n}}u[n",{"_index":2837,"text":{"Chap_7.html":{},"Chap_7.html#impulse-invariant-sampling":{}},"title":{}}],["right)n}}u[n]\\,{z",{"_index":2840,"text":{"Chap_7.html":{},"Chap_7.html#impulse-invariant-sampling":{}},"title":{}}],["right)r[n",{"_index":403,"text":{"Chap_10.html":{},"Chap_10.html#expressing-the-mean-square-error":{}},"title":{}}],["right)u(t",{"_index":3253,"text":{"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{}},"title":{}}],["right)u[n",{"_index":2445,"text":{"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function_1":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#expected-value":{}},"title":{}}],["right)u[n]u[n",{"_index":2452,"text":{"Chap_5.html":{},"Chap_5.html#a-digression":{}},"title":{}}],["right)u[n]{",{"_index":2481,"text":{"Chap_5.html":{},"Chap_5.html#a-digression":{}},"title":{}}],["right)v[n",{"_index":2845,"text":{"Chap_7.html":{},"Chap_7.html#impulse-invariant-sampling":{},"Chap_7.html#the-langevin-velocity-equation":{}},"title":{}}],["right)w[n]\\left",{"_index":2463,"text":{"Chap_5.html":{},"Chap_5.html#a-digression":{}},"title":{}}],["right)x",{"_index":3226,"text":{"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{}},"title":{}}],["right)x[n",{"_index":517,"text":{"Chap_10.html":{},"Chap_10.html#classic-example-classic-result":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#what-is-that-least-mean-square-error":{}},"title":{}}],["right){",{"_index":1454,"text":{"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#impulse-invariant-sampling":{}},"title":{}}],["right){\\left",{"_index":1692,"text":{"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_5.html":{},"Chap_5.html#a-digression":{}},"title":{}}],["right){\\rho",{"_index":1072,"text":{"Chap_11.html":{},"Chap_11.html#langevin-redux":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function":{},"Chap_7.html#autocorrelation-function_1":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#expected-value":{},"Chap_7.html#power-spectral-density":{}},"title":{}}],["right){\\varphi",{"_index":1154,"text":{"Chap_11.html":{},"Chap_11.html#trouble-in-paradise":{},"Chap_9.html":{},"Chap_9.html#the-matched-filter-as-an-autocorrelation":{}},"title":{}}],["right){c_{xx}}[k",{"_index":1152,"text":{"Chap_11.html":{},"Chap_11.html#trouble-in-paradise":{}},"title":{}}],["right){r_i",{"_index":1604,"text":{"Chap_13.html":{},"Chap_13.html#appendix-i-mean-square-error-minimization":{}},"title":{}}],["right){t_",{"_index":3101,"text":{"Chap_7.html":{},"Chap_7.html#power-spectral-density_1":{}},"title":{}}],["right){{\\left",{"_index":1657,"text":{"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_4.html":{},"Chap_4.html#auto-covariance":{},"Chap_4.html#cross-covariance":{}},"title":{}}],["right)}^*}dt",{"_index":1659,"text":{"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{}},"title":{}}],["right)}^*}y'(t)dt",{"_index":1676,"text":{"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{}},"title":{}}],["right)}^2",{"_index":354,"text":{"Chap_10.html":{},"Chap_10.html#expressing-the-mean-square-error":{},"Chap_10.html#using-the-least-mean-square-error-criterion":{},"Chap_10.html#what-is-that-least-mean-square-error":{},"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_11.html#problem-115":{},"Chap_11.html#problem-117":{},"Chap_12.html":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_13.html":{},"Chap_13.html#appendix-i-mean-square-error-minimization":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_4.html":{},"Chap_4.html#properties-of-averaging":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#tethered-particle-motion":{},"Chap_8.html":{},"Chap_8.html#example-not-too-noisy":{}},"title":{}}],["right)}^2}\\left",{"_index":2945,"text":{"Chap_7.html":{},"Chap_7.html#autocorrelation-function":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#power-spectral-density":{}},"title":{}}],["right)}^2}\\sum\\limits_{n",{"_index":2944,"text":{"Chap_7.html":{},"Chap_7.html#autocorrelation-function":{}},"title":{}}],["right)}^2}{\\rho",{"_index":1097,"text":{"Chap_11.html":{},"Chap_11.html#langevin-redux":{}},"title":{}}],["right)}^2}}}\\phi",{"_index":1048,"text":{"Chap_11.html":{},"Chap_11.html#how-good-is-our-estimator":{}},"title":{}}],["right)}^2}}}{{{{\\left",{"_index":3460,"text":{"Chap_8.html":{},"Chap_8.html#example-not-too-noisy":{}},"title":{}}],["right)}^i}}&{i",{"_index":2304,"text":{"Chap_4.html":{},"Chap_4.html#problem-41":{}},"title":{}}],["right)}^k}{",{"_index":2535,"text":{"Chap_5.html":{},"Chap_5.html#example-pink-noise":{}},"title":{}}],["right)}^m",{"_index":2350,"text":{"Chap_4.html":{},"Chap_4.html#problem-47":{}},"title":{}}],["right)}^n",{"_index":2444,"text":{"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_7.html":{},"Chap_7.html#impulse-invariant-sampling":{}},"title":{}}],["right)}^n}u[n",{"_index":3034,"text":{"Chap_7.html":{},"Chap_7.html#the-langevin-position-equation":{}},"title":{}}],["right)}^n}u[n]{",{"_index":2483,"text":{"Chap_5.html":{},"Chap_5.html#a-digression":{}},"title":{}}],["right)}^n}{",{"_index":889,"text":{"Chap_11.html":{},"Chap_11.html#example-estimating-the-poisson-rate":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{}},"title":{}}],["right)}^{\\left",{"_index":2532,"text":{"Chap_5.html":{},"Chap_5.html#example-pink-noise":{}},"title":{}}],["right)}^{n",{"_index":2451,"text":{"Chap_5.html":{},"Chap_5.html#a-digression":{}},"title":{}}],["right)}_{{\\rho",{"_index":3278,"text":{"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period_1":{}},"title":{}}],["right)}}u(t",{"_index":2832,"text":{"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#impulse-invariant-sampling":{}},"title":{}}],["right)}}{z",{"_index":2842,"text":{"Chap_7.html":{},"Chap_7.html#impulse-invariant-sampling":{}},"title":{}}],["right)}}{{(1",{"_index":3315,"text":{"Chap_7.html":{},"Chap_7.html#autocorrelation-function_2":{},"Chap_7.html#descriptive-statistic-variance":{}},"title":{}}],["right)}}{{\\pi",{"_index":1645,"text":{"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{}},"title":{}}],["right)}}{{\\sin",{"_index":1370,"text":{"Chap_12.html":{},"Chap_12.html#windowed-observations":{}},"title":{}}],["right)}}{{{n_o}/\\left",{"_index":3477,"text":{"Chap_8.html":{},"Chap_8.html#example-cocktail-party-noise":{}},"title":{}}],["right\\rangl",{"_index":2935,"text":{"Chap_7.html":{},"Chap_7.html#autocorrelation-function_1":{},"Chap_7.html#descriptive-statistic-variance":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#expected-value":{},"Chap_7.html#one-step-further":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#problem-711":{},"Chap_7.html#the-langevin-velocity-equation":{}},"title":{}}],["right\\}\\,\\,\\,\\,\\,\\,\\,\\,\\,{w_p}(\\omega",{"_index":1340,"text":{"Chap_12.html":{},"Chap_12.html#windowed-observations":{}},"title":{}}],["right\\}\\mathop",{"_index":2404,"text":{"Chap_5.html":{},"Chap_5.html#correlations-simple-and-complex":{}},"title":{}}],["right\\}e\\left",{"_index":544,"text":{"Chap_10.html":{},"Chap_10.html#classic-example-classic-result":{},"Chap_5.html":{},"Chap_5.html#correlations-and-memory":{}},"title":{}}],["right\\}h[n",{"_index":2636,"text":{"Chap_6.html":{},"Chap_6.html#the-mean":{}},"title":{}}],["right]}}{{\\parti",{"_index":922,"text":{"Chap_11.html":{},"Chap_11.html#example-estimating-the-poisson-rate":{}},"title":{}}],["rightarrow",{"_index":579,"text":{"Chap_10.html":{},"Chap_10.html#classic-example-classic-result":{},"Chap_11.html":{},"Chap_11.html#example-estimating-the-poisson-rate":{},"Chap_12.html":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_4.html":{},"Chap_4.html#example-fair-chance":{},"Chap_4.html#example-is-that-coin-fair":{},"Chap_5.html":{},"Chap_5.html#correlations-simple-and-complex":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#one-step-further":{},"Chap_7.html#tethered-particle-motion":{},"Chap_7.html#the-langevin-position-equation":{}},"title":{}}],["right|){\\rho",{"_index":1128,"text":{"Chap_11.html":{},"Chap_11.html#langevin-redux":{}},"title":{}}],["right|/d",{"_index":3536,"text":{"Chap_8.html":{},"Chap_8.html#problem-83":{}},"title":{}}],["right|/n",{"_index":1311,"text":{"Chap_12.html":{},"Chap_12.html#the-periodogram-unbiased":{}},"title":{}}],["right|\\left",{"_index":3637,"text":{"Chap_9.html":{},"Chap_9.html#laboratory-exercise-93":{}},"title":{}}],["right|^2",{"_index":367,"text":{"Chap_10.html":{},"Chap_10.html#using-the-least-mean-square-error-criterion":{},"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#spectral-estimation":{},"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#correlations-and-memory":{},"Chap_5.html#correlations-simple-and-complex":{},"Chap_5.html#example-pink-noise":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#the-langevin-velocity-equation":{},"Chap_8.html":{},"Chap_8.html#example-filtering-noise":{},"Chap_8.html#snr-for-random-signals-in-the-presence-of-noise":{},"Chap_9.html":{},"Chap_9.html#laboratory-exercise-93":{},"Chap_9.html#using-cauchy-schwartz":{}},"title":{}}],["right|^2}{\\left",{"_index":3639,"text":{"Chap_9.html":{},"Chap_9.html#laboratory-exercise-93":{}},"title":{}}],["right|^2}{\\varphi",{"_index":2707,"text":{"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{}},"title":{}}],["right|^2}{s_{xx}}(\\omega",{"_index":102,"text":{"Chap_1.html":{},"Chap_1.html#highlighting":{},"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_8.html":{},"Chap_8.html#example-filtering-noise":{}},"title":{}}],["right|_",{"_index":1678,"text":{"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{}},"title":{}}],["right|_{\\omega",{"_index":3041,"text":{"Chap_7.html":{},"Chap_7.html#expected-value":{}},"title":{}}],["right|_{k",{"_index":2771,"text":{"Chap_6.html":{},"Chap_6.html#problem-61":{}},"title":{}}],["right|d\\omega",{"_index":2695,"text":{"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{}},"title":{}}],["right|{\\rho",{"_index":1124,"text":{"Chap_11.html":{},"Chap_11.html#langevin-redux":{}},"title":{}}],["right|}(1",{"_index":3311,"text":{"Chap_7.html":{},"Chap_7.html#autocorrelation-function_2":{}},"title":{}}],["right|}^2",{"_index":336,"text":{"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#using-the-least-mean-square-error-criterion":{},"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_4.html":{},"Chap_4.html#cross-covariance":{},"Chap_5.html":{},"Chap_5.html#correlations-simple-and-complex":{},"Chap_5.html#example-pink-noise":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_6.html":{},"Chap_6.html#problem-66":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#power-spectral-density_1":{},"Chap_8.html":{},"Chap_8.html#example-not-too-noisy":{},"Chap_9.html":{},"Chap_9.html#example-matching-your-filter":{},"Chap_9.html#problem-92":{},"Chap_9.html#setting-up-the-problem":{},"Chap_9.html#using-cauchy-schwartz":{}},"title":{}}],["right|}^2}d\\omega",{"_index":1476,"text":{"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_9.html":{},"Chap_9.html#using-cauchy-schwartz":{}},"title":{}}],["right|}^2}dt",{"_index":1623,"text":{"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{}},"title":{}}],["right|}^2}{f_o",{"_index":3079,"text":{"Chap_7.html":{},"Chap_7.html#power-spectral-density_1":{}},"title":{}}],["right|}^2}{s_{ff}}(\\omega",{"_index":3078,"text":{"Chap_7.html":{},"Chap_7.html#power-spectral-density_1":{}},"title":{}}],["right|}^2}{s_{nn}}(\\omega",{"_index":3560,"text":{"Chap_9.html":{},"Chap_9.html#setting-up-the-problem":{}},"title":{}}],["right|}^2}{s_{xx}}(\\omega",{"_index":703,"text":{"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{}},"title":{}}],["right|}^2}{s_{xx}}({\\omega",{"_index":2686,"text":{"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{}},"title":{}}],["right|}^2}}}{{2\\pi",{"_index":2705,"text":{"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{}},"title":{}}],["right|}^2}}}{{{\\varphi",{"_index":3451,"text":{"Chap_8.html":{},"Chap_8.html#snr-for-random-signals-in-the-presence-of-noise":{}},"title":{}}],["right|}^2}}}{{{n_0",{"_index":3582,"text":{"Chap_9.html":{},"Chap_9.html#example-matching-your-filter":{}},"title":{}}],["right|}^2}}}{{{s_{nn}}(\\omega",{"_index":3571,"text":{"Chap_9.html":{},"Chap_9.html#using-cauchy-schwartz":{}},"title":{}}],["right|}}\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\left",{"_index":3514,"text":{"Chap_8.html":{},"Chap_8.html#problem-81":{}},"title":{}}],["right|}}\\sum\\limits_{n",{"_index":1028,"text":{"Chap_11.html":{},"Chap_11.html#estimating-the-autocorrelation-function":{},"Chap_11.html#how-good-is-our-estimator":{}},"title":{}}],["right|}}{",{"_index":2533,"text":{"Chap_5.html":{},"Chap_5.html#example-pink-noise":{}},"title":{}}],["right|}}{\\rho",{"_index":1098,"text":{"Chap_11.html":{},"Chap_11.html#langevin-redux":{}},"title":{}}],["right|}}{n",{"_index":1151,"text":{"Chap_11.html":{},"Chap_11.html#trouble-in-paradise":{},"Chap_12.html":{},"Chap_12.html#the-periodogram-unbiased":{}},"title":{}}],["right|}}{n}{\\varphi",{"_index":1308,"text":{"Chap_12.html":{},"Chap_12.html#the-periodogram-unbiased":{}},"title":{}}],["right|}}{n}}&{\\left",{"_index":1327,"text":{"Chap_12.html":{},"Chap_12.html#windowed-observations":{}},"title":{}}],["right|}}{{\\sqrt",{"_index":3557,"text":{"Chap_9.html":{},"Chap_9.html#setting-up-the-problem":{}},"title":{}}],["right|}}{{{\\sigma",{"_index":3429,"text":{"Chap_8.html":{},"Chap_8.html#snr-for-deterministic-signals-in-the-presence-of-noise":{}},"title":{}}],["rise",{"_index":1753,"text":{"Chap_2.html":{},"Chap_2.html#prologue":{},"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{}},"title":{}}],["river",{"_index":2048,"text":{"Chap_3.html":{},"Chap_3.html#problem-310":{},"Chap_4.html":{},"Chap_4.html#laboratory-exercise-42":{},"Chap_5.html":{},"Chap_5.html#laboratory-exercise-51":{},"Chap_7.html":{},"Chap_7.html#problem-711":{}},"title":{}}],["rm",{"_index":1488,"text":{"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_7.html":{},"Chap_7.html#one-step-further":{},"Chap_8.html":{},"Chap_8.html#example-not-too-noisy":{}},"title":{}}],["rm{m}}{{\\rm{g",{"_index":3135,"text":{"Chap_7.html":{},"Chap_7.html#tethered-particle-motion":{}},"title":{}}],["rm{rad}}/{\\rm{",{"_index":3238,"text":{"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{}},"title":{}}],["rm{sinc}}(t",{"_index":1661,"text":{"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{}},"title":{}}],["rm{the\\,chicago\\,cubs\\,will\\,not\\,win\\,the\\,world\\,seri",{"_index":3614,"text":{"Chap_9.html":{},"Chap_9.html#problem-92":{}},"title":{}}],["rm{the\\,chicago\\,cubs\\,will\\,win\\,the\\,nba",{"_index":3608,"text":{"Chap_9.html":{},"Chap_9.html#problem-92":{}},"title":{}}],["rm{the\\,chicago\\,cubs\\,will\\,win\\,the\\,sup",{"_index":3611,"text":{"Chap_9.html":{},"Chap_9.html#problem-92":{}},"title":{}}],["rm{the\\,chicago\\,cubs\\,will\\,win\\,the\\,world\\,seri",{"_index":3606,"text":{"Chap_9.html":{},"Chap_9.html#problem-92":{}},"title":{}}],["robust",{"_index":3595,"text":{"Chap_9.html":{},"Chap_9.html#performance-in-the-presence-of-noise":{},"Chap_9.html#problem-91":{}},"title":{}}],["roc",{"_index":2844,"text":{"Chap_7.html":{},"Chap_7.html#impulse-invariant-sampling":{}},"title":{}}],["role",{"_index":3424,"text":{"Chap_8.html":{},"Chap_8.html#example-filtering-noise":{}},"title":{}}],["ronald",{"_index":1727,"text":{"Chap_13.html":{},"Chap_13.html#epilogue":{},"info.html":{},"info.html#authors":{}},"title":{}}],["rondo",{"_index":3726,"text":{"info.html":{},"info.html#musical-data":{}},"title":{}}],["room",{"_index":663,"text":{"Chap_10.html":{},"Chap_10.html#example-sound-of-distorted-music":{}},"title":{}}],["root",{"_index":965,"text":{"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_3.html":{},"Chap_3.html#problem-310":{},"Chap_4.html":{},"Chap_4.html#properties-of-averaging":{},"Chap_7.html":{},"Chap_7.html#one-step-further":{},"Chap_8.html":{},"Chap_8.html#example-not-too-noisy":{}},"title":{}}],["rotterdam",{"_index":2194,"text":{"Chap_4.html":{},"Chap_4.html#the-mechanics-of-correlations":{}},"title":{}}],["rough",{"_index":2889,"text":{"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small":{}},"title":{}}],["rout",{"_index":2571,"text":{"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{}},"title":{}}],["row",{"_index":625,"text":{"Chap_10.html":{},"Chap_10.html#why-we-avoid-the-inverse-filter":{},"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{}},"title":{}}],["royal",{"_index":1258,"text":{"Chap_11.html":{},"Chap_11.html#laboratory-exercise-113":{},"Chap_4.html":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"info.html":{},"info.html#cover":{},"info.html#weather-data":{}},"title":{}}],["rubinstein",{"_index":3222,"text":{"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#problem-711":{}},"title":{}}],["rule",{"_index":1854,"text":{"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{}},"title":{}}],["ruler",{"_index":1239,"text":{"Chap_11.html":{},"Chap_11.html#laboratory-exercise-113":{}},"title":{}}],["rule\u2014togeth",{"_index":1746,"text":{"Chap_13.html":{},"Chap_13.html#epilogue":{}},"title":{}}],["run",{"_index":3701,"text":{"info.html":{},"info.html#technical-details":{}},"title":{}}],["rvert",{"_index":2911,"text":{"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#power-spectral-density_1":{}},"title":{}}],["rvert/m",{"_index":2978,"text":{"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#power-spectral-density_1":{}},"title":{}}],["rvert^2",{"_index":2983,"text":{"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#power-spectral-density_1":{}},"title":{}}],["rvert_{\\tau",{"_index":2987,"text":{"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#power-spectral-density_1":{}},"title":{}}],["s",{"_index":216,"text":{"Chap_1.html":{},"Chap_1.html#enhanced-experience":{},"Chap_11.html":{},"Chap_11.html#laboratory-exercise-113":{},"Chap_12.html":{},"Chap_12.html#problem-122":{},"Chap_3.html":{},"Chap_3.html#problem-310":{},"Chap_4.html":{},"Chap_4.html#problem-42":{},"Chap_5.html":{},"Chap_5.html#laboratory-exercise-51":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#how-big-is-big-how-small-is-small":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#power-spectral-density_2":{},"Chap_7.html#problem-711":{},"Chap_7.html#problem-79":{},"Chap_7.html#tethered-particle-motion":{},"Chap_7.html#the-langevin-position-equation":{},"Chap_8.html":{},"Chap_8.html#problem-82":{},"Chap_8.html#problem-83":{}},"title":{}}],["s(\\omega",{"_index":3368,"text":{"Chap_7.html":{},"Chap_7.html#why-this-case-study":{}},"title":{}}],["s[n",{"_index":3466,"text":{"Chap_8.html":{},"Chap_8.html#example-cocktail-party-noise":{},"Chap_8.html#problem-83":{}},"title":{}}],["s[n\\rbrack",{"_index":3467,"text":{"Chap_8.html":{},"Chap_8.html#example-cocktail-party-noise":{}},"title":{}}],["s\\tild",{"_index":3425,"text":{"Chap_8.html":{},"Chap_8.html#snr-for-deterministic-signals-in-the-presence-of-noise":{},"Chap_8.html#snr-for-random-signals-in-the-presence-of-noise":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{},"Chap_9.html":{},"Chap_9.html#example-matching-your-filter":{},"Chap_9.html#setting-up-the-problem":{},"Chap_9.html#using-cauchy-schwartz":{}},"title":{}}],["s_",{"_index":2785,"text":{"Chap_6.html":{},"Chap_6.html#laboratory-exercise-63":{}},"title":{}}],["s_0",{"_index":3480,"text":{"Chap_8.html":{},"Chap_8.html#example-cocktail-party-noise":{}},"title":{}}],["s_1}[n",{"_index":3604,"text":{"Chap_9.html":{},"Chap_9.html#problem-92":{}},"title":{}}],["s_2}[n",{"_index":3607,"text":{"Chap_9.html":{},"Chap_9.html#problem-92":{}},"title":{}}],["s_3}[n",{"_index":3610,"text":{"Chap_9.html":{},"Chap_9.html#problem-92":{}},"title":{}}],["s_4}[n",{"_index":3613,"text":{"Chap_9.html":{},"Chap_9.html#problem-92":{}},"title":{}}],["s_i}[n",{"_index":3599,"text":{"Chap_9.html":{},"Chap_9.html#problem-91":{},"Chap_9.html#problem-92":{}},"title":{}}],["s_i}[n\\rbrack",{"_index":3596,"text":{"Chap_9.html":{},"Chap_9.html#problem-91":{}},"title":{}}],["s_k",{"_index":3374,"text":{"Chap_7.html":{},"Chap_7.html#problem-72":{}},"title":{}}],["s_k}t}}u(t",{"_index":2849,"text":{"Chap_7.html":{},"Chap_7.html#impulse-invariant-sampling":{}},"title":{}}],["s_o",{"_index":1282,"text":{"Chap_12.html":{},"Chap_12.html#spectral-estimation":{}},"title":{}}],["s_x^2",{"_index":1204,"text":{"Chap_11.html":{},"Chap_11.html#problem-117":{}},"title":{}}],["s_{\\psi",{"_index":1227,"text":{"Chap_11.html":{},"Chap_11.html#problem-119":{}},"title":{}}],["s_{ff}}(\\omega",{"_index":2927,"text":{"Chap_7.html":{},"Chap_7.html#power-spectral-density":{},"Chap_7.html#the-langevin-velocity-equation":{}},"title":{}}],["s_{hh}}(\\omega",{"_index":2673,"text":{"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_7.html":{},"Chap_7.html#power-spectral-density":{}},"title":{}}],["s_{nn}}(\\omega",{"_index":556,"text":{"Chap_10.html":{},"Chap_10.html#classic-example-classic-result":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#example-cleaning-up-our-act":{},"Chap_8.html":{},"Chap_8.html#example-cocktail-party-noise":{},"Chap_9.html":{},"Chap_9.html#the-classic-example":{},"Chap_9.html#using-cauchy-schwartz":{}},"title":{}}],["s_{pp}}\\left",{"_index":2552,"text":{"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{}},"title":{}}],["s_{rr}}(\\omega",{"_index":492,"text":{"Chap_10.html":{},"Chap_10.html#as-seen-from-the-fourier-domain":{},"Chap_10.html#classic-example-classic-result":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#example-cleaning-up-our-act":{},"Chap_10.html#why-we-avoid-the-inverse-filter":{}},"title":{}}],["s_{rx}}(\\omega",{"_index":491,"text":{"Chap_10.html":{},"Chap_10.html#as-seen-from-the-fourier-domain":{},"Chap_10.html#classic-example-classic-result":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#what-is-that-least-mean-square-error":{}},"title":{}}],["s_{ss}}(\\omega",{"_index":3468,"text":{"Chap_8.html":{},"Chap_8.html#example-cocktail-party-noise":{},"Chap_8.html#problem-83":{}},"title":{}}],["s_{tt}}(\\omega",{"_index":1279,"text":{"Chap_12.html":{},"Chap_12.html#spectral-estimation":{}},"title":{}}],["s_{tt}}\\left",{"_index":2551,"text":{"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{}},"title":{}}],["s_{vv",{"_index":2981,"text":{"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{}},"title":{}}],["s_{vv}}(\\omega",{"_index":2939,"text":{"Chap_7.html":{},"Chap_7.html#autocorrelation-function":{},"Chap_7.html#power-spectral-density":{},"Chap_7.html#problem-75":{}},"title":{}}],["s_{xx",{"_index":2507,"text":{"Chap_5.html":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_7.html":{},"Chap_7.html#power-spectral-density_1":{}},"title":{}}],["s_{xx}^*(\\omega",{"_index":2510,"text":{"Chap_5.html":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{}},"title":{}}],["s_{xx}}(\\omega",{"_index":502,"text":{"Chap_10.html":{},"Chap_10.html#classic-example-classic-result":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#example-sound-of-distorted-music":{},"Chap_10.html#what-is-that-least-mean-square-error":{},"Chap_10.html#why-we-avoid-the-inverse-filter":{},"Chap_11.html":{},"Chap_11.html#aspects-of-estimation":{},"Chap_11.html#problem-119":{},"Chap_12.html":{},"Chap_12.html#spectral-estimation":{},"Chap_12.html#the-periodogram-unbiased":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_12.html#windowed-observations":{},"Chap_5.html":{},"Chap_5.html#example-pink-noise":{},"Chap_5.html#example-white-noise":{},"Chap_5.html#problem-54":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_7.html":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#power-spectral-density_2":{},"Chap_7.html#problem-76":{},"Chap_8.html":{},"Chap_8.html#example-filtering-noise":{},"Chap_8.html#problem-81":{}},"title":{}}],["s_{xx}}(f",{"_index":2601,"text":{"Chap_5.html":{},"Chap_5.html#problem-56":{}},"title":{}}],["s_{xx}}({\\omega",{"_index":2688,"text":{"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{}},"title":{}}],["s_{xy}}(\\omega",{"_index":2517,"text":{"Chap_5.html":{},"Chap_5.html#problem-55":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{}},"title":{}}],["s_{yx}}(\\omega",{"_index":695,"text":{"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{}},"title":{}}],["s_{yy}}(\\omega",{"_index":98,"text":{"Chap_1.html":{},"Chap_1.html#highlighting":{},"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#example-sound-of-distorted-music":{},"Chap_6.html":{},"Chap_6.html#problem-64":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_7.html":{},"Chap_7.html#problem-73":{},"Chap_8.html":{},"Chap_8.html#example-filtering-noise":{}},"title":{}}],["s_{yy}}({\\omega",{"_index":2691,"text":{"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{}},"title":{}}],["saddl",{"_index":740,"text":{"Chap_10.html":{},"Chap_10.html#problem-101":{},"Chap_11.html":{},"Chap_11.html#example-estimating-the-poisson-rate":{},"Chap_3.html":{},"Chap_3.html#problem-310":{},"Chap_4.html":{},"Chap_4.html#laboratory-exercise-42":{},"Chap_5.html":{},"Chap_5.html#laboratory-exercise-51":{},"Chap_7.html":{},"Chap_7.html#problem-711":{}},"title":{}}],["safari",{"_index":60,"text":{"Chap_1.html":{},"Chap_1.html#how-to-use-this-ibook":{}},"title":{}}],["sake",{"_index":1531,"text":{"Chap_12.html":{},"Chap_12.html#problem-122":{}},"title":{}}],["sale",{"_index":2745,"text":{"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{}},"title":{}}],["same",{"_index":1216,"text":{"Chap_11.html":{},"Chap_11.html#laboratory-exercise-112":{},"Chap_11.html#problem-117":{},"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#problem-122":{},"Chap_12.html#the-periodogram-unbiased":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_3.html#problem-310":{},"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#describing-the-time-average":{},"Chap_4.html#properties-of-averaging":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_5.html":{},"Chap_5.html#example-white-noise":{},"Chap_5.html#fourier-description-of-correlation-functions":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{},"Chap_6.html#interpretation-of-the-convolution-result":{},"Chap_6.html#problem-64":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function_2":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#one-step-further":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#problem-78":{},"Chap_7.html#the-langevin-position-equation":{},"Chap_8.html":{},"Chap_8.html#snr-for-random-signals-in-the-presence-of-noise":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{},"Chap_9.html":{},"Chap_9.html#the-matched-filter":{}},"title":{}}],["sampl",{"_index":39,"text":{"Chap_1.html":{},"Chap_1.html#how-to-use-this-ibook":{},"Chap_10.html":{},"Chap_10.html#example-cleaning-up-our-act":{},"Chap_10.html#laboratory-exercise-105":{},"Chap_10.html#problem-104":{},"Chap_11.html":{},"Chap_11.html#aspects-of-estimation":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_11.html#estimating-the-autocorrelation-function":{},"Chap_11.html#estimating-the-mean":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_11.html#laboratory-exercise-113":{},"Chap_11.html#problem-112":{},"Chap_11.html#problem-114":{},"Chap_11.html#problem-117":{},"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#laboratory-exercise-122":{},"Chap_12.html#problem-121":{},"Chap_12.html#problem-122":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_2.html":{},"Chap_2.html#prologue":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_4.html":{},"Chap_4.html#example-dice-money":{},"Chap_4.html#example-fair-chance":{},"Chap_4.html#problem-45":{},"Chap_4.html#problem-48":{},"Chap_6.html":{},"Chap_6.html#laboratory-exercise-63":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#descriptive-statistic-variance":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#from-t-to-n":{},"Chap_7.html#impulse-invariant-sampling":{},"Chap_7.html#one-step-further":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#power-spectral-density_2":{},"Chap_7.html#problem-72":{},"Chap_7.html#problem-79":{},"Chap_7.html#the-langevin-equation-a-case-study":{},"Chap_8.html":{},"Chap_8.html#example-cocktail-party-noise":{}},"title":{"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#impulse-invariant-sampling":{}}}],["samples/record",{"_index":1401,"text":{"Chap_12.html":{},"Chap_12.html#the-periodogram-what-about-convergence":{}},"title":{}}],["samples\u2014se",{"_index":1161,"text":{"Chap_11.html":{},"Chap_11.html#trouble-in-paradise":{}},"title":{}}],["sand",{"_index":2371,"text":{"Chap_4.html":{},"Chap_4.html#laboratory-exercise-42":{},"Chap_7.html":{},"Chap_7.html#problem-711":{}},"title":{}}],["satisfi",{"_index":1670,"text":{"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_4.html":{},"Chap_4.html#problem-48":{},"Chap_4.html#problem-49":{},"Chap_5.html":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_7.html":{},"Chap_7.html#problem-72":{},"Chap_9.html":{},"Chap_9.html#setting-up-the-problem":{}},"title":{}}],["save",{"_index":3602,"text":{"Chap_9.html":{},"Chap_9.html#problem-91":{},"Chap_9.html#problem-92":{}},"title":{}}],["saw",{"_index":1063,"text":{"Chap_11.html":{},"Chap_11.html#langevin-redux":{},"Chap_7.html":{},"Chap_7.html#descriptive-statistic-variance":{},"Chap_7.html#expected-value":{},"Chap_7.html#power-spectral-density_1":{},"Chap_9.html":{},"Chap_9.html#performance-in-the-presence-of-noise":{}},"title":{}}],["scalar",{"_index":3632,"text":{"Chap_9.html":{},"Chap_9.html#laboratory-exercise-93":{}},"title":{}}],["scale",{"_index":2431,"text":{"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_6.html":{},"Chap_6.html#interpretation-of-the-convolution-result":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#one-step-further":{},"Chap_7.html#tethered-particle-motion":{}},"title":{}}],["scatter",{"_index":3408,"text":{"Chap_7.html":{},"Chap_7.html#problem-711":{}},"title":{}}],["schafer",{"_index":2383,"text":{"Chap_4.html":{},"Chap_4.html#laboratory-exercise-42":{},"Chap_5.html":{},"Chap_5.html#laboratory-exercise-51":{}},"title":{}}],["schiphol",{"_index":2232,"text":{"Chap_4.html":{},"Chap_4.html#the-mechanics-of-correlations":{}},"title":{}}],["scholarship",{"_index":237,"text":{"Chap_1.html":{},"Chap_1.html#enhanced-experience":{}},"title":{}}],["schr\u00f6dinger\u2019",{"_index":2306,"text":{"Chap_4.html":{},"Chap_4.html#problem-42":{}},"title":{}}],["schwartz",{"_index":1682,"text":{"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_9.html":{},"Chap_9.html#laboratory-exercise-93":{},"Chap_9.html#using-cauchy-schwartz":{}},"title":{"Chap_9.html#using-cauchy-schwartz":{}}}],["scienc",{"_index":856,"text":{"Chap_11.html":{},"Chap_11.html#aspects-of-estimation":{},"Chap_12.html":{},"Chap_12.html#laboratory-exercise-124":{}},"title":{}}],["scientist",{"_index":1249,"text":{"Chap_11.html":{},"Chap_11.html#laboratory-exercise-113":{}},"title":{}}],["screen",{"_index":69,"text":{"Chap_1.html":{},"Chap_1.html#getting-around":{},"Chap_1.html#how-to-use-this-ibook":{},"info.html":{},"info.html#tips-short-cuts":{}},"title":{}}],["scroll",{"_index":3653,"text":{"info.html":{},"info.html#tips-short-cuts":{}},"title":{}}],["search",{"_index":1355,"text":{"Chap_12.html":{},"Chap_12.html#other-windows":{},"Chap_12.html#windowed-observations":{},"Chap_9.html":{},"Chap_9.html#the-matched-filter":{},"info.html":{},"info.html#tips-short-cuts":{}},"title":{}}],["season",{"_index":2590,"text":{"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{}},"title":{}}],["second",{"_index":550,"text":{"Chap_10.html":{},"Chap_10.html#classic-example-classic-result":{},"Chap_10.html#why-we-avoid-the-inverse-filter":{},"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_11.html#langevin-redux":{},"Chap_11.html#problem-119":{},"Chap_12.html":{},"Chap_12.html#problem-122":{},"Chap_12.html#problem-123":{},"Chap_12.html#the-periodogram-unbiased":{},"Chap_13.html":{},"Chap_13.html#epilogue":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_4.html":{},"Chap_4.html#auto-covariance":{},"Chap_4.html#cross-covariance":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#problem-42":{},"Chap_5.html":{},"Chap_5.html#correlations-simple-and-complex":{},"Chap_5.html#problem-51":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#expected-value":{},"Chap_7.html#how-big-is-big-how-small-is-small":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#one-step-further":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#tethered-particle-motion":{},"info.html":{},"info.html#version":{}},"title":{}}],["second\u2014so",{"_index":3509,"text":{"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{}},"title":{}}],["section",{"_index":220,"text":{"Chap_1.html":{},"Chap_1.html#enhanced-experience":{},"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#example-sound-of-distorted-music":{},"Chap_10.html#problem-104":{},"Chap_10.html#what-is-that-least-mean-square-error":{},"Chap_11.html":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_11.html#laboratory-exercise-113":{},"Chap_12.html":{},"Chap_12.html#other-windows":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_3.html":{},"Chap_3.html#problem-39":{},"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#example-is-that-coin-fair":{},"Chap_4.html#laboratory-exercise-42":{},"Chap_5.html":{},"Chap_5.html#fourier-description-of-correlation-functions":{},"Chap_5.html#laboratory-exercise-51":{},"Chap_7.html":{},"Chap_7.html#from-t-to-n":{},"Chap_7.html#how-big-is-big-how-small-is-small":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#problem-79":{},"Chap_7.html#tethered-particle-motion":{},"Chap_8.html":{},"Chap_8.html#example-filtering-noise":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{}},"title":{}}],["see",{"_index":6,"text":{"Chap_1.html":{},"Chap_1.html#getting-around":{},"Chap_1.html#outside-this-device":{},"Chap_10.html":{},"Chap_10.html#classic-example-classic-result":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#using-the-least-mean-square-error-criterion":{},"Chap_10.html#what-is-that-least-mean-square-error":{},"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_11.html#estimating-the-mean":{},"Chap_11.html#example-estimating-the-poisson-rate":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_11.html#langevin-redux":{},"Chap_11.html#maximum-likelihood-estimation":{},"Chap_11.html#problem-117":{},"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#problem-122":{},"Chap_12.html#the-periodogram-unbiased":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_12.html#windowed-observations":{},"Chap_13.html":{},"Chap_13.html#appendix-i-mean-square-error-minimization":{},"Chap_13.html#epilogue":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_4.html":{},"Chap_4.html#auto-covariance":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#example-dice-money":{},"Chap_4.html#example-is-that-coin-fair":{},"Chap_4.html#laboratory-exercise-41":{},"Chap_4.html#laboratory-exercise-42":{},"Chap_4.html#properties-of-averaging":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#correlations-and-memory":{},"Chap_5.html#correlations-simple-and-complex":{},"Chap_5.html#example-white-noise":{},"Chap_5.html#fourier-description-of-correlation-functions":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_6.html":{},"Chap_6.html#interpretation-of-the-convolution-result":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_6.html#the-mean":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#descriptive-statistic-variance":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#from-t-to-n":{},"Chap_7.html#how-big-is-big-how-small-is-small":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#impulse-invariant-sampling":{},"Chap_7.html#one-step-further":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#power-spectral-density_2":{},"Chap_7.html#tethered-particle-motion":{},"Chap_7.html#the-langevin-equation-a-case-study":{},"Chap_7.html#the-langevin-position-equation":{},"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{},"Chap_9.html":{},"Chap_9.html#performance-in-the-presence-of-noise":{}},"title":{}}],["seek",{"_index":687,"text":{"Chap_10.html":{},"Chap_10.html#example-cleaning-up-our-act":{},"Chap_11.html":{},"Chap_11.html#example-estimating-the-poisson-rate":{},"Chap_13.html":{},"Chap_13.html#appendix-i-mean-square-error-minimization":{},"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{}},"title":{}}],["seem",{"_index":907,"text":{"Chap_11.html":{},"Chap_11.html#example-estimating-the-poisson-rate":{},"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#the-periodogram-unbiased":{},"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#properties-of-averaging":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#impulse-invariant-sampling":{}},"title":{}}],["seemingli",{"_index":2470,"text":{"Chap_5.html":{},"Chap_5.html#a-digression":{}},"title":{}}],["seen",{"_index":486,"text":{"Chap_10.html":{},"Chap_12.html":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_7.html":{},"Chap_7.html#expected-value":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#problem-78":{},"Chap_7.html#tethered-particle-motion":{},"Chap_7.html#why-this-case-study":{},"Chap_9.html":{},"Chap_9.html#problem-91":{}},"title":{"Chap_10.html#as-seen-from-the-fourier-domain":{}}}],["segment",{"_index":3229,"text":{"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{}},"title":{}}],["select",{"_index":165,"text":{"Chap_1.html":{},"Chap_1.html#sound-of-music":{},"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#example-sound-of-distorted-music":{},"Chap_9.html":{},"Chap_9.html#problem-91":{}},"title":{}}],["semant",{"_index":2610,"text":{"Chap_5.html":{},"Chap_5.html#laboratory-exercise-51":{}},"title":{}}],["send",{"_index":3664,"text":{"info.html":{},"info.html#contact":{}},"title":{}}],["sens",{"_index":2085,"text":{"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_6.html":{},"Chap_6.html#the-mean":{},"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{}},"title":{}}],["sensit",{"_index":3541,"text":{"Chap_8.html":{},"Chap_8.html#problem-83":{}},"title":{}}],["sent",{"_index":3618,"text":{"Chap_9.html":{},"Chap_9.html#problem-92":{}},"title":{}}],["sentenc",{"_index":209,"text":{"Chap_1.html":{},"Chap_1.html#enhanced-experience":{}},"title":{}}],["separ",{"_index":1561,"text":{"Chap_12.html":{},"Chap_12.html#problem-123":{},"Chap_9.html":{},"Chap_9.html#the-matched-filter":{}},"title":{}}],["sequenc",{"_index":3350,"text":{"Chap_7.html":{},"Chap_7.html#one-step-further":{}},"title":{}}],["seri",{"_index":496,"text":{"Chap_10.html":{},"Chap_10.html#what-is-that-least-mean-square-error":{},"Chap_11.html":{},"Chap_11.html#laboratory-exercise-113":{},"Chap_11.html#problem-114":{},"Chap_12.html":{},"Chap_12.html#problem-122":{},"Chap_4.html":{},"Chap_4.html#describing-the-time-average":{},"Chap_7.html":{},"Chap_7.html#descriptive-statistic-variance":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"info.html":{},"info.html#cover":{}},"title":{}}],["serious",{"_index":1372,"text":{"Chap_12.html":{},"Chap_12.html#the-periodogram-what-about-convergence":{}},"title":{}}],["serv",{"_index":992,"text":{"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{}},"title":{}}],["session",{"_index":2348,"text":{"Chap_4.html":{},"Chap_4.html#problem-47":{}},"title":{}}],["set",{"_index":918,"text":{"Chap_11.html":{},"Chap_11.html#example-estimating-the-poisson-rate":{},"Chap_12.html":{},"Chap_12.html#the-periodogram-unbiased":{},"Chap_13.html":{},"Chap_13.html#appendix-i-mean-square-error-minimization":{},"Chap_13.html#epilogue":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_5.html":{},"Chap_5.html#correlations-simple-and-complex":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_6.html":{},"Chap_6.html#the-autocorrelation-function":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function":{},"Chap_9.html":{},"info.html":{},"info.html#technical-details":{}},"title":{"Chap_9.html#setting-up-the-problem":{}}}],["settl",{"_index":2052,"text":{"Chap_4.html":{},"Chap_4.html#characterization-of-random-signals":{}},"title":{}}],["sever",{"_index":708,"text":{"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_11.html":{},"Chap_11.html#langevin-redux":{},"Chap_3.html":{},"Chap_3.html#the-basics":{},"Chap_3.html#what-is-a-random-signal":{},"Chap_4.html":{},"Chap_4.html#properties-of-averaging":{},"Chap_5.html":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_7.html":{},"Chap_7.html#from-t-to-n":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_8.html":{},"Chap_8.html#example-filtering-noise":{}},"title":{}}],["shall",{"_index":244,"text":{"Chap_1.html":{},"Chap_1.html#enhanced-experience":{},"Chap_12.html":{},"Chap_12.html#problem-122":{},"Chap_13.html":{},"Chap_13.html#appendix-i-mean-square-error-minimization":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#impulse-invariant-sampling":{},"Chap_7.html#tethered-particle-motion":{},"Chap_7.html#the-langevin-equation-a-case-study":{},"Chap_7.html#the-langevin-position-equation":{},"Chap_7.html#why-this-case-study":{}},"title":{}}],["shankar",{"_index":3739,"text":{"info.html":{},"info.html#musical-data":{}},"title":{}}],["shape",{"_index":1356,"text":{"Chap_12.html":{},"Chap_12.html#laboratory-exercise-123":{},"Chap_12.html#laboratory-exercise-124":{},"Chap_12.html#windowed-observations":{}},"title":{}}],["shift",{"_index":1017,"text":{"Chap_11.html":{},"Chap_11.html#estimating-the-autocorrelation-function":{},"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_5.html":{},"Chap_5.html#example-delayed-effect":{},"Chap_9.html":{},"Chap_9.html#the-matched-filter-as-an-autocorrelation":{}},"title":{}}],["short",{"_index":643,"text":{"Chap_10.html":{},"Chap_10.html#example-sound-of-distorted-music":{},"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"info.html":{}},"title":{"info.html#tips-short-cuts":{}}}],["shorter",{"_index":1698,"text":{"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{}},"title":{}}],["shorthand",{"_index":1822,"text":{"Chap_3.html":{},"Chap_3.html#the-basics":{}},"title":{}}],["show",{"_index":270,"text":{"Chap_10.html":{},"Chap_10.html#classic-example-classic-result":{},"Chap_10.html#problem-101":{},"Chap_10.html#problem-102":{},"Chap_10.html#the-wiener-filter":{},"Chap_10.html#what-is-that-least-mean-square-error":{},"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_11.html#example-estimating-the-poisson-rate":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_11.html#langevin-redux":{},"Chap_11.html#problem-111":{},"Chap_11.html#problem-1110":{},"Chap_11.html#problem-115":{},"Chap_11.html#problem-116":{},"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#the-periodogram-unbiased":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_12.html#windowed-observations":{},"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_3.html#problem-38":{},"Chap_3.html#what-is-a-random-signal":{},"Chap_5.html":{},"Chap_5.html#correlations-and-memory":{},"Chap_5.html#correlations-simple-and-complex":{},"Chap_5.html#example-pink-noise":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_5.html#problem-54":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function_1":{},"Chap_7.html#expected-value":{},"Chap_7.html#problem-710":{},"Chap_7.html#problem-711":{},"Chap_7.html#problem-72":{},"Chap_7.html#problem-74":{},"Chap_7.html#problem-75":{},"Chap_7.html#problem-76":{},"Chap_7.html#why-this-case-study":{},"Chap_8.html":{},"Chap_8.html#problem-83":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{}},"title":{}}],["shown",{"_index":311,"text":{"Chap_10.html":{},"Chap_10.html#example-cleaning-up-our-act":{},"Chap_10.html#example-sound-of-distorted-music":{},"Chap_10.html#the-restoration-case-noise":{},"Chap_10.html#using-the-least-mean-square-error-criterion":{},"Chap_10.html#why-we-avoid-the-inverse-filter":{},"Chap_11.html":{},"Chap_11.html#aspects-of-estimation":{},"Chap_11.html#estimating-the-autocorrelation-function":{},"Chap_11.html#estimating-the-mean":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_11.html#laboratory-exercise-113":{},"Chap_11.html#problem-117":{},"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#problem-123":{},"Chap_12.html#spectral-estimation":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_13.html":{},"Chap_13.html#appendix-i-mean-square-error-minimization":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_3.html#problem-310":{},"Chap_3.html#problem-36":{},"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{},"Chap_6.html#interpretation-of-the-convolution-result":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#power-spectral-density":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#power-spectral-density_2":{},"Chap_7.html#problem-79":{},"Chap_7.html#tethered-particle-motion":{},"Chap_8.html":{},"Chap_8.html#example-cocktail-party-noise":{},"Chap_8.html#problem-82":{},"Chap_8.html#problem-83":{},"Chap_9.html":{},"Chap_9.html#example-matching-your-filter":{},"Chap_9.html#performance-in-the-presence-of-noise":{},"Chap_9.html#problem-91":{},"Chap_9.html#problem-92":{},"Chap_9.html#the-matched-filter":{},"Chap_9.html#the-matched-filter-as-an-autocorrelation":{},"info.html":{},"info.html#tips-short-cuts":{}},"title":{}}],["show\u2014se",{"_index":554,"text":{"Chap_10.html":{},"Chap_10.html#classic-example-classic-result":{}},"title":{}}],["si",{"_index":1899,"text":{"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{}},"title":{}}],["side",{"_index":387,"text":{"Chap_10.html":{},"Chap_10.html#as-seen-from-the-fourier-domain":{},"Chap_10.html#classic-example-classic-result":{},"Chap_10.html#correlation-returns":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#expressing-the-mean-square-error":{},"Chap_12.html":{},"Chap_12.html#windowed-observations":{},"Chap_6.html":{},"Chap_6.html#the-autocorrelation-function":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_7.html":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#problem-78":{},"Chap_9.html":{},"Chap_9.html#the-classic-example":{}},"title":{}}],["sidelob",{"_index":1527,"text":{"Chap_12.html":{},"Chap_12.html#problem-122":{}},"title":{}}],["sigma",{"_index":963,"text":{"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_11.html#estimating-the-mean":{},"Chap_11.html#problem-112":{},"Chap_11.html#problem-117":{},"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#problem-122":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_3.html":{},"Chap_3.html#problem-34":{},"Chap_4.html":{},"Chap_4.html#cross-covariance":{},"Chap_4.html#example-is-that-coin-fair":{},"Chap_4.html#problem-44":{},"Chap_4.html#problem-45":{},"Chap_4.html#problem-49":{},"Chap_4.html#properties-of-averaging":{},"Chap_5.html":{},"Chap_5.html#correlations-simple-and-complex":{},"Chap_5.html#problem-53":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#descriptive-statistic-variance":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#power-spectral-density_2":{},"Chap_7.html#problem-77":{},"Chap_7.html#problem-78":{},"Chap_7.html#tethered-particle-motion":{},"Chap_7.html#the-langevin-velocity-equation":{},"Chap_7.html#why-this-case-study":{},"Chap_8.html":{},"Chap_8.html#example-not-too-noisy":{},"Chap_8.html#snr-for-random-signals-in-the-presence-of-noise":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{},"Chap_9.html":{},"Chap_9.html#problem-91":{}},"title":{}}],["sigma=1/\\sqrt{12",{"_index":1879,"text":{"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{}},"title":{}}],["sigma_\\alpha",{"_index":1976,"text":{"Chap_3.html":{},"Chap_3.html#problem-35":{}},"title":{}}],["sigma_r",{"_index":1985,"text":{"Chap_3.html":{},"Chap_3.html#problem-37":{}},"title":{}}],["signal",{"_index":108,"text":{"Chap_1.html":{},"Chap_1.html#at-the-movies":{},"Chap_1.html#highlighting":{},"Chap_1.html#sound-of-music":{},"Chap_10.html":{},"Chap_10.html#classic-example-classic-result":{},"Chap_10.html#correlation-returns":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#example-cleaning-up-our-act":{},"Chap_10.html#example-sound-of-distorted-music":{},"Chap_10.html#laboratory-exercise-101":{},"Chap_10.html#laboratory-exercise-103":{},"Chap_10.html#laboratory-exercise-105":{},"Chap_10.html#problem-102":{},"Chap_10.html#problem-103":{},"Chap_10.html#problem-104":{},"Chap_10.html#the-more-general-restoration-case-noise-distortion":{},"Chap_10.html#the-restoration-case-noise":{},"Chap_10.html#the-wiener-filter":{},"Chap_10.html#the-wiener-hopf-equation":{},"Chap_10.html#using-the-least-mean-square-error-criterion":{},"Chap_10.html#why-we-avoid-the-inverse-filter":{},"Chap_11.html":{},"Chap_11.html#estimating-the-autocorrelation-function":{},"Chap_11.html#problem-118":{},"Chap_11.html#trouble-in-paradise":{},"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#laboratory-exercise-121":{},"Chap_12.html#problem-122":{},"Chap_12.html#problem-123":{},"Chap_12.html#spectral-estimation":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_13.html#epilogue":{},"Chap_2.html":{},"Chap_2.html#problem-21":{},"Chap_2.html#prologue":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_3.html#introduction":{},"Chap_3.html#problem-31":{},"Chap_3.html#problem-310":{},"Chap_3.html#problem-32":{},"Chap_3.html#problem-33":{},"Chap_3.html#problem-38":{},"Chap_3.html#problem-39":{},"Chap_3.html#the-basics":{},"Chap_3.html#what-is-a-random-signal":{},"Chap_4.html":{},"Chap_4.html#characterization-of-random-signals":{},"Chap_4.html#correlation-the-workhorse":{},"Chap_4.html#cross-correlation":{},"Chap_4.html#cross-covariance":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#describing-the-time-average":{},"Chap_4.html#example-dice-money":{},"Chap_4.html#example-fair-chance":{},"Chap_4.html#example-is-that-coin-fair":{},"Chap_4.html#laboratory-exercise-41":{},"Chap_4.html#laboratory-exercise-42":{},"Chap_4.html#properties-of-averaging":{},"Chap_4.html#the-ergodic-process":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#correlations-and-memory":{},"Chap_5.html#example-delayed-effect":{},"Chap_5.html#example-pink-noise":{},"Chap_5.html#laboratory-exercise-51":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_5.html#problem-52":{},"Chap_5.html#problem-55":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_6.html":{},"Chap_6.html#filtering-of-stochastic-signals":{},"Chap_6.html#interpretation-of-the-convolution-result":{},"Chap_6.html#laboratory-exercise-67":{},"Chap_6.html#problem-61":{},"Chap_6.html#problem-62":{},"Chap_6.html#problem-63":{},"Chap_6.html#problem-64":{},"Chap_6.html#problem-66":{},"Chap_6.html#the-autocorrelation-function":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_6.html#the-mean":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function_1":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#power-spectral-density":{},"Chap_7.html#problem-711":{},"Chap_7.html#problem-72":{},"Chap_7.html#problem-73":{},"Chap_7.html#tethered-particle-motion":{},"Chap_7.html#why-this-case-study":{},"Chap_8.html":{},"Chap_8.html#characterizing-signal-to-noise-ratios":{},"Chap_8.html#example-cocktail-party-noise":{},"Chap_8.html#example-filtering-noise":{},"Chap_8.html#example-not-too-noisy":{},"Chap_8.html#problem-83":{},"Chap_8.html#snr-for-deterministic-signals-in-the-presence-of-noise":{},"Chap_8.html#snr-for-random-signals-in-the-presence-of-noise":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{},"Chap_9.html":{},"Chap_9.html#example-matching-your-filter":{},"Chap_9.html#laboratory-exercise-93":{},"Chap_9.html#performance-in-the-presence-of-noise":{},"Chap_9.html#problem-91":{},"Chap_9.html#problem-92":{},"Chap_9.html#the-matched-filter":{},"Chap_9.html#the-matched-filter-as-an-autocorrelation":{},"Chap_9.html#using-cauchy-schwartz":{},"info.html":{},"info.html#technical-details":{}},"title":{"Chap_3.html#what-is-a-random-signal":{},"Chap_4.html":{},"Chap_4.html#characterization-of-random-signals":{},"Chap_6.html":{},"Chap_6.html#filtering-of-stochastic-signals":{},"Chap_8.html":{},"Chap_8.html#characterizing-signal-to-noise-ratios":{},"Chap_8.html#snr-for-deterministic-signals-in-the-presence-of-noise":{},"Chap_8.html#snr-for-random-signals-in-the-presence-of-noise":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{}}}],["signal\u201d\u2014measur",{"_index":1754,"text":{"Chap_2.html":{},"Chap_2.html#prologue":{}},"title":{}}],["signific",{"_index":677,"text":{"Chap_10.html":{},"Chap_10.html#example-cleaning-up-our-act":{},"Chap_10.html#laboratory-exercise-102":{},"Chap_12.html":{},"Chap_12.html#problem-122":{},"Chap_4.html":{},"Chap_4.html#cross-covariance":{},"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_7.html":{},"Chap_7.html#impulse-invariant-sampling":{}},"title":{}}],["significantli",{"_index":2592,"text":{"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{}},"title":{}}],["simeq",{"_index":2904,"text":{"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{}},"title":{}}],["similar",{"_index":2086,"text":{"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#laboratory-exercise-42":{},"Chap_5.html":{},"Chap_5.html#correlations-and-memory":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{},"Chap_6.html#the-autocorrelation-function":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function":{},"Chap_7.html#autocorrelation-function_1":{},"Chap_7.html#power-spectral-density_1":{},"Chap_9.html":{},"Chap_9.html#laboratory-exercise-92":{}},"title":{}}],["similarli",{"_index":1706,"text":{"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_3.html":{},"Chap_3.html#problem-310":{},"Chap_4.html":{},"Chap_4.html#cross-covariance":{},"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{}},"title":{}}],["simpl",{"_index":684,"text":{"Chap_10.html":{},"Chap_10.html#example-cleaning-up-our-act":{},"Chap_10.html#laboratory-exercise-101":{},"Chap_11.html":{},"Chap_11.html#aspects-of-estimation":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_11.html#trouble-in-paradise":{},"Chap_3.html":{},"Chap_3.html#what-is-a-random-signal":{},"Chap_4.html":{},"Chap_4.html#properties-of-averaging":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#correlations-and-memory":{},"Chap_5.html#example-delayed-effect":{},"Chap_5.html#example-pink-noise":{},"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{},"Chap_7.html":{},"Chap_7.html#descriptive-statistic-variance":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#problem-77":{},"Chap_8.html":{},"Chap_8.html#snr-for-random-signals-in-the-presence-of-noise":{}},"title":{"Chap_5.html#correlations-simple-and-complex":{}}}],["simpler",{"_index":3218,"text":{"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{}},"title":{}}],["simplest",{"_index":2037,"text":{"Chap_3.html":{},"Chap_3.html#problem-310":{}},"title":{}}],["simpli",{"_index":571,"text":{"Chap_10.html":{},"Chap_10.html#classic-example-classic-result":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_11.html":{},"Chap_11.html#example-estimating-the-poisson-rate":{},"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{},"Chap_6.html#the-autocorrelation-function":{},"Chap_7.html":{},"Chap_7.html#the-langevin-position-equation":{},"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{},"Chap_9.html":{},"Chap_9.html#the-matched-filter":{}},"title":{}}],["simplic",{"_index":3550,"text":{"Chap_9.html":{},"Chap_9.html#the-matched-filter":{}},"title":{}}],["simplicity\u2019",{"_index":1530,"text":{"Chap_12.html":{},"Chap_12.html#problem-122":{}},"title":{}}],["simplifi",{"_index":775,"text":{"Chap_10.html":{},"Chap_10.html#laboratory-exercise-105":{},"Chap_12.html":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_3.html":{},"Chap_3.html#problem-38":{},"Chap_5.html":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_6.html":{},"Chap_6.html#the-mean":{},"Chap_8.html":{},"Chap_8.html#snr-for-random-signals-in-the-presence-of-noise":{}},"title":{}}],["simul",{"_index":2811,"text":{"Chap_7.html":{},"Chap_7.html#tethered-particle-motion":{},"Chap_7.html#the-langevin-equation-a-case-study":{}},"title":{}}],["simultan",{"_index":1610,"text":{"Chap_13.html":{},"Chap_13.html#appendix-i-mean-square-error-minimization":{}},"title":{}}],["sinc",{"_index":1646,"text":{"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{}},"title":{}}],["sine",{"_index":3631,"text":{"Chap_9.html":{},"Chap_9.html#laboratory-exercise-93":{}},"title":{}}],["singl",{"_index":1577,"text":{"Chap_12.html":{},"Chap_12.html#problem-123":{},"Chap_4.html":{},"Chap_4.html#correlation-the-workhorse":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_5.html":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_7.html":{},"Chap_7.html#problem-711":{}},"title":{}}],["singular",{"_index":3049,"text":{"Chap_7.html":{},"Chap_7.html#expected-value":{}},"title":{}}],["sink",{"_index":2872,"text":{"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{}},"title":{}}],["sinusoid",{"_index":2573,"text":{"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_9.html":{},"Chap_9.html#laboratory-exercise-93":{}},"title":{}}],["situat",{"_index":539,"text":{"Chap_10.html":{},"Chap_10.html#classic-example-classic-result":{},"Chap_10.html#the-more-general-restoration-case-noise-distortion":{},"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_6.html":{},"Chap_6.html#interpretation-of-the-convolution-result":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_7.html":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#problem-71":{},"Chap_7.html#tethered-particle-motion":{},"Chap_8.html":{},"Chap_8.html#example-filtering-noise":{}},"title":{}}],["six",{"_index":1847,"text":{"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{}},"title":{}}],["six\u2014w",{"_index":2075,"text":{"Chap_4.html":{},"Chap_4.html#example-fair-chance":{}},"title":{}}],["size",{"_index":1587,"text":{"Chap_12.html":{},"Chap_12.html#laboratory-exercise-124":{},"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_7.html":{},"Chap_7.html#power-spectral-density_1":{}},"title":{}}],["sketch",{"_index":2017,"text":{"Chap_3.html":{},"Chap_3.html#problem-310":{},"Chap_5.html":{},"Chap_5.html#problem-55":{},"Chap_8.html":{},"Chap_8.html#problem-83":{},"Chap_9.html":{},"Chap_9.html#problem-91":{}},"title":{}}],["skip",{"_index":3652,"text":{"info.html":{},"info.html#tips-short-cuts":{}},"title":{}}],["slope",{"_index":3245,"text":{"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{}},"title":{}}],["small",{"_index":1349,"text":{"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#other-windows":{},"Chap_12.html#problem-122":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_12.html#windowed-observations":{},"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#descriptive-statistic-variance":{},"Chap_7.html#how-big-is-big-how-small-is-small":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#tethered-particle-motion":{},"Chap_7.html#the-langevin-equation-a-case-study":{}},"title":{"Chap_7.html#how-big-is-big-how-small-is-small":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{}}}],["smaller",{"_index":933,"text":{"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_7.html":{},"Chap_7.html#descriptive-statistic-variance":{},"Chap_7.html#how-big-is-big-how-small-is-small":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#one-step-further":{},"Chap_8.html":{},"Chap_8.html#problem-82":{}},"title":{}}],["smallest",{"_index":1516,"text":{"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{}},"title":{}}],["smartphon",{"_index":27,"text":{"Chap_1.html":{},"Chap_1.html#how-to-use-this-ibook":{},"info.html":{},"info.html#tips-short-cuts":{}},"title":{}}],["smooth",{"_index":1545,"text":{"Chap_12.html":{},"Chap_12.html#problem-122":{},"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{}},"title":{}}],["smoothli",{"_index":1542,"text":{"Chap_12.html":{},"Chap_12.html#problem-122":{}},"title":{}}],["snr",{"_index":273,"text":{"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#the-wiener-filter":{},"Chap_12.html":{},"Chap_12.html#problem-123":{},"Chap_3.html":{},"Chap_3.html#what-is-a-random-signal":{},"Chap_8.html":{},"Chap_8.html#example-cocktail-party-noise":{},"Chap_8.html#example-filtering-noise":{},"Chap_8.html#problem-82":{},"Chap_8.html#snr-for-random-signals-in-the-presence-of-noise":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{},"Chap_9.html":{},"Chap_9.html#performance-in-the-presence-of-noise":{},"Chap_9.html#setting-up-the-problem":{},"Chap_9.html#the-matched-filter":{},"Chap_9.html#using-cauchy-schwartz":{}},"title":{"Chap_8.html#snr-for-deterministic-signals-in-the-presence-of-noise":{},"Chap_8.html#snr-for-random-signals-in-the-presence-of-noise":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{}}}],["sn{r_d",{"_index":3432,"text":{"Chap_8.html":{},"Chap_8.html#example-not-too-noisy":{},"Chap_8.html#snr-for-deterministic-signals-in-the-presence-of-noise":{},"Chap_8.html#snr-for-random-signals-in-the-presence-of-noise":{}},"title":{}}],["sn{r_p",{"_index":3500,"text":{"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{}},"title":{}}],["sn{r_r",{"_index":3441,"text":{"Chap_8.html":{},"Chap_8.html#example-cocktail-party-noise":{},"Chap_8.html#snr-for-random-signals-in-the-presence-of-noise":{}},"title":{}}],["social",{"_index":855,"text":{"Chap_11.html":{},"Chap_11.html#aspects-of-estimation":{}},"title":{}}],["societi",{"_index":1259,"text":{"Chap_11.html":{},"Chap_11.html#laboratory-exercise-113":{},"Chap_12.html":{},"Chap_12.html#laboratory-exercise-122":{}},"title":{}}],["socraticsoftware.org",{"_index":3662,"text":{"info.html":{},"info.html#venue":{}},"title":{}}],["solar",{"_index":2576,"text":{"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{}},"title":{}}],["sold",{"_index":3747,"text":{"info.html":{},"info.html#usage":{}},"title":{}}],["sole",{"_index":3746,"text":{"info.html":{},"info.html#usage":{}},"title":{}}],["solut",{"_index":458,"text":{"Chap_10.html":{},"Chap_10.html#classic-example-classic-result":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#the-wiener-hopf-equation":{},"Chap_12.html":{},"Chap_12.html#spectral-estimation":{},"Chap_9.html":{},"Chap_9.html#the-classic-example":{}},"title":{}}],["solv",{"_index":924,"text":{"Chap_11.html":{},"Chap_11.html#example-estimating-the-poisson-rate":{},"Chap_11.html#langevin-redux":{}},"title":{}}],["someon",{"_index":2344,"text":{"Chap_4.html":{},"Chap_4.html#problem-47":{}},"title":{}}],["someth",{"_index":1792,"text":{"Chap_2.html":{},"Chap_2.html#prologue":{},"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#tethered-particle-motion":{}},"title":{}}],["somewhat",{"_index":470,"text":{"Chap_10.html":{},"Chap_10.html#the-wiener-hopf-equation":{}},"title":{}}],["son",{"_index":790,"text":{"Chap_10.html":{},"Chap_10.html#laboratory-exercise-105":{},"Chap_13.html":{},"Chap_13.html#epilogue":{},"Chap_7.html":{},"Chap_7.html#problem-711":{},"Chap_9.html":{},"Chap_9.html#laboratory-exercise-93":{}},"title":{}}],["soon",{"_index":2856,"text":{"Chap_7.html":{},"Chap_7.html#impulse-invariant-sampling":{}},"title":{}}],["sort",{"_index":1512,"text":{"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{}},"title":{}}],["sought",{"_index":2581,"text":{"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{}},"title":{}}],["sound",{"_index":146,"text":{"Chap_1.html":{},"Chap_1.html#sound-of-music":{},"Chap_10.html":{},"Chap_12.html":{},"Chap_12.html#problem-123":{}},"title":{"Chap_1.html#sound-of-music":{},"Chap_10.html#example-sound-of-distorted-music":{}}}],["soundtrack",{"_index":3733,"text":{"info.html":{},"info.html#musical-data":{}},"title":{}}],["sourc",{"_index":121,"text":{"Chap_1.html":{},"Chap_1.html#outside-this-device":{},"Chap_10.html":{},"Chap_10.html#the-more-general-restoration-case-noise-distortion":{},"Chap_12.html":{},"Chap_12.html#laboratory-exercise-123":{},"Chap_7.html":{},"Chap_7.html#tethered-particle-motion":{},"Chap_8.html":{},"Chap_8.html#problem-83":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{}},"title":{}}],["space",{"_index":2093,"text":{"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#laboratory-exercise-42":{},"Chap_4.html#the-mechanics-of-correlations":{},"info.html":{},"info.html#tips-short-cuts":{}},"title":{}}],["spatial",{"_index":474,"text":{"Chap_10.html":{},"Chap_10.html#the-wiener-hopf-equation":{},"Chap_4.html":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_7.html":{},"Chap_7.html#the-langevin-equation-a-case-study":{}},"title":{}}],["speaker",{"_index":70,"text":{"Chap_1.html":{},"Chap_1.html#how-to-use-this-ibook":{}},"title":{}}],["special",{"_index":94,"text":{"Chap_1.html":{},"Chap_1.html#highlighting":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function_2":{}},"title":{}}],["specif",{"_index":148,"text":{"Chap_1.html":{},"Chap_1.html#sound-of-music":{},"Chap_10.html":{},"Chap_10.html#using-the-least-mean-square-error-criterion":{},"Chap_11.html":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_11.html#laboratory-exercise-113":{},"Chap_11.html#maximum-likelihood-estimation":{},"Chap_11.html#trouble-in-paradise":{},"Chap_12.html":{},"Chap_12.html#other-windows":{},"Chap_12.html#the-periodogram-unbiased":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#correlations-and-memory":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function":{},"Chap_7.html#autocorrelation-function_1":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_9.html":{},"Chap_9.html#problem-91":{},"Chap_9.html#setting-up-the-problem":{},"info.html":{},"info.html#tips-short-cuts":{}},"title":{}}],["specifi",{"_index":228,"text":{"Chap_1.html":{},"Chap_1.html#enhanced-experience":{},"Chap_3.html":{},"Chap_3.html#problem-39":{},"Chap_4.html":{},"Chap_4.html#characterization-of-random-signals":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_8.html":{},"Chap_8.html#problem-83":{},"Chap_9.html":{},"Chap_9.html#the-matched-filter":{}},"title":{}}],["specimen",{"_index":3490,"text":{"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{}},"title":{}}],["spectra",{"_index":583,"text":{"Chap_10.html":{},"Chap_10.html#classic-example-classic-result":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#laboratory-exercise-105":{},"Chap_10.html#problem-104":{},"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#problem-122":{},"Chap_12.html#windowed-observations":{},"Chap_3.html":{},"Chap_3.html#what-is-a-random-signal":{},"Chap_5.html":{},"Chap_5.html#example-pink-noise":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_8.html":{},"Chap_8.html#example-cocktail-party-noise":{},"Chap_9.html":{},"Chap_9.html#laboratory-exercise-93":{}},"title":{"Chap_5.html":{},"Chap_5.html#correlations-and-spectra":{},"Chap_5.html#examples-of-power-spectra":{}}}],["spectral",{"_index":636,"text":{"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#example-cleaning-up-our-act":{},"Chap_10.html#problem-103":{},"Chap_10.html#why-we-avoid-the-inverse-filter":{},"Chap_11.html":{},"Chap_11.html#laboratory-exercise-113":{},"Chap_11.html#problem-119":{},"Chap_11.html#trouble-in-paradise":{},"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#laboratory-exercise-122":{},"Chap_12.html#laboratory-exercise-124":{},"Chap_12.html#other-windows":{},"Chap_12.html#problem-122":{},"Chap_12.html#spectral-estimation":{},"Chap_12.html#the-periodogram-unbiased":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_12.html#windowed-observations":{},"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_6.html":{},"Chap_6.html#laboratory-exercise-63":{},"Chap_6.html#problem-64":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#power-spectral-density":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#power-spectral-density_2":{},"Chap_7.html#problem-73":{},"Chap_7.html#problem-75":{},"Chap_7.html#problem-76":{},"Chap_7.html#why-this-case-study":{},"Chap_8.html":{},"Chap_8.html#problem-81":{},"Chap_8.html#problem-83":{},"info.html":{},"info.html#cover":{}},"title":{"Chap_12.html":{},"Chap_12.html#spectral-estimation":{},"Chap_7.html#power-spectral-density":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#power-spectral-density_2":{}}}],["spectrum",{"_index":574,"text":{"Chap_10.html":{},"Chap_10.html#classic-example-classic-result":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#example-cleaning-up-our-act":{},"Chap_10.html#example-sound-of-distorted-music":{},"Chap_10.html#laboratory-exercise-105":{},"Chap_10.html#why-we-avoid-the-inverse-filter":{},"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#laboratory-exercise-121":{},"Chap_12.html#other-windows":{},"Chap_12.html#problem-121":{},"Chap_12.html#spectral-estimation":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_12.html#windowed-observations":{},"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_3.html":{},"Chap_3.html#problem-39":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#example-pink-noise":{},"Chap_5.html#example-white-noise":{},"Chap_5.html#fourier-description-of-correlation-functions":{},"Chap_5.html#laboratory-exercise-51":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_5.html#problem-56":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_6.html":{},"Chap_6.html#laboratory-exercise-67":{},"Chap_6.html#problem-64":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#problem-79":{},"Chap_8.html":{},"Chap_8.html#example-cocktail-party-noise":{},"Chap_8.html#example-filtering-noise":{}},"title":{"Chap_5.html#the-power-density-spectrum-and-its-properties":{}}}],["spectrum\u2014ani",{"_index":1585,"text":{"Chap_12.html":{},"Chap_12.html#laboratory-exercise-123":{}},"title":{}}],["spectrum\u2014i",{"_index":1586,"text":{"Chap_12.html":{},"Chap_12.html#laboratory-exercise-123":{}},"title":{}}],["speech",{"_index":751,"text":{"Chap_10.html":{},"Chap_10.html#problem-103":{},"Chap_2.html":{},"Chap_2.html#prologue":{},"Chap_3.html":{},"Chap_3.html#what-is-a-random-signal":{},"Chap_7.html":{},"Chap_7.html#why-this-case-study":{},"Chap_8.html":{},"Chap_8.html#example-cocktail-party-noise":{},"Chap_8.html#snr-for-random-signals-in-the-presence-of-noise":{}},"title":{}}],["sphere",{"_index":2865,"text":{"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small":{},"Chap_7.html#tethered-particle-motion":{}},"title":{}}],["spie",{"_index":3416,"text":{"Chap_7.html":{},"Chap_7.html#problem-711":{}},"title":{}}],["spirituoso",{"_index":3728,"text":{"info.html":{},"info.html#musical-data":{}},"title":{}}],["split",{"_index":1397,"text":{"Chap_12.html":{},"Chap_12.html#the-periodogram-what-about-convergence":{}},"title":{}}],["spread",{"_index":3182,"text":{"Chap_7.html":{},"Chap_7.html#tethered-particle-motion":{}},"title":{}}],["spring",{"_index":3163,"text":{"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#one-step-further":{},"Chap_7.html#tethered-particle-motion":{}},"title":{}}],["sqrt",{"_index":1470,"text":{"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#expected-value":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#one-step-further":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#the-langevin-velocity-equation":{},"Chap_8.html":{},"Chap_8.html#example-not-too-noisy":{},"Chap_8.html#snr-for-random-signals-in-the-presence-of-noise":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{},"Chap_9.html":{},"Chap_9.html#example-matching-your-filter":{},"Chap_9.html#using-cauchy-schwartz":{}},"title":{}}],["squar",{"_index":327,"text":{"Chap_10.html":{},"Chap_10.html#laboratory-exercise-103":{},"Chap_10.html#the-more-general-restoration-case-noise-distortion":{},"Chap_10.html#using-the-least-mean-square-error-criterion":{},"Chap_10.html#what-is-that-least-mean-square-error":{},"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_11.html#problem-115":{},"Chap_11.html#problem-116":{},"Chap_11.html#problem-117":{},"Chap_11.html#problem-118":{},"Chap_13.html":{},"Chap_13.html#appendix-i-mean-square-error-minimization":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_3.html":{},"Chap_3.html#problem-310":{},"Chap_4.html":{},"Chap_4.html#properties-of-averaging":{},"Chap_5.html":{},"Chap_5.html#example-pink-noise":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#descriptive-statistic-variance":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#one-step-further":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#problem-711":{},"Chap_7.html#problem-77":{},"Chap_8.html":{},"Chap_8.html#example-not-too-noisy":{}},"title":{"Chap_10.html#expressing-the-mean-square-error":{},"Chap_10.html#using-the-least-mean-square-error-criterion":{},"Chap_10.html#what-is-that-least-mean-square-error":{},"Chap_13.html#appendix-i-mean-square-error-minimization":{}}}],["square\\;of\\;process",{"_index":2398,"text":{"Chap_5.html":{},"Chap_5.html#correlations-simple-and-complex":{}},"title":{}}],["squared\\;error",{"_index":334,"text":{"Chap_10.html":{},"Chap_10.html#using-the-least-mean-square-error-criterion":{}},"title":{}}],["stabil",{"_index":3594,"text":{"Chap_9.html":{},"Chap_9.html#laboratory-exercise-91":{},"Chap_9.html#performance-in-the-presence-of-noise":{}},"title":{}}],["stabl",{"_index":2828,"text":{"Chap_7.html":{},"Chap_7.html#impulse-invariant-sampling":{},"Chap_7.html#problem-71":{},"Chap_7.html#the-langevin-position-equation":{}},"title":{}}],["stage",{"_index":3353,"text":{"Chap_7.html":{},"Chap_7.html#one-step-further":{}},"title":{}}],["stand",{"_index":2994,"text":{"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{}},"title":{}}],["standard",{"_index":799,"text":{"Chap_10.html":{},"Chap_10.html#laboratory-exercise-105":{},"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_11.html#example-estimating-the-poisson-rate":{},"Chap_11.html#problem-117":{},"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_3.html":{},"Chap_3.html#problem-34":{},"Chap_3.html#problem-35":{},"Chap_3.html#problem-37":{},"Chap_4.html":{},"Chap_4.html#problem-49":{},"Chap_4.html#properties-of-averaging":{},"Chap_5.html":{},"Chap_5.html#correlations-simple-and-complex":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_6.html":{},"Chap_6.html#the-mean":{},"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#the-langevin-velocity-equation":{},"Chap_8.html":{},"Chap_8.html#problem-83":{},"Chap_8.html#snr-for-random-signals-in-the-presence-of-noise":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{},"Chap_9.html":{},"Chap_9.html#problem-91":{}},"title":{"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{}}}],["star",{"_index":179,"text":{"Chap_1.html":{},"Chap_1.html#at-the-movies":{}},"title":{}}],["start",{"_index":316,"text":{"Chap_10.html":{},"Chap_10.html#as-seen-from-the-fourier-domain":{},"Chap_10.html#expressing-the-mean-square-error":{},"Chap_10.html#laboratory-exercise-101":{},"Chap_10.html#laboratory-exercise-102":{},"Chap_10.html#laboratory-exercise-103":{},"Chap_10.html#laboratory-exercise-104":{},"Chap_10.html#laboratory-exercise-105":{},"Chap_10.html#problem-101":{},"Chap_10.html#the-restoration-case-noise":{},"Chap_10.html#what-is-that-least-mean-square-error":{},"Chap_11.html":{},"Chap_11.html#estimating-the-autocorrelation-function":{},"Chap_11.html#laboratory-exercise-111":{},"Chap_11.html#laboratory-exercise-112":{},"Chap_11.html#laboratory-exercise-113":{},"Chap_12.html":{},"Chap_12.html#laboratory-exercise-121":{},"Chap_12.html#laboratory-exercise-122":{},"Chap_12.html#laboratory-exercise-123":{},"Chap_12.html#laboratory-exercise-124":{},"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_13.html#epilogue":{},"Chap_2.html":{},"Chap_2.html#prologue":{},"Chap_4.html":{},"Chap_4.html#laboratory-exercise-41":{},"Chap_4.html#laboratory-exercise-42":{},"Chap_4.html#properties-of-averaging":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#correlations-simple-and-complex":{},"Chap_5.html#laboratory-exercise-51":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{},"Chap_6.html#laboratory-exercise-61":{},"Chap_6.html#laboratory-exercise-62":{},"Chap_6.html#laboratory-exercise-63":{},"Chap_6.html#laboratory-exercise-64":{},"Chap_6.html#laboratory-exercise-65":{},"Chap_6.html#laboratory-exercise-66":{},"Chap_6.html#laboratory-exercise-67":{},"Chap_6.html#laboratory-exercise-68":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function_2":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#expected-value":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#problem-711":{},"Chap_7.html#problem-74":{},"Chap_7.html#problem-75":{},"Chap_7.html#problem-76":{},"Chap_7.html#the-langevin-position-equation":{},"Chap_8.html":{},"Chap_8.html#characterizing-signal-to-noise-ratios":{},"Chap_9.html":{},"Chap_9.html#laboratory-exercise-91":{},"Chap_9.html#laboratory-exercise-92":{},"Chap_9.html#problem-92":{},"Chap_9.html#the-matched-filter":{}},"title":{}}],["start\u201d\u2014go",{"_index":2453,"text":{"Chap_5.html":{},"Chap_5.html#a-digression":{}},"title":{}}],["state",{"_index":116,"text":{"Chap_1.html":{},"Chap_1.html#highlighting":{},"Chap_5.html":{},"Chap_5.html#correlations-and-memory":{},"Chap_5.html#correlations-and-spectra":{},"Chap_5.html#problem-52":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_7.html":{},"Chap_7.html#one-step-further":{}},"title":{}}],["statement",{"_index":749,"text":{"Chap_10.html":{},"Chap_10.html#problem-102":{},"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#problem-49":{},"Chap_5.html":{},"Chap_5.html#problem-53":{},"Chap_5.html#problem-56":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_6.html":{},"Chap_6.html#the-mean":{}},"title":{}}],["static",{"_index":1709,"text":{"Chap_13.html":{},"Chap_13.html#epilogue":{}},"title":{}}],["stationar",{"_index":2236,"text":{"Chap_4.html":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_5.html":{},"Chap_5.html#the-mechanics-of-correlations-redux":{}},"title":{}}],["stationari",{"_index":2112,"text":{"Chap_4.html":{},"Chap_4.html#correlation-the-workhorse":{},"Chap_4.html#cross-covariance":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#example-dice-money":{},"Chap_4.html#example-is-that-coin-fair":{},"Chap_4.html#other-averages":{},"Chap_4.html#problem-45":{},"Chap_4.html#problem-47":{},"Chap_4.html#properties-of-averaging":{},"Chap_4.html#the-ergodic-process":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_5.html":{},"Chap_5.html#correlations-and-spectra":{},"Chap_6.html":{},"Chap_6.html#filtering-of-stochastic-signals":{},"Chap_6.html#interpretation-of-the-convolution-result":{},"Chap_6.html#the-autocorrelation-function":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_6.html#the-mean":{},"Chap_7.html":{},"Chap_7.html#problem-73":{},"Chap_7.html#the-langevin-equation-a-case-study":{},"Chap_9.html":{},"Chap_9.html#problem-91":{}},"title":{}}],["statist",{"_index":289,"text":{"Chap_10.html":{},"Chap_10.html#classic-example-classic-result":{},"Chap_10.html#laboratory-exercise-105":{},"Chap_10.html#the-more-general-restoration-case-noise-distortion":{},"Chap_10.html#the-wiener-filter":{},"Chap_11.html":{},"Chap_11.html#estimating-the-autocorrelation-function":{},"Chap_11.html#estimating-the-mean":{},"Chap_11.html#laboratory-exercise-113":{},"Chap_13.html":{},"Chap_13.html#epilogue":{},"Chap_2.html":{},"Chap_2.html#problem-21":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_3.html#problem-310":{},"Chap_3.html#what-is-a-random-signal":{},"Chap_4.html":{},"Chap_4.html#example-is-that-coin-fair":{},"Chap_4.html#laboratory-exercise-42":{},"Chap_4.html#the-ergodic-process":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_5.html":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#problem-711":{},"Chap_7.html#why-this-case-study":{},"Chap_8.html":{},"Chap_8.html#example-filtering-noise":{},"Chap_8.html#problem-83":{},"Chap_8.html#snr-for-random-signals-in-the-presence-of-noise":{}},"title":{"Chap_7.html#descriptive-statistic-variance":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{}}}],["statu",{"_index":3654,"text":{"info.html":{},"info.html#tips-short-cuts":{}},"title":{}}],["steep",{"_index":2740,"text":{"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{}},"title":{}}],["step",{"_index":1607,"text":{"Chap_13.html":{},"Chap_13.html#appendix-i-mean-square-error-minimization":{},"Chap_3.html":{},"Chap_3.html#problem-39":{},"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#the-ergodic-process":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_6.html":{},"Chap_6.html#problem-61":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#expected-value":{},"Chap_7.html#power-spectral-density":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#the-langevin-equation-a-case-study":{}},"title":{"Chap_7.html#one-step-further":{}}}],["steradian",{"_index":2893,"text":{"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small":{}},"title":{}}],["stiff",{"_index":3230,"text":{"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{}},"title":{}}],["still",{"_index":1030,"text":{"Chap_11.html":{},"Chap_11.html#estimating-the-autocorrelation-function":{},"Chap_6.html":{},"Chap_6.html#interpretation-of-the-convolution-result":{},"Chap_7.html":{},"Chap_7.html#tethered-particle-motion":{},"Chap_9.html":{},"Chap_9.html#problem-92":{}},"title":{}}],["stimulu",{"_index":3517,"text":{"Chap_8.html":{},"Chap_8.html#problem-82":{}},"title":{}}],["stochast",{"_index":153,"text":{"Chap_1.html":{},"Chap_1.html#at-the-movies":{},"Chap_1.html#sound-of-music":{},"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#example-cleaning-up-our-act":{},"Chap_10.html#example-sound-of-distorted-music":{},"Chap_10.html#laboratory-exercise-105":{},"Chap_10.html#problem-103":{},"Chap_10.html#the-more-general-restoration-case-noise-distortion":{},"Chap_10.html#the-restoration-case-noise":{},"Chap_10.html#the-wiener-filter":{},"Chap_10.html#why-we-avoid-the-inverse-filter":{},"Chap_11.html":{},"Chap_11.html#aspects-of-estimation":{},"Chap_11.html#langevin-redux":{},"Chap_11.html#problem-118":{},"Chap_11.html#trouble-in-paradise":{},"Chap_12.html":{},"Chap_12.html#spectral-estimation":{},"Chap_12.html#the-periodogram-unbiased":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_12.html#windowed-observations":{},"Chap_13.html":{},"Chap_13.html#epilogue":{},"Chap_2.html":{},"Chap_2.html#problem-21":{},"Chap_2.html#prologue":{},"Chap_3.html":{},"Chap_3.html#problem-310":{},"Chap_3.html#what-is-a-random-signal":{},"Chap_4.html":{},"Chap_4.html#correlation-the-workhorse":{},"Chap_4.html#cross-covariance":{},"Chap_4.html#example-fair-chance":{},"Chap_4.html#example-is-that-coin-fair":{},"Chap_4.html#laboratory-exercise-41":{},"Chap_4.html#problem-42":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#laboratory-exercise-51":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{},"Chap_6.html#filtering-of-stochastic-signals":{},"Chap_6.html#interpretation-of-the-convolution-result":{},"Chap_6.html#laboratory-exercise-64":{},"Chap_6.html#laboratory-exercise-65":{},"Chap_6.html#laboratory-exercise-66":{},"Chap_6.html#problem-61":{},"Chap_6.html#problem-63":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function_1":{},"Chap_7.html#how-big-is-big-how-small-is-small":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#problem-711":{},"Chap_7.html#problem-72":{},"Chap_7.html#problem-73":{},"Chap_7.html#tethered-particle-motion":{},"Chap_7.html#the-langevin-equation-a-case-study":{},"Chap_7.html#why-this-case-study":{},"Chap_8.html":{},"Chap_8.html#characterizing-signal-to-noise-ratios":{},"Chap_8.html#example-filtering-noise":{},"Chap_8.html#problem-83":{},"Chap_8.html#snr-for-random-signals-in-the-presence-of-noise":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{},"info.html":{},"info.html#cover":{},"info.html#tips-short-cuts":{}},"title":{"Chap_6.html":{},"Chap_6.html#filtering-of-stochastic-signals":{}}}],["stoke",{"_index":2876,"text":{"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small":{},"Chap_7.html#problem-77":{}},"title":{}}],["straight",{"_index":3228,"text":{"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{}},"title":{}}],["straightforward",{"_index":1628,"text":{"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_5.html":{},"Chap_5.html#correlations-simple-and-complex":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function_2":{},"Chap_7.html#expected-value":{},"Chap_7.html#impulse-invariant-sampling":{},"Chap_7.html#power-spectral-density":{}},"title":{}}],["strand",{"_index":3132,"text":{"Chap_7.html":{},"Chap_7.html#tethered-particle-motion":{}},"title":{}}],["strang",{"_index":2105,"text":{"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{}},"title":{}}],["strength",{"_index":563,"text":{"Chap_10.html":{},"Chap_10.html#classic-example-classic-result":{},"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{}},"title":{}}],["strong",{"_index":2566,"text":{"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{}},"title":{}}],["struck",{"_index":2748,"text":{"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{}},"title":{}}],["structur",{"_index":2593,"text":{"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{}},"title":{}}],["student",{"_index":1724,"text":{"Chap_13.html":{},"Chap_13.html#epilogue":{},"Chap_2.html":{},"Chap_2.html#prologue":{},"info.html":{},"info.html#acknowledgments":{},"info.html#usage":{}},"title":{}}],["studi",{"_index":1062,"text":{"Chap_11.html":{},"Chap_11.html#langevin-redux":{},"Chap_13.html":{},"Chap_13.html#epilogue":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_3.html#introduction":{},"Chap_4.html":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_6.html":{},"Chap_6.html#laboratory-exercise-64":{},"Chap_6.html#laboratory-exercise-65":{},"Chap_6.html#laboratory-exercise-66":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#expected-value":{},"Chap_7.html#from-t-to-n":{},"Chap_7.html#problem-711":{},"Chap_7.html#tethered-particle-motion":{},"Chap_7.html#the-langevin-equation-a-case-study":{},"Chap_7.html#why-this-case-study":{}},"title":{"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{},"Chap_7.html":{},"Chap_7.html#the-langevin-equation-a-case-study":{},"Chap_7.html#why-this-case-study":{}}}],["subject",{"_index":1722,"text":{"Chap_13.html":{},"Chap_13.html#epilogue":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#the-langevin-equation-a-case-study":{}},"title":{}}],["subsequ",{"_index":3732,"text":{"info.html":{},"info.html#musical-data":{}},"title":{}}],["substant",{"_index":3679,"text":{"info.html":{},"info.html#acknowledgments":{}},"title":{}}],["substanti",{"_index":251,"text":{"Chap_1.html":{},"Chap_1.html#enhanced-experience":{}},"title":{}}],["substitut",{"_index":525,"text":{"Chap_10.html":{},"Chap_10.html#what-is-that-least-mean-square-error":{},"Chap_11.html":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_11.html#langevin-redux":{},"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_4.html":{},"Chap_4.html#properties-of-averaging":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{},"Chap_7.html":{},"Chap_7.html#descriptive-statistic-variance":{},"Chap_7.html#how-big-is-big-how-small-is-small":{},"Chap_7.html#one-step-further":{},"Chap_7.html#the-langevin-velocity-equation":{}},"title":{}}],["substrat",{"_index":3146,"text":{"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#one-step-further":{},"Chap_7.html#tethered-particle-motion":{}},"title":{}}],["subtract",{"_index":2263,"text":{"Chap_4.html":{},"Chap_4.html#cross-covariance":{}},"title":{}}],["subunits\u2014and",{"_index":3145,"text":{"Chap_7.html":{},"Chap_7.html#tethered-particle-motion":{}},"title":{}}],["success",{"_index":3483,"text":{"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{}},"title":{}}],["succinct",{"_index":2436,"text":{"Chap_5.html":{},"Chap_5.html#the-mechanics-of-correlations-redux":{}},"title":{}}],["such",{"_index":59,"text":{"Chap_1.html":{},"Chap_1.html#enhanced-experience":{},"Chap_1.html#how-to-use-this-ibook":{},"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#problem-103":{},"Chap_10.html#the-wiener-hopf-equation":{},"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_11.html#maximum-likelihood-estimation":{},"Chap_11.html#problem-116":{},"Chap_11.html#trouble-in-paradise":{},"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#problem-122":{},"Chap_2.html":{},"Chap_2.html#prologue":{},"Chap_3.html":{},"Chap_3.html#introduction":{},"Chap_4.html":{},"Chap_4.html#characterization-of-random-signals":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#describing-the-time-average":{},"Chap_4.html#example-fair-chance":{},"Chap_4.html#problem-49":{},"Chap_4.html#properties-of-averaging":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#from-t-to-n":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#one-step-further":{},"Chap_7.html#tethered-particle-motion":{},"Chap_7.html#the-langevin-position-equation":{},"Chap_7.html#why-this-case-study":{},"Chap_8.html":{},"Chap_8.html#example-filtering-noise":{},"Chap_8.html#snr-for-random-signals-in-the-presence-of-noise":{},"Chap_9.html":{},"Chap_9.html#the-matched-filter":{}},"title":{}}],["suffic",{"_index":2701,"text":{"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{}},"title":{}}],["suffici",{"_index":2076,"text":{"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#laboratory-exercise-42":{},"Chap_5.html":{},"Chap_5.html#example-pink-noise":{},"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_7.html":{},"Chap_7.html#descriptive-statistic-variance":{},"Chap_7.html#power-spectral-density_1":{}},"title":{}}],["suggest",{"_index":2221,"text":{"Chap_4.html":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#expected-value":{},"Chap_9.html":{},"Chap_9.html#problem-91":{}},"title":{}}],["suitabl",{"_index":275,"text":{"Chap_10.html":{},"Chap_10.html#the-wiener-filter":{},"Chap_11.html":{},"Chap_11.html#laboratory-exercise-111":{},"Chap_7.html":{},"Chap_7.html#impulse-invariant-sampling":{}},"title":{}}],["sum",{"_index":433,"text":{"Chap_10.html":{},"Chap_10.html#correlation-returns":{},"Chap_11.html":{},"Chap_11.html#langevin-redux":{},"Chap_11.html#problem-119":{},"Chap_12.html":{},"Chap_12.html#problem-123":{},"Chap_12.html#the-periodogram-unbiased":{},"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_3.html":{},"Chap_3.html#problem-38":{},"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#example-average-experience":{},"Chap_4.html#example-fair-chance":{},"Chap_4.html#laboratory-exercise-42":{},"Chap_4.html#properties-of-averaging":{},"Chap_4.html#the-ergodic-process":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_6.html":{},"Chap_6.html#interpretation-of-the-convolution-result":{},"Chap_6.html#the-autocorrelation-function":{},"Chap_7.html":{},"Chap_7.html#expected-value":{},"Chap_7.html#how-big-is-big-how-small-is-small":{},"Chap_7.html#impulse-invariant-sampling":{},"Chap_8.html":{},"Chap_8.html#problem-83":{},"Chap_9.html":{},"Chap_9.html#laboratory-exercise-93":{}},"title":{}}],["sum\\limits_k",{"_index":1596,"text":{"Chap_13.html":{},"Chap_13.html#appendix-i-mean-square-error-minimization":{},"Chap_5.html":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{}},"title":{}}],["sum\\limits_n",{"_index":2494,"text":{"Chap_5.html":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{}},"title":{}}],["sum\\limits_{i",{"_index":515,"text":{"Chap_10.html":{},"Chap_10.html#what-is-that-least-mean-square-error":{},"Chap_11.html":{},"Chap_11.html#example-estimating-the-poisson-rate":{},"Chap_4.html":{},"Chap_4.html#example-average-experience":{},"Chap_4.html#laboratory-exercise-42":{}},"title":{}}],["sum\\limits_{k",{"_index":384,"text":{"Chap_10.html":{},"Chap_10.html#correlation-returns":{},"Chap_10.html#expressing-the-mean-square-error":{},"Chap_10.html#problem-102":{},"Chap_10.html#what-is-that-least-mean-square-error":{},"Chap_12.html":{},"Chap_12.html#spectral-estimation":{},"Chap_12.html#the-periodogram-unbiased":{},"Chap_12.html#windowed-observations":{},"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_3.html":{},"Chap_3.html#introduction":{},"Chap_5.html":{},"Chap_5.html#example-pink-noise":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_6.html":{},"Chap_6.html#interpretation-of-the-convolution-result":{},"Chap_6.html#problem-61":{},"Chap_6.html#the-mean":{},"Chap_7.html":{},"Chap_7.html#problem-72":{}},"title":{}}],["sum\\limits_{m",{"_index":317,"text":{"Chap_10.html":{},"Chap_10.html#the-restoration-case-noise":{},"Chap_10.html#the-wiener-hopf-equation":{},"Chap_10.html#using-the-least-mean-square-error-criterion":{},"Chap_10.html#what-is-that-least-mean-square-error":{},"Chap_11.html":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_11.html#langevin-redux":{},"Chap_11.html#problem-119":{},"Chap_6.html":{},"Chap_6.html#the-autocorrelation-function":{},"Chap_6.html#the-cross-correlation-function":{}},"title":{}}],["sum\\limits_{n",{"_index":843,"text":{"Chap_11.html":{},"Chap_11.html#aspects-of-estimation":{},"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_3.html":{},"Chap_3.html#problem-38":{},"Chap_4.html":{},"Chap_4.html#example-fair-chance":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#problem-55":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_6.html":{},"Chap_6.html#the-autocorrelation-function":{},"Chap_7.html":{},"Chap_7.html#impulse-invariant-sampling":{},"Chap_9.html":{},"Chap_9.html#problem-92":{}},"title":{}}],["sum\\limits_{r",{"_index":2648,"text":{"Chap_6.html":{},"Chap_6.html#the-autocorrelation-function":{}},"title":{}}],["sum\\nolimits_k",{"_index":1606,"text":{"Chap_13.html":{},"Chap_13.html#appendix-i-mean-square-error-minimization":{},"Chap_7.html":{},"Chap_7.html#expected-value":{},"Chap_7.html#impulse-invariant-sampling":{}},"title":{}}],["sum\\nolimits_n",{"_index":2458,"text":{"Chap_5.html":{},"Chap_5.html#a-digression":{}},"title":{}}],["sum_{i=0}^{6}p(i)=1\\text",{"_index":1849,"text":{"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{}},"title":{}}],["summabl",{"_index":2474,"text":{"Chap_5.html":{},"Chap_5.html#a-digression":{}},"title":{}}],["summar",{"_index":1422,"text":{"Chap_12.html":{},"Chap_12.html#other-windows":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_5.html":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#the-langevin-velocity-equation":{}},"title":{}}],["summari",{"_index":1900,"text":{"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{}},"title":{}}],["summat",{"_index":420,"text":{"Chap_10.html":{},"Chap_10.html#correlation-returns":{},"Chap_10.html#what-is-that-least-mean-square-error":{},"Chap_11.html":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_12.html":{},"Chap_12.html#the-periodogram-unbiased":{},"Chap_12.html#windowed-observations":{},"Chap_5.html":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_6.html":{},"Chap_6.html#problem-61":{}},"title":{}}],["suppplement",{"_index":1260,"text":{"Chap_11.html":{},"Chap_11.html#laboratory-exercise-113":{}},"title":{}}],["suppress",{"_index":1535,"text":{"Chap_12.html":{},"Chap_12.html#problem-122":{}},"title":{}}],["surpris",{"_index":2442,"text":{"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_7.html":{},"Chap_7.html#expected-value_1":{},"Chap_7.html#power-spectral-density_1":{}},"title":{}}],["surround",{"_index":2735,"text":{"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{},"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{}},"title":{}}],["surviv",{"_index":2329,"text":{"Chap_4.html":{},"Chap_4.html#problem-42":{}},"title":{}}],["suspens",{"_index":3529,"text":{"Chap_8.html":{},"Chap_8.html#problem-83":{}},"title":{}}],["switch",{"_index":760,"text":{"Chap_10.html":{},"Chap_10.html#problem-104":{}},"title":{}}],["symbol",{"_index":3646,"text":{"info.html":{},"info.html#tips-short-cuts":{}},"title":{}}],["symmetr",{"_index":2290,"text":{"Chap_4.html":{},"Chap_4.html#describing-the-time-average":{},"Chap_5.html":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{}},"title":{}}],["symmetri",{"_index":1094,"text":{"Chap_11.html":{},"Chap_11.html#langevin-redux":{},"Chap_3.html":{},"Chap_3.html#problem-38":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{}},"title":{}}],["synthet",{"_index":1538,"text":{"Chap_12.html":{},"Chap_12.html#problem-122":{}},"title":{}}],["system",{"_index":109,"text":{"Chap_1.html":{},"Chap_1.html#highlighting":{},"Chap_10.html":{},"Chap_10.html#the-more-general-restoration-case-noise-distortion":{},"Chap_10.html#using-the-least-mean-square-error-criterion":{},"Chap_2.html":{},"Chap_2.html#prologue":{},"Chap_3.html":{},"Chap_3.html#introduction":{},"Chap_3.html#problem-310":{},"Chap_3.html#problem-33":{},"Chap_3.html#the-basics":{},"Chap_3.html#what-is-a-random-signal":{},"Chap_4.html":{},"Chap_4.html#laboratory-exercise-42":{},"Chap_4.html#problem-48":{},"Chap_5.html":{},"Chap_5.html#laboratory-exercise-51":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{},"Chap_6.html#filtering-of-stochastic-signals":{},"Chap_6.html#interpretation-of-the-convolution-result":{},"Chap_6.html#problem-61":{},"Chap_6.html#problem-62":{},"Chap_6.html#problem-64":{},"Chap_6.html#problem-65":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_6.html#the-mean":{},"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#problem-710":{},"Chap_7.html#problem-711":{},"Chap_7.html#problem-72":{},"Chap_7.html#problem-73":{},"Chap_7.html#tethered-particle-motion":{},"Chap_7.html#the-langevin-equation-a-case-study":{},"Chap_7.html#the-langevin-velocity-equation":{},"Chap_8.html":{},"Chap_8.html#characterizing-signal-to-noise-ratios":{},"Chap_8.html#example-filtering-noise":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{},"Chap_9.html":{},"Chap_9.html#the-matched-filter":{}},"title":{"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{}}}],["system\u2014on",{"_index":2813,"text":{"Chap_7.html":{},"Chap_7.html#from-t-to-n":{}},"title":{}}],["s}}{",{"_index":3520,"text":{"Chap_8.html":{},"Chap_8.html#problem-82":{}},"title":{}}],["s\u00f1r",{"_index":3472,"text":{"Chap_8.html":{},"Chap_8.html#example-cocktail-party-noise":{},"Chap_8.html#problem-83":{}},"title":{}}],["t",{"_index":886,"text":{"Chap_11.html":{},"Chap_11.html#example-estimating-the-poisson-rate":{},"Chap_12.html":{},"Chap_12.html#problem-122":{},"Chap_12.html#problem-123":{},"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_4.html":{},"Chap_4.html#characterization-of-random-signals":{},"Chap_4.html#laboratory-exercise-41":{},"Chap_4.html#problem-42":{},"Chap_4.html#problem-47":{},"Chap_7.html":{},"Chap_7.html#one-step-further":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#problem-711":{},"Chap_7.html#problem-72":{},"Chap_7.html#problem-79":{},"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{},"info.html":{},"info.html#authors":{}},"title":{"Chap_7.html#from-t-to-n":{}}}],["t)&\\lvert",{"_index":2039,"text":{"Chap_3.html":{},"Chap_3.html#problem-310":{}},"title":{}}],["t)}}{{\\pi",{"_index":1649,"text":{"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{}},"title":{}}],["t/\\tau",{"_index":2331,"text":{"Chap_4.html":{},"Chap_4.html#problem-42":{}},"title":{}}],["t/\\theta",{"_index":2833,"text":{"Chap_7.html":{},"Chap_7.html#impulse-invariant-sampling":{}},"title":{}}],["t/m",{"_index":2831,"text":{"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#impulse-invariant-sampling":{}},"title":{}}],["t/m}}u(t",{"_index":2972,"text":{"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#the-langevin-position-equation":{}},"title":{}}],["t[n",{"_index":2553,"text":{"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{}},"title":{}}],["t[n\\rbrack",{"_index":2585,"text":{"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{}},"title":{}}],["t\\left",{"_index":1179,"text":{"Chap_11.html":{},"Chap_11.html#problem-114":{}},"title":{}}],["t\\rvert>\\sqrt{3",{"_index":2042,"text":{"Chap_3.html":{},"Chap_3.html#problem-310":{}},"title":{}}],["t\\rvert>\\sqrt{3}\\end{cas",{"_index":2016,"text":{"Chap_3.html":{},"Chap_3.html#problem-310":{}},"title":{}}],["t\\rvert\\leq\\sqrt{3",{"_index":2040,"text":{"Chap_3.html":{},"Chap_3.html#problem-310":{}},"title":{}}],["t\\rvert\\leq\\sqrt{3}\\\\0&\\lvert",{"_index":2015,"text":{"Chap_3.html":{},"Chap_3.html#problem-310":{}},"title":{}}],["t^2}{{\\left",{"_index":1685,"text":{"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{}},"title":{}}],["t_",{"_index":2826,"text":{"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#descriptive-statistic-variance":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#impulse-invariant-sampling":{},"Chap_7.html#one-step-further":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#power-spectral-density_2":{},"Chap_7.html#problem-711":{},"Chap_7.html#problem-72":{},"Chap_7.html#problem-79":{}},"title":{}}],["t_1},{t_2},{t_3},...,{t_n",{"_index":1183,"text":{"Chap_11.html":{},"Chap_11.html#problem-114":{}},"title":{}}],["t_s}/m",{"_index":1075,"text":{"Chap_11.html":{},"Chap_11.html#langevin-redux":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#impulse-invariant-sampling":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#the-langevin-position-equation":{},"Chap_7.html#the-langevin-velocity-equation":{}},"title":{}}],["t_s}/m)n}}u[n",{"_index":2941,"text":{"Chap_7.html":{},"Chap_7.html#autocorrelation-function":{}},"title":{}}],["t_s}\\,\\sigma",{"_index":3004,"text":{"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{}},"title":{}}],["t_s}\\sigma",{"_index":3122,"text":{"Chap_7.html":{},"Chap_7.html#descriptive-statistic-variance":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#problem-78":{}},"title":{}}],["t_{1/2",{"_index":2314,"text":{"Chap_4.html":{},"Chap_4.html#problem-42":{}},"title":{}}],["t_{1/2}}/\\ln",{"_index":2332,"text":{"Chap_4.html":{},"Chap_4.html#problem-42":{}},"title":{}}],["t_{18",{"_index":2208,"text":{"Chap_4.html":{},"Chap_4.html#the-mechanics-of-correlations":{}},"title":{}}],["t_{rms}}\\delta",{"_index":1481,"text":{"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{}},"title":{}}],["tabl",{"_index":1437,"text":{"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#other-windows":{},"Chap_12.html#problem-121":{},"Chap_7.html":{},"Chap_7.html#descriptive-statistic-variance":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#power-spectral-density_1":{}},"title":{}}],["tablet",{"_index":26,"text":{"Chap_1.html":{},"Chap_1.html#how-to-use-this-ibook":{},"info.html":{},"info.html#tips-short-cuts":{}},"title":{}}],["tail",{"_index":2056,"text":{"Chap_4.html":{},"Chap_4.html#example-fair-chance":{},"Chap_4.html#example-is-that-coin-fair":{},"Chap_4.html#laboratory-exercise-41":{},"Chap_4.html#problem-47":{}},"title":{}}],["take",{"_index":488,"text":{"Chap_10.html":{},"Chap_10.html#as-seen-from-the-fourier-domain":{},"Chap_10.html#classic-example-classic-result":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_13.html":{},"Chap_13.html#appendix-i-mean-square-error-minimization":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_4.html":{},"Chap_4.html#autocorrelation":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#example-dice-money":{},"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_9.html":{},"Chap_9.html#the-classic-example":{}},"title":{}}],["taken",{"_index":135,"text":{"Chap_1.html":{},"Chap_1.html#at-the-movies":{},"Chap_1.html#getting-around":{},"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{}},"title":{}}],["talk",{"_index":1887,"text":{"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{}},"title":{}}],["tap",{"_index":144,"text":{"Chap_1.html":{},"Chap_1.html#getting-around":{},"info.html":{},"info.html#tips-short-cuts":{}},"title":{}}],["taper",{"_index":1541,"text":{"Chap_12.html":{},"Chap_12.html#problem-122":{}},"title":{}}],["tau",{"_index":2281,"text":{"Chap_4.html":{},"Chap_4.html#example-is-that-coin-fair":{},"Chap_4.html#problem-42":{},"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#the-langevin-equation-a-case-study":{}},"title":{}}],["tauber",{"_index":3395,"text":{"Chap_7.html":{},"Chap_7.html#problem-711":{}},"title":{}}],["taught",{"_index":1582,"text":{"Chap_12.html":{},"Chap_12.html#laboratory-exercise-122":{}},"title":{}}],["taylor",{"_index":1549,"text":{"Chap_12.html":{},"Chap_12.html#problem-122":{},"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{}},"title":{}}],["tchebyshev",{"_index":1253,"text":{"Chap_11.html":{},"Chap_11.html#laboratory-exercise-113":{}},"title":{}}],["teach",{"_index":234,"text":{"Chap_1.html":{},"Chap_1.html#enhanced-experience":{}},"title":{}}],["teacher",{"_index":1720,"text":{"Chap_13.html":{},"Chap_13.html#epilogue":{},"Chap_2.html":{},"Chap_2.html#prologue":{}},"title":{}}],["tech@socraticsoftware.org",{"_index":3667,"text":{"info.html":{},"info.html#contact":{}},"title":{}}],["technic",{"_index":3666,"text":{"info.html":{},"info.html#contact":{},"info.html#technical-details":{}},"title":{"info.html#technical-details":{}}}],["techniqu",{"_index":469,"text":{"Chap_10.html":{},"Chap_10.html#example-cleaning-up-our-act":{},"Chap_10.html#the-wiener-hopf-equation":{},"Chap_12.html":{},"Chap_12.html#problem-123":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_2.html":{},"Chap_2.html#prologue":{},"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#from-t-to-n":{},"Chap_7.html#impulse-invariant-sampling":{},"Chap_7.html#the-langevin-position-equation":{}},"title":{}}],["technolog",{"_index":1591,"text":{"Chap_12.html":{},"Chap_12.html#laboratory-exercise-124":{},"Chap_13.html":{},"Chap_13.html#epilogue":{},"Chap_7.html":{},"Chap_7.html#problem-711":{}},"title":{}}],["technology\u2014such",{"_index":21,"text":{"Chap_1.html":{},"Chap_1.html#how-to-use-this-ibook":{}},"title":{}}],["ted",{"_index":1725,"text":{"Chap_13.html":{},"Chap_13.html#epilogue":{}},"title":{}}],["tediou",{"_index":1040,"text":{"Chap_11.html":{},"Chap_11.html#how-good-is-our-estimator":{}},"title":{}}],["tell",{"_index":3629,"text":{"Chap_9.html":{},"Chap_9.html#laboratory-exercise-93":{}},"title":{}}],["temperatur",{"_index":657,"text":{"Chap_10.html":{},"Chap_10.html#example-sound-of-distorted-music":{},"Chap_11.html":{},"Chap_11.html#problem-119":{},"Chap_12.html":{},"Chap_12.html#spectral-estimation":{},"Chap_2.html":{},"Chap_2.html#prologue":{},"Chap_4.html":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#how-big-is-big-how-small-is-small":{},"Chap_7.html#one-step-further":{},"Chap_7.html#problem-78":{},"info.html":{},"info.html#cover":{}},"title":{}}],["templat",{"_index":3549,"text":{"Chap_9.html":{},"Chap_9.html#the-matched-filter":{}},"title":{}}],["tempor",{"_index":473,"text":{"Chap_10.html":{},"Chap_10.html#the-wiener-hopf-equation":{}},"title":{}}],["temporarili",{"_index":1605,"text":{"Chap_13.html":{},"Chap_13.html#appendix-i-mean-square-error-minimization":{}},"title":{}}],["tempt",{"_index":3482,"text":{"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{}},"title":{}}],["temptat",{"_index":613,"text":{"Chap_10.html":{},"Chap_10.html#why-we-avoid-the-inverse-filter":{}},"title":{}}],["ten",{"_index":2583,"text":{"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{}},"title":{}}],["term",{"_index":296,"text":{"Chap_10.html":{},"Chap_10.html#classic-example-classic-result":{},"Chap_10.html#correlation-returns":{},"Chap_10.html#problem-103":{},"Chap_10.html#the-restoration-case-noise":{},"Chap_11.html":{},"Chap_11.html#estimating-the-mean":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_11.html#langevin-redux":{},"Chap_11.html#problem-1110":{},"Chap_11.html#problem-119":{},"Chap_12.html":{},"Chap_12.html#the-periodogram-unbiased":{},"Chap_13.html":{},"Chap_13.html#appendix-i-mean-square-error-minimization":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_2.html":{},"Chap_2.html#prologue":{},"Chap_3.html":{},"Chap_3.html#problem-38":{},"Chap_4.html":{},"Chap_4.html#example-fair-chance":{},"Chap_4.html#example-is-that-coin-fair":{},"Chap_4.html#problem-44":{},"Chap_4.html#properties-of-averaging":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#correlations-and-memory":{},"Chap_5.html#example-white-noise":{},"Chap_5.html#laboratory-exercise-51":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_5.html#problem-55":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_6.html":{},"Chap_6.html#the-autocorrelation-function":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_6.html#the-mean":{},"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#expected-value":{},"Chap_7.html#impulse-invariant-sampling":{},"Chap_7.html#one-step-further":{},"Chap_7.html#problem-73":{},"Chap_7.html#problem-77":{},"Chap_7.html#the-langevin-equation-a-case-study":{},"Chap_8.html":{},"Chap_8.html#snr-for-random-signals-in-the-presence-of-noise":{},"Chap_9.html":{},"Chap_9.html#problem-92":{}},"title":{}}],["termin",{"_index":2873,"text":{"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{}},"title":{}}],["term\u2014a",{"_index":3388,"text":{"Chap_7.html":{},"Chap_7.html#problem-79":{}},"title":{}}],["test",{"_index":159,"text":{"Chap_1.html":{},"Chap_1.html#sound-of-music":{},"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#one-step-further":{},"Chap_8.html":{},"Chap_8.html#example-not-too-noisy":{},"Chap_8.html#problem-83":{}},"title":{}}],["tether",{"_index":3127,"text":{"Chap_7.html":{},"Chap_7.html#expected-value_1":{},"Chap_7.html#one-step-further":{},"Chap_7.html#problem-711":{},"Chap_7.html#tethered-particle-motion":{},"Chap_7.html#why-this-case-study":{}},"title":{"Chap_7.html#tethered-particle-motion":{}}}],["text",{"_index":33,"text":{"Chap_1.html":{},"Chap_1.html#enhanced-experience":{},"Chap_1.html#how-to-use-this-ibook":{},"Chap_11.html":{},"Chap_11.html#problem-119":{},"Chap_12.html":{},"Chap_12.html#problem-121":{},"Chap_5.html":{},"Chap_5.html#problem-52":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#power-spectral-density_2":{},"Chap_7.html#problem-77":{},"info.html":{},"info.html#technical-details":{},"info.html#tips-short-cuts":{}},"title":{}}],["textbook",{"_index":12,"text":{"Chap_1.html":{},"Chap_1.html#how-to-use-this-ibook":{},"Chap_13.html":{},"Chap_13.html#appendix-i-mean-square-error-minimization":{},"Chap_13.html#epilogue":{},"Chap_2.html":{},"Chap_2.html#prologue":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_3.html#the-basics":{},"Chap_5.html":{},"Chap_5.html#problem-56":{},"Chap_7.html":{},"Chap_7.html#from-t-to-n":{},"Chap_9.html":{},"Chap_9.html#problem-92":{},"info.html":{},"info.html#tips-short-cuts":{}},"title":{}}],["th",{"_index":480,"text":{"Chap_10.html":{},"Chap_10.html#the-wiener-hopf-equation":{},"Chap_2.html":{},"Chap_2.html#prologue":{}},"title":{}}],["thank",{"_index":3675,"text":{"info.html":{},"info.html#acknowledgments":{}},"title":{}}],["theme",{"_index":1836,"text":{"Chap_3.html":{},"Chap_3.html#what-is-a-random-signal":{}},"title":{}}],["themselv",{"_index":2393,"text":{"Chap_5.html":{},"Chap_5.html#correlations-simple-and-complex":{},"Chap_7.html":{},"Chap_7.html#tethered-particle-motion":{},"Chap_7.html#why-this-case-study":{}},"title":{}}],["theorem",{"_index":532,"text":{"Chap_10.html":{},"Chap_10.html#problem-102":{},"Chap_10.html#what-is-that-least-mean-square-error":{},"Chap_2.html":{},"Chap_2.html#prologue":{},"Chap_4.html":{},"Chap_4.html#problem-48":{},"Chap_5.html":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#how-big-is-big-how-small-is-small":{},"Chap_7.html#problem-72":{}},"title":{}}],["theoret",{"_index":1256,"text":{"Chap_11.html":{},"Chap_11.html#laboratory-exercise-113":{}},"title":{}}],["theori",{"_index":344,"text":{"Chap_10.html":{},"Chap_10.html#laboratory-exercise-105":{},"Chap_10.html#using-the-least-mean-square-error-criterion":{},"Chap_11.html":{},"Chap_11.html#aspects-of-estimation":{},"Chap_11.html#laboratory-exercise-113":{},"Chap_11.html#langevin-redux":{},"Chap_12.html":{},"Chap_12.html#spectral-estimation":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_12.html#windowed-observations":{},"Chap_13.html":{},"Chap_13.html#epilogue":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_3.html#introduction":{},"Chap_3.html#problem-310":{},"Chap_3.html#the-basics":{},"Chap_3.html#what-is-a-random-signal":{},"Chap_4.html":{},"Chap_4.html#laboratory-exercise-42":{},"Chap_5.html":{},"Chap_5.html#laboratory-exercise-51":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_6.html":{},"Chap_6.html#interpretation-of-the-convolution-result":{},"Chap_6.html#the-autocorrelation-function":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_6.html#the-mean":{},"Chap_7.html":{},"Chap_7.html#problem-711":{},"Chap_9.html":{},"Chap_9.html#problem-92":{},"Chap_9.html#the-matched-filter":{}},"title":{}}],["therebi",{"_index":2827,"text":{"Chap_7.html":{},"Chap_7.html#impulse-invariant-sampling":{},"info.html":{},"info.html#acknowledgments":{}},"title":{}}],["therefor",{"_index":666,"text":{"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#example-cleaning-up-our-act":{},"Chap_10.html#example-sound-of-distorted-music":{},"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_4.html":{},"Chap_4.html#properties-of-averaging":{},"Chap_5.html":{},"Chap_5.html#correlations-simple-and-complex":{},"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_6.html#the-mean":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#how-big-is-big-how-small-is-small":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#power-spectral-density_1":{},"Chap_8.html":{},"Chap_8.html#snr-for-random-signals-in-the-presence-of-noise":{}},"title":{}}],["thermal",{"_index":3006,"text":{"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#problem-711":{},"Chap_7.html#tethered-particle-motion":{},"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{}},"title":{}}],["theta",{"_index":860,"text":{"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_11.html#example-estimating-the-poisson-rate":{},"Chap_11.html#maximum-likelihood-estimation":{},"Chap_11.html#problem-116":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#how-big-is-big-how-small-is-small":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#impulse-invariant-sampling":{},"Chap_7.html#power-spectral-density_1":{},"Chap_9.html":{},"Chap_9.html#laboratory-exercise-93":{}},"title":{}}],["thing",{"_index":2091,"text":{"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{}},"title":{}}],["think",{"_index":1145,"text":{"Chap_11.html":{},"Chap_11.html#trouble-in-paradise":{},"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{}},"title":{}}],["third",{"_index":629,"text":{"Chap_10.html":{},"Chap_10.html#why-we-avoid-the-inverse-filter":{},"Chap_5.html":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_7.html":{},"Chap_7.html#tethered-particle-motion":{}},"title":{}}],["thoma",{"_index":3488,"text":{"Chap_8.html":{},"Chap_8.html#problem-83":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{}},"title":{}}],["thorough",{"_index":2817,"text":{"Chap_7.html":{},"Chap_7.html#from-t-to-n":{}},"title":{}}],["those",{"_index":374,"text":{"Chap_10.html":{},"Chap_10.html#classic-example-classic-result":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#using-the-least-mean-square-error-criterion":{},"Chap_10.html#why-we-avoid-the-inverse-filter":{},"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_2.html":{},"Chap_2.html#prologue":{},"Chap_4.html":{},"Chap_4.html#characterization-of-random-signals":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_8.html":{},"Chap_8.html#example-filtering-noise":{}},"title":{}}],["though",{"_index":3007,"text":{"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{}},"title":{}}],["thought",{"_index":1627,"text":{"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{}},"title":{}}],["thousand",{"_index":798,"text":{"Chap_10.html":{},"Chap_10.html#laboratory-exercise-105":{}},"title":{}}],["three",{"_index":845,"text":{"Chap_11.html":{},"Chap_11.html#aspects-of-estimation":{},"Chap_12.html":{},"Chap_12.html#problem-123":{},"Chap_4.html":{},"Chap_4.html#problem-44":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#from-t-to-n":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#tethered-particle-motion":{},"Chap_7.html#why-this-case-study":{}},"title":{}}],["through",{"_index":66,"text":{"Chap_1.html":{},"Chap_1.html#enhanced-experience":{},"Chap_1.html#how-to-use-this-ibook":{},"Chap_1.html#outside-this-device":{},"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#example-sound-of-distorted-music":{},"Chap_10.html#laboratory-exercise-104":{},"Chap_10.html#the-wiener-hopf-equation":{},"Chap_10.html#what-is-that-least-mean-square-error":{},"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_12.html":{},"Chap_12.html#laboratory-exercise-123":{},"Chap_12.html#problem-122":{},"Chap_12.html#windowed-observations":{},"Chap_2.html":{},"Chap_2.html#problem-21":{},"Chap_2.html#prologue":{},"Chap_3.html":{},"Chap_3.html#introduction":{},"Chap_3.html#the-basics":{},"Chap_4.html":{},"Chap_4.html#example-dice-money":{},"Chap_4.html#problem-42":{},"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_6.html":{},"Chap_6.html#filtering-of-stochastic-signals":{},"Chap_6.html#the-mean":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function_1":{},"Chap_7.html#expected-value":{},"Chap_7.html#one-step-further":{},"Chap_7.html#power-spectral-density":{},"Chap_7.html#tethered-particle-motion":{},"Chap_7.html#why-this-case-study":{},"Chap_8.html":{},"Chap_8.html#characterizing-signal-to-noise-ratios":{},"Chap_8.html#problem-83":{},"Chap_9.html":{},"Chap_9.html#the-matched-filter":{}},"title":{}}],["throughout",{"_index":1697,"text":{"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{}},"title":{}}],["throw",{"_index":982,"text":{"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_12.html":{},"Chap_12.html#laboratory-exercise-124":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_3.html#problem-37":{},"Chap_4.html":{},"Chap_4.html#example-dice-money":{},"Chap_4.html#other-averages":{}},"title":{}}],["thu",{"_index":551,"text":{"Chap_10.html":{},"Chap_10.html#classic-example-classic-result":{},"Chap_10.html#why-we-avoid-the-inverse-filter":{},"Chap_11.html":{},"Chap_11.html#estimating-the-mean":{},"Chap_11.html#trouble-in-paradise":{},"Chap_12.html":{},"Chap_12.html#the-periodogram-unbiased":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_4.html":{},"Chap_4.html#cross-covariance":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#example-pink-noise":{},"Chap_5.html#laboratory-exercise-51":{},"Chap_6.html":{},"Chap_6.html#filtering-of-stochastic-signals":{},"Chap_6.html#interpretation-of-the-convolution-result":{},"Chap_6.html#problem-61":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#impulse-invariant-sampling":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#tethered-particle-motion":{},"Chap_7.html#the-langevin-position-equation":{},"Chap_8.html":{},"Chap_8.html#problem-83":{}},"title":{}}],["ti",{"_index":1772,"text":{"Chap_2.html":{},"Chap_2.html#prologue":{}},"title":{}}],["tild",{"_index":1188,"text":{"Chap_11.html":{},"Chap_11.html#problem-115":{}},"title":{}}],["time",{"_index":641,"text":{"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#example-cleaning-up-our-act":{},"Chap_10.html#example-sound-of-distorted-music":{},"Chap_10.html#laboratory-exercise-105":{},"Chap_10.html#problem-104":{},"Chap_10.html#why-we-avoid-the-inverse-filter":{},"Chap_11.html":{},"Chap_11.html#example-estimating-the-poisson-rate":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_11.html#laboratory-exercise-113":{},"Chap_11.html#langevin-redux":{},"Chap_11.html#problem-113":{},"Chap_11.html#problem-114":{},"Chap_11.html#problem-116":{},"Chap_11.html#problem-118":{},"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#other-windows":{},"Chap_12.html#problem-122":{},"Chap_12.html#problem-123":{},"Chap_12.html#windowed-observations":{},"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_13.html#epilogue":{},"Chap_2.html":{},"Chap_2.html#problem-21":{},"Chap_2.html#prologue":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_3.html#introduction":{},"Chap_3.html#problem-310":{},"Chap_3.html#problem-32":{},"Chap_3.html#the-basics":{},"Chap_3.html#what-is-a-random-signal":{},"Chap_4.html":{},"Chap_4.html#autocorrelation":{},"Chap_4.html#correlation-the-workhorse":{},"Chap_4.html#cross-covariance":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#describing-the-time-average":{},"Chap_4.html#example-dice-money":{},"Chap_4.html#example-fair-chance":{},"Chap_4.html#example-is-that-coin-fair":{},"Chap_4.html#laboratory-exercise-41":{},"Chap_4.html#laboratory-exercise-42":{},"Chap_4.html#problem-42":{},"Chap_4.html#problem-47":{},"Chap_4.html#problem-48":{},"Chap_4.html#the-ergodic-process":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#correlations-and-memory":{},"Chap_5.html#example-delayed-effect":{},"Chap_5.html#example-pink-noise":{},"Chap_5.html#laboratory-exercise-51":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_5.html#problem-52":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{},"Chap_6.html#filtering-of-stochastic-signals":{},"Chap_6.html#problem-61":{},"Chap_6.html#problem-62":{},"Chap_6.html#problem-64":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_7.html":{},"Chap_7.html#descriptive-statistic-variance":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#expected-value":{},"Chap_7.html#from-t-to-n":{},"Chap_7.html#how-big-is-big-how-small-is-small":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#impulse-invariant-sampling":{},"Chap_7.html#one-step-further":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#power-spectral-density_2":{},"Chap_7.html#problem-71":{},"Chap_7.html#problem-73":{},"Chap_7.html#problem-78":{},"Chap_7.html#problem-79":{},"Chap_7.html#tethered-particle-motion":{},"Chap_7.html#the-langevin-equation-a-case-study":{},"Chap_7.html#the-langevin-position-equation":{},"Chap_7.html#why-this-case-study":{},"Chap_8.html":{},"Chap_8.html#example-cocktail-party-noise":{},"Chap_8.html#problem-83":{},"Chap_8.html#snr-for-deterministic-signals-in-the-presence-of-noise":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{},"Chap_9.html":{},"Chap_9.html#example-matching-your-filter":{},"Chap_9.html#setting-up-the-problem":{},"Chap_9.html#the-matched-filter":{},"info.html":{},"info.html#cover":{}},"title":{"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_4.html#describing-the-time-average":{}}}],["time\u2014i",{"_index":3485,"text":{"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{}},"title":{}}],["tip",{"_index":3642,"text":{"info.html":{}},"title":{"info.html#tips-short-cuts":{}}}],["titl",{"_index":3651,"text":{"info.html":{},"info.html#tips-short-cuts":{}},"title":{}}],["today",{"_index":2115,"text":{"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_5.html":{},"Chap_5.html#correlations-and-memory":{}},"title":{}}],["togeth",{"_index":1443,"text":{"Chap_12.html":{},"Chap_12.html#other-windows":{},"Chap_2.html":{},"Chap_2.html#prologue":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_7.html":{},"Chap_7.html#power-spectral-density_1":{}},"title":{}}],["tone",{"_index":1562,"text":{"Chap_12.html":{},"Chap_12.html#problem-123":{}},"title":{}}],["took",{"_index":1790,"text":{"Chap_2.html":{},"Chap_2.html#prologue":{}},"title":{}}],["tool",{"_index":1768,"text":{"Chap_2.html":{},"Chap_2.html#prologue":{},"Chap_5.html":{},"Chap_5.html#correlations-and-memory":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_6.html":{},"Chap_6.html#filtering-of-stochastic-signals":{},"Chap_6.html#laboratory-exercise-61":{},"Chap_6.html#laboratory-exercise-64":{},"Chap_6.html#laboratory-exercise-65":{},"Chap_6.html#laboratory-exercise-66":{},"Chap_6.html#laboratory-exercise-67":{},"Chap_6.html#laboratory-exercise-68":{},"Chap_7.html":{},"Chap_7.html#the-langevin-equation-a-case-study":{},"Chap_7.html#why-this-case-study":{}},"title":{}}],["top",{"_index":145,"text":{"Chap_1.html":{},"Chap_1.html#getting-around":{},"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#example-cleaning-up-our-act":{},"Chap_10.html#why-we-avoid-the-inverse-filter":{},"Chap_11.html":{},"Chap_11.html#estimating-the-autocorrelation-function":{},"Chap_12.html":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_12.html#windowed-observations":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{},"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{},"Chap_9.html":{},"Chap_9.html#example-matching-your-filter":{},"Chap_9.html#performance-in-the-presence-of-noise":{},"info.html":{},"info.html#tips-short-cuts":{}},"title":{}}],["topic",{"_index":734,"text":{"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_2.html":{},"Chap_2.html#prologue":{},"Chap_4.html":{},"Chap_4.html#properties-of-averaging":{},"Chap_7.html":{},"Chap_7.html#from-t-to-n":{},"Chap_9.html":{},"Chap_9.html#problem-92":{},"info.html":{},"info.html#acknowledgments":{},"info.html#tips-short-cuts":{}},"title":{}}],["toss",{"_index":2265,"text":{"Chap_4.html":{},"Chap_4.html#example-is-that-coin-fair":{},"Chap_4.html#laboratory-exercise-41":{}},"title":{}}],["total",{"_index":80,"text":{"Chap_1.html":{},"Chap_1.html#how-to-use-this-ibook":{},"Chap_10.html":{},"Chap_10.html#the-restoration-case-noise":{},"Chap_10.html#what-is-that-least-mean-square-error":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_6.html":{},"Chap_6.html#interpretation-of-the-convolution-result":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#one-step-further":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#tethered-particle-motion":{},"info.html":{},"info.html#tips-short-cuts":{}},"title":{}}],["tpm",{"_index":2810,"text":{"Chap_7.html":{},"Chap_7.html#descriptive-statistic-variance":{},"Chap_7.html#one-step-further":{},"Chap_7.html#power-spectral-density_2":{},"Chap_7.html#problem-710":{},"Chap_7.html#problem-77":{},"Chap_7.html#problem-79":{},"Chap_7.html#tethered-particle-motion":{},"Chap_7.html#the-langevin-equation-a-case-study":{},"Chap_7.html#why-this-case-study":{}},"title":{}}],["trade",{"_index":1164,"text":{"Chap_11.html":{},"Chap_11.html#trouble-in-paradise":{},"Chap_12.html":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_12.html#windowed-observations":{}},"title":{}}],["trademark",{"_index":200,"text":{"Chap_1.html":{},"Chap_1.html#enhanced-experience":{}},"title":{}}],["tradeoff",{"_index":1364,"text":{"Chap_12.html":{},"Chap_12.html#windowed-observations":{}},"title":{}}],["trade\u201d\u2014can",{"_index":911,"text":{"Chap_11.html":{},"Chap_11.html#example-estimating-the-poisson-rate":{}},"title":{}}],["traffic",{"_index":2425,"text":{"Chap_5.html":{},"Chap_5.html#the-mechanics-of-correlations-redux":{}},"title":{}}],["train",{"_index":2354,"text":{"Chap_4.html":{},"Chap_4.html#problem-47":{}},"title":{}}],["transfer",{"_index":619,"text":{"Chap_10.html":{},"Chap_10.html#why-we-avoid-the-inverse-filter":{},"Chap_12.html":{},"Chap_12.html#windowed-observations":{},"Chap_7.html":{},"Chap_7.html#impulse-invariant-sampling":{},"Chap_7.html#problem-79":{},"Chap_7.html#tethered-particle-motion":{}},"title":{}}],["transform",{"_index":489,"text":{"Chap_10.html":{},"Chap_10.html#as-seen-from-the-fourier-domain":{},"Chap_10.html#classic-example-classic-result":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#laboratory-exercise-105":{},"Chap_10.html#problem-102":{},"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_2.html":{},"Chap_2.html#prologue":{},"Chap_3.html":{},"Chap_3.html#problem-31":{},"Chap_3.html#problem-310":{},"Chap_3.html#problem-32":{},"Chap_3.html#problem-33":{},"Chap_3.html#problem-38":{},"Chap_3.html#problem-39":{},"Chap_3.html#the-basics":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#fourier-description-of-correlation-functions":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_6.html":{},"Chap_6.html#problem-65":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_6.html#the-mean":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#expected-value":{},"Chap_7.html#from-t-to-n":{},"Chap_7.html#impulse-invariant-sampling":{},"Chap_7.html#problem-71":{},"Chap_7.html#problem-72":{},"Chap_7.html#problem-73":{},"Chap_7.html#the-langevin-equation-a-case-study":{},"Chap_7.html#the-langevin-velocity-equation":{},"Chap_8.html":{},"Chap_8.html#problem-83":{},"Chap_9.html":{},"Chap_9.html#the-classic-example":{}},"title":{}}],["transform\u2014a",{"_index":3048,"text":{"Chap_7.html":{},"Chap_7.html#expected-value":{}},"title":{}}],["transit",{"_index":3362,"text":{"Chap_7.html":{},"Chap_7.html#one-step-further":{}},"title":{}}],["translat",{"_index":1514,"text":{"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_9.html":{},"Chap_9.html#the-matched-filter-as-an-autocorrelation":{}},"title":{}}],["transmit",{"_index":3748,"text":{"info.html":{},"info.html#usage":{}},"title":{}}],["treat",{"_index":648,"text":{"Chap_10.html":{},"Chap_10.html#example-sound-of-distorted-music":{},"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{}},"title":{}}],["tri",{"_index":1147,"text":{"Chap_11.html":{},"Chap_11.html#trouble-in-paradise":{},"Chap_13.html":{},"Chap_13.html#epilogue":{},"Chap_3.html":{},"Chap_3.html#what-is-a-random-signal":{},"Chap_9.html":{},"Chap_9.html#laboratory-exercise-92":{},"Chap_9.html#problem-92":{}},"title":{}}],["triangl",{"_index":163,"text":{"Chap_1.html":{},"Chap_1.html#at-the-movies":{},"Chap_1.html#sound-of-music":{},"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#example-sound-of-distorted-music":{}},"title":{}}],["triangleq",{"_index":1810,"text":{"Chap_3.html":{},"Chap_3.html#introduction":{}},"title":{}}],["triangular",{"_index":1323,"text":{"Chap_12.html":{},"Chap_12.html#other-windows":{},"Chap_12.html#problem-121":{},"Chap_12.html#windowed-observations":{}},"title":{}}],["trick",{"_index":910,"text":{"Chap_11.html":{},"Chap_11.html#example-estimating-the-poisson-rate":{}},"title":{}}],["tricki",{"_index":2922,"text":{"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{}},"title":{}}],["trivial",{"_index":1581,"text":{"Chap_12.html":{},"Chap_12.html#laboratory-exercise-121":{},"Chap_5.html":{},"Chap_5.html#fourier-description-of-correlation-functions":{}},"title":{}}],["troubl",{"_index":1142,"text":{"Chap_11.html":{}},"title":{"Chap_11.html#trouble-in-paradise":{}}}],["true",{"_index":326,"text":{"Chap_10.html":{},"Chap_10.html#the-restoration-case-noise":{},"Chap_11.html":{},"Chap_11.html#estimating-the-mean":{},"Chap_11.html#problem-115":{},"Chap_11.html#problem-116":{},"Chap_11.html#trouble-in-paradise":{},"Chap_12.html":{},"Chap_12.html#other-windows":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_13.html":{},"Chap_13.html#appendix-i-mean-square-error-minimization":{},"Chap_6.html":{},"Chap_6.html#the-mean":{}},"title":{}}],["tube",{"_index":2869,"text":{"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small":{},"Chap_8.html":{},"Chap_8.html#problem-83":{}},"title":{}}],["tukey",{"_index":1431,"text":{"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#other-windows":{},"Chap_12.html#problem-121":{}},"title":{}}],["turn",{"_index":2854,"text":{"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#impulse-invariant-sampling":{},"Chap_7.html#tethered-particle-motion":{},"info.html":{},"info.html#acknowledgments":{}},"title":{}}],["tweezer",{"_index":3203,"text":{"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{}},"title":{}}],["twice",{"_index":3359,"text":{"Chap_7.html":{},"Chap_7.html#one-step-further":{}},"title":{}}],["two",{"_index":446,"text":{"Chap_10.html":{},"Chap_10.html#classic-example-classic-result":{},"Chap_10.html#laboratory-exercise-103":{},"Chap_10.html#problem-102":{},"Chap_10.html#the-wiener-hopf-equation":{},"Chap_11.html":{},"Chap_11.html#aspects-of-estimation":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_11.html#laboratory-exercise-113":{},"Chap_11.html#langevin-redux":{},"Chap_11.html#problem-118":{},"Chap_11.html#trouble-in-paradise":{},"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#other-windows":{},"Chap_12.html#problem-121":{},"Chap_12.html#problem-122":{},"Chap_12.html#windowed-observations":{},"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_2.html":{},"Chap_2.html#prologue":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_3.html#problem-36":{},"Chap_3.html#problem-37":{},"Chap_3.html#what-is-a-random-signal":{},"Chap_4.html":{},"Chap_4.html#correlation-the-workhorse":{},"Chap_4.html#cross-correlation":{},"Chap_4.html#cross-covariance":{},"Chap_4.html#describing-the-time-average":{},"Chap_4.html#example-dice-money":{},"Chap_4.html#example-fair-chance":{},"Chap_4.html#problem-42":{},"Chap_4.html#properties-of-averaging":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#correlations-and-memory":{},"Chap_5.html#correlations-and-spectra":{},"Chap_5.html#example-pink-noise":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_5.html#problem-55":{},"Chap_5.html#problem-56":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{},"Chap_6.html#filtering-of-stochastic-signals":{},"Chap_6.html#problem-64":{},"Chap_6.html#the-autocorrelation-function":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function_1":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#one-step-further":{},"Chap_7.html#power-spectral-density":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#problem-710":{},"Chap_7.html#tethered-particle-motion":{},"Chap_8.html":{},"Chap_8.html#example-cocktail-party-noise":{},"Chap_8.html#example-filtering-noise":{},"Chap_8.html#problem-83":{},"Chap_9.html":{},"Chap_9.html#laboratory-exercise-93":{},"Chap_9.html#problem-92":{},"Chap_9.html#the-matched-filter-as-an-autocorrelation":{},"info.html":{},"info.html#technical-details":{}},"title":{}}],["twofold",{"_index":1708,"text":{"Chap_13.html":{},"Chap_13.html#epilogue":{}},"title":{}}],["ty(t",{"_index":1667,"text":{"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{}},"title":{}}],["ty(t){y^*}(t)dt",{"_index":1672,"text":{"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{}},"title":{}}],["type",{"_index":969,"text":{"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_11.html#langevin-redux":{},"Chap_3.html":{},"Chap_3.html#what-is-a-random-signal":{},"Chap_4.html":{},"Chap_4.html#example-dice-money":{},"Chap_6.html":{},"Chap_6.html#laboratory-exercise-67":{},"Chap_7.html":{},"Chap_7.html#descriptive-statistic-variance":{},"Chap_7.html#tethered-particle-motion":{},"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{},"info.html":{},"info.html#acknowledgments":{},"info.html#tips-short-cuts":{}},"title":{}}],["typic",{"_index":3233,"text":{"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{}},"title":{}}],["t{\\left",{"_index":1679,"text":{"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{}},"title":{}}],["t{e",{"_index":1180,"text":{"Chap_11.html":{},"Chap_11.html#problem-114":{}},"title":{}}],["t{y^*}(t",{"_index":1743,"text":{"Chap_13.html":{},"Chap_13.html#epilogue":{}},"title":{}}],["t{{\\left",{"_index":1677,"text":{"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{}},"title":{}}],["t}}\\,\\,\\,\\,\\,\\,\\,\\,t",{"_index":1181,"text":{"Chap_11.html":{},"Chap_11.html#problem-114":{}},"title":{}}],["t}}{{\\sqrt",{"_index":3506,"text":{"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{}},"title":{}}],["t}}}}{{n",{"_index":890,"text":{"Chap_11.html":{},"Chap_11.html#example-estimating-the-poisson-rate":{},"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{}},"title":{}}],["u",{"_index":1941,"text":{"Chap_3.html":{},"Chap_3.html#problem-310":{},"Chap_3.html#problem-33":{}},"title":{}}],["u(\\omega)=\\mathscr{f}\\left\\{u[n]\\right\\}=\\left(\\frac{1}{1",{"_index":2002,"text":{"Chap_3.html":{},"Chap_3.html#problem-39":{}},"title":{}}],["u(t",{"_index":1742,"text":{"Chap_13.html":{},"Chap_13.html#epilogue":{},"Chap_7.html":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#the-langevin-position-equation":{}},"title":{}}],["u(t)v'(t)dt",{"_index":1739,"text":{"Chap_13.html":{},"Chap_13.html#epilogue":{}},"title":{}}],["u(t)v(t",{"_index":1740,"text":{"Chap_13.html":{},"Chap_13.html#epilogue":{}},"title":{}}],["u.",{"_index":204,"text":{"Chap_1.html":{},"Chap_1.html#enhanced-experience":{}},"title":{}}],["u[n",{"_index":2001,"text":{"Chap_3.html":{},"Chap_3.html#problem-39":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#problem-55":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function_1":{},"Chap_7.html#expected-value":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#the-langevin-position-equation":{}},"title":{}}],["u[n]\\qquad",{"_index":1944,"text":{"Chap_3.html":{},"Chap_3.html#problem-33":{}},"title":{}}],["u[n]\\qquad\\lvert\\alpha\\rvert<1\\\\h[n]&=\\beta^n",{"_index":1935,"text":{"Chap_3.html":{},"Chap_3.html#problem-33":{}},"title":{}}],["u[n]\\qquad\\lvert\\beta\\rvert<1\\end{aligned}\\qquad",{"_index":1936,"text":{"Chap_3.html":{},"Chap_3.html#problem-33":{}},"title":{}}],["u[n]{",{"_index":2482,"text":{"Chap_5.html":{},"Chap_5.html#a-digression":{}},"title":{}}],["u_e(\\omega)=\\mathscr{f}\\left\\{u_e[n]\\right",{"_index":2005,"text":{"Chap_3.html":{},"Chap_3.html#problem-39":{}},"title":{}}],["u_o(\\omega",{"_index":2007,"text":{"Chap_3.html":{},"Chap_3.html#problem-39":{}},"title":{}}],["u_o(\\omega)=\\mathscr{f}\\left\\{u_o[n]\\right",{"_index":2006,"text":{"Chap_3.html":{},"Chap_3.html#problem-39":{}},"title":{}}],["uk",{"_index":3414,"text":{"Chap_7.html":{},"Chap_7.html#problem-711":{}},"title":{}}],["ultrasensit",{"_index":3417,"text":{"Chap_7.html":{},"Chap_7.html#problem-711":{}},"title":{}}],["unbias",{"_index":942,"text":{"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_11.html#estimating-the-mean":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_11.html#problem-115":{},"Chap_11.html#problem-117":{},"Chap_11.html#trouble-in-paradise":{},"Chap_12.html":{},"Chap_12.html#the-periodogram-unbiased":{}},"title":{"Chap_12.html#the-periodogram-unbiased":{}}}],["unbound",{"_index":1704,"text":{"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_7.html":{},"Chap_7.html#power-spectral-density_1":{}},"title":{}}],["uncertainti",{"_index":971,"text":{"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#problem-122":{},"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{}},"title":{"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{}}}],["unchang",{"_index":577,"text":{"Chap_10.html":{},"Chap_10.html#classic-example-classic-result":{}},"title":{}}],["uncommon",{"_index":1166,"text":{"Chap_11.html":{},"Chap_11.html#trouble-in-paradise":{}},"title":{}}],["uncorrel",{"_index":1223,"text":{"Chap_11.html":{},"Chap_11.html#problem-118":{},"Chap_7.html":{},"Chap_7.html#the-langevin-equation-a-case-study":{}},"title":{}}],["uncov",{"_index":1723,"text":{"Chap_13.html":{},"Chap_13.html#epilogue":{}},"title":{}}],["undefin",{"_index":1977,"text":{"Chap_3.html":{},"Chap_3.html#problem-36":{}},"title":{}}],["under",{"_index":184,"text":{"Chap_1.html":{},"Chap_1.html#at-the-movies":{},"Chap_11.html":{},"Chap_11.html#aspects-of-estimation":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_5.html":{},"Chap_5.html#problem-56":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small":{},"Chap_7.html#problem-72":{},"Chap_8.html":{},"Chap_8.html#problem-83":{},"Chap_9.html":{},"Chap_9.html#the-matched-filter":{},"Chap_9.html#the-matched-filter-as-an-autocorrelation":{},"info.html":{},"info.html#copyright":{}},"title":{}}],["underbrac",{"_index":1108,"text":{"Chap_11.html":{},"Chap_11.html#langevin-redux":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period_1":{}},"title":{}}],["underdamp",{"_index":3192,"text":{"Chap_7.html":{},"Chap_7.html#tethered-particle-motion":{}},"title":{}}],["underdamped\\,system",{"_index":3191,"text":{"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#tethered-particle-motion":{}},"title":{}}],["underestim",{"_index":941,"text":{"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_11.html#trouble-in-paradise":{},"Chap_12.html":{},"Chap_12.html#the-periodogram-unbiased":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_13.html":{},"Chap_13.html#appendix-i-mean-square-error-minimization":{}},"title":{}}],["underli",{"_index":1427,"text":{"Chap_12.html":{},"Chap_12.html#other-windows":{},"Chap_2.html":{},"Chap_2.html#prologue":{},"Chap_4.html":{},"Chap_4.html#problem-45":{},"Chap_4.html#the-mechanics-of-correlations":{}},"title":{}}],["undersampl",{"_index":2894,"text":{"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{}},"title":{}}],["understand",{"_index":560,"text":{"Chap_10.html":{},"Chap_10.html#classic-example-classic-result":{},"Chap_11.html":{},"Chap_11.html#langevin-redux":{},"Chap_12.html":{},"Chap_12.html#the-periodogram-unbiased":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_4.html":{},"Chap_4.html#correlation-the-workhorse":{},"Chap_4.html#properties-of-averaging":{},"Chap_5.html":{},"Chap_5.html#laboratory-exercise-51":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_6.html":{},"Chap_6.html#filtering-of-stochastic-signals":{},"Chap_7.html":{},"Chap_7.html#expected-value":{},"Chap_7.html#from-t-to-n":{},"Chap_8.html":{},"Chap_8.html#example-filtering-noise":{},"Chap_9.html":{},"Chap_9.html#laboratory-exercise-93":{},"info.html":{},"info.html#acknowledgments":{}},"title":{}}],["unencumb",{"_index":3175,"text":{"Chap_7.html":{},"Chap_7.html#tethered-particle-motion":{}},"title":{}}],["unexpect",{"_index":2089,"text":{"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{}},"title":{}}],["ungainli",{"_index":3261,"text":{"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period_1":{}},"title":{}}],["uniform",{"_index":1867,"text":{"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_3.html#problem-35":{}},"title":{}}],["unit",{"_index":893,"text":{"Chap_11.html":{},"Chap_11.html#example-estimating-the-poisson-rate":{},"Chap_3.html":{},"Chap_3.html#problem-39":{},"Chap_4.html":{},"Chap_4.html#example-is-that-coin-fair":{},"Chap_4.html#properties-of-averaging":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_6.html":{},"Chap_6.html#interpretation-of-the-convolution-result":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_7.html":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#problem-78":{},"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{}},"title":{}}],["units\u2014dimensions\u2014ar",{"_index":3381,"text":{"Chap_7.html":{},"Chap_7.html#problem-78":{}},"title":{}}],["univers",{"_index":1272,"text":{"Chap_11.html":{},"Chap_11.html#laboratory-exercise-113":{},"Chap_12.html":{},"Chap_12.html#laboratory-exercise-124":{},"Chap_3.html":{},"Chap_3.html#problem-310":{},"Chap_4.html":{},"Chap_4.html#laboratory-exercise-42":{},"Chap_7.html":{},"Chap_7.html#problem-711":{},"Chap_7.html#tethered-particle-motion":{}},"title":{}}],["unless",{"_index":2023,"text":{"Chap_3.html":{},"Chap_3.html#problem-310":{},"Chap_4.html":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_7.html":{},"Chap_7.html#impulse-invariant-sampling":{},"info.html":{},"info.html#copyright":{}},"title":{}}],["unpleas",{"_index":2090,"text":{"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{}},"title":{}}],["unpredict",{"_index":655,"text":{"Chap_10.html":{},"Chap_10.html#example-sound-of-distorted-music":{},"Chap_4.html":{},"Chap_4.html#the-mechanics-of-correlations":{}},"title":{}}],["unpublish",{"_index":261,"text":{"Chap_1.html":{},"Chap_1.html#enhanced-experience":{}},"title":{}}],["unreason",{"_index":2812,"text":{"Chap_7.html":{},"Chap_7.html#the-langevin-equation-a-case-study":{}},"title":{}}],["until",{"_index":2422,"text":{"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_9.html":{},"Chap_9.html#the-matched-filter":{}},"title":{}}],["up",{"_index":674,"text":{"Chap_10.html":{},"Chap_11.html":{},"Chap_11.html#trouble-in-paradise":{},"Chap_12.html":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_4.html":{},"Chap_4.html#problem-47":{},"Chap_9.html":{},"info.html":{},"info.html#tips-short-cuts":{}},"title":{"Chap_10.html#example-cleaning-up-our-act":{},"Chap_9.html#setting-up-the-problem":{}}}],["upon",{"_index":256,"text":{"Chap_1.html":{},"Chap_1.html#enhanced-experience":{},"Chap_10.html":{},"Chap_10.html#example-sound-of-distorted-music":{},"Chap_10.html#expressing-the-mean-square-error":{},"Chap_11.html":{},"Chap_11.html#estimating-the-mean":{},"Chap_11.html#laboratory-exercise-111":{},"Chap_11.html#langevin-redux":{},"Chap_11.html#problem-116":{},"Chap_11.html#problem-117":{},"Chap_12.html":{},"Chap_12.html#the-periodogram-unbiased":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_4.html":{},"Chap_4.html#characterization-of-random-signals":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#example-average-experience":{},"Chap_4.html#example-dice-money":{},"Chap_4.html#example-fair-chance":{},"Chap_4.html#laboratory-exercise-41":{},"Chap_4.html#problem-49":{},"Chap_4.html#properties-of-averaging":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_5.html":{},"Chap_5.html#correlations-and-memory":{},"Chap_5.html#correlations-simple-and-complex":{},"Chap_5.html#problem-52":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_6.html":{},"Chap_6.html#laboratory-exercise-63":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#from-t-to-n":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#one-step-further":{},"Chap_7.html#tethered-particle-motion":{},"Chap_7.html#the-langevin-velocity-equation":{},"Chap_9.html":{},"Chap_9.html#problem-91":{},"info.html":{},"info.html#musical-data":{}},"title":{}}],["upper",{"_index":2047,"text":{"Chap_3.html":{},"Chap_3.html#problem-310":{},"Chap_4.html":{},"Chap_4.html#laboratory-exercise-42":{},"Chap_5.html":{},"Chap_5.html#laboratory-exercise-51":{},"Chap_7.html":{},"Chap_7.html#problem-711":{},"info.html":{},"info.html#tips-short-cuts":{}},"title":{}}],["us",{"_index":2,"text":{"Chap_1.html":{},"Chap_1.html#at-the-movies":{},"Chap_1.html#enhanced-experience":{},"Chap_1.html#how-to-use-this-ibook":{},"Chap_10.html":{},"Chap_10.html#classic-example-classic-result":{},"Chap_10.html#correlation-returns":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#example-sound-of-distorted-music":{},"Chap_10.html#laboratory-exercise-105":{},"Chap_10.html#problem-102":{},"Chap_10.html#problem-104":{},"Chap_10.html#the-restoration-case-noise":{},"Chap_10.html#the-wiener-filter":{},"Chap_10.html#the-wiener-hopf-equation":{},"Chap_10.html#what-is-that-least-mean-square-error":{},"Chap_10.html#why-we-avoid-the-inverse-filter":{},"Chap_11.html":{},"Chap_11.html#aspects-of-estimation":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_11.html#estimating-the-autocorrelation-function":{},"Chap_11.html#example-estimating-the-poisson-rate":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_11.html#laboratory-exercise-113":{},"Chap_11.html#maximum-likelihood-estimation":{},"Chap_11.html#problem-1110":{},"Chap_11.html#problem-116":{},"Chap_11.html#problem-117":{},"Chap_11.html#problem-119":{},"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#laboratory-exercise-122":{},"Chap_12.html#laboratory-exercise-123":{},"Chap_12.html#other-windows":{},"Chap_12.html#problem-122":{},"Chap_12.html#spectral-estimation":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_12.html#windowed-observations":{},"Chap_13.html":{},"Chap_13.html#appendix-i-mean-square-error-minimization":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_13.html#epilogue":{},"Chap_2.html":{},"Chap_2.html#prologue":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_3.html#problem-310":{},"Chap_3.html#what-is-a-random-signal":{},"Chap_4.html":{},"Chap_4.html#characterization-of-random-signals":{},"Chap_4.html#correlation-the-workhorse":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#describing-the-time-average":{},"Chap_4.html#example-average-experience":{},"Chap_4.html#example-dice-money":{},"Chap_4.html#example-is-that-coin-fair":{},"Chap_4.html#laboratory-exercise-42":{},"Chap_4.html#problem-48":{},"Chap_4.html#problem-49":{},"Chap_4.html#properties-of-averaging":{},"Chap_4.html#the-ergodic-process":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#correlations-and-memory":{},"Chap_5.html#example-pink-noise":{},"Chap_5.html#laboratory-exercise-51":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_5.html#problem-53":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{},"Chap_6.html#laboratory-exercise-65":{},"Chap_6.html#laboratory-exercise-66":{},"Chap_6.html#laboratory-exercise-67":{},"Chap_6.html#problem-66":{},"Chap_6.html#the-autocorrelation-function":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_6.html#the-mean":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function":{},"Chap_7.html#autocorrelation-function_1":{},"Chap_7.html#autocorrelation-function_2":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#descriptive-statistic-variance":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#expected-value":{},"Chap_7.html#expected-value_1":{},"Chap_7.html#from-t-to-n":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#impulse-invariant-sampling":{},"Chap_7.html#one-step-further":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#power-spectral-density_2":{},"Chap_7.html#tethered-particle-motion":{},"Chap_7.html#the-langevin-equation-a-case-study":{},"Chap_7.html#the-langevin-position-equation":{},"Chap_7.html#why-this-case-study":{},"Chap_8.html":{},"Chap_8.html#example-cocktail-party-noise":{},"Chap_8.html#problem-81":{},"Chap_8.html#snr-for-deterministic-signals-in-the-presence-of-noise":{},"Chap_8.html#snr-for-random-signals-in-the-presence-of-noise":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{},"Chap_9.html":{},"Chap_9.html#laboratory-exercise-93":{},"Chap_9.html#performance-in-the-presence-of-noise":{},"Chap_9.html#problem-91":{},"Chap_9.html#setting-up-the-problem":{},"Chap_9.html#using-cauchy-schwartz":{},"info.html":{},"info.html#acknowledgments":{},"info.html#technical-details":{},"info.html#tips-short-cuts":{},"info.html#usage":{},"info.html#weather-data":{}},"title":{"Chap_1.html":{},"Chap_1.html#how-to-use-this-ibook":{},"Chap_10.html#using-the-least-mean-square-error-criterion":{},"Chap_9.html#using-cauchy-schwartz":{}}}],["usag",{"_index":3745,"text":{"info.html":{}},"title":{"info.html#usage":{}}}],["user",{"_index":73,"text":{"Chap_1.html":{},"Chap_1.html#how-to-use-this-ibook":{}},"title":{}}],["user\u2019",{"_index":51,"text":{"Chap_1.html":{},"Chap_1.html#how-to-use-this-ibook":{}},"title":{}}],["usual",{"_index":422,"text":{"Chap_10.html":{},"Chap_10.html#correlation-returns":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#problem-102":{},"Chap_11.html":{},"Chap_11.html#laboratory-exercise-113":{},"Chap_5.html":{},"Chap_5.html#laboratory-exercise-51":{},"Chap_7.html":{},"Chap_7.html#the-langevin-equation-a-case-study":{}},"title":{}}],["v",{"_index":2044,"text":{"Chap_3.html":{},"Chap_3.html#problem-310":{},"Chap_4.html":{},"Chap_4.html#laboratory-exercise-42":{},"Chap_5.html":{},"Chap_5.html#laboratory-exercise-51":{},"Chap_7.html":{},"Chap_7.html#problem-711":{},"Chap_7.html#problem-78":{},"Chap_7.html#the-langevin-equation-a-case-study":{}},"title":{}}],["v'(t",{"_index":1744,"text":{"Chap_13.html":{},"Chap_13.html#epilogue":{}},"title":{}}],["v(t",{"_index":2807,"text":{"Chap_7.html":{},"Chap_7.html#from-t-to-n":{},"Chap_7.html#the-langevin-equation-a-case-study":{},"Chap_7.html#the-langevin-velocity-equation":{}},"title":{}}],["v(t)u'(t)dt",{"_index":1741,"text":{"Chap_13.html":{},"Chap_13.html#epilogue":{}},"title":{}}],["v[n",{"_index":2814,"text":{"Chap_7.html":{},"Chap_7.html#from-t-to-n":{},"Chap_7.html#impulse-invariant-sampling":{},"Chap_7.html#the-langevin-velocity-equation":{}},"title":{}}],["v^2",{"_index":2989,"text":{"Chap_7.html":{},"Chap_7.html#descriptive-statistic-variance":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{}},"title":{}}],["v_x^2",{"_index":3019,"text":{"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{}},"title":{}}],["valid",{"_index":2596,"text":{"Chap_5.html":{},"Chap_5.html#problem-53":{},"Chap_7.html":{},"Chap_7.html#problem-78":{}},"title":{}}],["valu",{"_index":259,"text":{"Chap_1.html":{},"Chap_1.html#enhanced-experience":{},"Chap_10.html":{},"Chap_10.html#example-cleaning-up-our-act":{},"Chap_10.html#using-the-least-mean-square-error-criterion":{},"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_11.html#estimating-the-mean":{},"Chap_11.html#example-estimating-the-poisson-rate":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_11.html#langevin-redux":{},"Chap_11.html#maximum-likelihood-estimation":{},"Chap_11.html#problem-111":{},"Chap_11.html#problem-115":{},"Chap_11.html#problem-116":{},"Chap_11.html#problem-117":{},"Chap_11.html#problem-118":{},"Chap_11.html#problem-119":{},"Chap_11.html#trouble-in-paradise":{},"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#problem-122":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_13.html":{},"Chap_13.html#appendix-i-mean-square-error-minimization":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_2.html":{},"Chap_2.html#prologue":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_3.html#introduction":{},"Chap_3.html#problem-310":{},"Chap_3.html#problem-34":{},"Chap_3.html#problem-36":{},"Chap_3.html#problem-37":{},"Chap_3.html#what-is-a-random-signal":{},"Chap_4.html":{},"Chap_4.html#autocorrelation":{},"Chap_4.html#cross-covariance":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#example-dice-money":{},"Chap_4.html#example-fair-chance":{},"Chap_4.html#example-is-that-coin-fair":{},"Chap_4.html#laboratory-exercise-42":{},"Chap_4.html#other-averages":{},"Chap_4.html#problem-41":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#correlations-and-memory":{},"Chap_5.html#example-pink-noise":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_5.html#problem-52":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_6.html":{},"Chap_6.html#filtering-of-stochastic-signals":{},"Chap_6.html#interpretation-of-the-convolution-result":{},"Chap_6.html#problem-66":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_6.html#the-mean":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function_1":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#descriptive-statistic-variance":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#expected-value":{},"Chap_7.html#how-big-is-big-how-small-is-small":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#power-spectral-density":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#power-spectral-density_2":{},"Chap_7.html#problem-710":{},"Chap_7.html#problem-79":{},"Chap_7.html#tethered-particle-motion":{},"Chap_7.html#the-langevin-velocity-equation":{},"Chap_8.html":{},"Chap_8.html#example-cocktail-party-noise":{},"Chap_8.html#problem-83":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{},"Chap_9.html":{},"Chap_9.html#laboratory-exercise-93":{},"Chap_9.html#performance-in-the-presence-of-noise":{}},"title":{"Chap_7.html#expected-value":{},"Chap_7.html#expected-value_1":{}}}],["valuabl",{"_index":3693,"text":{"info.html":{},"info.html#acknowledgments":{}},"title":{}}],["van",{"_index":823,"text":{"Chap_11.html":{},"Chap_11.html#aspects-of-estimation":{},"Chap_11.html#laboratory-exercise-113":{},"info.html":{},"info.html#acknowledgments":{}},"title":{}}],["vanish",{"_index":1680,"text":{"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{}},"title":{}}],["var",{"_index":998,"text":{"Chap_11.html":{},"Chap_11.html#estimating-the-mean":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_11.html#trouble-in-paradise":{}},"title":{}}],["var(\\theta",{"_index":1193,"text":{"Chap_11.html":{},"Chap_11.html#problem-116":{}},"title":{}}],["var(x",{"_index":2183,"text":{"Chap_4.html":{},"Chap_4.html#properties-of-averaging":{}},"title":{}}],["var\\left",{"_index":1001,"text":{"Chap_11.html":{},"Chap_11.html#estimating-the-mean":{},"Chap_11.html#problem-116":{},"Chap_12.html":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_4.html":{},"Chap_4.html#properties-of-averaging":{}},"title":{}}],["varepsilon",{"_index":3538,"text":{"Chap_8.html":{},"Chap_8.html#problem-83":{}},"title":{}}],["vari",{"_index":357,"text":{"Chap_10.html":{},"Chap_10.html#using-the-least-mean-square-error-criterion":{},"Chap_7.html":{},"Chap_7.html#one-step-further":{},"Chap_9.html":{},"Chap_9.html#performance-in-the-presence-of-noise":{}},"title":{}}],["variabl",{"_index":440,"text":{"Chap_10.html":{},"Chap_10.html#problem-104":{},"Chap_10.html#the-wiener-hopf-equation":{},"Chap_10.html#what-is-that-least-mean-square-error":{},"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_11.html#estimating-the-autocorrelation-function":{},"Chap_11.html#problem-116":{},"Chap_11.html#problem-117":{},"Chap_11.html#problem-119":{},"Chap_12.html":{},"Chap_12.html#the-periodogram-unbiased":{},"Chap_13.html":{},"Chap_13.html#appendix-i-mean-square-error-minimization":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_2.html":{},"Chap_2.html#prologue":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_3.html#problem-310":{},"Chap_3.html#problem-34":{},"Chap_3.html#problem-35":{},"Chap_3.html#problem-38":{},"Chap_3.html#what-is-a-random-signal":{},"Chap_4.html":{},"Chap_4.html#autocorrelation":{},"Chap_4.html#cross-covariance":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#example-dice-money":{},"Chap_4.html#example-fair-chance":{},"Chap_4.html#laboratory-exercise-42":{},"Chap_4.html#other-averages":{},"Chap_4.html#problem-41":{},"Chap_4.html#problem-44":{},"Chap_4.html#problem-49":{},"Chap_4.html#properties-of-averaging":{},"Chap_5.html":{},"Chap_5.html#correlations-simple-and-complex":{},"Chap_5.html#laboratory-exercise-51":{},"Chap_6.html":{},"Chap_6.html#interpretation-of-the-convolution-result":{},"Chap_6.html#the-autocorrelation-function":{},"Chap_6.html#the-mean":{},"Chap_7.html":{},"Chap_7.html#expected-value":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#problem-78":{}},"title":{}}],["varianc",{"_index":947,"text":{"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_11.html#estimating-the-mean":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_11.html#langevin-redux":{},"Chap_11.html#problem-116":{},"Chap_11.html#problem-117":{},"Chap_11.html#problem-119":{},"Chap_11.html#trouble-in-paradise":{},"Chap_12.html":{},"Chap_12.html#spectral-estimation":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_4.html":{},"Chap_4.html#problem-44":{},"Chap_4.html#problem-45":{},"Chap_4.html#properties-of-averaging":{},"Chap_5.html":{},"Chap_5.html#problem-53":{},"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#problem-73":{},"Chap_7.html#problem-77":{},"Chap_7.html#problem-78":{},"Chap_7.html#why-this-case-study":{}},"title":{"Chap_7.html#descriptive-statistic-variance":{}}}],["variance\\left",{"_index":2180,"text":{"Chap_4.html":{},"Chap_4.html#properties-of-averaging":{}},"title":{}}],["variance\u2014th",{"_index":3085,"text":{"Chap_7.html":{},"Chap_7.html#power-spectral-density_1":{}},"title":{}}],["variance\u2014whos",{"_index":1185,"text":{"Chap_11.html":{},"Chap_11.html#problem-115":{}},"title":{}}],["variant",{"_index":3130,"text":{"Chap_7.html":{},"Chap_7.html#tethered-particle-motion":{},"Chap_7.html#why-this-case-study":{}},"title":{}}],["variat",{"_index":2339,"text":{"Chap_4.html":{},"Chap_4.html#problem-44":{},"Chap_5.html":{},"Chap_5.html#correlations-and-memory":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{},"Chap_8.html":{},"Chap_8.html#problem-83":{},"Chap_9.html":{},"Chap_9.html#setting-up-the-problem":{}},"title":{}}],["varieti",{"_index":818,"text":{"Chap_11.html":{},"Chap_11.html#aspects-of-estimation":{},"Chap_11.html#maximum-likelihood-estimation":{},"Chap_4.html":{},"Chap_4.html#characterization-of-random-signals":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{}},"title":{}}],["variou",{"_index":151,"text":{"Chap_1.html":{},"Chap_1.html#at-the-movies":{},"Chap_1.html#sound-of-music":{},"Chap_11.html":{},"Chap_11.html#langevin-redux":{},"Chap_12.html":{},"Chap_12.html#other-windows":{},"Chap_12.html#problem-122":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_12.html#windowed-observations":{},"Chap_3.html":{},"Chap_3.html#what-is-a-random-signal":{},"Chap_4.html":{},"Chap_4.html#example-is-that-coin-fair":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_6.html":{},"Chap_6.html#laboratory-exercise-67":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_9.html":{},"Chap_9.html#problem-91":{},"info.html":{},"info.html#contact":{}},"title":{}}],["varphi",{"_index":416,"text":{"Chap_10.html":{},"Chap_10.html#classic-example-classic-result":{},"Chap_10.html#correlation-returns":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#problem-103":{},"Chap_10.html#the-wiener-hopf-equation":{},"Chap_10.html#what-is-that-least-mean-square-error":{},"Chap_11.html":{},"Chap_11.html#aspects-of-estimation":{},"Chap_11.html#estimating-the-autocorrelation-function":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_11.html#langevin-redux":{},"Chap_11.html#problem-1110":{},"Chap_11.html#problem-118":{},"Chap_11.html#problem-119":{},"Chap_11.html#trouble-in-paradise":{},"Chap_12.html":{},"Chap_12.html#spectral-estimation":{},"Chap_12.html#the-periodogram-unbiased":{},"Chap_4.html":{},"Chap_4.html#auto-covariance":{},"Chap_4.html#autocorrelation":{},"Chap_4.html#cross-correlation":{},"Chap_4.html#cross-covariance":{},"Chap_4.html#describing-the-time-average":{},"Chap_4.html#example-is-that-coin-fair":{},"Chap_4.html#the-ergodic-process":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#correlations-and-memory":{},"Chap_5.html#correlations-simple-and-complex":{},"Chap_5.html#example-delayed-effect":{},"Chap_5.html#example-pink-noise":{},"Chap_5.html#example-white-noise":{},"Chap_5.html#fourier-description-of-correlation-functions":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_5.html#problem-53":{},"Chap_5.html#problem-54":{},"Chap_5.html#problem-55":{},"Chap_5.html#problem-56":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{},"Chap_6.html#filtering-of-stochastic-signals":{},"Chap_6.html#interpretation-of-the-convolution-result":{},"Chap_6.html#laboratory-exercise-63":{},"Chap_6.html#problem-61":{},"Chap_6.html#problem-62":{},"Chap_6.html#problem-64":{},"Chap_6.html#the-autocorrelation-function":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function":{},"Chap_7.html#autocorrelation-function_1":{},"Chap_7.html#autocorrelation-function_2":{},"Chap_7.html#descriptive-statistic-variance":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#power-spectral-density":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#power-spectral-density_2":{},"Chap_7.html#problem-73":{},"Chap_7.html#problem-74":{},"Chap_7.html#the-langevin-equation-a-case-study":{},"Chap_7.html#the-langevin-velocity-equation":{},"Chap_7.html#why-this-case-study":{},"Chap_8.html":{},"Chap_8.html#example-cocktail-party-noise":{},"Chap_8.html#example-filtering-noise":{},"Chap_8.html#problem-81":{},"Chap_8.html#problem-83":{},"Chap_8.html#snr-for-random-signals-in-the-presence-of-noise":{},"Chap_9.html":{},"Chap_9.html#the-matched-filter-as-an-autocorrelation":{}},"title":{}}],["varphi_{vv",{"_index":2986,"text":{"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{}},"title":{}}],["varphi_{xx",{"_index":3116,"text":{"Chap_7.html":{},"Chap_7.html#power-spectral-density_1":{}},"title":{}}],["vec",{"_index":2084,"text":{"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{}},"title":{}}],["vector",{"_index":1611,"text":{"Chap_13.html":{},"Chap_13.html#appendix-i-mean-square-error-minimization":{},"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_9.html":{},"Chap_9.html#laboratory-exercise-93":{}},"title":{}}],["veloc",{"_index":1065,"text":{"Chap_11.html":{},"Chap_11.html#langevin-redux":{},"Chap_11.html#problem-119":{},"Chap_2.html":{},"Chap_2.html#prologue":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#how-big-is-big-how-small-is-small":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#impulse-invariant-sampling":{},"Chap_7.html#power-spectral-density":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#problem-74":{},"Chap_7.html#problem-75":{},"Chap_7.html#problem-79":{},"Chap_7.html#the-langevin-equation-a-case-study":{},"Chap_7.html#the-langevin-velocity-equation":{},"Chap_8.html":{},"Chap_8.html#problem-83":{}},"title":{"Chap_7.html#the-langevin-velocity-equation":{}}}],["venu",{"_index":3661,"text":{"info.html":{}},"title":{"info.html#venue":{}}}],["verbeek",{"_index":1435,"text":{"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#laboratory-exercise-124":{},"Chap_12.html#other-windows":{},"Chap_12.html#problem-122":{},"info.html":{},"info.html#acknowledgments":{}},"title":{}}],["veri",{"_index":931,"text":{"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_11.html#trouble-in-paradise":{},"Chap_3.html":{},"Chap_3.html#what-is-a-random-signal":{},"Chap_4.html":{},"Chap_4.html#characterization-of-random-signals":{},"Chap_4.html#correlation-the-workhorse":{},"Chap_7.html":{},"Chap_7.html#impulse-invariant-sampling":{},"Chap_7.html#problem-79":{},"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{}},"title":{}}],["vermolen",{"_index":3415,"text":{"Chap_7.html":{},"Chap_7.html#problem-711":{}},"title":{}}],["versa",{"_index":1892,"text":{"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{}},"title":{}}],["version",{"_index":77,"text":{"Chap_1.html":{},"Chap_1.html#how-to-use-this-ibook":{},"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#example-sound-of-distorted-music":{},"Chap_11.html":{},"Chap_11.html#estimating-the-autocorrelation-function":{},"Chap_11.html#problem-117":{},"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_4.html":{},"Chap_4.html#example-average-experience":{},"Chap_5.html":{},"Chap_5.html#example-delayed-effect":{},"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{},"Chap_6.html#interpretation-of-the-convolution-result":{},"Chap_7.html":{},"Chap_7.html#impulse-invariant-sampling":{},"Chap_8.html":{},"Chap_8.html#problem-83":{},"Chap_9.html":{},"Chap_9.html#example-matching-your-filter":{},"Chap_9.html#performance-in-the-presence-of-noise":{},"info.html":{},"info.html#acknowledgments":{},"info.html#technical-details":{},"info.html#tips-short-cuts":{},"info.html#version":{}},"title":{"info.html#version":{}}}],["versu",{"_index":2529,"text":{"Chap_5.html":{},"Chap_5.html#example-white-noise":{},"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{}},"title":{}}],["vert",{"_index":1871,"text":{"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{}},"title":{}}],["vibrat",{"_index":3493,"text":{"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{}},"title":{}}],["vice",{"_index":1891,"text":{"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{}},"title":{}}],["vicin",{"_index":1552,"text":{"Chap_12.html":{},"Chap_12.html#problem-122":{}},"title":{}}],["video",{"_index":3455,"text":{"Chap_8.html":{},"Chap_8.html#example-not-too-noisy":{}},"title":{}}],["view",{"_index":125,"text":{"Chap_1.html":{},"Chap_1.html#outside-this-device":{},"Chap_7.html":{},"Chap_7.html#tethered-particle-motion":{}},"title":{}}],["violin",{"_index":645,"text":{"Chap_10.html":{},"Chap_10.html#example-sound-of-distorted-music":{},"info.html":{},"info.html#musical-data":{}},"title":{}}],["violinist",{"_index":656,"text":{"Chap_10.html":{},"Chap_10.html#example-sound-of-distorted-music":{}},"title":{}}],["virtual",{"_index":2579,"text":{"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{}},"title":{}}],["viscos",{"_index":2880,"text":{"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#how-big-is-big-how-small-is-small":{}},"title":{}}],["viscou",{"_index":2799,"text":{"Chap_7.html":{},"Chap_7.html#the-langevin-equation-a-case-study":{}},"title":{}}],["visit",{"_index":2388,"text":{"Chap_4.html":{},"Chap_4.html#laboratory-exercise-42":{}},"title":{}}],["visual",{"_index":3526,"text":{"Chap_8.html":{},"Chap_8.html#problem-82":{},"Chap_8.html#problem-83":{}},"title":{}}],["vliet",{"_index":3677,"text":{"info.html":{},"info.html#acknowledgments":{}},"title":{}}],["voic",{"_index":1789,"text":{"Chap_2.html":{},"Chap_2.html#prologue":{}},"title":{}}],["vol",{"_index":1261,"text":{"Chap_11.html":{},"Chap_11.html#laboratory-exercise-113":{},"Chap_4.html":{},"Chap_4.html#laboratory-exercise-42":{}},"title":{}}],["volt",{"_index":1755,"text":{"Chap_2.html":{},"Chap_2.html#prologue":{},"Chap_7.html":{},"Chap_7.html#problem-78":{},"Chap_8.html":{},"Chap_8.html#example-not-too-noisy":{}},"title":{}}],["volum",{"_index":3160,"text":{"Chap_7.html":{},"Chap_7.html#tethered-particle-motion":{},"info.html":{},"info.html#musical-data":{}},"title":{}}],["w",{"_index":784,"text":{"Chap_10.html":{},"Chap_10.html#laboratory-exercise-105":{},"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#laboratory-exercise-124":{},"Chap_13.html":{},"Chap_13.html#epilogue":{},"Chap_4.html":{},"Chap_4.html#laboratory-exercise-42":{},"Chap_5.html":{},"Chap_5.html#laboratory-exercise-51":{}},"title":{}}],["w(\\omega",{"_index":1343,"text":{"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#windowed-observations":{},"Chap_9.html":{},"Chap_9.html#laboratory-exercise-93":{},"Chap_9.html#using-cauchy-schwartz":{}},"title":{}}],["w[n",{"_index":1317,"text":{"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#windowed-observations":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function_1":{}},"title":{}}],["w[n\\rbrack",{"_index":1521,"text":{"Chap_12.html":{},"Chap_12.html#problem-121":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function_1":{},"Chap_7.html#power-spectral-density_1":{}},"title":{}}],["w\\left",{"_index":1480,"text":{"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#problem-121":{}},"title":{}}],["w^2}[n",{"_index":1473,"text":{"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{}},"title":{}}],["w_g}(\\omega",{"_index":1558,"text":{"Chap_12.html":{},"Chap_12.html#problem-122":{}},"title":{}}],["w_g}(q",{"_index":1547,"text":{"Chap_12.html":{},"Chap_12.html#problem-122":{}},"title":{}}],["w_i}(\\omega",{"_index":1335,"text":{"Chap_12.html":{},"Chap_12.html#windowed-observations":{}},"title":{}}],["w_i}[k",{"_index":1325,"text":{"Chap_12.html":{},"Chap_12.html#windowed-observations":{}},"title":{}}],["w_i}[k]{\\varphi",{"_index":1319,"text":{"Chap_12.html":{},"Chap_12.html#windowed-observations":{}},"title":{}}],["w_i}[n",{"_index":1519,"text":{"Chap_12.html":{},"Chap_12.html#problem-121":{}},"title":{}}],["w_i}[n\\rbrack",{"_index":1358,"text":{"Chap_12.html":{},"Chap_12.html#windowed-observations":{}},"title":{}}],["w_i}\\left",{"_index":1357,"text":{"Chap_12.html":{},"Chap_12.html#problem-121":{},"Chap_12.html#windowed-observations":{}},"title":{}}],["w_p}(\\omega",{"_index":1337,"text":{"Chap_12.html":{},"Chap_12.html#windowed-observations":{}},"title":{}}],["w_p}[k",{"_index":1332,"text":{"Chap_12.html":{},"Chap_12.html#windowed-observations":{}},"title":{}}],["w_p}[k]{\\varphi",{"_index":1321,"text":{"Chap_12.html":{},"Chap_12.html#windowed-observations":{}},"title":{}}],["w_p}[n",{"_index":1518,"text":{"Chap_12.html":{},"Chap_12.html#problem-121":{}},"title":{}}],["w_p}[n\\rbrack",{"_index":1360,"text":{"Chap_12.html":{},"Chap_12.html#windowed-observations":{}},"title":{}}],["w_p}\\left",{"_index":1359,"text":{"Chap_12.html":{},"Chap_12.html#problem-121":{},"Chap_12.html#windowed-observations":{}},"title":{}}],["w_v}(\\omega",{"_index":1559,"text":{"Chap_12.html":{},"Chap_12.html#problem-122":{}},"title":{}}],["w_v}(q",{"_index":1554,"text":{"Chap_12.html":{},"Chap_12.html#problem-122":{}},"title":{}}],["wadsworth",{"_index":1736,"text":{"Chap_13.html":{},"Chap_13.html#epilogue":{}},"title":{}}],["waldo",{"_index":3627,"text":{"Chap_9.html":{},"Chap_9.html#laboratory-exercise-92":{}},"title":{}}],["walk",{"_index":3053,"text":{"Chap_7.html":{},"Chap_7.html#expected-value":{},"Chap_7.html#power-spectral-density_1":{}},"title":{}}],["walli",{"_index":3628,"text":{"Chap_9.html":{},"Chap_9.html#laboratory-exercise-92":{}},"title":{}}],["want",{"_index":139,"text":{"Chap_1.html":{},"Chap_1.html#getting-around":{},"Chap_10.html":{},"Chap_10.html#the-restoration-case-noise":{},"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_11.html#problem-119":{},"Chap_12.html":{},"Chap_12.html#laboratory-exercise-122":{},"Chap_3.html":{},"Chap_3.html#problem-310":{},"Chap_4.html":{},"Chap_4.html#problem-48":{},"Chap_9.html":{},"Chap_9.html#problem-92":{},"info.html":{},"info.html#tips-short-cuts":{}},"title":{}}],["warner",{"_index":177,"text":{"Chap_1.html":{},"Chap_1.html#at-the-movies":{}},"title":{}}],["warrant",{"_index":2859,"text":{"Chap_7.html":{},"Chap_7.html#impulse-invariant-sampling":{},"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{}},"title":{}}],["water",{"_index":2867,"text":{"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#how-big-is-big-how-small-is-small":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#tethered-particle-motion":{}},"title":{}}],["watt",{"_index":1265,"text":{"Chap_11.html":{},"Chap_11.html#laboratory-exercise-113":{},"Chap_12.html":{},"Chap_12.html#laboratory-exercise-124":{},"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{}},"title":{}}],["watt/hz",{"_index":3600,"text":{"Chap_9.html":{},"Chap_9.html#problem-91":{}},"title":{}}],["watts/hz",{"_index":2692,"text":{"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{}},"title":{}}],["waveform",{"_index":1855,"text":{"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{}},"title":{}}],["wavelength",{"_index":2611,"text":{"Chap_5.html":{},"Chap_5.html#laboratory-exercise-51":{}},"title":{}}],["way",{"_index":158,"text":{"Chap_1.html":{},"Chap_1.html#sound-of-music":{},"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#example-sound-of-distorted-music":{},"Chap_10.html#the-wiener-hopf-equation":{},"Chap_11.html":{},"Chap_11.html#aspects-of-estimation":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_2.html":{},"Chap_2.html#prologue":{},"Chap_3.html":{},"Chap_3.html#problem-310":{},"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#example-fair-chance":{},"Chap_4.html#laboratory-exercise-41":{},"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function_1":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#one-step-further":{}},"title":{}}],["weakest",{"_index":624,"text":{"Chap_10.html":{},"Chap_10.html#why-we-avoid-the-inverse-filter":{}},"title":{}}],["weather",{"_index":1277,"text":{"Chap_12.html":{},"Chap_12.html#spectral-estimation":{},"Chap_2.html":{},"Chap_2.html#prologue":{},"Chap_4.html":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_5.html":{},"Chap_5.html#correlations-and-memory":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"info.html":{},"info.html#weather-data":{}},"title":{"info.html#weather-data":{}}}],["weber",{"_index":3522,"text":{"Chap_8.html":{},"Chap_8.html#problem-82":{},"Chap_8.html#problem-83":{}},"title":{}}],["week",{"_index":2222,"text":{"Chap_4.html":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_5.html":{},"Chap_5.html#correlations-and-memory":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{}},"title":{}}],["weight",{"_index":1436,"text":{"Chap_12.html":{},"Chap_12.html#other-windows":{},"Chap_13.html":{},"Chap_13.html#appendix-i-mean-square-error-minimization":{},"Chap_4.html":{},"Chap_4.html#properties-of-averaging":{},"Chap_6.html":{},"Chap_6.html#interpretation-of-the-convolution-result":{},"Chap_6.html#the-mean":{},"Chap_9.html":{},"Chap_9.html#laboratory-exercise-93":{}},"title":{}}],["welcom",{"_index":2969,"text":{"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{}},"title":{}}],["well",{"_index":651,"text":{"Chap_10.html":{},"Chap_10.html#example-sound-of-distorted-music":{},"Chap_10.html#laboratory-exercise-104":{},"Chap_10.html#laboratory-exercise-105":{},"Chap_11.html":{},"Chap_11.html#example-estimating-the-poisson-rate":{},"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#other-windows":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_12.html#windowed-observations":{},"Chap_2.html":{},"Chap_2.html#problem-21":{},"Chap_2.html#prologue":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_4.html":{},"Chap_4.html#laboratory-exercise-41":{},"Chap_4.html#properties-of-averaging":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#correlations-and-memory":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_6.html":{},"Chap_6.html#filtering-of-stochastic-signals":{},"Chap_6.html#the-autocorrelation-function":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function_2":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#tethered-particle-motion":{},"Chap_8.html":{},"Chap_8.html#example-filtering-noise":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{},"Chap_9.html":{},"Chap_9.html#performance-in-the-presence-of-noise":{},"Chap_9.html#setting-up-the-problem":{}},"title":{}}],["wellhead",{"_index":2715,"text":{"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{}},"title":{}}],["wesley",{"_index":2379,"text":{"Chap_4.html":{},"Chap_4.html#laboratory-exercise-42":{},"Chap_7.html":{},"Chap_7.html#problem-711":{},"Chap_8.html":{},"Chap_8.html#problem-83":{}},"title":{}}],["where}\\otimes\\text",{"_index":1920,"text":{"Chap_3.html":{},"Chap_3.html#problem-31":{}},"title":{}}],["whether",{"_index":241,"text":{"Chap_1.html":{},"Chap_1.html#enhanced-experience":{},"Chap_11.html":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_12.html":{},"Chap_12.html#the-periodogram-unbiased":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_5.html":{},"Chap_5.html#a-digression":{}},"title":{}}],["whistl",{"_index":171,"text":{"Chap_1.html":{},"Chap_1.html#at-the-movies":{}},"title":{}}],["white",{"_index":675,"text":{"Chap_10.html":{},"Chap_10.html#example-cleaning-up-our-act":{},"Chap_12.html":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_4.html":{},"Chap_4.html#example-is-that-coin-fair":{},"Chap_4.html#problem-48":{},"Chap_5.html":{},"Chap_5.html#example-pink-noise":{},"Chap_5.html#example-white-noise":{},"Chap_5.html#laboratory-exercise-51":{},"Chap_6.html":{},"Chap_6.html#laboratory-exercise-61":{},"Chap_6.html#problem-64":{},"Chap_7.html":{},"Chap_7.html#impulse-invariant-sampling":{},"Chap_7.html#power-spectral-density":{},"Chap_7.html#the-langevin-equation-a-case-study":{},"Chap_7.html#the-langevin-velocity-equation":{},"Chap_8.html":{},"Chap_8.html#example-filtering-noise":{},"Chap_9.html":{},"Chap_9.html#the-classic-example":{}},"title":{"Chap_5.html#example-white-noise":{}}}],["whole",{"_index":254,"text":{"Chap_1.html":{},"Chap_1.html#enhanced-experience":{},"Chap_11.html":{},"Chap_11.html#laboratory-exercise-113":{}},"title":{}}],["wholli",{"_index":1974,"text":{"Chap_3.html":{},"Chap_3.html#problem-35":{}},"title":{}}],["whose",{"_index":1186,"text":{"Chap_11.html":{},"Chap_11.html#problem-115":{},"Chap_12.html":{},"Chap_12.html#spectral-estimation":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_7.html":{},"Chap_7.html#expected-value":{},"Chap_7.html#how-big-is-big-how-small-is-small":{},"Chap_7.html#impulse-invariant-sampling":{},"Chap_7.html#problem-73":{},"Chap_8.html":{},"Chap_8.html#problem-83":{},"Chap_8.html#snr-for-random-signals-in-the-presence-of-noise":{},"Chap_9.html":{},"Chap_9.html#problem-91":{}},"title":{}}],["why?\u2014w",{"_index":1413,"text":{"Chap_12.html":{},"Chap_12.html#the-periodogram-what-about-convergence":{}},"title":{}}],["wide",{"_index":1348,"text":{"Chap_12.html":{},"Chap_12.html#windowed-observations":{},"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{}},"title":{}}],["wider",{"_index":1345,"text":{"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#windowed-observations":{}},"title":{}}],["width",{"_index":1019,"text":{"Chap_11.html":{},"Chap_11.html#estimating-the-autocorrelation-function":{},"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#problem-121":{},"Chap_12.html#windowed-observations":{},"Chap_3.html":{},"Chap_3.html#problem-310":{},"Chap_3.html#problem-35":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function_1":{},"Chap_7.html#power-spectral-density_1":{}},"title":{}}],["wiener",{"_index":268,"text":{"Chap_10.html":{},"Chap_10.html#classic-example-classic-result":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#laboratory-exercise-101":{},"Chap_10.html#laboratory-exercise-103":{},"Chap_10.html#laboratory-exercise-105":{},"Chap_10.html#the-more-general-restoration-case-noise-distortion":{},"Chap_10.html#the-wiener-hopf-equation":{},"Chap_10.html#why-we-avoid-the-inverse-filter":{},"Chap_5.html":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{}},"title":{"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#the-wiener-filter":{},"Chap_10.html#the-wiener-hopf-equation":{}}}],["wiertz",{"_index":3404,"text":{"Chap_7.html":{},"Chap_7.html#problem-711":{}},"title":{}}],["wiley",{"_index":789,"text":{"Chap_10.html":{},"Chap_10.html#laboratory-exercise-105":{},"Chap_11.html":{},"Chap_11.html#laboratory-exercise-113":{},"Chap_13.html":{},"Chap_13.html#epilogue":{},"Chap_7.html":{},"Chap_7.html#problem-711":{},"Chap_9.html":{},"Chap_9.html#laboratory-exercise-93":{}},"title":{}}],["willski",{"_index":2045,"text":{"Chap_3.html":{},"Chap_3.html#problem-310":{},"Chap_5.html":{},"Chap_5.html#laboratory-exercise-51":{},"Chap_7.html":{},"Chap_7.html#problem-711":{}},"title":{}}],["wind",{"_index":1767,"text":{"Chap_2.html":{},"Chap_2.html#prologue":{}},"title":{}}],["window",{"_index":895,"text":{"Chap_11.html":{},"Chap_11.html#example-estimating-the-poisson-rate":{},"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#laboratory-exercise-123":{},"Chap_12.html#laboratory-exercise-124":{},"Chap_12.html#other-windows":{},"Chap_12.html#problem-121":{},"Chap_12.html#problem-122":{},"Chap_12.html#windowed-observations":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function_1":{},"Chap_7.html#power-spectral-density_1":{},"Chap_8.html":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{},"info.html":{},"info.html#tips-short-cuts":{}},"title":{"Chap_12.html#a-family-of-windows":{},"Chap_12.html#other-windows":{},"Chap_12.html#windowed-observations":{}}}],["windows/android/linux",{"_index":3649,"text":{"info.html":{},"info.html#tips-short-cuts":{}},"title":{}}],["window\u2019",{"_index":1363,"text":{"Chap_12.html":{},"Chap_12.html#windowed-observations":{}},"title":{}}],["wiri",{"_index":3708,"text":{"info.html":{},"info.html#technical-details":{}},"title":{}}],["wish",{"_index":291,"text":{"Chap_10.html":{},"Chap_10.html#the-restoration-case-noise":{},"Chap_11.html":{},"Chap_11.html#problem-113":{},"Chap_11.html#problem-117":{},"Chap_11.html#problem-118":{},"Chap_11.html#problem-119":{},"Chap_13.html":{},"Chap_13.html#appendix-i-mean-square-error-minimization":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_4.html":{},"Chap_4.html#describing-the-time-average":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_8.html":{},"Chap_8.html#problem-83":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{},"Chap_9.html":{},"Chap_9.html#the-matched-filter":{}},"title":{}}],["within",{"_index":132,"text":{"Chap_1.html":{},"Chap_1.html#getting-around":{},"Chap_4.html":{},"Chap_4.html#laboratory-exercise-42":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_6.html":{},"Chap_6.html#the-autocorrelation-function":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_7.html":{},"Chap_7.html#tethered-particle-motion":{}},"title":{}}],["without",{"_index":1199,"text":{"Chap_11.html":{},"Chap_11.html#problem-117":{},"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_3.html":{},"Chap_3.html#what-is-a-random-signal":{},"Chap_4.html":{},"Chap_4.html#problem-49":{},"info.html":{},"info.html#usage":{}},"title":{}}],["with}\\nolimit",{"_index":2765,"text":{"Chap_6.html":{},"Chap_6.html#problem-61":{}},"title":{}}],["wive",{"_index":3692,"text":{"info.html":{},"info.html#acknowledgments":{}},"title":{}}],["wlc",{"_index":3221,"text":{"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{}},"title":{}}],["wolfram",{"_index":3695,"text":{"info.html":{},"info.html#technical-details":{}},"title":{}}],["wonder",{"_index":175,"text":{"Chap_1.html":{},"Chap_1.html#at-the-movies":{}},"title":{}}],["word",{"_index":196,"text":{"Chap_1.html":{},"Chap_1.html#enhanced-experience":{},"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_11.html#maximum-likelihood-estimation":{},"Chap_12.html":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_3.html":{},"Chap_3.html#problem-310":{},"Chap_4.html":{},"Chap_4.html#characterization-of-random-signals":{},"Chap_4.html#laboratory-exercise-42":{},"Chap_4.html#problem-44":{},"Chap_9.html":{},"Chap_9.html#laboratory-exercise-93":{},"Chap_9.html#problem-92":{},"info.html":{},"info.html#technical-details":{},"info.html#tips-short-cuts":{}},"title":{}}],["work",{"_index":223,"text":{"Chap_1.html":{},"Chap_1.html#enhanced-experience":{},"Chap_11.html":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_12.html":{},"Chap_12.html#spectral-estimation":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_3.html":{},"Chap_3.html#problem-310":{},"Chap_4.html":{},"Chap_4.html#problem-47":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function_1":{},"Chap_7.html#the-langevin-equation-a-case-study":{},"Chap_9.html":{},"Chap_9.html#performance-in-the-presence-of-noise":{},"Chap_9.html#problem-91":{},"Chap_9.html#problem-92":{},"info.html":{},"info.html#tips-short-cuts":{}},"title":{}}],["workhors",{"_index":2184,"text":{"Chap_4.html":{}},"title":{"Chap_4.html#correlation-the-workhorse":{}}}],["world",{"_index":1712,"text":{"Chap_13.html":{},"Chap_13.html#epilogue":{},"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{},"Chap_7.html":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#problem-78":{}},"title":{"Chap_6.html#example-a-world-of-random-events-a-case-study":{}}}],["world\u2019",{"_index":1784,"text":{"Chap_2.html":{},"Chap_2.html#prologue":{}},"title":{}}],["worm",{"_index":3220,"text":{"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{}},"title":{}}],["wors",{"_index":671,"text":{"Chap_10.html":{},"Chap_10.html#example-sound-of-distorted-music":{},"Chap_12.html":{},"Chap_12.html#the-periodogram-what-about-convergence":{}},"title":{}}],["wozencraft",{"_index":3624,"text":{"Chap_9.html":{},"Chap_9.html#laboratory-exercise-93":{},"Chap_9.html#problem-92":{}},"title":{}}],["write",{"_index":899,"text":{"Chap_11.html":{},"Chap_11.html#example-estimating-the-poisson-rate":{},"Chap_11.html#problem-113":{},"Chap_13.html":{},"Chap_13.html#epilogue":{},"Chap_4.html":{},"Chap_4.html#example-is-that-coin-fair":{},"Chap_4.html#laboratory-exercise-42":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_6.html":{},"Chap_6.html#interpretation-of-the-convolution-result":{},"Chap_6.html#problem-61":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function_1":{},"Chap_9.html":{},"Chap_9.html#the-matched-filter-as-an-autocorrelation":{}},"title":{}}],["written",{"_index":2125,"text":{"Chap_4.html":{},"Chap_4.html#other-averages":{},"Chap_5.html":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_7.html":{},"Chap_7.html#descriptive-statistic-variance":{},"Chap_7.html#the-langevin-equation-a-case-study":{},"info.html":{},"info.html#technical-details":{},"info.html#usage":{}},"title":{}}],["wrote",{"_index":650,"text":{"Chap_10.html":{},"Chap_10.html#example-sound-of-distorted-music":{},"Chap_12.html":{},"Chap_12.html#problem-123":{},"Chap_13.html":{},"Chap_13.html#epilogue":{},"Chap_3.html":{},"Chap_3.html#problem-310":{}},"title":{}}],["x",{"_index":382,"text":{"Chap_10.html":{},"Chap_10.html#example-cleaning-up-our-act":{},"Chap_10.html#expressing-the-mean-square-error":{},"Chap_10.html#laboratory-exercise-105":{},"Chap_11.html":{},"Chap_11.html#problem-111":{},"Chap_11.html#problem-112":{},"Chap_11.html#problem-117":{},"Chap_11.html#problem-119":{},"Chap_13.html":{},"Chap_13.html#appendix-i-mean-square-error-minimization":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_3.html#introduction":{},"Chap_3.html#problem-34":{},"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#example-average-experience":{},"Chap_4.html#example-dice-money":{},"Chap_4.html#laboratory-exercise-42":{},"Chap_4.html#other-averages":{},"Chap_4.html#problem-41":{},"Chap_4.html#problem-44":{},"Chap_4.html#problem-45":{},"Chap_4.html#problem-49":{},"Chap_4.html#properties-of-averaging":{},"Chap_5.html":{},"Chap_5.html#correlations-simple-and-complex":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#how-big-is-big-how-small-is-small":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#one-step-further":{},"Chap_7.html#problem-72":{},"info.html":{},"info.html#technical-details":{}},"title":{}}],["x(\\omega",{"_index":1228,"text":{"Chap_11.html":{},"Chap_11.html#problem-119":{},"Chap_12.html":{},"Chap_12.html#spectral-estimation":{},"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_3.html":{},"Chap_3.html#problem-31":{},"Chap_3.html#problem-32":{},"Chap_3.html#problem-33":{},"Chap_3.html#problem-38":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#example-pink-noise":{},"Chap_5.html#problem-55":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_9.html":{},"Chap_9.html#example-matching-your-filter":{},"Chap_9.html#setting-up-the-problem":{},"Chap_9.html#using-cauchy-schwartz":{}},"title":{}}],["x(\\omega)&=\\sum_{n",{"_index":1816,"text":{"Chap_3.html":{},"Chap_3.html#the-basics":{}},"title":{}}],["x(\\omega)=\\frac{1}{2}(1+\\cos^2(\\omega",{"_index":1929,"text":{"Chap_3.html":{},"Chap_3.html#problem-32":{}},"title":{}}],["x(\\omega)=\\frac{1}{\\left(1",{"_index":1923,"text":{"Chap_3.html":{},"Chap_3.html#problem-32":{}},"title":{}}],["x(\\omega)=\\left(\\frac{\\sin(5\\omega/2)}{\\sin(\\omega/2)}\\right)\\qquad",{"_index":1947,"text":{"Chap_3.html":{},"Chap_3.html#problem-33":{}},"title":{}}],["x(\\omega)=\\left(\\frac{\\sin(5\\omega/2)}{\\sin(\\omega/2)}\\right)^2",{"_index":1928,"text":{"Chap_3.html":{},"Chap_3.html#problem-32":{}},"title":{}}],["x(\\omega)=\\mathscr{f}\\left\\{x[n]\\right",{"_index":1823,"text":{"Chap_3.html":{},"Chap_3.html#the-basics":{}},"title":{}}],["x(\\omega)=x(\\omega+2\\pi",{"_index":1921,"text":{"Chap_3.html":{},"Chap_3.html#problem-32":{}},"title":{}}],["x(t",{"_index":1622,"text":{"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_4.html":{},"Chap_4.html#problem-48":{},"Chap_5.html":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_7.html":{},"Chap_7.html#from-t-to-n":{},"Chap_7.html#problem-73":{}},"title":{}}],["x(t)=\\delta(t",{"_index":2011,"text":{"Chap_3.html":{},"Chap_3.html#problem-310":{}},"title":{}}],["x[0",{"_index":3061,"text":{"Chap_7.html":{},"Chap_7.html#expected-value":{},"Chap_7.html#power-spectral-density_1":{}},"title":{}}],["x[0],x[1],x[2],...,x[m",{"_index":1396,"text":{"Chap_12.html":{},"Chap_12.html#the-periodogram-what-about-convergence":{}},"title":{}}],["x[k",{"_index":1641,"text":{"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_4.html":{},"Chap_4.html#auto-covariance":{},"Chap_6.html":{},"Chap_6.html#interpretation-of-the-convolution-result":{},"Chap_6.html#the-mean":{}},"title":{}}],["x[k]\\,\\delta",{"_index":2625,"text":{"Chap_6.html":{},"Chap_6.html#interpretation-of-the-convolution-result":{}},"title":{}}],["x[k]\\,h[n",{"_index":2627,"text":{"Chap_6.html":{},"Chap_6.html#interpretation-of-the-convolution-result":{},"Chap_6.html#the-mean":{}},"title":{}}],["x[k]{\\rm{sinc}}(t",{"_index":1658,"text":{"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{}},"title":{}}],["x[m",{"_index":2406,"text":{"Chap_5.html":{},"Chap_5.html#correlations-simple-and-complex":{},"Chap_9.html":{},"Chap_9.html#the-matched-filter-as-an-autocorrelation":{}},"title":{}}],["x[n",{"_index":286,"text":{"Chap_10.html":{},"Chap_10.html#classic-example-classic-result":{},"Chap_10.html#correlation-returns":{},"Chap_10.html#example-sound-of-distorted-music":{},"Chap_10.html#expressing-the-mean-square-error":{},"Chap_10.html#problem-103":{},"Chap_10.html#the-more-general-restoration-case-noise-distortion":{},"Chap_10.html#the-restoration-case-noise":{},"Chap_10.html#the-wiener-filter":{},"Chap_10.html#the-wiener-hopf-equation":{},"Chap_10.html#using-the-least-mean-square-error-criterion":{},"Chap_10.html#what-is-that-least-mean-square-error":{},"Chap_11.html":{},"Chap_11.html#aspects-of-estimation":{},"Chap_11.html#estimating-the-autocorrelation-function":{},"Chap_11.html#estimating-the-mean":{},"Chap_11.html#problem-118":{},"Chap_12.html":{},"Chap_12.html#spectral-estimation":{},"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_2.html":{},"Chap_2.html#problem-21":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_3.html#introduction":{},"Chap_3.html#problem-32":{},"Chap_3.html#problem-33":{},"Chap_3.html#problem-38":{},"Chap_4.html":{},"Chap_4.html#auto-covariance":{},"Chap_4.html#cross-correlation":{},"Chap_4.html#cross-covariance":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#describing-the-time-average":{},"Chap_4.html#example-dice-money":{},"Chap_4.html#example-fair-chance":{},"Chap_4.html#example-is-that-coin-fair":{},"Chap_4.html#other-averages":{},"Chap_4.html#problem-45":{},"Chap_4.html#properties-of-averaging":{},"Chap_4.html#the-ergodic-process":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#correlations-and-memory":{},"Chap_5.html#correlations-and-spectra":{},"Chap_5.html#correlations-simple-and-complex":{},"Chap_5.html#example-delayed-effect":{},"Chap_5.html#example-pink-noise":{},"Chap_5.html#fourier-description-of-correlation-functions":{},"Chap_5.html#problem-54":{},"Chap_5.html#problem-55":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_6.html":{},"Chap_6.html#filtering-of-stochastic-signals":{},"Chap_6.html#interpretation-of-the-convolution-result":{},"Chap_6.html#problem-61":{},"Chap_6.html#problem-62":{},"Chap_6.html#problem-64":{},"Chap_6.html#problem-65":{},"Chap_6.html#problem-66":{},"Chap_6.html#the-autocorrelation-function":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function_1":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#expected-value":{},"Chap_7.html#from-t-to-n":{},"Chap_7.html#the-langevin-position-equation":{},"Chap_8.html":{},"Chap_8.html#example-filtering-noise":{},"Chap_9.html":{},"Chap_9.html#example-matching-your-filter":{},"Chap_9.html#problem-92":{},"Chap_9.html#setting-up-the-problem":{},"Chap_9.html#the-matched-filter":{},"Chap_9.html#the-matched-filter-as-an-autocorrelation":{}},"title":{}}],["x[n\\rbrack",{"_index":315,"text":{"Chap_10.html":{},"Chap_10.html#the-restoration-case-noise":{},"Chap_10.html#why-we-avoid-the-inverse-filter":{},"Chap_11.html":{},"Chap_11.html#estimating-the-autocorrelation-function":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_7.html":{},"Chap_7.html#autocorrelation-function_1":{},"Chap_7.html#power-spectral-density_1":{}},"title":{}}],["x[n\\rbrack,x[k\\rbrack",{"_index":2162,"text":{"Chap_4.html":{},"Chap_4.html#example-dice-money":{}},"title":{}}],["x[n]&=\\frac{1}{2\\pi}\\int\\limits_",{"_index":1819,"text":{"Chap_3.html":{},"Chap_3.html#the-basics":{}},"title":{}}],["x[n],y[k",{"_index":2153,"text":{"Chap_4.html":{},"Chap_4.html#example-dice-money":{}},"title":{}}],["x[n]=+a",{"_index":1872,"text":{"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{}},"title":{}}],["x[n]=\\begin{cases}1&\\lvert",{"_index":1912,"text":{"Chap_3.html":{},"Chap_3.html#problem-31":{}},"title":{}}],["x[n]=\\delta[n",{"_index":1904,"text":{"Chap_3.html":{},"Chap_3.html#problem-31":{},"Chap_3.html#problem-33":{}},"title":{}}],["x[n]=\\delta[n]=\\begin{cases}1&n=0\\\\0&n\\neq",{"_index":1902,"text":{"Chap_3.html":{},"Chap_3.html#problem-31":{}},"title":{}}],["x[n]=\\delta[n]\\qquad",{"_index":1930,"text":{"Chap_3.html":{},"Chap_3.html#problem-33":{}},"title":{}}],["x[n]=\\frac{\\sin(n)}{\\pi",{"_index":1917,"text":{"Chap_3.html":{},"Chap_3.html#problem-31":{}},"title":{}}],["x[n]=\\left(\\frac{1}{2}\\right",{"_index":1909,"text":{"Chap_3.html":{},"Chap_3.html#problem-31":{}},"title":{}}],["x[n]=\\left(\\frac{1}{7}\\right)^n",{"_index":1943,"text":{"Chap_3.html":{},"Chap_3.html#problem-33":{}},"title":{}}],["x[n]=\\mathscr{f",{"_index":1824,"text":{"Chap_3.html":{},"Chap_3.html#the-basics":{}},"title":{}}],["x[n]=\\sin(\\omega_{0}n",{"_index":1907,"text":{"Chap_3.html":{},"Chap_3.html#problem-31":{}},"title":{}}],["x[n]=e",{"_index":1905,"text":{"Chap_3.html":{},"Chap_3.html#problem-31":{},"Chap_3.html#problem-33":{}},"title":{}}],["x[n]\\,w[n",{"_index":2460,"text":{"Chap_5.html":{},"Chap_5.html#a-digression":{}},"title":{}}],["x[n]\\,x[n",{"_index":1015,"text":{"Chap_11.html":{},"Chap_11.html#estimating-the-autocorrelation-function":{}},"title":{}}],["x[n]\\,y[n",{"_index":2597,"text":{"Chap_5.html":{},"Chap_5.html#problem-55":{}},"title":{}}],["x[n]\\,{x^*}[k",{"_index":2190,"text":{"Chap_4.html":{},"Chap_4.html#autocorrelation":{}},"title":{}}],["x[n]\\,{x^*}[n",{"_index":2191,"text":{"Chap_4.html":{},"Chap_4.html#autocorrelation":{},"Chap_5.html":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_6.html":{},"Chap_6.html#filtering-of-stochastic-signals":{},"Chap_6.html#problem-62":{}},"title":{}}],["x[n]\\,{y^*}[n",{"_index":2403,"text":{"Chap_5.html":{},"Chap_5.html#correlations-simple-and-complex":{},"Chap_5.html#problem-55":{},"Chap_5.html#the-mechanics-of-correlations-redux":{},"Chap_6.html":{},"Chap_6.html#filtering-of-stochastic-signals":{}},"title":{}}],["x[n]\\co",{"_index":2343,"text":{"Chap_4.html":{},"Chap_4.html#problem-45":{}},"title":{}}],["x[n]\\frac{{\\sin",{"_index":1644,"text":{"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{}},"title":{}}],["x[n]\\left",{"_index":2668,"text":{"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{}},"title":{}}],["x[n]\\rvert",{"_index":1870,"text":{"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{}},"title":{}}],["x[n]\\rvert^2",{"_index":1994,"text":{"Chap_3.html":{},"Chap_3.html#problem-38":{}},"title":{}}],["x[n]\\sum\\limits_k",{"_index":2495,"text":{"Chap_5.html":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{}},"title":{}}],["x[n]h[n",{"_index":609,"text":{"Chap_10.html":{},"Chap_10.html#the-more-general-restoration-case-noise-distortion":{}},"title":{}}],["x[n]r[n",{"_index":407,"text":{"Chap_10.html":{},"Chap_10.html#correlation-returns":{}},"title":{}}],["x[n]x[n",{"_index":548,"text":{"Chap_10.html":{},"Chap_10.html#classic-example-classic-result":{},"Chap_11.html":{},"Chap_11.html#estimating-the-autocorrelation-function":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_11.html#trouble-in-paradise":{}},"title":{}}],["x[n]y[k",{"_index":2150,"text":{"Chap_4.html":{},"Chap_4.html#example-dice-money":{}},"title":{}}],["x[n]{\\rm{sinc}}(t",{"_index":1643,"text":{"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{}},"title":{}}],["x[n]{e",{"_index":2480,"text":{"Chap_5.html":{},"Chap_5.html#a-digression":{}},"title":{}}],["x[n]{e^{j\\omega",{"_index":2497,"text":{"Chap_5.html":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{}},"title":{}}],["x[n]{x^*}[n",{"_index":815,"text":{"Chap_11.html":{},"Chap_11.html#aspects-of-estimation":{},"Chap_11.html#estimating-the-autocorrelation-function":{},"Chap_11.html#problem-118":{},"Chap_4.html":{},"Chap_4.html#cross-covariance":{},"Chap_4.html#describing-the-time-average":{},"Chap_4.html#example-is-that-coin-fair":{},"Chap_4.html#the-ergodic-process":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_5.html#correlations-and-memory":{},"Chap_5.html#correlations-simple-and-complex":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{}},"title":{}}],["x[n]{y^*}[k",{"_index":2250,"text":{"Chap_4.html":{},"Chap_4.html#cross-correlation":{}},"title":{}}],["x[n]{y^*}[n",{"_index":2251,"text":{"Chap_4.html":{},"Chap_4.html#cross-correlation":{},"Chap_4.html#cross-covariance":{},"Chap_5.html":{},"Chap_5.html#correlations-simple-and-complex":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_6.html":{},"Chap_6.html#the-cross-correlation-function":{}},"title":{}}],["x[n_0]=6\\delta[n",{"_index":1843,"text":{"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{}},"title":{}}],["x[{n_0",{"_index":3593,"text":{"Chap_9.html":{},"Chap_9.html#the-matched-filter-as-an-autocorrelation":{}},"title":{}}],["x\\,p(x[n])dx",{"_index":2171,"text":{"Chap_4.html":{},"Chap_4.html#properties-of-averaging":{}},"title":{}}],["x\\,y\\,p(x[n],y[k])dxdi",{"_index":2151,"text":{"Chap_4.html":{},"Chap_4.html#example-dice-money":{}},"title":{}}],["x\\,{p_{x[n]}}(x,n)dx",{"_index":2101,"text":{"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{}},"title":{}}],["x\\lbrack",{"_index":2447,"text":{"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_6.html":{},"Chap_6.html#interpretation-of-the-convolution-result":{},"Chap_9.html":{},"Chap_9.html#example-matching-your-filter":{}},"title":{}}],["x\\left",{"_index":2478,"text":{"Chap_5.html":{},"Chap_5.html#a-digression":{}},"title":{}}],["x\\left|\\,{\\mu",{"_index":1168,"text":{"Chap_11.html":{},"Chap_11.html#problem-112":{}},"title":{}}],["x\\leq{+\\infti",{"_index":1969,"text":{"Chap_3.html":{},"Chap_3.html#problem-34":{}},"title":{}}],["x^*}[k]\\int\\limits_",{"_index":1660,"text":{"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{}},"title":{}}],["x^*}[m]{e",{"_index":2499,"text":{"Chap_5.html":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{}},"title":{}}],["x^*}[n",{"_index":2419,"text":{"Chap_5.html":{},"Chap_5.html#correlations-and-memory":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_6.html":{},"Chap_6.html#the-autocorrelation-function":{},"Chap_6.html#the-cross-correlation-function":{}},"title":{}}],["x^2",{"_index":2133,"text":{"Chap_4.html":{},"Chap_4.html#example-dice-money":{},"Chap_4.html#example-is-that-coin-fair":{},"Chap_4.html#other-averages":{},"Chap_7.html":{},"Chap_7.html#descriptive-statistic-variance":{},"Chap_7.html#one-step-further":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#problem-711":{}},"title":{}}],["x^2/2}&x\\geq",{"_index":1971,"text":{"Chap_3.html":{},"Chap_3.html#problem-34":{}},"title":{}}],["x^2}[n",{"_index":507,"text":{"Chap_10.html":{},"Chap_10.html#what-is-that-least-mean-square-error":{},"Chap_4.html":{},"Chap_4.html#example-is-that-coin-fair":{},"Chap_4.html#other-averages":{},"Chap_4.html#properties-of-averaging":{}},"title":{}}],["x^2}p(x)dx",{"_index":2134,"text":{"Chap_4.html":{},"Chap_4.html#other-averages":{}},"title":{}}],["x^2}p(x[n])dx",{"_index":2128,"text":{"Chap_4.html":{},"Chap_4.html#other-averages":{}},"title":{}}],["x_1",{"_index":2174,"text":{"Chap_4.html":{},"Chap_4.html#properties-of-averaging":{}},"title":{}}],["x_1[n",{"_index":1856,"text":{"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{}},"title":{}}],["x_1},{x_2},...,{x_n",{"_index":1171,"text":{"Chap_11.html":{},"Chap_11.html#problem-112":{}},"title":{}}],["x_1},{x_2},{x_3},\\,...\\,,{x_n}|\\theta",{"_index":867,"text":{"Chap_11.html":{},"Chap_11.html#maximum-likelihood-estimation":{}},"title":{}}],["x_1},{x_2},{x_3},\\,...\\,,{x_n}|{\\theta",{"_index":877,"text":{"Chap_11.html":{},"Chap_11.html#maximum-likelihood-estimation":{}},"title":{}}],["x_1}[n",{"_index":3057,"text":{"Chap_7.html":{},"Chap_7.html#expected-value":{}},"title":{}}],["x_2",{"_index":2175,"text":{"Chap_4.html":{},"Chap_4.html#properties-of-averaging":{}},"title":{}}],["x_2[n",{"_index":1857,"text":{"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{}},"title":{}}],["x_3[n",{"_index":1858,"text":{"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{}},"title":{}}],["x_4[n",{"_index":1859,"text":{"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{}},"title":{}}],["x_e",{"_index":381,"text":{"Chap_10.html":{},"Chap_10.html#expressing-the-mean-square-error":{},"Chap_13.html":{},"Chap_13.html#appendix-i-mean-square-error-minimization":{}},"title":{}}],["x_e[n",{"_index":1995,"text":{"Chap_3.html":{},"Chap_3.html#problem-38":{}},"title":{}}],["x_e[n]=x_",{"_index":1986,"text":{"Chap_3.html":{},"Chap_3.html#problem-38":{}},"title":{}}],["x_e[n]\\cos(\\omega",{"_index":1996,"text":{"Chap_3.html":{},"Chap_3.html#problem-38":{}},"title":{}}],["x_e[n]\\sin(\\omega",{"_index":1997,"text":{"Chap_3.html":{},"Chap_3.html#problem-38":{}},"title":{}}],["x_e^2[n",{"_index":508,"text":{"Chap_10.html":{},"Chap_10.html#what-is-that-least-mean-square-error":{}},"title":{}}],["x_e}[n",{"_index":294,"text":{"Chap_10.html":{},"Chap_10.html#expressing-the-mean-square-error":{},"Chap_10.html#the-more-general-restoration-case-noise-distortion":{},"Chap_10.html#the-restoration-case-noise":{},"Chap_10.html#the-wiener-hopf-equation":{},"Chap_10.html#using-the-least-mean-square-error-criterion":{},"Chap_10.html#what-is-that-least-mean-square-error":{}},"title":{}}],["x_e}[n\\rbrack",{"_index":727,"text":{"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{}},"title":{}}],["x_e}[n]x[n",{"_index":509,"text":{"Chap_10.html":{},"Chap_10.html#what-is-that-least-mean-square-error":{}},"title":{}}],["x_i}p({x_i",{"_index":2120,"text":{"Chap_4.html":{},"Chap_4.html#example-average-experience":{}},"title":{}}],["x_n",{"_index":1206,"text":{"Chap_11.html":{},"Chap_11.html#problem-117":{}},"title":{}}],["x_o",{"_index":1988,"text":{"Chap_3.html":{},"Chap_3.html#problem-38":{}},"title":{}}],["x_o[n",{"_index":1987,"text":{"Chap_3.html":{},"Chap_3.html#problem-38":{}},"title":{}}],["x_o[n=0",{"_index":1990,"text":{"Chap_3.html":{},"Chap_3.html#problem-38":{}},"title":{}}],["x_o[n]\\cos(\\omega",{"_index":1998,"text":{"Chap_3.html":{},"Chap_3.html#problem-38":{}},"title":{}}],["x_o[n]\\sin(\\omega",{"_index":1999,"text":{"Chap_3.html":{},"Chap_3.html#problem-38":{}},"title":{}}],["y",{"_index":783,"text":{"Chap_10.html":{},"Chap_10.html#laboratory-exercise-105":{},"Chap_13.html":{},"Chap_13.html#epilogue":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_4.html":{},"Chap_4.html#problem-44":{},"Chap_4.html#problem-45":{},"Chap_5.html":{},"Chap_5.html#correlations-simple-and-complex":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_7.html":{},"Chap_7.html#one-step-further":{},"Chap_7.html#problem-711":{},"Chap_7.html#problem-72":{}},"title":{}}],["y'(t",{"_index":1668,"text":{"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_13.html#epilogue":{}},"title":{}}],["y(\\omega",{"_index":1651,"text":{"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_3.html":{},"Chap_3.html#problem-33":{},"Chap_5.html":{},"Chap_5.html#problem-55":{}},"title":{}}],["y(\\omega)=x(\\omega)h(\\omega",{"_index":1812,"text":{"Chap_3.html":{},"Chap_3.html#introduction":{}},"title":{}}],["y(t",{"_index":1639,"text":{"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_7.html":{},"Chap_7.html#problem-73":{}},"title":{}}],["y(t)=h(t",{"_index":2012,"text":{"Chap_3.html":{},"Chap_3.html#problem-310":{}},"title":{}}],["y.w",{"_index":1716,"text":{"Chap_13.html":{},"Chap_13.html#epilogue":{}},"title":{}}],["y[k",{"_index":2147,"text":{"Chap_4.html":{},"Chap_4.html#cross-correlation":{},"Chap_4.html#cross-covariance":{},"Chap_4.html#example-dice-money":{}},"title":{}}],["y[m]\\,{x^*}[m",{"_index":2408,"text":{"Chap_5.html":{},"Chap_5.html#correlations-simple-and-complex":{}},"title":{}}],["y[n",{"_index":667,"text":{"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{},"Chap_10.html#example-cleaning-up-our-act":{},"Chap_10.html#example-sound-of-distorted-music":{},"Chap_11.html":{},"Chap_11.html#problem-118":{},"Chap_3.html":{},"Chap_3.html#introduction":{},"Chap_3.html#problem-33":{},"Chap_4.html":{},"Chap_4.html#example-dice-money":{},"Chap_4.html#problem-45":{},"Chap_4.html#properties-of-averaging":{},"Chap_5.html":{},"Chap_5.html#correlations-and-spectra":{},"Chap_5.html#example-delayed-effect":{},"Chap_5.html#problem-55":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{},"Chap_6.html":{},"Chap_6.html#interpretation-of-the-convolution-result":{},"Chap_6.html#problem-61":{},"Chap_6.html#problem-62":{},"Chap_6.html#problem-65":{},"Chap_6.html#the-cross-correlation-function":{},"Chap_6.html#the-mean":{},"Chap_8.html":{},"Chap_8.html#example-filtering-noise":{},"Chap_8.html#snr-for-deterministic-signals-in-the-presence-of-noise":{},"Chap_8.html#snr-for-random-signals-in-the-presence-of-noise":{},"Chap_9.html":{},"Chap_9.html#problem-92":{},"Chap_9.html#the-matched-filter":{}},"title":{}}],["y[n\\rbrack",{"_index":631,"text":{"Chap_10.html":{},"Chap_10.html#example-cleaning-up-our-act":{},"Chap_10.html#why-we-avoid-the-inverse-filter":{}},"title":{}}],["y[n]\\,{y^*}[n",{"_index":2412,"text":{"Chap_5.html":{},"Chap_5.html#example-delayed-effect":{},"Chap_6.html":{},"Chap_6.html#problem-61":{},"Chap_6.html#problem-62":{}},"title":{}}],["y[n]x[n",{"_index":691,"text":{"Chap_10.html":{},"Chap_10.html#determining-the-wiener-filter":{}},"title":{}}],["y[n]{y^*}[n",{"_index":2647,"text":{"Chap_6.html":{},"Chap_6.html#the-autocorrelation-function":{}},"title":{}}],["y\\lbrack",{"_index":2630,"text":{"Chap_6.html":{},"Chap_6.html#interpretation-of-the-convolution-result":{}},"title":{}}],["y\\left",{"_index":1689,"text":{"Chap_13.html":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{}},"title":{}}],["y^*}(\\omega",{"_index":2524,"text":{"Chap_5.html":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{}},"title":{}}],["y^*}[m]{e",{"_index":2521,"text":{"Chap_5.html":{},"Chap_5.html#the-power-density-spectrum-and-its-properties":{}},"title":{}}],["y^2",{"_index":3356,"text":{"Chap_7.html":{},"Chap_7.html#one-step-further":{}},"title":{}}],["y_0}[n",{"_index":3448,"text":{"Chap_8.html":{},"Chap_8.html#snr-for-random-signals-in-the-presence-of-noise":{}},"title":{}}],["y_1(t",{"_index":2019,"text":{"Chap_3.html":{},"Chap_3.html#problem-310":{}},"title":{}}],["y_2(t",{"_index":2020,"text":{"Chap_3.html":{},"Chap_3.html#problem-310":{}},"title":{}}],["y_3(t",{"_index":2021,"text":{"Chap_3.html":{},"Chap_3.html#problem-310":{}},"title":{}}],["y_c",{"_index":2027,"text":{"Chap_3.html":{},"Chap_3.html#problem-310":{}},"title":{}}],["y_c)^2y(t)dt}{\\int\\limits_",{"_index":2035,"text":{"Chap_3.html":{},"Chap_3.html#problem-310":{}},"title":{}}],["y_c=\\frac{\\int\\limits_",{"_index":2029,"text":{"Chap_3.html":{},"Chap_3.html#problem-310":{}},"title":{}}],["y_n(t",{"_index":2036,"text":{"Chap_3.html":{},"Chap_3.html#problem-310":{}},"title":{}}],["y_n}[n",{"_index":3553,"text":{"Chap_9.html":{},"Chap_9.html#setting-up-the-problem":{},"Chap_9.html#the-matched-filter":{}},"title":{}}],["y_n}[{n_0",{"_index":3559,"text":{"Chap_9.html":{},"Chap_9.html#setting-up-the-problem":{}},"title":{}}],["y_x}[n",{"_index":3552,"text":{"Chap_9.html":{},"Chap_9.html#example-matching-your-filter":{},"Chap_9.html#setting-up-the-problem":{},"Chap_9.html#the-matched-filter":{},"Chap_9.html#the-matched-filter-as-an-autocorrelation":{}},"title":{}}],["y_x}[{n_0",{"_index":3562,"text":{"Chap_9.html":{},"Chap_9.html#setting-up-the-problem":{},"Chap_9.html#using-cauchy-schwartz":{}},"title":{}}],["y_{100}(t",{"_index":2022,"text":{"Chap_3.html":{},"Chap_3.html#problem-310":{}},"title":{}}],["y_{ij}}[n",{"_index":3601,"text":{"Chap_9.html":{},"Chap_9.html#problem-91":{}},"title":{}}],["y_{rm",{"_index":2032,"text":{"Chap_3.html":{},"Chap_3.html#problem-310":{}},"title":{}}],["y_{rms}=\\sqrt{\\frac{\\int\\limits_",{"_index":2033,"text":{"Chap_3.html":{},"Chap_3.html#problem-310":{}},"title":{}}],["ye",{"_index":2024,"text":{"Chap_3.html":{},"Chap_3.html#problem-310":{}},"title":{}}],["year",{"_index":2116,"text":{"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{},"Chap_6.html":{},"Chap_6.html#example-a-world-of-random-events-a-case-study":{},"Chap_7.html":{},"Chap_7.html#tethered-particle-motion":{},"Chap_8.html":{},"Chap_8.html#problem-82":{},"info.html":{},"info.html#acknowledgments":{}},"title":{}}],["yearli",{"_index":2575,"text":{"Chap_5.html":{},"Chap_5.html#predicting-the-natural-climate-a-case-study":{}},"title":{}}],["yellow",{"_index":96,"text":{"Chap_1.html":{},"Chap_1.html#highlighting":{}},"title":{}}],["yesterday",{"_index":2114,"text":{"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_5.html":{},"Chap_5.html#correlations-and-memory":{}},"title":{}}],["yield",{"_index":369,"text":{"Chap_10.html":{},"Chap_10.html#using-the-least-mean-square-error-criterion":{},"Chap_10.html#what-is-that-least-mean-square-error":{},"Chap_11.html":{},"Chap_11.html#langevin-redux":{},"Chap_11.html#problem-117":{},"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#windowed-observations":{},"Chap_13.html":{},"Chap_13.html#epilogue":{},"Chap_4.html":{},"Chap_4.html#the-mechanics-of-correlations":{},"Chap_5.html":{},"Chap_5.html#a-digression":{},"Chap_6.html":{},"Chap_6.html#problem-64":{},"Chap_6.html#the-autocorrelation-function":{},"Chap_7.html":{},"Chap_7.html#how-big-is-big-how-small-is-small-redux":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#tethered-particle-motion":{},"Chap_7.html#the-langevin-position-equation":{},"Chap_7.html#the-langevin-velocity-equation":{},"Chap_8.html":{},"Chap_8.html#snr-for-random-signals-in-the-presence-of-noise":{},"Chap_9.html":{},"Chap_9.html#the-classic-example":{}},"title":{}}],["york",{"_index":787,"text":{"Chap_10.html":{},"Chap_10.html#laboratory-exercise-105":{},"Chap_13.html":{},"Chap_13.html#epilogue":{},"Chap_3.html":{},"Chap_3.html#problem-310":{},"Chap_5.html":{},"Chap_5.html#laboratory-exercise-51":{},"Chap_7.html":{},"Chap_7.html#problem-711":{},"Chap_9.html":{},"Chap_9.html#laboratory-exercise-93":{}},"title":{}}],["young",{"_index":1726,"text":{"Chap_13.html":{},"Chap_13.html#epilogue":{},"Chap_7.html":{},"Chap_7.html#problem-711":{},"info.html":{},"info.html#authors":{}},"title":{}}],["z",{"_index":2108,"text":{"Chap_4.html":{},"Chap_4.html#describing-the-ensemble-average":{},"Chap_4.html#problem-49":{},"Chap_7.html":{},"Chap_7.html#choosing-the-sampling-period_1":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#expected-value":{},"Chap_7.html#how-big-is-big-how-small-is-small":{},"Chap_7.html#impulse-invariant-sampling":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#the-langevin-position-equation":{}},"title":{}}],["z(\\omega",{"_index":3566,"text":{"Chap_9.html":{},"Chap_9.html#laboratory-exercise-93":{},"Chap_9.html#using-cauchy-schwartz":{}},"title":{}}],["zero",{"_index":540,"text":{"Chap_10.html":{},"Chap_10.html#classic-example-classic-result":{},"Chap_10.html#example-cleaning-up-our-act":{},"Chap_10.html#example-sound-of-distorted-music":{},"Chap_10.html#problem-103":{},"Chap_10.html#the-more-general-restoration-case-noise-distortion":{},"Chap_10.html#why-we-avoid-the-inverse-filter":{},"Chap_11.html":{},"Chap_11.html#but-is-it-a-good-estimate":{},"Chap_11.html#estimating-the-mean":{},"Chap_11.html#example-estimating-the-poisson-rate":{},"Chap_11.html#how-good-is-our-estimator":{},"Chap_11.html#trouble-in-paradise":{},"Chap_12.html":{},"Chap_12.html#a-family-of-windows":{},"Chap_12.html#problem-122":{},"Chap_12.html#the-periodogram-what-about-convergence":{},"Chap_13.html":{},"Chap_13.html#appendix-i-mean-square-error-minimization":{},"Chap_13.html#appendix-ii-the-discrete-time-uncertainty-principle":{},"Chap_3.html":{},"Chap_3.html#example-dont-bet-on-it":{},"Chap_4.html":{},"Chap_4.html#example-is-that-coin-fair":{},"Chap_7.html":{},"Chap_7.html#descriptive-statistics-mean-and-standard-deviation":{},"Chap_7.html#expected-value":{},"Chap_7.html#expected-value_1":{},"Chap_7.html#power-spectral-density_1":{},"Chap_7.html#the-langevin-equation-a-case-study":{},"Chap_7.html#the-langevin-velocity-equation":{},"Chap_8.html":{},"Chap_8.html#example-not-too-noisy":{},"Chap_8.html#snr-for-random-signals-in-the-presence-of-noise":{},"Chap_8.html#snr-for-signals-and-systems-with-poisson-noise":{},"Chap_9.html":{},"Chap_9.html#problem-91":{},"Chap_9.html#setting-up-the-problem":{}},"title":{}}],["zhao",{"_index":3690,"text":{"info.html":{},"info.html#acknowledgments":{}},"title":{}}],["zoom",{"_index":3657,"text":{"info.html":{},"info.html#tips-short-cuts":{}},"title":{}}]],"pipeline":["stemmer"],"version":"2.3.8"}}; var search = { index: new Promise(resolve => setTimeout(() => resolve(local_index), 200)) }